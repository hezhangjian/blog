[{"title":"Palantir Foundry技术演进：从定制代码到AIP智能决策","url":"/2025/10/10/Palantir%20Foundry%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%EF%BC%9A%E4%BB%8E%E5%AE%9A%E5%88%B6%E4%BB%A3%E7%A0%81%E5%88%B0AIP%E6%99%BA%E8%83%BD%E5%86%B3%E7%AD%96/","content":"TLDR笔者推测Palantir起初以支持定制代码运行为基础，在构筑自己部署平台（Apollo，Palantir GitHub上也有很多开发者构建、Lint工具）的同时，逐渐抽象出Dataset、本体、Function、Action API，打造了坚实的Foundry平台，让应用从定制化开发逐步“长在平台上”。最终，Palantir 推出人工智能平台（AIP），实现数据驱动的智能决策。\n前言近年来，Palantir 无疑成为数据分析领域的焦点之一。作为一家以解决复杂问题为核心的公司，Palantir 为政府、国防和企业客户提供了强大的数据整合与分析能力。Palantir 的核心产品 Foundry 是一个面向数据整合与分析的平台，它如何从最初的定制化开发逐渐演变为如今的通用数据智能平台？笔者尝试基于公开资源推测梳理 Palantir Foundry技术平台的演进路线，分享一些分析与推测。本文仅代表个人观点，欢迎读者交流探讨。\n阶段0 定制代码运行从Palantir的Offering来看，其核心始终是为客户解决复杂问题，拥有大量的FDE。合理推测Palantir最早其实以定制代码运行交付作为基础，通过高度定制化的软件开发满足客户在政府、国防和企业领域的特定需求。阶段0，此时都处于定制开发状态。\n阶段1 从定制代码运行到Palantir平台运行正如《人月神话》中所说，优秀的程序员都会有自己的library库，优秀的定制开发商也倾向于提炼可复用的技术框架。\n对于定制代码来说，我们把定制代码分为编写态和运行态\n\n编写态，对应Palantir Code Repositories，可以看到Palantir的很多东西，其实跟Git很相似，有分支、合并等等。\n运行态，将Palantir Code Repositories的代码构建运行，支持多种触发方式，比如通过API调用来执行，定时执行等。Apollo 平台进一步支持多环境部署（如云和边缘）。\n\n阶段2 数据的平台化存储和管理当开发工作逐渐迁移到 Palantir 平台后，数据的存储和管理成为下一个重点。如果代码已经运行在平台上，那么数据为什么不能也存储在平台中呢？\nPalantir 在这一阶段引入了 Dataset 和本体（Ontology）模型，构建了平台化的数据管理能力。Dataset 作为数据的核心容器，支持结构化和非结构化数据的存储；本体则定义了数据之间的语义关系，为数据提供了更高级的抽象层。此外，Palantir 接入了时序数据库，增加了对时间序列数据的支持，满足了金融、工业等领域对实时数据处理的需求。\n同时，也把数据集的变更增加为一个触发条件。例如，当某个 Dataset 发生变化时，平台可以自动触发预定义的操作，如运行一段代码或更新其他数据集。\n\n阶段3 抽象Action Function在本体已经定义了DataSet以及数据集之间关系的基础上，通过Action、Function的定义，同时Action、Function可以通过拖拉拽简单地生成，无需书写代码。对于难以无码的复杂逻辑，还可以通过定制代码来书写。\n其实Workflow和Pipeline都是在更高层次、更简便地操作代码的手段而存在，底层实现上：\n\nPipeline &#x3D; Datasets+Builds+Schedules\nWorkflow &#x3D; Schedules + Builds + Jobs\n\n\n阶段 4：AIP 的智能决策赋能在Foundry坚实的基础上，Palantir 2023 年推出了 AIP（人工智能平台）整合大语言模型（LLM）与 Foundry 数据，自动化复杂决策。其核心功能包括：\n\n自然语言处理：用户通过对话界面查询数据或生成分析，如“预测下季度库存需求”。\n自动化工作流：基于 Ontology，AIP 驱动智能决策，例如优化供应链或调度资源。\n实时推理：结合时序数据，AIP 支持动态预测，如医疗资源分配或工业故障检测。\n\n总结图：笔者设想的企业使用Foundry路线图\n本文分析了Palantir Foundry的技术实现路径，笔者认为Palantir Foundry 的技术演进展现了一个从“定制”到“平台原生”的清晰路径。应用从分散的定制代码，逐步迁移到平台上运行，扎根于平台的数据和触发机制，最终成为完全依赖平台功能的原生应用。\n","tags":["Palantir"]},{"title":"Calcite Parser代码生成详解","url":"/2022/09/26/Calcite%20Parser%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90%E8%AF%A6%E8%A7%A3/","content":"本文代码均已上传到giteecalcite的parser代码生成分为如下两个步骤  \n  \n生成Parse.jj文件目录如下\n├── pom.xml└── src    ├── main    │   ├── codegen    │   │   ├── config.fmpp    │   │   ├── includes    │   │   │   ├── compoundIdentifier.ftl    │   │   │   └── parserImpls.ftl    │   │   └── templates    │   │       └── Parser.jj\n\n添加calcite dependency\n&lt;dependency&gt;    &lt;groupId&gt;org.apache.calcite&lt;/groupId&gt;    &lt;artifactId&gt;calcite-core&lt;/artifactId&gt;&lt;/dependency&gt;\n\n\n\n配置drill-fmpp-maven-plugin插件如下\n&lt;plugin&gt;    &lt;groupId&gt;org.apache.drill.tools&lt;/groupId&gt;    &lt;artifactId&gt;drill-fmpp-maven-plugin&lt;/artifactId&gt;    &lt;executions&gt;        &lt;execution&gt;            &lt;configuration&gt;                &lt;config&gt;src/main/codegen/config.fmpp&lt;/config&gt;                &lt;output&gt;$&#123;project.build.directory&#125;/generated-sources/fmpp&lt;/output&gt;                &lt;templates&gt;src/main/codegen/templates&lt;/templates&gt;            &lt;/configuration&gt;            &lt;id&gt;generate-fmpp-sources&lt;/id&gt;            &lt;phase&gt;validate&lt;/phase&gt;            &lt;goals&gt;                &lt;goal&gt;generate&lt;/goal&gt;            &lt;/goals&gt;        &lt;/execution&gt;    &lt;/executions&gt;&lt;/plugin&gt;\n\ncodegen 模块的文件都拷贝自对应版本的calclite core&#x2F;src&#x2F;main&#x2F;codegen路径 https://github.com/apache/calcite/tree/main/core/src/main/codegen\n然后把https://github.com/apache/calcite/blob/main/core/src/main/codegen/default_config.fmpp 中的parser属性与config.fmpp中的parser属性合并。就可以通过mvn package命令生成Parser.jj了。当然，如果有定制化修改的需求，也可以在这个阶段修改config.fmpp  \n  \nParser.jj生成java代码文件目录如下\n├── pom.xml├── src│   ├── main│   │   ├── codegen│   │   │   └── Parser.jj\n\nParser.jj就是我们上一步生成的Parser.jj，如果有什么想要的定制化修改，也可以在这个步骤改入到Parser.jj中。\n添加calcite dependency\n&lt;dependency&gt;    &lt;groupId&gt;org.apache.calcite&lt;/groupId&gt;    &lt;artifactId&gt;calcite-core&lt;/artifactId&gt;&lt;/dependency&gt;\n\n配置javacc-maven-plugin如下\n&lt;plugin&gt;    &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt;    &lt;artifactId&gt;javacc-maven-plugin&lt;/artifactId&gt;    &lt;executions&gt;        &lt;execution&gt;            &lt;id&gt;javacc&lt;/id&gt;            &lt;goals&gt;                &lt;goal&gt;javacc&lt;/goal&gt;            &lt;/goals&gt;            &lt;configuration&gt;                &lt;sourceDirectory&gt;$&#123;project.basedir&#125;/src/main/codegen&lt;/sourceDirectory&gt;                &lt;includes&gt;                    &lt;include&gt;**/Parser.jj&lt;/include&gt;                &lt;/includes&gt;            &lt;/configuration&gt;        &lt;/execution&gt;    &lt;/executions&gt;&lt;/plugin&gt;\n\n生成代码  \n  \n无Parser.jj定制化修改，一步生成无Parser.jj定制化修改，一步生成如果不需要对Parser.jj进行定制化修改，那么可以通过连续运行两个插件来生成代码，这里给出pom文件样例，不再赘述\n&lt;plugin&gt;    &lt;groupId&gt;org.apache.drill.tools&lt;/groupId&gt;    &lt;artifactId&gt;drill-fmpp-maven-plugin&lt;/artifactId&gt;    &lt;executions&gt;        &lt;execution&gt;            &lt;configuration&gt;                &lt;config&gt;src/main/codegen/config.fmpp&lt;/config&gt;                &lt;output&gt;$&#123;project.build.directory&#125;/generated-sources/fmpp&lt;/output&gt;                &lt;templates&gt;src/main/codegen/templates&lt;/templates&gt;            &lt;/configuration&gt;            &lt;id&gt;generate-fmpp-sources&lt;/id&gt;            &lt;phase&gt;validate&lt;/phase&gt;            &lt;goals&gt;                &lt;goal&gt;generate&lt;/goal&gt;            &lt;/goals&gt;        &lt;/execution&gt;    &lt;/executions&gt;&lt;/plugin&gt;&lt;plugin&gt;    &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt;    &lt;artifactId&gt;javacc-maven-plugin&lt;/artifactId&gt;    &lt;executions&gt;        &lt;execution&gt;            &lt;id&gt;javacc&lt;/id&gt;            &lt;goals&gt;                &lt;goal&gt;javacc&lt;/goal&gt;            &lt;/goals&gt;            &lt;configuration&gt;                &lt;sourceDirectory&gt;$&#123;project.build.directory&#125;/generated-sources/fmpp&lt;/sourceDirectory&gt;                &lt;includes&gt;                    &lt;include&gt;**/Parser.jj&lt;/include&gt;                &lt;/includes&gt;                &lt;lookAhead&gt;2&lt;/lookAhead&gt;                &lt;isStatic&gt;false&lt;/isStatic&gt;            &lt;/configuration&gt;        &lt;/execution&gt;        &lt;execution&gt;            &lt;id&gt;javacc-test&lt;/id&gt;            &lt;phase&gt;generate-test-sources&lt;/phase&gt;            &lt;goals&gt;                &lt;goal&gt;javacc&lt;/goal&gt;            &lt;/goals&gt;            &lt;configuration&gt;                &lt;sourceDirectory&gt;$&#123;project.build.directory&#125;/generated-test-sources/fmpp&lt;/sourceDirectory&gt;                &lt;outputDirectory&gt;$&#123;project.build.directory&#125;/generated-test-sources/javacc&lt;/outputDirectory&gt;                &lt;includes&gt;                    &lt;include&gt;**/Parser.jj&lt;/include&gt;                &lt;/includes&gt;                &lt;isStatic&gt;false&lt;/isStatic&gt;                &lt;ignoreCase&gt;true&lt;/ignoreCase&gt;                &lt;unicodeInput&gt;true&lt;/unicodeInput&gt;            &lt;/configuration&gt;        &lt;/execution&gt;    &lt;/executions&gt;&lt;/plugin&gt;\n"},{"title":"Java DefaultUncaughtExceptionHandler 详解","url":"/2023/06/15/java%20DefaultUncaughtExceptionHandler%20%E8%AF%A6%E8%A7%A3/","content":"在Java程序运行时，一些非受检异常可能会导致程序崩溃，比如NullPointerException、ArrayIndexOutOfBoundsException等等，这些异常都是由JVM抛出的，如果不对这些异常进行处理，小则线程运行中突然退出，大则整个程序崩溃。理想的场景下，每一个非受检异常都应该被捕获并进行处理，但是在实际开发中，我们往往会忽略一些异常，这些异常可能是由于程序员的疏忽导致的，也可能是由于程序员无法预知的原因导致的，比如第三方库抛出的异常。\n为了避免这些异常导致程序崩溃，Java提供了一个全局的异常处理器，即DefaultUncaughtExceptionHandler，它可以捕获所有未被捕获的异常，从而避免程序崩溃。\nDefaultUncaught的使用示例如下：\npublic class UncaughtExceptionHandle &#123;    public static void main(String[] args) &#123;        Thread.setDefaultUncaughtExceptionHandler((t, e) -&gt; log.error(&quot;Uncaught exception: &quot;, e));    &#125;&#125;\n\n上述的代码会将未捕获的异常打印到日志中，如果你希望打印至标准输出或标准输出，可以将log替换为：\n// 标准输出System.out.println(&quot;Uncaught exception: &quot; + e);// 错误输出System.err.println(&quot;Uncaught exception: &quot; + e);\n","tags":["Java"]},{"title":"jetty servlet的代码字符集选择","url":"/2023/06/02/jetty%20servlet%E7%9A%84%E7%BC%96%E7%A0%81%E5%AD%97%E7%AC%A6%E9%9B%86%E9%80%89%E6%8B%A9/","content":"记一次中文指标乱码问题，问题也很简单，如下图所示：\n\n从metricbeat开始找原因，发现其实只要是UTF-8的编码格式就都可以解析，最终发现是webServer返回的数据非UTF-8格式，修改方案也很简单。将servlet中的content-type里面的text&#x2F;plain修改成text&#x2F;plain; charset&#x3D;utf-8就可以了，如下面代码所示:\nprotected void doGet(HttpServletRequest request, HttpServletResponse response)        throws IOException &#123;    response.setContentType(&quot;text/plain&quot;);    response.setStatus(HttpServletResponse.SC_OK);    response.getWriter().write(&quot;&lt;h1&gt;哈哈&lt;/h1&gt;&quot;);&#125;\n\n我们可以轻易使用一个demo来复现这个问题，在maven中添加如下依赖\n&lt;dependency&gt;    &lt;groupId&gt;org.eclipse.jetty&lt;/groupId&gt;    &lt;artifactId&gt;jetty-server&lt;/artifactId&gt;    &lt;version&gt;9.4.35.v20201120&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;org.eclipse.jetty&lt;/groupId&gt;    &lt;artifactId&gt;jetty-servlet&lt;/artifactId&gt;    &lt;version&gt;9.4.35.v20201120&lt;/version&gt;&lt;/dependency&gt;\n\npackage com.shoothzj.jetty;import org.eclipse.jetty.server.Server;import org.eclipse.jetty.servlet.ServletContextHandler;import org.eclipse.jetty.servlet.ServletHolder;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.IOException;public class SimpleJettyServer &#123;    public static void main(String[] args) throws Exception &#123;        Server server = new Server(8080);        ServletContextHandler context = new ServletContextHandler(ServletContextHandler.SESSIONS);        context.setContextPath(&quot;/&quot;);        server.setHandler(context);        context.addServlet(new ServletHolder(new HelloDefaultServlet()), &quot;/hello-default&quot;);        context.addServlet(new ServletHolder(new HelloUTF8Servlet()), &quot;/hello-utf8&quot;);        server.start();        server.join();    &#125;    public static class HelloDefaultServlet extends HttpServlet &#123;        @Override        protected void doGet(HttpServletRequest request, HttpServletResponse response)                throws IOException &#123;            response.setContentType(&quot;text/plain&quot;);            response.setStatus(HttpServletResponse.SC_OK);            response.getWriter().write(&quot;&lt;h1&gt;哈哈&lt;/h1&gt;&quot;);        &#125;    &#125;    public static class HelloUTF8Servlet extends HttpServlet &#123;        @Override        protected void doGet(HttpServletRequest request, HttpServletResponse response)                throws IOException &#123;            response.setContentType(&quot;text/plain; charset=UTF-8&quot;);            response.setStatus(HttpServletResponse.SC_OK);            response.getWriter().write(&quot;&lt;h1&gt;哈哈&lt;/h1&gt;&quot;);        &#125;    &#125;&#125;\n\n通过curl命令来复现这个问题\ncurl localhost:8080/hello-default&lt;h1&gt;??&lt;/h1&gt;%curl localhost:8080/hello-utf8&lt;h1&gt;哈哈&lt;/h1&gt;%\n\n那么servlet里面的数据如何编码，我们可以dive一下，首先servlet里面有一个函数叫**response.setCharacterEncoding();**这个函数可以指定编码格式。其次，servlet还会通过上面的setContentType函数来做一定的推断，比如content-type中携带了charset，就使用content-type中的charset。还有些特定的content-type，比如text&#x2F;json，在没有设置的情况下，servlet容器会假设它使用utf-8编码。在推断不出来，也没有手动设置的情况下，jetty默认的编码是iso-8859-1，这就解释了乱码的问题。\n"},{"title":"prometheus tsdb索引布局及查询流程","url":"/2022/07/18/prometheus%20tsdb%E7%B4%A2%E5%BC%95%E5%B8%83%E5%B1%80%E5%8F%8A%E6%9F%A5%E8%AF%A2%E6%B5%81%E7%A8%8B/","content":"prometheus 磁盘布局采集到的数据每两个小时形成一个block。每个block由一个目录组成，并存放在data路径下。该目录包含一个包含该时间窗口的所有时间序列样本的块子目录、一个元数据文件和一个索引文件（将metric_name和label索引到目录下的时间序列）。 chunks 目录中的样本默认组合成一个或多个段文件，每个段文件最大为 512MB。 当通过 API 删除系列时，删除记录存储在单独的 tombstone 文件中（而不是立即从块段中删除数据）。\n当前正在写入的块保存在内存中，没有完全持久化。通过WAL日志来防止崩溃丢失数据。预写日志分为数节(segments)保存在wal文件夹中。这些文件包含尚未压缩的原始数据； 因此它们比常规块文件大得多。 Prometheus 将至少保留三个预写日志文件。在高流量下，会保留三个以上的 WAL 文件，以便保留至少两个小时的原始数据。\n./data├── 01BKGV7JBM69T2G1BGBGM6KB12│   └── meta.json├── 01BKGTZQ1SYQJTR4PB43C8PD98│   ├── chunks│   │   └── 000001│   ├── tombstones│   ├── index│   └── meta.json├── 01BKGTZQ1HHWHV8FBJXW1Y3W0K│   └── meta.json├── 01BKGV7JC0RY8A6MACW02A2PJD│   ├── chunks│   │   └── 000001│   ├── tombstones│   ├── index│   └── meta.json├── chunks_head│   └── 000001└── wal    ├── 000000002    └── checkpoint.00000001        └── 00000000\n\nprometheus概念\nLabel: 标签，string格式的kv组合\nseries: 时间序列，label的组合\nchunk: 时间，value的数据\n\nprometheus索引格式┌────────────────────────────┬─────────────────────┐│ magic(0xBAAAD700) &lt;4b&gt;     │ version(1) &lt;1 byte&gt; │├────────────────────────────┴─────────────────────┤│ ┌──────────────────────────────────────────────┐ ││ │                 Symbol Table                 │ ││ ├──────────────────────────────────────────────┤ ││ │                    Series                    │ ││ ├──────────────────────────────────────────────┤ ││ │                   Postings 1                 │ ││ ├──────────────────────────────────────────────┤ ││ │                      ...                     │ ││ ├──────────────────────────────────────────────┤ ││ │                   Postings N                 │ ││ ├──────────────────────────────────────────────┤ ││ │             Postings Offset Table            │ ││ ├──────────────────────────────────────────────┤ ││ │                      TOC                     │ ││ └──────────────────────────────────────────────┘ │└──────────────────────────────────────────────────┘\n\n写入索引时，可以在上面列出的主要部分之间添加任意数量的0字节作为填充。顺序扫描文件时，必须跳过部分间的任意0字节。\n下面描述的大部分部分都以 len 字段开头。 它总是指定就在尾随 CRC32 校验和之前的字节数。 校验和就计算这些字节的校验和（不包含len字段）\n符号表符号表包含已存储序列的标签对中出现的重复数据删除字符串的排序列表。 它们可以从后续部分中引用，并显着减少总索引大小。\n该部分包含一系列字符串entry，每个entry都以字符串的原始字节长度为前缀。 所有字符串均采用 utf-8 编码。 字符串由顺序索引引用。 字符串按字典顺序升序排序。\n┌────────────────────┬─────────────────────┐│ len &lt;4b&gt;           │ #symbols &lt;4b&gt;       │├────────────────────┴─────────────────────┤│ ┌──────────────────────┬───────────────┐ ││ │ len(str_1) &lt;uvarint&gt; │ str_1 &lt;bytes&gt; │ ││ ├──────────────────────┴───────────────┤ ││ │                . . .                 │ ││ ├──────────────────────┬───────────────┤ ││ │ len(str_n) &lt;uvarint&gt; │ str_n &lt;bytes&gt; │ ││ └──────────────────────┴───────────────┘ │├──────────────────────────────────────────┤│ CRC32 &lt;4b&gt;                               │└──────────────────────────────────────────┘\n序列 series保存一个具体的时间序列，其中包含系列的label集合和block中的chunks。\n每个series都是16字节对齐。series的id为偏移量除以16。series ID 的排序列表也就是series label的字典排序列表。\n┌───────────────────────────────────────┐│ ┌───────────────────────────────────┐ ││ │   series_1                        │ ││ ├───────────────────────────────────┤ ││ │                 . . .             │ ││ ├───────────────────────────────────┤ ││ │   series_n                        │ ││ └───────────────────────────────────┘ │└───────────────────────────────────────┘\n\n每一个series先保存label的数量，然后是包含label键值对的引用。 标签对按字典顺序排序。然后是series涉及的索引块的个数，然后是一系列元数据条目，其中包含块的最小 (mint) 和最大 (maxt) 时间戳以及对其在块文件中位置的引用。mint 是第一个样本的时间，maxt 是块中最后一个样本的时间。 在索引中保存时间范围数据, 允许按照时间范围删除数据时，如果时间范围匹配，不需要直接访问时间数据。\n空间大小优化: 第一个块的 mint 被存储，它的 maxt 被存储为一个增量，并且 mint 和 maxt 被编码为后续块的前一个时间的增量。 类似的，第一个chunk的引用被存储，下一个引用被存储为前一个chunk的增量。\n┌──────────────────────────────────────────────────────────────────────────┐│ len &lt;uvarint&gt;                                                            │├──────────────────────────────────────────────────────────────────────────┤│ ┌──────────────────────────────────────────────────────────────────────┐ ││ │                     labels count &lt;uvarint64&gt;                         │ ││ ├──────────────────────────────────────────────────────────────────────┤ ││ │              ┌────────────────────────────────────────────┐          │ ││ │              │ ref(l_i.name) &lt;uvarint32&gt;                  │          │ ││ │              ├────────────────────────────────────────────┤          │ ││ │              │ ref(l_i.value) &lt;uvarint32&gt;                 │          │ ││ │              └────────────────────────────────────────────┘          │ ││ │                             ...                                      │ ││ ├──────────────────────────────────────────────────────────────────────┤ ││ │                     chunks count &lt;uvarint64&gt;                         │ ││ ├──────────────────────────────────────────────────────────────────────┤ ││ │              ┌────────────────────────────────────────────┐          │ ││ │              │ c_0.mint &lt;varint64&gt;                        │          │ ││ │              ├────────────────────────────────────────────┤          │ ││ │              │ c_0.maxt - c_0.mint &lt;uvarint64&gt;            │          │ ││ │              ├────────────────────────────────────────────┤          │ ││ │              │ ref(c_0.data) &lt;uvarint64&gt;                  │          │ ││ │              └────────────────────────────────────────────┘          │ ││ │              ┌────────────────────────────────────────────┐          │ ││ │              │ c_i.mint - c_i-1.maxt &lt;uvarint64&gt;          │          │ ││ │              ├────────────────────────────────────────────┤          │ ││ │              │ c_i.maxt - c_i.mint &lt;uvarint64&gt;            │          │ ││ │              ├────────────────────────────────────────────┤          │ ││ │              │ ref(c_i.data) - ref(c_i-1.data) &lt;varint64&gt; │          │ ││ │              └────────────────────────────────────────────┘          │ ││ │                             ...                                      │ ││ └──────────────────────────────────────────────────────────────────────┘ │├──────────────────────────────────────────────────────────────────────────┤│ CRC32 &lt;4b&gt;                                                               │└──────────────────────────────────────────────────────────────────────────┘\n\nPostingPosting这一节存放着关于series引用的单调递增列表，简单来说就是存放id和时间序列的对应关系\n┌────────────────────┬────────────────────┐│ len &lt;4b&gt;           │ #entries &lt;4b&gt;      │├────────────────────┴────────────────────┤│ ┌─────────────────────────────────────┐ ││ │ ref(series_1) &lt;4b&gt;                  │ ││ ├─────────────────────────────────────┤ ││ │ ...                                 │ ││ ├─────────────────────────────────────┤ ││ │ ref(series_n) &lt;4b&gt;                  │ ││ └─────────────────────────────────────┘ │├─────────────────────────────────────────┤│ CRC32 &lt;4b&gt;                              │└─────────────────────────────────────────┘\n\nPosting sections的顺序由postings offset table决定。\nPosting Offset Tablepostings offset table包含着一系列posting offset entry，根据label的名称和值排序。每一个posting offset entry存放着label的键值对以及在posting sections中其series列表的偏移量。用来跟踪posting sections。当index文件加载时，它们将部分加载到内存中。\n┌─────────────────────┬──────────────────────┐│ len &lt;4b&gt;            │ #entries &lt;4b&gt;        │├─────────────────────┴──────────────────────┤│ ┌────────────────────────────────────────┐ ││ │  n = 2 &lt;1b&gt;                            │ ││ ├──────────────────────┬─────────────────┤ ││ │ len(name) &lt;uvarint&gt;  │ name &lt;bytes&gt;    │ ││ ├──────────────────────┼─────────────────┤ ││ │ len(value) &lt;uvarint&gt; │ value &lt;bytes&gt;   │ ││ ├──────────────────────┴─────────────────┤ ││ │  offset &lt;uvarint64&gt;                    │ ││ └────────────────────────────────────────┘ ││                    . . .                   │├────────────────────────────────────────────┤│  CRC32 &lt;4b&gt;                                │└────────────────────────────────────────────┘\n\nTOCtable of contents是整个索引的入口点，并指向文件中的各个部分。 如果引用为零，则表示相应的部分不存在，查找时应返回空结果。\n┌─────────────────────────────────────────┐│ ref(symbols) &lt;8b&gt;                       │├─────────────────────────────────────────┤│ ref(series) &lt;8b&gt;                        │├─────────────────────────────────────────┤│ ref(label indices start) &lt;8b&gt;           │├─────────────────────────────────────────┤│ ref(label offset table) &lt;8b&gt;            │├─────────────────────────────────────────┤│ ref(postings start) &lt;8b&gt;                │├─────────────────────────────────────────┤│ ref(postings offset table) &lt;8b&gt;         │├─────────────────────────────────────────┤│ CRC32 &lt;4b&gt;                              │└─────────────────────────────────────────┘\n\nchunks 磁盘格式chunks文件创建在block中的chunks/目录中。 每个段文件的最大大小为 512MB。文件中的chunk由uint64的索引组织，索引低四位为文件内偏移，高四位为段序列号。\n┌──────────────────────────────┐│  magic(0x85BD40DD) &lt;4 byte&gt;  │├──────────────────────────────┤│    version(1) &lt;1 byte&gt;       │├──────────────────────────────┤│    padding(0) &lt;3 byte&gt;       │├──────────────────────────────┤│ ┌──────────────────────────┐ ││ │         Chunk 1          │ ││ ├──────────────────────────┤ ││ │          ...             │ ││ ├──────────────────────────┤ ││ │         Chunk N          │ ││ └──────────────────────────┘ │└──────────────────────────────┘\n\nchunks中的Chunk格式┌───────────────┬───────────────────┬──────────────┬────────────────┐│ len &lt;uvarint&gt; │ encoding &lt;1 byte&gt; │ data &lt;bytes&gt; │ CRC32 &lt;4 byte&gt; │└───────────────┴───────────────────┴──────────────┴────────────────┘\n\n查询数据code查询的prometheus方法签名\nSelect(sortSeries bool, hints *SelectHints, matchers ...*labels.Matcher) SeriesSet\n\n支持从block中，remote等各种地方查询获取数据\nprometheus会在内存中维护一个数据结构\n// Map of LabelName to a list of some LabelValues&#x27;s position in the offset table.// The first and last values for each name are always present.postings map[string][]postingOffset\n\n在内存中，保留每个label name，并且每n个保存label值，降低内存的占用。但是第一个和最后一个值总是保存在内存中。\n查询数据流程\n参考资料\nhttps://prometheus.io/docs/prometheus/latest/storage/\nhttps://github.com/prometheus/prometheus/blob/release-2.37/tsdb/docs/format/README.md\nhttps://github.com/prometheus/prometheus/blob/release-2.37/tsdb/docs/format/index.md\n\n","tags":["Prometheus"]},{"title":"微服务广播模式实践","url":"/2023/06/01/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%B9%BF%E6%92%AD%E6%A8%A1%E5%BC%8F%E5%AE%9E%E8%B7%B5/","content":"微服务广播模式，指的是在微服务多实例部署的场景下，将消息广播到多个微服务实例的一种模式。\n\n广播模式，一般用来维护微服务的内存数据，根据数据类型的不同，有助于解决两类问题。通常广播模式会使用支持发布订阅的消息中间件实现（如Redis、Kafka、Pulsar等），本文也基于消息中间件进行讨论。\n利用广播模式维护一致的缓存这应该是广播模式利用最多的一种场景，假想一个拥有海量用户的电商网站、或是一个亿级设备连接的IoT平台。势必会存在一些缓存数据，像是用户的购物车信息，或是设备的密钥缓存。如果没有广播模式，可能会存在这样的问题\n\n当用户更新了它的购物车之后，微服务实例1的数据发生了更新，数据库的数据也成功更新。但是微服务实例2中的缓存数据未能更新，那么如果用户的请求均衡到了实例2，就会发生意想不到的后果。\n这种情况下我们可以让微服务1在广播通道中发送一个缓存的invalidate消息，将微服务实例2中该用户的缓存清零，使得微服务实例2在下一次处理该用户的请求时，从数据库中读取最新的消息。\n使用该模式需要注意的点：\n\n每个微服务实例应该使用不同的消费组，可以通过微服务的IP、主机名、UUID等拼装成订阅组名称，这才称得上广播之名\n微服务消费消息的时候，应从Latest开始消费，避免从Earliest开始消费无用的缓存清理消息\n由于每一次微服务重启都会产生一个新的消费组，需要注意消费组的老化，可以通过消息中间件自带的不活跃消费组老化能力兜底，建议通过gracefulExit、监听kill信号等机制来主动删除消费组信息\n\n为什么说消费组老化比较重要呢，因为很多监控系统都会根据消费组的积压来做告警，很容易产生误告警。\n利用广播模式维护内存中的数据这种模式相对比较少见，常见于key的基数不是很大，能够将数据完整地存储在内存中，比如电商平台的企业卖家个数、物联网平台的用户个数等，并且对数据的一致性要求不是很高（因为广播模式情况下，对于两个微服务实例来说没有一致性保障）。像Apache Pulsar设计的TableView，在我看来，就是做这个事的一个最佳实践。Pulsar内部大量使用了topic存储数据，就是采用这个方式。\n使用该模式需要注意的点：\n\n同上，需要使用不同的消费组名称\n微服务消费消息的时候，应该从Earliest开始消费，保证所有微服务内存中的消息视图一致\n同上，需要注意消费组的老化\n\n为什么需要消费组老化作为保底手段因为在极端场景下，无论是graceful的代码，还是监听kill信号的代码，都不能保证代码百分百地被执行。需要兜底。\nKafka消费组老化Kafka通过offsets.retention.minutes参数控制消费组中offsets保留时间，在此时间内如果没有提交offset，offsets将会被删除。Kafka判定消息组中没有在线的消费者（如empty状态），且没有offsets时，将会删除此消费组。\nPulsar消费组老化pulsar的消费组老化策略更加灵活，可以配置到namespace级别。\nbin/pulsar-admin namespaces | grep expiration    get-subscription-expiration-time      Get subscription expiration time for       Usage: get-subscription-expiration-time [options] tenant/namespace    set-subscription-expiration-time      Set subscription expiration time for       Usage: set-subscription-expiration-time [options] tenant/namespace            Subscription expiration time in minutes    remove-subscription-expiration-time      Remove subscription expiration       Usage: remove-subscription-expiration-time [options] tenant/namespace\n\n这里注意要合理地配置消费组的老化时间，在pulsar的当前版本（2.11版本）下，catch up读，也就是说消费组平时积压量不大。如果将消费组的老化时间配置大于等于消息的老化时间，会出现消费组老化不了的现象。\n当然，由于消费组和消息老化都是定时任务，预估时间时，要考虑一定的buffer。\n这里让我们稍稍dive一下原理，消费组的老化是通过判断Cursor游标的LastActive time来判断能否老化的。如果该消费组的游标位置到达了消息老化区域，被老化掉了，消费组的游标位置就会强制更新到一个可用的位置，这个时候会更新游标的LastActive time到当前时间，周而复始，导致消费组无法老化。举个🌰\n假设消费组的老化时间为4h，消息的老化时间为3h，就可能会发生这样的事情\n\n总结广播模式在微服务架构中起到了重要的角色，尤其是在需要在微服务实例之间同步数据的场景中，它具有显著的优势。它能够帮助维护内存数据的缓存一致性。希望本篇文章能提供您全面的广播模式的知识。\n"},{"title":"打造可商用的Java程序之可维护性","url":"/2023/06/15/%E6%89%93%E9%80%A0%E5%8F%AF%E5%95%86%E7%94%A8%E7%9A%84Java%E7%A8%8B%E5%BA%8F%E4%B9%8B%E5%8F%AF%E7%BB%B4%E6%8A%A4%E6%80%A7/","content":"在主函数中捕获未处理的异常在主函数中捕获未处理的异常，防止程序崩溃，同时记录日志，方便排查问题。\npublic class UncaughtExceptionHandle &#123;    public static void main(String[] args) &#123;        Thread.setDefaultUncaughtExceptionHandler((t, e) -&gt; log.error(&quot;Uncaught exception: &quot;, e));    &#125;&#125;\n"},{"title":"线程锁导致的kafka客户端超时问题","url":"/2023/07/08/%E7%BA%BF%E7%A8%8B%E9%94%81%E5%AF%BC%E8%87%B4%E7%9A%84kafka%E5%AE%A2%E6%88%B7%E7%AB%AF%E8%B6%85%E6%97%B6%E9%97%AE%E9%A2%98/","content":"问题背景有一个环境的kafka client发送数据有部分超时，拓扑图也非常简单\n\n定位历程我们先对客户端的环境及JVM情况进行了排查，从JVM所在的虚拟机到kafka server的网络正常，垃圾回收（GC）时间也在预期范围内，没有出现异常。\n紧接着，我们把目光转向了kafka 服务器，进行了一些基础的检查，同时也查看了kafka处理请求的超时日志，其中我们关心的metadata和produce请求都没有超时。\n问题就此陷入了僵局，虽然也搜到了一些kafka server会对连上来的client反解导致超时的问题（ https://github.com/apache/kafka/pull/10059），但通过一些简单的分析，我们确定这并非是问题所在。\n同时，我们在环境上也发现一些异常情况，当时觉得不是核心问题&#x2F;解释不通，没有深入去看\n\n问题JVM线程数较高，已经超过10000，这个线程数量虽然确实较高，但并不会对1个4U的容器产生什么实质性的影响。\n负责指标上报的线程CPU较高，大约占用了1&#x2F;4 ~ 1&#x2F;2 的CPU核，这个对于4U的容器来看问题也不大\n\n当排查陷入僵局，我们开始考虑其他可能的调查手段。我们尝试抓包来找线索，这里的抓包是SASL鉴权+SSL加密的，非常难读，只能靠长度和响应时间勉强来推断报文的内容。\n在这个过程中，我们发现了一个非常重要的线索，客户端竟然发起了超时断链，并且超时的那条消息，实际服务端是有响应回复的。\n随后我们将kafka client的trace级别日志打开，这里不禁感叹kafka client日志打的相对较少，发现的确有log.debug(“Disconnecting from node {} due to request timeout.”, nodeId);的日志打印。\n与网络相关的流程：\ntry &#123;    // 这里发出了请求    client.send(request, time.milliseconds());    while (client.active()) &#123;        List&lt;ClientResponse&gt; responses = client.poll(Long.MAX_VALUE, time.milliseconds());        for (ClientResponse response : responses) &#123;            if (response.requestHeader().correlationId() == request.correlationId()) &#123;                if (response.wasDisconnected()) &#123;                    throw new IOException(&quot;Connection to &quot; + response.destination() + &quot; was disconnected before the response was read&quot;);                &#125;                if (response.versionMismatch() != null) &#123;                    throw response.versionMismatch();                &#125;                return response;            &#125;        &#125;    &#125;    throw new IOException(&quot;Client was shutdown before response was read&quot;);&#125; catch (DisconnectException e) &#123;    if (client.active())        throw e;    else        throw new IOException(&quot;Client was shutdown before response was read&quot;);&#125;\n\n这个poll方法，不是简单的poll方法，而在poll方法中会进行超时判断，查看poll方法中调用的handleTimedOutRequests方法\n@Overridepublic List&lt;ClientResponse&gt; poll(long timeout, long now) &#123;    ensureActive();    if (!abortedSends.isEmpty()) &#123;        // If there are aborted sends because of unsupported version exceptions or disconnects,        // handle them immediately without waiting for Selector#poll.        List&lt;ClientResponse&gt; responses = new ArrayList&lt;&gt;();        handleAbortedSends(responses);        completeResponses(responses);        return responses;    &#125;    long metadataTimeout = metadataUpdater.maybeUpdate(now);    try &#123;        this.selector.poll(Utils.min(timeout, metadataTimeout, defaultRequestTimeoutMs));    &#125; catch (IOException e) &#123;        log.error(&quot;Unexpected error during I/O&quot;, e);    &#125;    // process completed actions    long updatedNow = this.time.milliseconds();    List&lt;ClientResponse&gt; responses = new ArrayList&lt;&gt;();    handleCompletedSends(responses, updatedNow);    handleCompletedReceives(responses, updatedNow);    handleDisconnections(responses, updatedNow);    handleConnections();    handleInitiateApiVersionRequests(updatedNow);    // 关键的超时判断    handleTimedOutRequests(responses, updatedNow);    completeResponses(responses);    return responses;&#125;\n\n由此我们推断，问题可能在于客户端hang住了一段时间，从而导致超时断链。我们通过工具Arthas深入跟踪了Kafka的相关代码，甚至发现一些简单的操作（如A.field）也需要数秒的时间。这进一步确认了我们的猜想：问题可能出在JVM。JVM可能在某个时刻出现问题，导致系统hang住，但这并非由GC引起。\n\n为了解决这个问题，我们又检查了监控线程CPU较高的问题。我们发现线程的执行热点是从”sun.management.ThreadImpl”中的”getThreadInfo”方法。\n&quot;metrics-1@746&quot; prio=5 tid=0xf nid=NA runnable  java.lang.Thread.State: RUNNABLE    at sun.management.ThreadImpl.getThreadInfo(Native Method)\t  at sun.management.ThreadImpl.getThreadInfo(ThreadImpl.java:185)\t  at sun.management.ThreadImpl.getThreadInfo(ThreadImpl.java:149)\n\n进一步发现，在某些版本的JDK8中，读取线程信息是需要加锁的。\n至此，问题的根源已经清晰明了：过高的线程数以及线程监控时JVM全局锁的存在导致了这个问题。您可以使用如下的demo来复现这个问题\nimport java.lang.management.ManagementFactory;import java.lang.management.ThreadInfo;import java.lang.management.ThreadMXBean;import java.util.concurrent.Executors;import java.util.concurrent.ScheduledExecutorService;import java.util.concurrent.TimeUnit;public class ThreadLockSimple &#123;    public static void main(String[] args) &#123;        for (int i = 0; i &lt; 15_000; i++) &#123;            new Thread(new Runnable() &#123;                @Override                public void run() &#123;                    try &#123;                        Thread.sleep(200_000);                    &#125; catch (InterruptedException e) &#123;                        throw new RuntimeException(e);                    &#125;                &#125;            &#125;).start();        &#125;        ScheduledExecutorService executorService = Executors.newSingleThreadScheduledExecutor();        executorService.scheduleAtFixedRate(new Runnable() &#123;            @Override            public void run() &#123;                System.out.println(&quot;take &quot; + &quot; &quot; + System.currentTimeMillis());            &#125;        &#125;, 1, 1, TimeUnit.SECONDS);        ThreadMXBean threadMXBean = ManagementFactory.getThreadMXBean();        ScheduledExecutorService metricsService = Executors.newSingleThreadScheduledExecutor();        metricsService.scheduleAtFixedRate(new Runnable() &#123;            @Override            public void run() &#123;                long start = System.currentTimeMillis();                ThreadInfo[] threadInfoList = threadMXBean.getThreadInfo(threadMXBean.getAllThreadIds());                System.out.println(&quot;threads count &quot; + threadInfoList.length + &quot; cost :&quot; + (System.currentTimeMillis() - start));            &#125;        &#125;, 1, 1, TimeUnit.SECONDS);    &#125;&#125;\n\n为了解决这个问题，我们有以下几个可能的方案：\n\n将不合理的线程数往下降，可能存在线程泄露的场景\n升级jdk到jdk11或者jdk17（推荐）\n将Thread相关的监控临时关闭\n\n这个问题的解决方案应根据实际情况进行选择，希望对你有所帮助。\n","tags":["Kafka"]},{"title":"网络通信超时之后该不该重启客户端","url":"/2023/07/08/%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1%E8%B6%85%E6%97%B6%E4%B9%8B%E5%90%8E%E8%AF%A5%E4%B8%8D%E8%AF%A5%E9%87%8D%E5%90%AF%E5%AE%A2%E6%88%B7%E7%AB%AF/","content":"我写这篇文章来论证“超时之后要不要重启客户端”、“如何重启客户端”。简而言之，重启客户端还是为了让系统能够达到自愈，是比较高的可靠性要求。如果你的软件没有这么高的可靠性要求，像是人机交互程序等对可靠性要求较低的场景，可以选择不考虑这个功能。毕竟实现这个功能的时间至少够300倍你重新点击按钮&#x2F;重启的时间了。\n如果是一些串口协议，通过传输的间隙来判断报文的间隔，比如modbus协议，3.5个时间内不发送，就计算做一个协议报文的开始，那么故障时的报文毫无疑问会处理失败（因为存在CRC校验，奇偶校验等）。等待故障结束，又3.5个时间后，就会恢复正常。\n如果能确保网络通信报文不会遭到篡改、也没有宇宙射线&#x2F;太阳黑子修改你的比特位的场景下，笔者认为没有特别大的必要对客户端进行重启操作，因为不见得重启后就比之前更好，这种超时通常是由服务端处理时间长导致的。没做到建链限制的情况下，贸然重启，还可能会引起建链的波峰。\n但是，在实际复杂的网络环境下，如网络报文遭到篡改、部分字节丢失等的情况下，一切就大不一样了，不重启客户端就无法自愈。这其中的关键在于，切分报文是否正确。\n比如基于TCP的网络协议，这也是本文重点讨论的场景，假设应用协议采用最常见的LengthBasedFrame分包方式，这种协议，通常根据前0~4个字节来判断协议的总长度，比如前面的字节是00000014，那这个报文长度就是1*16 + 4 = 20长度。这种时候，一旦发生了报文篡改&#x2F;丢包，会导致通信端计算报文长度出错，一直在傻等，无法自愈。\n比如上面的例子一旦发生篡改，将4篡改5，那么就会导致客户端&#x2F;服务器一直在等待不存在的第21个字节，这种情况下，如果不做超时重建，那么这条链路就会一直处于等待状态，无法自愈。\n综上所述，实际复杂的网络环境下出现通信超时，这条链路可能会无法自愈。这种情况下，笔者推荐对针对tcp链路做超时重建，业内的一些例子像是：bookkeeper client没有做，kafka client做了。至于重建的触发条件，比如一次超时就重建、多次超时之后才重建、仅当心跳报文超时才重建，这些就交给读者自己把握了。如果区别不大，笔者倾向于一次超时就重建，逻辑简单清晰。\n"},{"title":"软件应该以标准的格式来交付","url":"/2025/09/22/%E8%BD%AF%E4%BB%B6%E5%BA%94%E8%AF%A5%E4%BB%A5%E6%A0%87%E5%87%86%E7%9A%84%E6%A0%BC%E5%BC%8F%E6%9D%A5%E4%BA%A4%E4%BB%98/","content":"令人深思的经历曾经历过这样的事情，平台侧要求应用提供满足平台特有格式的交付件，经过多次协商，最终还是应用侧与平台侧一起开会，由平台侧帮助应用侧输出。\n另一件事，Kubernetes Yaml以其独特、强大的合并属性能力闻名于江湖。应用侧对Kubernetes Yaml不熟悉，新手想要把环境上的Yaml导出直接作为标准交付件，虽然也行，但是包含了很多噪音，环境上的id、环境上的annotation、时间戳等等。\n私有化格式的交付困境越来越多的软件将自己定位为”平台”，无论是微信、飞书这样的国民应用，还是各类企业级软件。但平台交付的过程中，一个普遍存在的问题是：许多平台要求合作伙伴或第三方开发者使用其私有化的交付格式。这种私有化格式往往存在诸多问题：\n\n学习成本高，难以掌握。\n文档不完善，依赖平台方支持。\n迁移困难，形成供应商锁定。\n最终往往仍需平台方投入人力协助。\n\n软件交付应该标准化软件交付应该使用标准的格式，这有助于降低合作伙伴的接入成本，提高自身的可扩展性，尤其在AI辅助研发的现状下，采用标准的格式更有利于AI理解和生成代码。\n\n\n\n交付件\n标准格式\n使用场景\n\n\n\nJava库\nJar包\n作为依赖库被其他Java项目引用和集成，需要发布到Maven仓库。\n\n\n应用镜像\n标准镜像包\n以容器方式交付，确保运行的一致性。（但如x86、armv8、armv7）的差异依然存在。\n\n\n应用部署（I层资源已具备）\nhelm、docker compose\n商用场景多用Helm包，单机伪集群&#x2F;组合方式多用docker compose。\n\n\n应用部署及I层资源创建\nTerraform\n需要交付底层基础设施或云服务的场景，如整个应用运行环境。\n\n\n如果实在要使用私有的格式，可以对标准格式做一些裁剪&#x2F;扩展（Kubernetes的annotation），将标准格式转化到私有格式。\n"}]