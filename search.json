[{"title":"Android中实现定时任务【翻译】","url":"/2016/09/08/Android%E4%B8%AD%E5%AE%9E%E7%8E%B0%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E3%80%90%E7%BF%BB%E8%AF%91%E3%80%91/","content":"原文：http://android-developers.blogspot.sg/2007/11/stitch-in-time.html?m=0\n1.利用TimerTask实现任务的定时执行 \nTextView hezhangjian;int count = 0;//用于计数@Overrideprotected void onCreate(Bundle savedInstanceState) &#123;    super.onCreate(savedInstanceState);    setContentView(R.layout.activity_main);    hezhangjian = (TextView) findViewById(R.id.hezhangjian);    Timer timer = new Timer();//新建一个Timer    timer.schedule(new UpdateTimeTask(),100,200);    //通过schedule方法执行一个TimerTask，Timertask是一个抽象类，必须重写它的run方法。    //task,long a,long b代表的是先等待a毫秒的延迟执行任务，然后每次等待大约b时间执行任务。&#125;class UpdateTimeTask extends TimerTask&#123;    @Override    public void run() &#123;        count++;        runOnUiThread(new Runnable() &#123;            @Override            public void run() &#123;                hezhangjian.setText(&quot;这是&quot;+&quot;第&quot;+count+&quot;次&quot;);            &#125;        &#125;);    &#125;&#125;\n2.利用Handler实现定时任务的操作\n  TextView hezhangjian;int count = 0;private Handler mHandler;@Overrideprotected void onCreate(Bundle savedInstanceState) &#123;    super.onCreate(savedInstanceState);    setContentView(R.layout.activity_main);    mHandler = new Handler();//初始化handler    hezhangjian = (TextView) findViewById(R.id.hezhangjian);    mHandler.postDelayed(new UpdateTimeTask(),200);//延迟200，执行这个任务&#125;class UpdateTimeTask extends TimerTask&#123;    @Override    public void run() &#123;        count++;        runOnUiThread(new Runnable() &#123;            @Override            public void run() &#123;                hezhangjian.setText(&quot;这是&quot;+&quot;第&quot;+count+&quot;次&quot;);//执行完毕                mHandler.postDelayed(new UpdateTimeTask(),100);//延迟100，再执行这个任务            &#125;        &#125;);    &#125;&#125;\n\n如果你想要取消这个post事件，你可以使用handler的removeCallbacks(TimerTask task)方法。\n"},{"title":"Apache Ignite在华为云IoT服务产品部的使用","url":"/2023/12/07/Apache%20Ignite%E5%9C%A8%E5%8D%8E%E4%B8%BA%E4%BA%91IoT%E6%9C%8D%E5%8A%A1%E4%BA%A7%E5%93%81%E9%83%A8%E7%9A%84%E4%BD%BF%E7%94%A8/","content":"Apache Ignite简介Apache Ignite是一个开源分布式的数据库、缓存和计算平台。它的核心是一个内存数据网格，它可以将内存作为分布式的持久化存储，以提供高性能和可扩展性。它还提供了一个分布式的键值存储、SQL数据库、流式数据处理和复杂的事件处理等功能。\nIgnite的核心竞争力包括：\n\n兼容Mysql、Oracle语法\n性能强大，可以水平扩展\n缓存与数据库同源，可通过KV、SQL、JDBC、ODBC等方式访问\n\n同时，为了便于开发，除了jdbc、odbc、restful方式外，Ignite还官方提供了Java、C++、.Net、Python、Node.js、PHP等语言的客户端，可以方便的与Ignite进行交互。\n\nApache Ignite的问题频繁创建删除表，导致IGNITE_DISCOVERY_HISTORY_SIZE超过限制根据Ignite2的拓扑模型，集群的拓扑版本会在创建表&#x2F;删除表的时候发生变化，该变化版本号递增，且仅会保留最近$IgniteDiscoveryHistorySize条记录，程序某处会写死读取版本为0的数据，读取不到时，ignite集群会重启。默认值为500。社区issue: https://github.com/apache/ignite/issues/10894笔者暂时没有时间来修复这个issue，可以通过将IGNITE_DISCOVERY_HISTORY_SIZE设置地比较大，来规避这个问题。\nIgnite2客户端易用性问题Ignite2客户端超时默认值不合理Ignite2客户端的连接超时、执行sql超时默认都是0，没有精心研究过配置的用户在异常场景下，应用程序可能会hang住。从易用性的角度来说，网络通信的任何操作，默认都应该有超时时间。\nIgnite2客户端不支持永远的重试Ignite通过预先计算出所有需要重连的时间点来实现重连，如果想配置成永远的重连，会因为时间点的计算导致内存溢出。从易用性的角度来说，应该支持永远的重连。\nIgnite2客户端在某些异常下无法自愈当client执行sql的时候，碰到如下异常的时候，无法自愈。可以通过执行SQL对client进行定期检查并重建。\nCaused by: org.apache.ignite.internal.client.thin.ClientServerError: Ignite failed to process request [47]: 50000: Can not perform the operation because the cluster is inactive. Note, that the cluster is considered inactive by default if Ignite Persistent Store is used to let all the nodes join the cluster. To activate the cluster call Ignite.cluster.state(ClusterState.ACTIVE)\n\nIgnite2 SocketChannel泄露问题Ignite客户端在连接时，如果对应的Server端没有启动，会导致SocketChannel泄露，已由笔者提交代码修复：https://github.com/apache/ignite/pull/11016/files\n","tags":["Ignite"]},{"title":"Apache ZooKeeper在华为云IoT服务产品部的使用","url":"/2021/04/10/Apache%20ZooKeeper%E5%9C%A8%E5%8D%8E%E4%B8%BA%E4%BA%91IoT%E6%9C%8D%E5%8A%A1%E4%BA%A7%E5%93%81%E9%83%A8%E7%9A%84%E4%BD%BF%E7%94%A8/","content":"前言华为云IoT服务产品部致力于提供极简接入、智能化、安全可信等全栈全场景服务和开发、集成、托管、运营等一站式工具服务，助力合作伙伴&#x2F;客户轻松、快速地构建5G、AI万物互联的场景化物联网解决方案。\n架构方面，华为云IoT服务产品部采用云原生微服务架构，ZooKeeper组件在华为云IoT服务产品部的架构中扮演着重要的角色，本文将介绍华为云IoT服务产品部在ZooKeeper的使用。\nApache ZooKeeper 简介Apache ZooKeeper是一个分布式、开源的分布式协调服务，由Apache Hadoop的子项目发展而来。作为一个分布式原语的基石服务，几乎所有分布式功能都可以借助ZooKeeper来实现，例如：应用的主备选举，分布式锁，分布式任务分配，缓存通知，甚至是消息队列、配置中心等。\n抛开应用场景，讨论某个组件是否适合，并没有绝对正确的答案。尽管Apache ZooKeeper作为消息队列、配置中心时，性能不用想就知道很差。但是，倘若系统里面只有ZooKeeper，应用场景性能要求又不高，那使用ZooKeeper不失为一个好的选择。但ZooKeeper 客户端的编码难度较高，对开发人员的技术水平要求较高，尽量使用一些成熟开源的ZooKeeper客户端、框架，如：Curator、Spring Cloud ZooKeeper等。\nApache ZooKeeper 核心概念ZNodeZNode是ZooKeeper的数据节点，ZooKeeper的数据模型是树形结构，每个ZNode都可以存储数据，同时可以有多个子节点，每个ZNode都有一个路径标识，类似于文件系统的路径，例如：&#x2F;iot-service&#x2F;iot-device&#x2F;iot-device-1。\nApache ZooKeeper在华为云IoT服务产品部的使用\n支撑系统内关键组件很多开源组件都依赖ZooKeeper，如Flink、Ignite、Pulsar等，通过自建和优化ZooKeeper环境，我们能够为这些高级组件提供更加可靠和高效的服务支持，确保服务的平稳运行。\n严格分布式锁分布式锁是非常常见的需求，相比集群Redis、主备Mysql等，ZooKeeper更容易实现理论上的严格分布式锁。\n分布式缓存通知ZooKeeper的分布式缓存通知能够帮助我们实现分布式缓存的一致性，例如：我们可以在ZooKeeper上注册一个节点，然后在其他节点上监听这个节点，当这个节点发生变化时，其他节点就能够收到通知，然后更新本地缓存。\n这种方式的缺点是，ZooKeeper的性能不高，不适合频繁变更的场景，但是，对于一些不经常变更的配置，这种方式是非常适合的。如果系统中存在消息队列，那么可以使用消息队列来实现分布式缓存通知，这种方式的性能会更好、扩展性更强。\n分布式Id生成器直接使用ZooKeeper的有序节点应用程序可以直接使用ZooKeeper的有序节点来生成分布式Id，但是，这种方式的缺点是，ZooKeeper的性能不高，不适合频繁生成的场景。\nimport org.apache.zookeeper.CreateMode;import org.apache.zookeeper.ZooDefs;import org.apache.zookeeper.ZooKeeper;import org.apache.zookeeper.data.Stat;import java.util.Optional;public class ZkDirectIdGenerator &#123;    private ZooKeeper zooKeeper;    private String path = &quot;/zk-direct-id&quot;;    private static final String PATH_PREFIX = &quot;/id-&quot;;    public ZkDirectIdGenerator(String connectionString, int sessionTimeout) throws Exception &#123;        this.zooKeeper = new ZooKeeper(connectionString, sessionTimeout, event -&gt; &#123;&#125;);        initializePath();    &#125;    private void initializePath() throws Exception &#123;        Stat stat = zooKeeper.exists(path, false);        if (stat == null) &#123;            zooKeeper.create(path, new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);        &#125;    &#125;    public Optional&lt;String&gt; generateId() &#123;        try &#123;            String fullPath = zooKeeper.create(path + PATH_PREFIX, new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT_SEQUENTIAL);            return Optional.of(extractId(fullPath));        &#125; catch (Exception e) &#123;            log.error(&quot;create znode failed, exception is &quot;, e);            return Optional.empty();        &#125;    &#125;    private String extractId(String fullPath) &#123;        return fullPath.substring(fullPath.lastIndexOf(PATH_PREFIX) + PATH_PREFIX.length());    &#125;&#125;\n\n使用ZooKeeper生成机器号应用程序可以使用ZooKeeper生成机器号，然后使用机器号+时间戳+序列号来生成分布式Id。来解决ZooKeeper有序节点性能不高的问题。\nimport lombok.extern.slf4j.Slf4j;import org.apache.zookeeper.CreateMode;import org.apache.zookeeper.ZooDefs;import org.apache.zookeeper.ZooKeeper;import java.time.LocalDateTime;import java.util.Optional;import java.util.concurrent.atomic.AtomicInteger;import java.util.concurrent.atomic.AtomicReference;@Slf4jpublic class ZkIdGenerator &#123;    private final String path = &quot;/zk-id&quot;;    private final AtomicInteger atomicInteger = new AtomicInteger();    private final AtomicReference&lt;String&gt; machinePrefix = new AtomicReference&lt;&gt;(&quot;&quot;);    private static final String[] AUX_ARRAY = &#123;&quot;&quot;, &quot;0&quot;, &quot;00&quot;, &quot;000&quot;, &quot;0000&quot;, &quot;00000&quot;&#125;;    /**     * 通过zk获取不一样的机器号，机器号取有序节点最后三位     * id格式：     * 机器号 + 日期 + 小时 + 分钟 + 秒 + 5位递增号码     * 一秒可分近10w个id     * 需要对齐可以在每一位补零     *     * @return     */    public Optional&lt;String&gt; genId() &#123;        if (machinePrefix.get().isEmpty()) &#123;            acquireMachinePrefix();        &#125;        if (machinePrefix.get().isEmpty()) &#123;            // get id failed            return Optional.empty();        &#125;        final LocalDateTime now = LocalDateTime.now();        int aux = atomicInteger.getAndAccumulate(1, ((left, right) -&gt; &#123;            int val = left + right;            return val &gt; 99999 ? 1 : val;        &#125;));        String time = conv2Str(now.getDayOfYear(), 3) + conv2Str(now.getHour(), 2) + conv2Str(now.getMinute(), 2) + conv2Str(now.getSecond(), 2);        String suffix = conv2Str(aux, 5);        return Optional.of(machinePrefix.get() + time + suffix);    &#125;    private synchronized void acquireMachinePrefix() &#123;        if (!machinePrefix.get().isEmpty()) &#123;            return;        &#125;        try &#123;            ZooKeeper zooKeeper = new ZooKeeper(ZooKeeperConstant.SERVERS, 30_000, null);            final String s = zooKeeper.create(path, new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT_SEQUENTIAL);            if (s.length() &gt; 3) &#123;                machinePrefix.compareAndSet(&quot;&quot;, s.substring(s.length() - 3));            &#125;        &#125; catch (Exception e) &#123;            log.error(&quot;connect to zookeeper failed, exception is &quot;, e);        &#125;    &#125;    private static String conv2Str(int value, int length) &#123;        if (length &gt; 5) &#123;            throw new IllegalArgumentException(&quot;length should be less than 5&quot;);        &#125;        String str = String.valueOf(value);        return AUX_ARRAY[length - str.length()] + str;    &#125;&#125;\n\n微服务注册中心相比其他微服务引擎，如阿里云的MSE、Nacos等，已有的Zookeeper集群作为微服务的注册中心，既能满足微服务数量较少时的功能需求，并且更加节约成本\n数据库连接均衡在此前的架构中，我们采用了一种随机策略来分配微服务与数据库的连接地址。下图展示了这种随机分配可能导致的场景。考虑两个微服务：微服务B和微服务C。尽管微服务C的实例较多，但其对数据库的操作相对较少。相比之下，微服务B在运行期间对数据库的操作更为频繁。这种连接方式可能导致数据库Data2节点的连接数和CPU使用率持续居高，从而成为系统的瓶颈。\n\n启发于Kafka中的partition分配算法，我们提出了一种新的连接策略。例如，如果微服务B1连接到了Data1和Data2节点，那么微服务B2将连接到Data3和Data4节点。如果存在B3实例，它将再次连接到Data1和Data2节点。对于微服务C1，其连接将从Data1和Data2节点开始。然而，由于微服务的数量与数据库实例数量的两倍（每个微服务建立两个连接）并非总是能整除，这可能导致Data1和Data2节点的负载不均衡。\n为了解决这一问题，我们进一步优化了策略：第一个微服务实例在选择数据库节点时，将从一个随机起点开始。这种方法旨在确保Data1和Data2节点的负载均衡。具体的分配策略如下图所示。\n\nApache ZooKeeper在华为云IoT产品部的部署&#x2F;运维服务端部署方式我们所有微服务和中间件均采用容器化部署，选择3节点（没有learner）规格。使用statefulset和PVC的模式部署。为什么使用statefulset进行部署？statefulset非常适合用于像Zookeeper这样有持久化存储需求的服务，每个Pod可以和对应的存储资源绑定，保证数据的持久化，同时也简化了部署，如果想使用deploy的部署模式，需要规划、固定每个pod的虚拟机部署。\nZookeeper本身对云硬盘的要求并不高，普通IO，几十G存储就已经能够支撑Zookeeper平稳运行了。Zookeeper本身运行的资源，使用量不是很大，在我们的场景，规格主要取决于Pulsar的topic数量，如果Pulsar的topic不多，那么0.5核、2G内存已经能保证Zookeeper平稳运行了。\n客户端连接方式借助coredns，客户端使用域名的方式连接Zookeeper，这样可以避免Zookeeper的IP地址变更导致客户端连接失败的问题，如zookeeper-0.zookeeper:2181,zookeeper-1.zookeeper:2181,zookeeper-2.zookeeper:2181\n重要监控指标\nreadlantency、updatelantency\nzk的读写延迟\n\napproximate_data_size\nzk中数据的平均大小估计\n\noutstanding_requests\n等待Zookeeper处理的请求数\n\nznode_count\nZookeeper当前的znode总数\n\nnum_alive_connections\nZookeeper当前活跃的连接数\n\n\nApache ZooKeeper在华为云IoT产品部的问题readiness合理设置这是碰到的最有趣的问题，readiness接口是k8s判断pod是否正常的依据，那么对于Zookeeper集群来说，最合理的就是，当这个Zookeeper节点加入集群，获得了属于自己的Leader或Follower状态，就算pod正常。可是，当初次部署的时候，只有一个节点可用，该节点一个实例无法完成选举流程，导致无法部署。\n综上，我们把readiness的策略修改为：\n\nPS：为了让readiness检查不通过时，Zookeeper集群也能选主成功，需要配置publishNotReadyAddresses为true，示例如下\napiVersion: v1kind: Servicemetadata:  name: zookeeperspec:  selector:    app: zookeeper  clusterIP: None  sessionAffinity: None  publishNotReadyAddresses: true  ports:    - protocol: TCP      port: 2181      name: client    - protocol: TCP      port: 2888      name: peer    - protocol: TCP      port: 3888      name: leader\n\njute.maxbuffer超过上限jute.maxbuffer，这个是znode中存储数据大小的上限，在客户端和服务端都需要配置，根据自己在znode上存储的数据合理配置\nzookeeper的Prometheus全0监听不满足网络监听最小可见原则。修改策略，添加一个可配置参数来配置监听的IP metricsProvider.httpHost，PR已合入，见 https://github.com/apache/zookeeper/pull/1574/files\n客户端版本号过低，域名无法及时刷新客户端使用域名进行连接，但在客户端版本号过低的情况下，客户端并不会刷新新的ip，还是会用旧的ip尝试连接。升级客户端版本号到curator-4.3.0以上、zookeeper-3.6.2以上版本后解决。\n总结本文详细介绍了华为云IoT服务产品部如何使用Apache ZooKeeper来优化其云原生微服务架构。ZooKeeper作为分布式协调服务，在华为云IoT服务中发挥了重要作用，用于主备选举、分布式锁、任务分配和缓存通知等。文中还讨论了ZooKeeper在分布式ID生成、微服务注册中心、数据库连接均衡等方面的应用。此外，文章还覆盖了ZooKeeper在华为云IoT产品部的部署、运维策略和所遇到的挑战，包括容器化部署、监控指标和配置问题。\n","tags":["ZooKeeper"]},{"title":"BookKeeper 持久化文件解析","url":"/2021/02/16/BookKeeper%20%E6%8C%81%E4%B9%85%E5%8C%96%E6%96%87%E4%BB%B6%E8%A7%A3%E6%9E%90/","content":"Entry Log File背景测试环境上出现了一些entryLog解析异常的问题，想分析一下磁盘上.log文件的格式，分析分析我们的文件是否有问题\n解析代码地址https://github.com/protocol-laboratory/bookkeeper-codec-java/blob/main/src/main/java/com/github/protocol/EntryLogReader.java\n正文我们采用的配置是singleEntryLog模式，就是说很多ledger的信息都会放在一个log文件内部。\n插一句话：这种log文件，其实和LSM相似，属于不可变的数据结构，这种数据结构，得益于不可变，所以内容可以安排的非常紧凑，不像B树结构，需要预留一定空间给原地更新，随机插入等。\n\n如上图所示，接下来，我们沿着解析的流程，解读每个部分的详细格式\n解析头部首先，我们解析文件的头部字段，bookkeeper的设计中，文件头部预留了1024字节，目前只使用了20个字节前四个字节是BKLO的文件魔数然后紧跟着的4个字节是bk文件的版本号，这里我们仅分析版本号1然后8字节的long类型代表ledgersMap的开始位置，称为ledgersMapOffset。然后4字节的int类型代表ledgersMap的总长度。\n解析ledgerMap部分最前面四个字节，代表这部分的大小\n然后开始的ledgerId和entryId分别为-1，-2，随后是一个ledger的count大小，后面的ledgerId和size才是有效值\n随后的部分非常紧凑，由一个个ledgerId，size组成\n读取完ledgerMap，可以知道，这个文件包含了多少ledger，总大小是多少？\n注：size代表这一段ledger占用的磁盘空间大小\n解析body内容body内容也非常紧凑.最前面4个字节，代表这个entry的大小。然后8个字节，ledgerId然后8个字节，entryId剩下的内容，就是pulsar写数据的编码，不再属于bookkeeper的格式范畴了\nTxn Log File解析代码地址https://github.com/protocol-laboratory/bookkeeper-codec-java/blob/main/src/main/java/com/github/protocol/TxnLogReader.java\n简述bookkeeper中的journal log，和大部分基于LSM的数据结构一样，是用来保证文件一定被写入的。会在数据写入的时候，写入journal log，崩溃恢复的时候从journal log里面恢复。\n\n解析头部首先，我们解析文件的头部字段前四个字节是BKLG的文件魔数然后紧跟着的4个字节是bk文件的版本号\nprivate TxnHeader readHeader(FileChannel fileChannel) throws Exception &#123;    final ByteBuf headers = Unpooled.buffer(HEADER_SIZE);    final int read = fileChannel.read(headers.internalNioBuffer( index: 0, HEADER_SIZE));    headers.writerIndex(read);    final byte[] bklgByte = new byte[4];    headers.readBytes(bklgByte, dstIndex: 0, length: 4);    final int headerVersion = headers.readInt();    return new TxnHeader(headerVersion);&#125;\n\n解析内容内容非常紧凑，由ledgerId，entryId和内容组成。ledgerId一定大于0，entryId在小于0的情况下代表特殊的数据。如\n\n-0x1000即4096 代表ledger的masterKey\n-0x2000即8192 代表ledger是否被fence\n-0x4000即16384 代表ledger的force\n-0x8000即32768 代表ledger的显示LAC\n\n回放流程当bookkeeper启动的时候，他会从data路径下取得lastMark文件，该文件一定为16个字节，前八个字节代表落盘的最新journal log文件，后八个字节代表文件的位置。会从这个位置开始回放。值得一提的是，lastId文件，代表下一个dataLog该使用什么文件名。\n","tags":["BookKeeper"]},{"title":"Calcite Parser代码生成详解","url":"/2022/09/26/Calcite%20Parser%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90%E8%AF%A6%E8%A7%A3/","content":"本文代码均已上传到giteecalcite的parser代码生成分为如下两个步骤  \n  \n生成Parse.jj文件目录如下\n├── pom.xml└── src    ├── main    │   ├── codegen    │   │   ├── config.fmpp    │   │   ├── includes    │   │   │   ├── compoundIdentifier.ftl    │   │   │   └── parserImpls.ftl    │   │   └── templates    │   │       └── Parser.jj\n\n添加calcite dependency\n&lt;dependency&gt;    &lt;groupId&gt;org.apache.calcite&lt;/groupId&gt;    &lt;artifactId&gt;calcite-core&lt;/artifactId&gt;&lt;/dependency&gt;\n\n\n\n配置drill-fmpp-maven-plugin插件如下\n&lt;plugin&gt;    &lt;groupId&gt;org.apache.drill.tools&lt;/groupId&gt;    &lt;artifactId&gt;drill-fmpp-maven-plugin&lt;/artifactId&gt;    &lt;executions&gt;        &lt;execution&gt;            &lt;configuration&gt;                &lt;config&gt;src/main/codegen/config.fmpp&lt;/config&gt;                &lt;output&gt;$&#123;project.build.directory&#125;/generated-sources/fmpp&lt;/output&gt;                &lt;templates&gt;src/main/codegen/templates&lt;/templates&gt;            &lt;/configuration&gt;            &lt;id&gt;generate-fmpp-sources&lt;/id&gt;            &lt;phase&gt;validate&lt;/phase&gt;            &lt;goals&gt;                &lt;goal&gt;generate&lt;/goal&gt;            &lt;/goals&gt;        &lt;/execution&gt;    &lt;/executions&gt;&lt;/plugin&gt;\n\ncodegen 模块的文件都拷贝自对应版本的calclite core&#x2F;src&#x2F;main&#x2F;codegen路径 https://github.com/apache/calcite/tree/main/core/src/main/codegen\n然后把https://github.com/apache/calcite/blob/main/core/src/main/codegen/default_config.fmpp 中的parser属性与config.fmpp中的parser属性合并。就可以通过mvn package命令生成Parser.jj了。当然，如果有定制化修改的需求，也可以在这个阶段修改config.fmpp  \n  \nParser.jj生成java代码文件目录如下\n├── pom.xml├── src│   ├── main│   │   ├── codegen│   │   │   └── Parser.jj\n\nParser.jj就是我们上一步生成的Parser.jj，如果有什么想要的定制化修改，也可以在这个步骤改入到Parser.jj中。\n添加calcite dependency\n&lt;dependency&gt;    &lt;groupId&gt;org.apache.calcite&lt;/groupId&gt;    &lt;artifactId&gt;calcite-core&lt;/artifactId&gt;&lt;/dependency&gt;\n\n配置javacc-maven-plugin如下\n&lt;plugin&gt;    &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt;    &lt;artifactId&gt;javacc-maven-plugin&lt;/artifactId&gt;    &lt;executions&gt;        &lt;execution&gt;            &lt;id&gt;javacc&lt;/id&gt;            &lt;goals&gt;                &lt;goal&gt;javacc&lt;/goal&gt;            &lt;/goals&gt;            &lt;configuration&gt;                &lt;sourceDirectory&gt;$&#123;project.basedir&#125;/src/main/codegen&lt;/sourceDirectory&gt;                &lt;includes&gt;                    &lt;include&gt;**/Parser.jj&lt;/include&gt;                &lt;/includes&gt;            &lt;/configuration&gt;        &lt;/execution&gt;    &lt;/executions&gt;&lt;/plugin&gt;\n\n生成代码  \n  \n无Parser.jj定制化修改，一步生成如果不需要对Parser.jj进行定制化修改，那么可以通过连续运行两个插件来生成代码，这里给出pom文件样例，不再赘述\n&lt;plugin&gt;    &lt;groupId&gt;org.apache.drill.tools&lt;/groupId&gt;    &lt;artifactId&gt;drill-fmpp-maven-plugin&lt;/artifactId&gt;    &lt;executions&gt;        &lt;execution&gt;            &lt;configuration&gt;                &lt;config&gt;src/main/codegen/config.fmpp&lt;/config&gt;                &lt;output&gt;$&#123;project.build.directory&#125;/generated-sources/fmpp&lt;/output&gt;                &lt;templates&gt;src/main/codegen/templates&lt;/templates&gt;            &lt;/configuration&gt;            &lt;id&gt;generate-fmpp-sources&lt;/id&gt;            &lt;phase&gt;validate&lt;/phase&gt;            &lt;goals&gt;                &lt;goal&gt;generate&lt;/goal&gt;            &lt;/goals&gt;        &lt;/execution&gt;    &lt;/executions&gt;&lt;/plugin&gt;&lt;plugin&gt;    &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt;    &lt;artifactId&gt;javacc-maven-plugin&lt;/artifactId&gt;    &lt;executions&gt;        &lt;execution&gt;            &lt;id&gt;javacc&lt;/id&gt;            &lt;goals&gt;                &lt;goal&gt;javacc&lt;/goal&gt;            &lt;/goals&gt;            &lt;configuration&gt;                &lt;sourceDirectory&gt;$&#123;project.build.directory&#125;/generated-sources/fmpp&lt;/sourceDirectory&gt;                &lt;includes&gt;                    &lt;include&gt;**/Parser.jj&lt;/include&gt;                &lt;/includes&gt;                &lt;lookAhead&gt;2&lt;/lookAhead&gt;                &lt;isStatic&gt;false&lt;/isStatic&gt;            &lt;/configuration&gt;        &lt;/execution&gt;        &lt;execution&gt;            &lt;id&gt;javacc-test&lt;/id&gt;            &lt;phase&gt;generate-test-sources&lt;/phase&gt;            &lt;goals&gt;                &lt;goal&gt;javacc&lt;/goal&gt;            &lt;/goals&gt;            &lt;configuration&gt;                &lt;sourceDirectory&gt;$&#123;project.build.directory&#125;/generated-test-sources/fmpp&lt;/sourceDirectory&gt;                &lt;outputDirectory&gt;$&#123;project.build.directory&#125;/generated-test-sources/javacc&lt;/outputDirectory&gt;                &lt;includes&gt;                    &lt;include&gt;**/Parser.jj&lt;/include&gt;                &lt;/includes&gt;                &lt;isStatic&gt;false&lt;/isStatic&gt;                &lt;ignoreCase&gt;true&lt;/ignoreCase&gt;                &lt;unicodeInput&gt;true&lt;/unicodeInput&gt;            &lt;/configuration&gt;        &lt;/execution&gt;    &lt;/executions&gt;&lt;/plugin&gt;\n","tags":["Calcite"]},{"title":"Gin Web项目最佳实践","url":"/2024/10/29/Gin%20Web%E9%A1%B9%E7%9B%AE%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/","content":"本文包含，Gin项目推荐布局，一些最佳实践等等。\nGin项目推荐布局假设项目名称叫Hearth\n\nxxx、yyy代表大块的业务区分：如用户、订单、支付\naaa、bbb代表小块的业务区分：如(用户的)登录、注册、查询\n\nexample/|-- cmd/|   |-- production/|       |-- hearth.go|   |-- local/|       |-- hearth_local.go|-- pkg/|   |-- apimodel/ 存放所有的ApiModel，用oapi-codegen解析uadp yaml来生成|   |-- boot/|       |-- boot.go //装备Struct，用于Lauch整个项目|   |-- handler/|       |-- xxx/|           |-- xxx_aaa_handler.go|           |-- xxx_bbb_handler.go|       |-- yyy/|           |-- yyy_model.go|           |-- yyy_aaa_handler.go|           |-- yyy_bbb_handler.go|   |-- xxx/|       |-- xxx_aaa_model.go // 存放持久化model，如数据库表，消息中间件结构，redis结构等|       |-- xxx_aaa_service.go|   |-- yyy/|       |-- yyy_bbb_model.go|       |-- yyy_bbb_service.go|   |-- ignite/|       |-- ignite.go|       |-- ignite_test.go|   |-- influx/|       |-- influx.go|       |-- influx_test.go|-- docker-build/|   |-- scripts/|       |-- start.sh|-- Dockerfile\n\n放弃的布局方式此种布局比较适合独立的包，对api结构体的操作复用较差example/|-- cmd/|   |-- production/|       |-- hearth.go|   |-- local/|       |-- hearth_local.go|-- pkg/|   |-- boot/|       |-- boot.go //装备Struct，用于Lauch整个项目|   |-- handler/|       |-- xxx/|           |-- xxx_model.go // 将大块业务的model也放在这里，可以使用oapi-codegen来生成结构体|           |-- xxx_aaa_handler.go|           |-- xxx_bbb_handler.go|       |-- yyy/|           |-- yyy_model.go|           |-- yyy_aaa_handler.go|           |-- yyy_bbb_handler.go|   |-- xxx/|       |-- xxx_aaa_model.go // 存放持久化model，如数据库表，消息中间件结构，redis结构等|       |-- xxx_aaa_service.go|   |-- yyy/|       |-- yyy_bbb_model.go|       |-- yyy_bbb_service.go|   |-- ignite/|       |-- ignite.go|       |-- ignite_test.go|   |-- influx/|       |-- influx.go|       |-- influx_test.go|-- docker-build/|   |-- scripts/|       |-- start.sh|-- Dockerfile\n","tags":["Gin","Go"]},{"title":"GitHub Actions 参考大全","url":"/2023/11/24/GitHub%20Actions%20%E5%8F%82%E8%80%83%E5%A4%A7%E5%85%A8/","content":"通用 GitHub Actionscommit lintname: commit linton:  pull_request:    branches:      - mainjobs:  commitlint:    runs-on: ubuntu-latest    steps:      - uses: actions/checkout@v4      - uses: wagoid/commitlint-github-action@v5\n\nline lintname: line linton:  push:    branches:      - main  pull_request:    branches:      - mainjobs:  build:    name: line lint    runs-on: ubuntu-latest    steps:      - uses: actions/checkout@v4      - name: linelint        uses: fernandrone/linelint@master\n\nGogolangci-lintname: go ci Linton:  push:    branches:      - main  pull_request:    branches:      - mainjobs:  golangci:    name: lint    runs-on: ubuntu-latest    steps:      - uses: actions/checkout@v4      - uses: actions/setup-go@v4        with:          go-version: &#x27;1.21&#x27;      - name: golangci-lint        uses: golangci/golangci-lint-action@v3        with:          version: latest          args: --timeout 3m0s\n\ngo mod checkname: go mod checkon:  push:    branches:      - main  pull_request:    branches:      - mainjobs:  go_mod_check:    runs-on: ubuntu-latest    steps:      - uses: actions/checkout@v4      - name: Run Go Mod Check Action        uses: hezhangjian/go-mod-check-action@main        with:          prohibitIndirectDepUpdate: &#x27;true&#x27;\n\ngo unit testsname: go unit teston:  push:    branches:      - main  pull_request:    branches:      - mainjobs:  go_unit_test:    runs-on: ubuntu-latest    steps:      - uses: actions/checkout@v4      - uses: actions/setup-go@v4        with:          go-version: &#x27;1.21&#x27;      - name: setup OpenGemini        uses: hezhangjian/setup-opengemini-action@main      - name: Run coverage        run: go test ./... -coverpkg=./padmin/... -race -coverprofile=coverage.out -covermode=atomic\n\nJava GitHub Actionsmaven checkstylename: java checkstyleon:  push:    branches:      - main  pull_request:    branches:      - mainjobs:  java_checkstyle:    runs-on: ubuntu-latest    steps:      - uses: actions/checkout@v4      - name: Set up Maven Central Repository        uses: actions/setup-java@v3        with:          java-version: &#x27;17&#x27;          distribution: &#x27;temurin&#x27;      - name: checkstyle        run: mvn -B clean checkstyle:check\n\nmaven spotbugsname: java spotbugson:  push:    branches:      - main  pull_request:    branches:      - mainjobs:  java_spotbugs:    runs-on: ubuntu-latest    steps:      - uses: actions/checkout@v4      - name: Set up Maven Central Repository        uses: actions/setup-java@v3        with:          java-version: &#x27;17&#x27;          distribution: &#x27;temurin&#x27;      - name: spotbugs        run: mvn -B -DskipTests clean verify spotbugs:spotbugs\n\nmaven unit testsname: java unit testson:  push:    branches:      - main  pull_request:    branches:      - mainjobs:  java_unit_tests:    runs-on: ubuntu-latest    steps:      - uses: actions/checkout@v4      - name: Set up Maven Central Repository        uses: actions/setup-java@v3        with:          java-version: &#x27;17&#x27;          distribution: &#x27;temurin&#x27;      - name: unit tests        run: mvn -B clean test\n\nTypeScript GitHub Actionsnpm build testname: npm build teston:  push:    branches:      - main  pull_request:    branches:      - mainjobs:  npm_buid_test:    runs-on: ubuntu-latest    steps:      - uses: actions/checkout@v4      - uses: actions/setup-node@v4        with:          node-version: latest      - run: npm install      - run: npm run build      - name: setup pulsar        uses: hezhangjian/setup-pulsar-action@main      - run: npm run test\n\nprettiername: prettieron:  push:    branches:      - main  pull_request:    branches:      - mainjobs:  prettier:    runs-on: ubuntu-latest    steps:      - uses: actions/checkout@v4      - uses: actions/setup-node@v4        with:          node-version: latest      - run: npm install --save-dev prettier      - run: npm install --global prettier      - run: prettier --check &#x27;**/*.ts&#x27;\n","tags":["GitHub Actions"]},{"title":"Go Http SDK设计","url":"/2023/10/28/Go%20Http%20SDK%E8%AE%BE%E8%AE%A1/","content":"根据Go项目的需求和特性，可以为Go的Http SDK项目选择以下命名方式：\n\nxxx-client-go：如果这个项目只有Http SDK，没有其他协议的SDK，推荐使用这个命名方式。\nxxx-http-client-go：当存在其他协议的SDK时，可以使用这个命名方式，以区分不同协议的SDK。\nxxx-admin-go：当项目使用其他协议作为数据通道，使用HTTP协议作为管理通道时，可以使用这个命名方式。\n\n由于Go语言的调用方式是包名.结构体名.方法名，所以在设计SDK时，需要考虑包名、结构体名、方法名的设计。\n以xxx业务为例，假设业务名为xxx，推荐包名也为xxx，结构体名为Client。\n目录布局可以是这样子的：\nxxx-client-go/|-- xxx/|   |-- client.go\n","tags":["Go","SDK"]},{"title":"Go 项目结构组织","url":"/2023/10/08/Go%20%E9%A1%B9%E7%9B%AE%E7%BB%93%E6%9E%84%E7%BB%84%E7%BB%87/","content":"Web后端项目结构组织要点：\n\n使用model、service，而不是modles、services。差别不大，节约一个字母，更加简洁。\n如果是企业内部的微服务，基本不会、极少把部分的功能以library的形式开放出去，internal目录在这个时候就略显鸡肋，可以省略。\n\n备注:\n\nxxx、yyy代表大块的业务区分：如用户、订单、支付\naaa、bbb代表小块的业务区分：如(用户的)登录、注册、查询\n\n方案一：多业务模块通过文件名区分，不分子包适用于小型项目\n注：handler、model、service要留意方法、结构体、接口的命名，避免冲突\nexample/|-- cmd/|   |-- example-server/|       |-- example-server.go (start gin app, manage handler, middleware)|-- pkg/|   |-- handler/|       |-- aaa_handler.go|       |-- bbb_handler.go|   |-- middleware/|       |-- aaa_middleware.go|       |-- bbb_middleware.go|   |-- model/|       |-- aaa_model.go|       |-- bbb_model.go|   |-- service/|       |-- aaa_service.go|       |-- bbb_service.go|   |-- ignite/|       |-- ignite.go|       |-- ignite_test.go|   |-- influx/|       |-- influx.go|       |-- influx_test.go|-- docker-build/|   |-- scripts/|       |-- start.sh|-- Dockerfile\n\n方案二：多业务模块通过包名区分，但不拆分model和service方案二更适用于由多个小模块组合而成的项目，每个小模块不会太大，复用度较高。\nexample/|-- cmd/|   |-- example-server/|       |-- example-server.go (start gin app, manage handler, middleware)|-- pkg/|   |-- handler/|       |-- xxx/|           |-- xxx_aaa_handler.go|           |-- xxx_bbb_handler.go|       |-- yyy/|           |-- yyy_aaa_handler.go|           |-- yyy_bbb_handler.go|   |-- middleware/|       |-- xxx/|           |-- xxx_aaa_middleware.go|       |-- yyy/|           |-- yyy_bbb_middleware.go|   |-- xxx/|       |-- xxx_aaa_model.go|       |-- xxx_aaa_service.go|   |-- yyy/|       |-- yyy_bbb_model.go|       |-- yyy_bbb_service.go|   |-- ignite/|       |-- ignite.go|       |-- ignite_test.go|   |-- influx/|       |-- influx.go|       |-- influx_test.go|-- docker-build/|   |-- scripts/|       |-- start.sh|-- Dockerfile\n\n方案三：多业务模块通过包名区分，并在下层拆分model和service方案三更适用于由多个大模块组合而成的项目，每个大模块都很大，复用度较低，较少的互相调用。\n方案三在service依赖多个service的情况下，会发生命名冲突。\nexample/|-- cmd/|   |-- example-server/|       |-- example-server.go (start gin app, manage handler, middleware)|-- pkg/|   |-- handler/|       |-- xxx/|           |-- xxx_aaa_handler.go|       |-- yyy/|           |-- yyy_bbb_handler.go|   |-- middleware/|       |-- xxx/|           |-- xxx_aaa_middleware.go|       |-- yyy/|           |-- yyy_bbb_middleware.go|   |-- xxx/|       |-- model/|           |-- xxx_aaa_model.go|       |-- service/|           |-- xxx_aaa_service.go|   |-- yyy/|       |-- model/|           |-- yyy_bbb_model.go|       |-- service/|           |-- yyy_bbb_service.go|   |-- ignite/|       |-- ignite.go|       |-- ignite_test.go|   |-- influx/|       |-- influx.go|       |-- influx_test.go|-- docker-build/|   |-- scripts/|       |-- start.sh|-- Dockerfile\n","tags":["Go"]},{"title":"Java Http SDK设计","url":"/2023/10/27/Java%20Http%20SDK%E8%AE%BE%E8%AE%A1/","content":"Java Http SDK设计根据Java项目的需求和特性，可以为Java的Http SDK项目选择以下命名方式：\n\nxxx-client-java：如果这个项目只有Http SDK，没有其他协议的SDK，推荐使用这个命名方式。\nxxx-http-client-java：当存在其他协议的SDK时，可以使用这个命名方式，以区分不同协议的SDK。\nxxx-admin-java：当项目使用其他协议作为数据通道，使用HTTP协议作为管理通道时，可以使用这个命名方式。\n\nmaven模块设计maven module命名可以叫xxx-client或者xxx-http-client，这通常取决于你的项目是否有其他协议的client，如果没有，那么推荐直接使用xxx-client。\n假设包名前缀为com.xxx，module视图如下:\nxxx-client-java(maven artifactId: xxx-client-parent)/|-- xxx-client-api(接口定义，包名com.xxx.client.api，jdk8+)|-- xxx-client-common/core(核心实现，包名com.xxx.client.common，jdk8+)|-- xxx-client-jdk(基于jdk http client的实现，包名com.xxx.client.jdk，jdk17+)|-- xxx-client-okhttp(基于okhttp的实现，包名com.xxx.client.okhttp，jdk8+)|-- xxx-client-reactor(基于reactor-netty的实现，包名com.xxx.client.reactor，jdk8+)\n\n依赖关系图:\ngraph TD\napi[xxx-client-api]\ncommon[xxx-client-common]\njdk[xxx-client-jdk]\nokhttp[xxx-client-okhttp]\nreactor[xxx-client-reactor]\n\ncommon --> api\n\njdk --> common\nokhttp --> common\nreactor --> common\n\n\n import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs';\tmermaid.initialize({startOnLoad: true, flowchart: {curve: 'linear'}}); ","tags":["SDK","Java"]},{"title":"Java IO 相关类解析","url":"/2017/08/16/Java%20IO%20%E7%9B%B8%E5%85%B3%E7%B1%BB%E8%A7%A3%E6%9E%90/","content":"OutputStreamJava.io.OutputStream类声明了三个基本方法用来把byte数据写入到流中。当然也有用于关闭和刷新的流\npublic abstract void write(int b) throws IOExceptionpublic void write(byte[] data) throws IOExceptionpublic void write(byte[] data, int offset, int length) throws IOExceptionpublic void flush() throws IOExceptionpublic void close() throws IOException\n\nOutputStreams是一个抽象类，子类提供方法的实现。大多数情况下，你只需要知道你处理的对象是一个OutputStream就足够了。OutputStream中最基本的方法是write()\n  public abstract void write(int b) throws IOException这个方法书写了一个无符号byte（0-255），如果你传入了大于255或者小于0的数值，会对256取模直到得到一个合适的值。通常来说，对大量的数据，用byte来传递会更快一些。这正是两个write方法的用途第一个写入整个byte数组。第二个只写入数组的一部分，从offset开始写入length长度的数据。相反地，如果你尝试一次性写入太多的数据，性能上就会出现问题。文件最好一次一次地写入小的块，典型地数值像512，1024，2048.网络连接通常只需要更小的块，128或者256.输出流缓冲区用来提高性能。比起把每一个字节送到它想去的终点，字节们先在内存缓冲区中集合。当缓冲区被填满，数据被传送出去。flush方法强迫缓冲区没有满的时候输出。如果你只使用流很短的时间，你不需要明确地调用flush方法。它应该在流关闭的时候被flush。一旦你关闭了流，你就不能再向其中写入数据，如果你尝试这么做，就会引起IOException.\nInputStreamJava.io.InputStream类声明了三个基本方法用来把byte数据写入到流中。当然也有用于关闭和刷新的流,查看还有多少数据可以读，略过一些输入，在流中标记一个位置然后重置到那个位置，还有决定标记和重设是否是支持的。\npublic abstract int read() throws IOExceptionpublic int read(byte[] data) throws IOExceptionpublic int read(byte[] data, int offset, int length) throws IOExceptionpublic long skip(long n) throws IOExceptionpublic int available() throws IOExceptionpublic void close() throws IOExceptionpublic synchronized void mark(int readLimit)public synchronized void reset() throws IOExceptionpublic boolean markSupported()\n  InputStream中最基本的方法是read,这个方法读入一个无符号的byte类型，然后返回它的整型值。就像大多数的IO方法一样，read方法也会有异常抛出，如果read中无数据可读，你不会受到异常，而是返回-1。用这个作为流结尾的标志。如下的代码展示了如何catch IOException和查看是否为结尾。\ntry&#123;    int[] data = new int[10];    for(int i=0;i&lt;data.length;i++) &#123;        int datum = System.in.read();        if (datum == -1) break;        data[i] = datum;    &#125;&#125; catch (IOException e ) &#123;    System.err.println(&quot;Couldn&#x27;t read from System.in!&quot;);&#125;\n  read方法等待或者阻塞直到byte数据可用而且准备就绪。Input和Output可能会很慢，所以如果你的程序在执行其他重要的事情。你应该把IO操作放在它们自己的线程当中。下面这个类\npublic class StreamPrinter &#123;  InputStream theInput;    public static void main(String[] args) &#123;    StreamPrinter sr = new StreamPrinter(System.in);    sr.print();  &#125;  public StreamPrinter(InputStream in) &#123;    theInput = in;  &#125;    public void print() &#123;    try&#123;      while(true) &#123;        int datum = theInput.read();        if (datum == -1) break;        System.out.println(datum);      &#125;    &#125; catch (IOException e) &#123;      System.err.println(&quot;couldn&#x27;t read from system in&quot;)   &#125;  &#125;&#125;\n  第一个read方法读入一批连续数据到byte数组中，第二个尝试读入一定长度的data从offset开始到byte数组。它们两个都不保证读入任意数量的byte。  如果你打算从System.in读入10byte的数据，如下的代码可以完成操作：\nbyte[] b = new byte[10];System.in.read(b);\n  但是，并不是每次read都可以拿到你想要的那么多数据。但是这行代码也不能阻止你试图往read中写入超过容量的数据，如果你这么做了，就会导致ArrayIndexOutOfBoundsException.  如下的代码利用循环，确保尽可能多得获得数据：\nbyte[] b = new byte[100];int offset = 0;while(offset &lt;b.length) &#123;  int bytesRead = System.in.read(b, offset,b.length-offset);  if(bytesRead==-1) break;  offset+=bytesRead;&#125;\n  尽管上述的代码可以尽可能多得获取数据，但是并不能规避异常的发生。所以，如果在你尝试读它们之前，你可以知道有多少数据将要被读，这将会非常方便。InputStream中的available方法可以告诉你答案  你可以手动操作代码来忽略掉一部分的数据，但JAVA还是提供了skip方法用来跳过给定byte数的方法\npublic long skip(long bytesToSkip) throws IOException\n  返回值是实际略去的byte数。如果返回-1，则证明剩下的部分都被忽略了。通常来说skip方法比自己手动忽略要快。  并不是所有的流都需要被关闭，比如System.in。但是跟文件或者网络相关的连接还是需要被关闭的。\nFileInputStreamjava.io.FileInputStream是InputStream的具体实现，提供具体文件的输入流\npublic class FileInputStream extends InputStream\n  FileInputStream 实现了InputStream的常用方法\npublic int read() throws IOExceptionpublic int read(byte[] data) throws IOExceptionpublic int read(byte[] data, int offset, int length) throws IOExceptionpublic native long skip(long n) throws IOExceptionpublic native int available() throws IOExceptionpublic native void close() throws IOException\n  这些方法都是Java Native Code，除了read方法，但这些方法还是把参数传给了native方法。所以实际上，这些方法都是Native方法。  FileInputStream有三种构造方法，区别在于文件是如何指定的：\npublic FileInputStream(String fileName) throws IOExceptionpublic FileInputStream(File file) throws FileNotFoundExceptionpublic FileInputStream(FileDescriptor fdObj)\n  第一个构造函数使用文件的名称，文件的名称跟平台相关，所以硬编码文件名不是一个好的方案，相比之下，后两个就要好很多。  读取文件，我们只需要把文件名称传递给构造函数。然后像平常那样调用read方法即可。\nFileInputStream fis = new FileInputStream(&quot;README.TXT&quot;);int n;while ((n=fis.available())&gt;0) &#123;  byte[] b = new byte[n];  int result = fis.read(b);  if( result == -1) break;  String s = new String(b);  System.out.print(s); &#125;\n  Java在当前的工作路径寻找文件，通常来说，就是你键入java programName时的路径。在FileInputStream的构造函数中传入相对路径和绝对路径都是可行的。  如果你试图打开一个并不存在的文件，就会抛出FileNotFoundException。如果因为其他原因无法写入（比如权限不足）其他类型的异常会被抛出。下面是一个通过控制台获取文件名，然后把文件打印到控制台的例子\npublic class FileTyper &#123;  public static void main(String[] args) &#123;    if(args.length==0) &#123;      System.err.println(&quot;no file is determined&quot;);      return;    &#125;    for (int i=0;i&lt;args.length;i++) &#123;      try&#123;        typeFile(args[i]);        if(i+1&lt;args.length) &#123;          System.out.println();          System.out.println(&quot;--------&quot;);        &#125;       &#125; catch (IOException e) &#123;System.err.println(e);&#125;      &#125;  &#125;  public static void typeFile(String filename) throws IOException &#123;    FileInputStream fin = new FileInputStream(filename);    StreamCopier.copy(fin,System.out);    fin.close();  &#125;&#125;\n  如果需要的话，你也可以对同一个文件同时打开多个流。每一个流维护一个单独的指针，指向文件中的当前位置。读取文件并不会更改文件，如果是写文件的话，那就是另一回事了。\nFileOutputStream  java.io.FileOutputStream是java.io.OutputStream的具体实现,提供连接到文件的输出流。\npublic class FileOutputStream extends OutputStream\n  类中实现了OutputStream的所有常用方法\npublic native void write(int b) throws IOExceptionpublic void write(byte[] data) throws IOExceptionpublic void write(byte[] data, int offset, int length) throws IOExceptionpublic native void close() throws IOException\n  跟之前的FileInputStream相同，FileOutputStream的四个方法也都是实际上的native方法。如下的三种构造器，区别在于文件是如何指定的:\npublic FileOutputStream(String filename) throws IOExceptionpublic FileOutputStream(File file) throws IOExceptionpublic FileOutputStream(FileDescriptor fd)\n  和FileInputStream不同的是，如果指定的文件不存在，那么FileOutputStream会创建它，如果文件存在，FileOutputStream会覆盖它。这个特性让我们使用的时候有些不太方便，有的时候，往往我们需要往一个文件里面添加一些数据，比如向日志文件里面存储记录。这时候，第四个构造函数就体现了它的作用\npublic FileOutputStream(String name, boolean append) throws IOException\n  如果append设置为true，那么如果文件存在，FileOutputStream会向文件的末尾追加数据，而不是覆盖。  下面的程序获取两个文件名作为参数，然后把第一个文件复制到第二个文件：\npublic class FileCopier &#123;  public static void main(String[] args) &#123;    if(args!=2) &#123;      System.err.println(&quot;error input&quot;);//输入异常。      return;    &#125;    try &#123;      copy(args[0],args[1]);//调用复制文件的方法    &#125; catch (IOException e) &#123;System.err.println(e);&#125;  &#125;  public static void copy (String inFile, String outFile) throws IOException &#123;    FileInputStream fin = null;    FileOutputStream fout = null;    try&#123;      fin = new FileInputStream(inFile);      fout = new FileOutputStream(outFile);      StreamCopier.copy(fin,fout);    &#125;    finally &#123;      try &#123;        if (fin != null) fin.close();      &#125; catch (IOException e) &#123;&#125;      try &#123;        if (fout != null) fout.close();      &#125; catch (IOException e) &#123;&#125;  &#125;&#125;public class StreamCopier &#123;  public static void copy(InputStream in,OutputStream out) throws IOException &#123;    //Do not allow other threads read from the input or write the output    synchronized (in) &#123;      synchronized (out) &#123;        byte[] buffer = new byte[256];        while(true) &#123;          int bytesRead = in.read(buffer);          if(bytesRead == -1) break;          out.write(buffer,0,bytesRead);        &#125;      &#125;  &#125;&#125;\n\nURLSjava.net.URL类是标准资源定位符。每一个URL明确地指定了因特网上一个资源的位置。URL有四个构造函数，每一个都声明了MalformedURLException\npublic URL(String u) throws MalformedURLExceptionpublic URL(String protocol, String host, String file) throws MalformedURLExceptionpublic URL(String protocol, String host, int port, String file) throws MalformedURLExceptionpublic URL(URL context, String u) throws MalformedURLException\n  如果构造器没有给定一个URL，MalformedURLException会被抛出。如果给你一个绝对的URL比如”http://www.jianshu.com/u/9e21abacd418&quot;,你会这样构造一个URL对象:\nURL u = null;try &#123;  u = new URL(&quot;http://www.jianshu.com/u/9e21abacd418&quot;);&#125; catch (MalformedURLException e)　&#123;&#125;\n  你也可以把协议，host和路径分开传入\nURL u = null;try &#123;  u = new URL(&quot;http&quot;,&quot;www.jianshu.com&quot;,&quot;/u/9e21abacd418&quot;);&#125; catch (MalformedURLException e)　&#123;&#125;\n  一般情况下，你不需要特地指定协议的端口，大多数协议有他们默认的端口，比如HTTP的协议的默认端口是80.如果端口改变了，可以使用下面的构造方法:\nu = new URL(&quot;http&quot;,&quot;www.jianshu.com&quot;,8080,&quot;/u/9e21abacd418&quot;);\n  一旦URL对象被构造，有两种方式获得它的内容。openStream()方法返回原始的数据流，getContent()方法返回一个对象代表数据。当你调用getContent()方法的时候，JAVA根据它的MIME类型，寻找一个content handler，然后返回一个可用的数据对象。  openStream()方法和URL代表的服务器和端口建立了一个Socket连接，返回一个可以获取数据的InputStream，允许你从服务器上下载数据。所有的头文件，跟数据无关的东西在流打开的时候都被跳过了。\npublic final InputStream openStream() throws IOException\n  使用reader或者InputStream来获取数据:\ntry &#123;  URL u = new URL(&quot;http://www.amnesty.org/&quot;);  InputStream in = u.openStream();  int b;  while ((b = in.read()) != -1) &#123;    System.out.write(b);  &#125; &#125;catch (MalformedURLException e) &#123;System.err.println(e);&#125;  catch (IOException e) &#123;System.err.println(e);&#125;\n\nUrlConnectionURL Connection和URL有着密切的联系，就像名字一样。你通过URL的openConnection()方法得到一个URL Connection的引用。在大多数情况下，URL只是对URL Connection对象的一种封装。然而URL提供了更多的控制。\n  URL Connection不仅仅提供了让客户端读取服务器上信息的能力，而且提供了OutputStream使得，客户端的文件可以发送向服务器。\n  java.net.URLConnection类是一个处理多种不同类型服务器的抽象类，比如FTP服务器和web服务器。  一.从URL Connection中读取数据  1.构造URL对象  2.通过openConnection()方法创建一个URLConnection对象  3.连接的参数和需要的属性已经设置完毕  4.使用connect()方法建立连接，可能是使用socket的网络连接，也可能是文件读入流的本地连接。响应的头部信息从服务器传入。  5.使用InputStream来读取数据，或者使用相应(MIME 类型)content handler的getContent()方法。  举个如下的例子:\npublic class Main &#123;    public static void main(String[] args) throws IOException &#123;        URL url = new URL(&quot;http://www.huawei.com&quot;);        URLConnection uc = url.openConnection();        uc.connect();        InputStream in = uc.getInputStream();        //...after operation        //close the stream        in.close();    &#125;&#125;\n  如果连接无法被建立，会抛出一个IOException。\n  二.向URL中写入数据    1.构造URL对象    2.通过openConnection()方法创建一个URLConnection对象    3.调用setDoOutput(boolean doOutput)方法并传入true表明这个连接会被用于写入数据    4.如果你仍然想从InputStream中读取数据，调用setDoInput(boolean doInput)方法并传入true表明这个连接会被用于读取数据    5.创建你想要写入的数据    6.调用getOutputStream拿到OutputStream对象。把第5步中的数据写入其中    7.关闭输出流\n  下面是一个例子:\npublic class MailClient &#123;  public static void main(String[] args) &#123;    if (args.length == 0) &#123;      System.err.println(&quot;Usage: java MailClient username@host.com&quot;);      return;    &#125;    try &#123;      URL u = new URL(&quot;mailto:&quot; + args[0]);      URLConnection uc = u.openConnection();      uc.setDoOutput(true);      uc.connect();      OutputStream out = uc.getOutputStream();      StreamCopier.copy(System.in, out);      out.close();     &#125;    catch (IOException e) &#123;System.err.println(e);&#125;  &#125;&#125;\n\nSockets在数据在互联网中从一个主机到另一个主机的传递之时，它被分割成大小不同但是有限的数据包中(datagrams)。如果要发送的数据大于了数据包的最大大小，它就会被分割成数个包发送，这样做的好处是，如果其中有一个包丢失，那么只需要重传一个包，而不必把所有的包重传。如果包抵达的顺序不同，也会在接收点重新组转完毕。\n这一操作对程序员来说是透明的，我们工作在高层抽象的socket上。socket提供了两个主机之间可靠地连接。这样子，你就不需要考虑数据包的编码， 数据包的分割，数据包的重传或者是数据包的组装。Scoket提供这四种基本操作:\n1.远程连接到一个机器2.发送数据3.接收数据4.关闭连接\njava.net.socket是一个network socket提供了这四种基本操作。在这四种操作中，没有一个抽象了协议，这个类就是为了网络客户端和服务器的连接设计的。为了创建一个连接，你调用socket构造函数中的一种。每一个socket对象仅仅连接到一个指定的远程主机。如果要连接到不同的主机，你必须创建一个新的socket对象：\npublic Socket (String host, int port) throws UnknownHostException, IOExceptionpublic Socket(InteAddress address, int port) throws IOExceptionpublic Socket(String host, int port, InetAddress localAddr, int localPort) throws IOExceptionpublic Socket(InetAddress address, int port, InetAddress localAddr, int localPort) throws IOException\n\nhost可以是像“"},{"title":"Java NIO 解析","url":"/2017/08/18/Java%20NIO%20%E8%A7%A3%E6%9E%90/","content":"NIO 主要概念介绍1.Buffers(缓冲区)Buffer类是常规JAVA类和channels(管道)之间的通道。Buffer包含固定长度的数组中，数组中存放着原始数据，封装在一个包含状态的对象中。管道可以消耗缓冲区的数据，也可以向缓冲区中存入数据。此外，还有一种特殊类型的缓冲区，用于内存映射文件。\n2.Channels(通道)NIO中引入的最抽象的概念就是Channel。通道对象代表着通信连接。通信连接可以是单向的，也可以是双向的。可以理解成缓冲区和IO设备之间的道路。\n一些java.io中的旧类也可以使用channel。为了和使用通道的文件，socket连接，或多或少地添加了新方法\n大多数通道可以工作在非块模式下，有很好的可扩展性，尤其是在和Selectors(选择器)同时使用的时候。\n3.File locking and memory-mapped files(文件锁和内存映射文件)FileChannel对象提供许多面向文件的功能。比如文件锁这个进程之间处理数据必不可少的功能。把内存映射到文件，在你看来，文件就像是在内存之上一样，省去了把文件拷贝到内存的操作。\n4.SocketsSocketChannel 提供了一种和网络套接字新的交互方法，SocketChannel可以工作在非阻塞模式可以用来和Selectors一起工作。作为结果，许多scoket可以多路传输，比起java.net里的传统socket类更高效\n5.SelectorsSelectors提供准备就绪选择(查看channel是否准备就绪)。也可以确定你感兴趣的Channel。通过使用Selector，大量的活动中的I&#x2F;O channel 可以被一个线程简单有效地监控操作。\n6.Character sets(字符集)提供了多种从byte流映射到字符的方式。\nBufferBuffer即缓冲区，是包含有一定量数据的容器。Buffer的工作和Channel有着紧密的联系。Channel是I&#x2F;O的出入口，buffer就是IO的来源或者目标。要向外传输数据，把数据存放在buffer中交给channel要接受数据，提供buffer让channel写入。\n\nCapacity  Buffer可以包含的最大字节数。当Buffer创建的时候，容量被设置而且不可更改\nLimit  Buffer中的第一个元素，这个元素不应该被读或者是被写。包含着在buffer中“存活”的数据个数\nPosition  下一个被操作的数据的位置。put和get操作会更新position的位置\nMark  一个有记忆的位置，设置了mark，之后可以回退到标记点，重新进行操作。\n新创建一个大小为10的Buffer，概念中可以理解成是这样的\n\n下面是Buffer的方法签名\npublic abstract class Buffer&#123;  public final int capacity()  public final int position()  public final Buffer position (int newPosition)  public final int limit ()  public final Buffer limit(int newLimit)  public final Buffer mark()  public final Buffer reset()  public final Buffer clear()  public final Buffer flip()  public final Buffer rewind()  public final int remaining()  public final boolean hasRemaining();  public abstract boolean isReadOnly();&#125;\n你可能会觉得有一些方法应该返回空值，但是却返回了buffer对象，这是为了构建一个流式的API。比如像这样的代码 buffer.mark();buffer.position(5);buffer.reset()//就可以写成下面这样buffer.mark().position(5).reset();所有的buffer都是可读的，但并不是所有的buffer都支持写操作，通过isReadOnly方法判断是否可以写，如果你试图向不支持写操作的buffer中写入数据，会抛出ReadOnlyBufferException异常。\nBuffer管理着给定数目的数据元素。但是在大多数情况下，我们只关心其中的一部分数据。就像是，当我们想要向池子里倒水时，水盆里的水，只盛了一半。但我们需要追踪一些信息，buffer中已经有的数据，下一个处理哪个数据？position属性负责处理这个信息。当处理put（向buffer中写入数据）或者get方法（从buffer中获取数据）的时候，position就会更新。\n尽管在JAVA NIO BUFFER（一）中，列表中没有put和get方法。但是每个Buffer都包含这两个方法，因为每个buffer的实现不同，需要处理不同的数据类型，没法被声明为抽象方法(nio在jdk1.4被引入，泛型是1.5)。我们用ByteBuffer作为例子，来看这两个方法的声明\npublic abstract class ByteBuffer extends Buffer implements Comparable &#123;  //列出了一部分api  public abstract byte get();  public abstract byte get(int index);  public abstract ByteBuffer put(byte b);  public abstract ByteBuffer put(int index, byte b);&#125;\n\n如果不指定具体的位置，put和get就会操作在现有的position属性上，并将position加1。如果超出了capacity。如果是读操作就会抛出BufferOverflowException,写操作就会BufferUnderflowException.如果是任意操作，也会抛出一个IndexOutOfBoundsException.\n让我们试着对ByteBuffer中写入数据，如果执行下面的命令，JAVA NIO BUFFER（一）中的概念图，就会变成如下的样子。\nbuffer.put((byte)&#x27;H&#x27;).put((byte)&#x27;e&#x27;).put((byte)&#x27;l&#x27;).put((byte)&#x27;l&#x27;).put((byte)&#x27;o&#x27;);\n\n\n猜一猜，如果执行这个命令\nbuffer.put(0,(byte)&#x27;M&#x27;).put((byte)&#x27;w&#x27;);\n会变成什么样子？\n\n会变成这样！，第一个把0位置的H替换为M，然后紧接着的put操作查看到了position在5位置，把5位置写入W,然后position自加变为6.\n我们准备好了Buffer，现在我们要将它交由Channel处理。现在假设我们填满了一个Buffer，emmmm，然后把它传给Channel对象，Channel对象对buffer调用get方法，然后position自加，会怎么样？IndexOutOfBoundsException被抛出了！\n那怎么办？为了让Channel能够处理对象，我们需要把postion重设为你希望它开始处理的位置，顺便再设置limite为现在存储的位置，假设我们需要Channel从头开始处理对象，那么就应该做如下的处理:\nbuffer.limit(buffer.position()).position(0);//上面的调用，等同于如下的方法buffer.flip();\n然后概念图就会变成下面这样:JAVA NIO BUFFER（一）中提到的rewind()方法，只把position设置为0，并不影响limit的位置。\n进行完这个操作之后，你就可以试着读取里面的数据\n//利用hasRemaining()方法判断Buffer中是否还有数据for(int i=0;buffer.hasRemaining();i++) &#123;  myByteArray[I]=buffer.get();&#125;//上面的方法未必高效，循环体中每次循环都要进行一次判断//你可以使用remaining()方法，返回剩余的数目int count = buffer.remaining();for(int i=0;buffer.count;i++) &#123;  myByteArray[I]=buffer.get();&#125;//如果你对Buffer有着惊人的控制，那么不进行数据检查将会是最快的\n一旦Buffer使用完毕，它就可以进行复用，clear()方法把一个Buffer重置到一个空的状态。它不更改任何数据，把limit设置为capacity，并把position设置为0.至于里面是不是还有数据？这不重要，Buffer仅仅通过position来判断数据的“死活”为什么一定要将数据置空，这些操作难道不需要时间吗？下面的例子使用到了一些buffer的基本操作:\npublic class BufferFillDrain &#123;    //原代码作者 Ron Hitchens (ron@ronsoft.com)    private static int index = 0;    private static String[] strings = &#123;            &quot;Hello, this is ZhangJian&quot;,            &quot;He likes Eminem&quot;,            &quot;Put the dick in the dust&quot;,            &quot;And? Fuck the world?&quot;,            &quot;Lyrics are great&quot;,            &quot;But what I like more&quot;,            &quot;is the spirit&quot;    &#125;;    public static void main(String[] args) throws Exception &#123;        CharBuffer buffer = CharBuffer.allocate(100);        while( fillBuffer(buffer)) &#123;            buffer.flip();            drainBuffer(buffer);            buffer.clear();        &#125;    &#125;    private static void drainBuffer (CharBuffer buffer) &#123;        while (buffer.hasRemaining()) &#123;            System.out.print(buffer.get());        &#125;        System.out.println(&quot;&quot;);    &#125;    private static boolean fillBuffer(CharBuffer buffer) &#123;        if(index &gt;= strings.length) &#123;            return false;        &#125;        String string = strings[index++];        for(int i=0;i&lt;string.length();i++) &#123;            buffer.put(string.charAt(i));        &#125;        return true;    &#125;&#125;\n\n有一些情况，你只想把Buffer的一部分输出，然后下次再接着操作，下次操作的时候下标也要从0开始。这么做的话，就必须将未读的数据左移至开头，这样做毫无疑问是低效率的，如果一定要这么做的话，Buffer提供了compact方法\nbuffer.compact();\n假设你输出了两个字符那么现在概念图就会变成这样:\n然后你调用了compact方法\n4，5都会保持不变，还是同样的道理，Buffer不会做那些看上去合理但并没有用的操作。\nMark方法，允许buffer记下一个位置，如果reset被调用，那么position会转移到mark的位置。如果在mark还未指定的情况下调用reset，会抛出InvalidMarkException。如果你调用一些buffer方法，mark标记会被丢弃，比如rewind，clear和flip。如果调用带参数的limit或者position方法，如果该参数值在mark标记之前，那么mark也会废弃。\n设计buffer的目标是为了有效的数据交换，在循环中依次移动数据非常地没有效率。如下列出了CharBuffer中大量移动数据的API\npublic abstract class CharBuffer extends Buffer implements CharSequence,Comparable &#123;  //这只是方法的一部分  public CharBuffer get (char[] dst)  public CharBuffer get(char[] dst, int offset, int length)  public final CharBuffer put (char[] src)  public CharBuffer put(char[] src, int offset, int length)  public CharBuffer put(char[] src)    public final CharBuffer put(String src)  public CharBuffer put(String src, int start, int end)\n两种方式从数组中复制数据。第一个方法，只携带一个数组作为参数。第二个携带偏移量和长度两个参数指定子数组。虽然最终这个和循环移动的结果相同，但是这种方式往往更加有效，因为通常这些方法都会优化移动数据或者调用native代码。\n如果你要求的数据们无法被转移，那么会抛出BufferUnderflowException.或者你要求的参数，buffer无法全部填充，也会抛出异常。在尝试获取数据之前，你应该先判断一下容量是否充足：\nchar[] bigArray = new char[1000];//获取buffer剩余输出int length = buffer.remaining();//如果length不够填充整个数组buffer.get(bigArray,0,length);processData(bigArray,length);\n但是如果buffer持有的数据大于了你的数组，你可以这么做:\nchar[] smallArray = new char[10];while (buffer.hasRemaining()) &#123;    int length = Math.min(buffer.remaining(), smallArray.length);    buffer.get(smallArray, 0, length);    processData(smallArray, length);&#125;\n\nbuffer的put方法，如果buffer有空间存放这些数据，数据就会从现在buffer的position中开始写入，并且更新buffer的position值。如果空间不足，不会有任何数据写入，并抛出BufferOverflowException。\n当然buffer的put方法也可以直接传入一个buffer作为参数，这和下面的操作等价:\ndstBuffer.put(srcBuffer) 等价于 dstBuffer.put(srcBuffer.get());\n\n如果是以String为参数的put方法，和charArray类似。尽管String并不是char的集合，但我们倾向于把String概念化为char的集合。\n在JAVA NIO BUFFER（一）看到了七个基本的buffer类，我们以CharBuffer为例。来看看如何创建一个CharBuffer对象:\npublic abstract class CharBuffer extends Buffer implements CharSequence, Comparable &#123;  public static CharBuffer allocate (int capacity)    public static CharBuffer wrap(char[] array)  public static CharBuffer wrap(char[] array, int offset, int length)  public final boolean hasArray()  public final char[] array()  public final int arrayOffset()&#125;\n通过包装或者分配都可以构造一个新的Buffer对象，分配方式创建了一个Buffer对象并且给它分配了私人空间。包装方式创建了一个Buffer对象但是没有给它分配私人空间(就使用你传递给它的数组参数)\n//分配一个CharBuffer可以容纳100个字符CharBuffer charBuffer = CharBuffer.allocate(100);//如果你想要使用你自己的数组char[] myArray = new char[100];CharBuffer charBuffer = CharBuffer.wrap(myArray);\n\n那么你觉得如下的代码会怎么样呢\nCharBuffer charBuffer = CharBuffer.wrap(myArray,12,42);\n会分配一个大小为30的数组给你操作？\n不是，假如myArray的长度是100，CharBuffer还是掌控着长度为100的数组，只是初始的position为12，limit为42.而后面要提到的slice方法可以生成一个只能够操作给定范围的CharBuffer。\n通过allocate或者wrap生成的buffer是不直接的。不直接的buffer包含有着数组。hasArray方法告诉你是否存在数组，如果这个方法返回true，那么array方法就会返回给你这个数组的引用。如果返回false，不要调用array或者arrayOffset方法，否则就会抛出UnsupportedOperationException.\n如果Buffer是只读的，就算它是通过wrap数组方法生成的，调用它的array或者arrayOffset方法也会抛出ReadOnlyBufferException 防止你通过数组修改只读数据。\n通过数组的形式存储数据，可以实现Buffer的功能，进而创建Buffer对象，但是Buffer可不仅仅只能通过数组才能实现。Buffer还可以管理其它buffer的数组。一旦这么做，就是一个view buffer对象。大多数view buffers是bytebuffers的视图。\nView Buffers通常通过调用已经存在buffer的方法生成。创建的view buffer不仅可以通过get，put方法操作原有的buffer，而且如果原来的buffer是直接的，view buffer也可以得到同样的性能优势。以CharBuffer为例，查看它的相关方法声明:\npublic abstract class CharBuffer extends Buffer implements CharSequence, Comparable &#123;  public abstract CharBuffer duplicate();  public abstract CharBuffer asReadOnlyBuffer();  public abstract CharBuffer slice();&#125;\nduplicate方法创建了一个跟原来相似的新的buffer。两个buffer共享数据，有相同的容量，但是两个buffer独自管理自己的position，limit和mark。对数据的更改会反应在两个buffer之上。\n你也可以通过asReadOnlyBuffer来创建一个只读的CharBuffer，大部分和duplicate相同，新的buffer会禁用put方法，而且它的isReadOnly方法会返回true。如果试图破坏这个CharBuffer的只读属性，会抛出ReadOnlyBufferException，值得一提的是，对数据元素的更改也会反应在只读的CharBuffer上。\nslice方法跟duplicate方法也很相似，但是slice方法返回的是一部分，下图说明一个原本大小为8的CharBuffer被slice之后，生成的新CharBuffer的属性\nCharBuffer buffer = CharBuffer.allocate(8);buffer.position(3).limit(5);CharBuffer sliceBuffer = buffer.slice();\n\n这些方法都不会对mark属性进行操作。\n除了布尔类型，其他基本类型都有自身的Buffer类，但是byteBuffer还有不少其他特性。操作系统和他的IO设备来看，byte是最基本的数据单元。需要把其他类型的数据转化为bytes来操作。为了方便参阅，这里列出来了ByteBuffer的完整API。\npublic abstract class ByteBuffer extends Buffer implements Comparable &#123;  public static ByteBuffer allocate (int capacity)  public static ByteBuffer allocateDirect (int capacity)  public abstract boolean isDirect(  );  public static ByteBuffer wrap (byte[] array, int offset,int length)  public static ByteBuffer wrap (byte[] array)  public abstract ByteBuffer duplicate(  );  public abstract ByteBuffer asReadOnlyBuffer(  );  public abstract ByteBuffer slice(  );  public final boolean hasArray(  )  public final byte [] array(  )  public final int arrayOffset(  )  public abstract byte get(  );  public abstract byte get (int index);  public ByteBuffer get (byte[] dst, int offset, int length)  public ByteBuffer get (byte[] dst, int offset, int length)  public abstract ByteBuffer put (byte b);  public abstract ByteBuffer put (int index, byte b);  public ByteBuffer put (ByteBuffer src)  public ByteBuffer put (byte[] src, int offset, int length)  public final ByteBuffer put (byte[] src)  public final ByteOrder order(  )  public final ByteBuffer order (ByteOrder bo)  public abstract CharBuffer asCharBuffer(  );  public abstract ShortBuffer asShortBuffer(  );  public abstract IntBuffer asIntBuffer(  );  public abstract LongBuffer asLongBuffer(  );  public abstract FloatBuffer asFloatBuffer(  );  public abstract DoubleBuffer asDoubleBuffer(  );  public abstract char getChar(  );  public abstract char getChar (int index);  public abstract ByteBuffer putChar (char value);  public abstract ByteBuffer putChar (int index, char value);  public abstract short getShort(  );  public abstract short getShort (int index);  public abstract ByteBuffer putShort (short value);  public abstract ByteBuffer putShort (int index, short value);  public abstract int getInt(  );  public abstract int getInt (int index);  public abstract ByteBuffer putInt (int value);  public abstract ByteBuffer putInt (int index, int value);  public abstract long getLong(  );  public abstract long getLong (int index);  public abstract ByteBuffer putLong (long value);  public abstract ByteBuffer putLong (int index, long value);  public abstract float getFloat(  );  public abstract float getFloat (int index);  public abstract ByteBuffer putFloat (float value);  public abstract ByteBuffer putFloat (int index, float value);  public abstract double getDouble(  );  public abstract double getDouble (int index);  public abstract ByteBuffer putDouble (double value);  public abstract ByteBuffer putDouble (int index, double value);  public abstract ByteBuffer compact(  );  public boolean equals (Object ob);  public int compareTo (Object ob);  public String toString(  );  public int hashCode(  );&#125;\n除了boolean类型之外，byte占1个byte，char两个，short两个，int四个，long八个，float四个，double八个。虽然这些字节一定是按照顺序的，但是也有大端和小端之分。(指的是连续的内存单元，先放高字节，还是先存放低字节)在java.nio中，字节顺序由ByteOrder这个类来封装\npublic final class ByteOrder &#123;  public static final ByteOrder BIG_ENDIAN  public static final ByteOrder LITTLE_ENDIAN  public static ByteOrder nativeOrder()  public String toString()&#125;\n这个类定义了两个自己实例的公共域，在JVM中，只有这两个实例，所以要比较的话，可以使用&#x3D;&#x3D;。如果你需要知道JVM上的字节顺序，调用nativeOrder方法。\n每一个buffer类都可以通过order方法知悉自己现在的字节顺序设置\npublic final ByteOrder order()\n返回ByteOrder的两个实现之一，但和ByteBuffer不同，这个返回的对象只是可读的。ByteBuffer的默认字节顺序是大根端(无论运行在什么字节顺序的平台上),Java的默认字节顺序也是大根端，允许类文件，序列化的对象运行在任何JVM上。如果本地的硬件设备是小根端的话，这可能会有着性能的影响。把ByteBuffer作为其他数据类型接受的时候，使用本地的字节顺序会更有效。\nByteBuffer的字节顺序可以通过order方法改变\npublic final ByteOrder order()public final ByteOrder order(ByteOrder bo)\n如果buffer被创建为ByteBuffer的一个视图，那么order返回的就是当这个buffer创建时，原来的buffer的字节顺序，即使原来的buffer改变字节顺序，buffer的字节顺序也不会改变。\nByteBuffer和其他Buffer不同的是，它们可以作为Channel(通道)操作的起点或者终点。通道只接受ByteBuffer作为参数。\n操作系统在内存区中进行IO操作，这些内存区域就是连续的byte。操作系统会直接进入进程的地址空间来转移数据。也就是说内存区的数据最好是连续的字节数。但是在JVM中，字节数组并不一定存储在连续的内存区域，GC可能会移动它们。如何存储数组，根据JVM的实现还有很大的区别。\n因为这个原因，引入了direct buffer这一概念，direct buffer来处理通道和本地IO操作。尽最大努力把byte数据存储在一个channel可以直接使用的或者可以直接由本地方法通知操作系统，操作系统直接操作的内存区域。\n这往往是IO最高效的选择，支持JVM能支持的最高效IO机制。非直接的Buffer也可以传递给channel，但是会导致性能的损失。通常情况下，非直接的buffer是不可能作为本地IO操作的目标的。如果你将一个非直接buffer传递给channel操作，channel可能会做如下的操作  1.创建一个临时的direct ByteBuffer对象  2.把非直接的ByteBuffer中的内容拷贝到1创建的对象中  3.利用临时对象进行低等级的IO操作  4.临时对象使用完毕，等待GC回收\n创建DirectBuffer的代价可能会更高，DirectBuffer使用的内存是越过JVM，直接由本地代码分配的。而且DirectBuffer使用的内存无法被垃圾回收，因为它们在JVM堆之外。\npublic abstract class ByteBuffer extends Buffer implements Comparable &#123;  public static ByteBuffer allocate(int capacity)  public static ByteBuffer allocateDirect(int capacity)  public abstract boolean isDirect();&#125;\n调用allocateDirect方法来创建一个DirectBuffer。那些根据wrap方法创建的buffer，总是非直接的(non-direct)。\nChannelChannels是java.nio的第二个主要创新，提供了跟IO服务的直接连接。Channel是bytebuffer，文件，或者socket之间传输数据的导管。Channel提供了平台无关的抽象，但仍然可以比拟现代操作系统上native代码的IO能力。\npublic interface Channel &#123;  public boolean isOpen();  public void close() throws IOException;&#125;\n跟buffer不同，channel的实现在不同的操作系统上差距很大，所以channel只定义为一个接口，描述它可以做什么。通常情况下用native方法实现。只有两个方法，一个用来判断通道是否处于打开状态，一个用于关闭通道。\nInterruptibleChannel是一个标记接口，代表这个通道是可中断的，可中断的通道在运行它们的线程中断时有特殊的特性。\nIO分为两个大类，文件IO和流IO。通道也分为，文件通道和socket通道。Socket通道有工厂方法可以直接创建。但是一个文件通道不能够直接创建，只能够通过调用RandomAccessFile,FileInputStream,FileOutputStream的getChannel方法。你不能够直接创建一个FileChannel对象\nSocketChannel sc = SocketChannel.open();sc.connect(new InetSocketAddress(&quot;some host&quot;,someport));ServerSocketChannel ssc = new ServerSocketChannel().open();ssc.socket().bind(new InetSocketAddress(somelocalport));DatagramChannel dc = DatagramChannel.open();RandomAccessFile raf = new RandomAccessFile(&quot;somefile&quot;,&quot;r&quot;);FileChannel fc = raf.getChannel();\n\n先看如下的API\npublic interface ReadableByteChannel extends Channel &#123;  public int read (ByteBuffer dst) throws IOException;&#125;public interface WritableByteChannel extends Channel &#123;  public int write(ByteBuffer src) throws IOException;&#125;public interface ByteChannel extends ReadableByteChannel, WritableByteChannel &#123;&#125;\n通道可以是双向的也可以是单向的。根据需要实现这三个接口中的一个。\n通道的read(),write()方法都以ByteBuffer作为参数，每个都返回操作了的字节数，并更新ByteBuffer中的position属性。下面的例子展示了使用channel进行putget的基本操作\npublic static final int BUFFER_SIZE = 16*1024;public static void main(String[] args) throws IOException &#123;    ReadableByteChannel source = Channels.newChannel(System.in);    WritableByteChannel dest = Channels.newChannel(System.out);    //call one of copy method    source.close();    dest.close();&#125;public static void channelCopy1 (ReadableByteChannel src, WritableByteChannel dest) throws IOException&#123;    ByteBuffer buffer = ByteBuffer.allocate(BUFFER_SIZE);    while (src.read(buffer)!=-1) &#123;        //准备好数据        buffer.flip();        //向通道中写入数据，可能阻塞        dest.write(buffer);        //调用compact方法，可以确保数据都被dest处理        buffer.compact();    &#125;    //还有可能有数据剩余，此时只是没有可读数据了而已    while (buffer.hasRemaining()) &#123;        dest.write(buffer);    &#125;    buffer.clear();&#125;public static void channelCopy2 (ReadableByteChannel src, WritableByteChannel dest) throws IOException &#123;    ByteBuffer buffer = ByteBuffer.allocate(BUFFER_SIZE);    while (src.read(buffer)!=-1) &#123;        buffer.flip();        while (buffer.hasRemaining()) &#123;            dest.write(buffer);        &#125;        buffer.clear();    &#125;&#125;\n通道可以工作在阻塞或者非阻塞模式下。如果工作在非阻塞模式下，调用它的线程永远不会sleep。请求操作要么立刻完成，要么返回结果表明没有进行任何操作。只有面向流的通道，像socket或者pipe才可以工作在非阻塞模式。\n跟buffer不同，channel不可以被复用。一个打开的通道代表着跟特定IO服务之间的连接，还封装着连接的状态。当通道关闭的时候，连接丢失。调用通道的close方法会导致当关闭IO服务的时候，线程短暂地阻塞，就算工作在非阻塞模式也一样。对同一个通道调用多次close方法是无害的。如果第一个线程在close方法中阻塞，其他调用close方法的线程也会阻塞等待。后面的close方法什么都不做，然后立刻返回。\n通道有一些和关闭中断相关的特性。如果一个通道实现了InterruptibleChannel接口。那么，如果线程正在被通道所阻塞，然后线程被中断，通道会被关闭，然后线程会收到一个ClosedByInterruptException异常。另外，如果线程被设置为中断状态，然后线程尝试获取一个通道，通道就会立刻关闭，抛出同样的异常。\n先看如下的API\npublic interface ReadableByteChannel extends Channel &#123;  public int read (ByteBuffer dst) throws IOException;&#125;public interface WritableByteChannel extends Channel &#123;  public int write(ByteBuffer src) throws IOException;&#125;public interface ByteChannel extends ReadableByteChannel, WritableByteChannel &#123;&#125;\n通道可以是双向的也可以是单向的。根据需要实现这三个接口中的一个。\n通道的read(),write()方法都以ByteBuffer作为参数，每个都返回操作了的字节数，并更新ByteBuffer中的position属性。下面的例子展示了使用channel进行putget的基本操作\npublic static final int BUFFER_SIZE = 16*1024;public static void main(String[] args) throws IOException &#123;    ReadableByteChannel source = Channels.newChannel(System.in);    WritableByteChannel dest = Channels.newChannel(System.out);    //call one of copy method    source.close();    dest.close();&#125;public static void channelCopy1 (ReadableByteChannel src, WritableByteChannel dest) throws IOException&#123;    ByteBuffer buffer = ByteBuffer.allocate(BUFFER_SIZE);    while (src.read(buffer)!=-1) &#123;        //准备好数据        buffer.flip();        //向通道中写入数据，可能阻塞        dest.write(buffer);        //调用compact方法，可以确保数据都被dest处理        buffer.compact();    &#125;    //还有可能有数据剩余，此时只是没有可读数据了而已    while (buffer.hasRemaining()) &#123;        dest.write(buffer);    &#125;    buffer.clear();&#125;public static void channelCopy2 (ReadableByteChannel src, WritableByteChannel dest) throws IOException &#123;    ByteBuffer buffer = ByteBuffer.allocate(BUFFER_SIZE);    while (src.read(buffer)!=-1) &#123;        buffer.flip();        while (buffer.hasRemaining()) &#123;            dest.write(buffer);        &#125;        buffer.clear();    &#125;&#125;\n通道可以工作在阻塞或者非阻塞模式下。如果工作在非阻塞模式下，调用它的线程永远不会sleep。请求操作要么立刻完成，要么返回结果表明没有进行任何操作。只有面向流的通道，像socket或者pipe才可以工作在非阻塞模式。\n跟buffer不同，channel不可以被复用。一个打开的通道代表着跟特定IO服务之间的连接，还封装着连接的状态。当通道关闭的时候，连接丢失。调用通道的close方法会导致当关闭IO服务的时候，线程短暂地阻塞，就算工作在非阻塞模式也一样。对同一个通道调用多次close方法是无害的。如果第一个线程在close方法中阻塞，其他调用close方法的线程也会阻塞等待。后面的close方法什么都不做，然后立刻返回。\n通道有一些和关闭中断相关的特性。如果一个通道实现了InterruptibleChannel接口。那么，如果线程正在被通道所阻塞，然后线程被中断，通道会被关闭，然后线程会收到一个ClosedByInterruptException异常。另外，如果线程被设置为中断状态，然后线程尝试获取一个通道，通道就会立刻关闭，抛出同样的异常。\n通道提供了分散聚合的能力。就是说一次IO操作可以对应多个buffer。\n对于写操作(向通道中写入数据),数据从数个buffer中汇合然后沿通道发送对于读操作(从通道中读出数据),从通道中出来的数据分散到许多不同的buffer，尽可能地读取，直到数据或者buffer的可用空间被耗尽。\n许多现代操作系统支持native vectored（矢量） IO；当你在一个通道上发起一个分散聚合请求时，请求会被解释成native方法。这样子buffer的复制和系统调用可以减少甚至消除。最好使用direct buffer，得到最优的性能。\npublic interface ScatteringByteChannel extends ReadableByteChannel &#123;  public long read(ByteBuffer[] dsts) throws IOException;  public long read(ByteBuffer[] dots,int offset, int length) throws IOException;&#125;public interface GatheringByteChannel extends WritableByteChannel &#123;  public long write(ByteBuffer[] srcs) throws IOException;  public long write(ByteBuffer[] srcs, int offset, int length) throws IOException;&#125;\n看看下面的代码段\nByteBuffer header = ByteBuffer.allocateDirect(10);ByteBuffer body = ByteBuffer.allocateDirect(80);ByteBuffer[] buffers = &#123;header, body&#125;;int bytesRead = channel.read(buffers);\n如果返回值bytesRead为48，那么head中拥有最先的10个数据，body中有38个。\n相似的，我们可以组装数据在不同的buffer中，然后发送聚合\nbody.clear();body.put(&quot;FOO&quot;.getBytes()).flip();header.clear();header.putShort(TYPE_FILE).putLong(body.limit()).flip();long bytesWritten = channel.write(buffers);\n\nFileChannel继承了ScatteringByteChannel,ByteChannel和GatheringByteChannel。在类中还引入了文件锁。下面是部分的API\npublic class FileLock implements AutoClosable&#123;  public FileChannel channel()  public long position()  public long size()  public boolean isShared()  public boolean overlaps(long position, long size)  public boolean isValid()  public void release()  public String toString()&#125;\n文件通道总是运行在阻塞模式而且不能在非阻塞模式下工作。面向流的非阻塞模式对文件操作来说意义不大。对于文件来说，真正需要的是异步IO，从操作系统发出一条或多条IO请求而不需要等待它们完成，而是在完成之后收到通知。\nFileChannel对象可以通过调用RandomAccessFile,FileInputStream,FileOutputStream的getChannel方法得到，调用这个方法得到一个FileChannel对象，拥有和File对象一样的访问权限。\nFileChannel是一个抽象类，你通过getChannel方法得到的是一个具体实现，往往实现中有着大量native代码。FileChannel是线程安全的。多线程可以同时调用他们的方法而不会引起任何问题，但不是所有操作都是多线程的，影响到通道的位置和文件大小是单线程的。如果有线程试图做这样的操作，那么它必须等待另一个线程执行完毕。\nFileChannel保证同一个JVM中的所有实例看到的文件视图都是一致的。但这个视图和非JVM线程看到的可能相同也可能不同，这高度取决于底层的操作系统和文件系统。一般情况下来说，都是相同的。\nFileChannel中的position，代表着数据下一个写入或者读取的地方，无参数的position方法，返回一个long类型的当前位置。第二个需要一个long类型的参数，如果你把参数设置为负，会抛出IllegalArgumentException,但是如果设置的超出了文件的大小不会抛出异常，但不会更改文件的大小。如果读操作超出了文件的大小，会返回EOF，如果是写操作，就会更改文件的大小。每个FileChannel对象都和一个File descriptor有着一对一的联系。而File descriptor是channel创建的时候被共享的。也就是说他们可以看到彼此对position的更改，如下例所示：\nRandomAccessFile randomAccessFile = new RandomAccessFile(&quot;filename&quot;,&quot;r&quot;);//设置positionrandomAccessFile.seek(1000);//创建一个channelFielChannel fileChannel = randomAccessFile.getChannel();System.out.println(fileChannel.position());//打印1000randomAccessFile.seek(500);System.out.println(fileChannel.position());//500fileChannel.position(200);System.out.println(randomAccessFile.getFilePointer());//200\n和buffer相似，FileChannel的read方法和write方法都可以携带一个position参数，这样子比起不带参数的read，write方法更为高效，因为不需要更新channel的状态，可以直接通过native code实现。最好的是，多线程可以同时访问一个文件而不需要相互打扰。\n如果视图读取文件的结尾，会收到EOF，如果在这时，往超出文件大小的地方写入，文件就会自动增长，但在这EOF和此时写入的位置之间无数据的地方就要看具体的操作系统和文件系统了，可能会导致一个file hole。当你觉得有必要调整文件的大小时，调用truncate方法，携带一个long类型作为参数，如果大于你此时文件的大小，无事发生过。但是如果小于，大于这个数值的数据会被丢弃。\n最后force方法，要求强制把现在已经做了的更改应用到磁盘文件上，参数表明是否更新元数据(如文件所有者，访问权限，最后一次修改时间等)\n文件锁FileLock文件锁可以是shared(共享锁)或者exclusive(排他锁)。不是所有的平台都以同一种方式实现文件锁，不同的操作系统可能不同，同一操作系统上的不同文件系统也可能不同。有些操作系统只提供协同锁，有些只提供强制锁，有些则都提供。\n文件锁是以文件为单位的，不是以通道，也不是线程。所以文件锁不适合同一个多个线程访问的情形。如果一个线程获得了给定文件的排他锁，第二个线程请求打开了一个新的channel，请求获得排他锁，请求会被批准。但如果这两个线程运行在不同的JVM中，第二个线程会阻塞，因为锁往往是根据进程来进行裁决，而不是线程。锁工作于一个文件，而不是单独的文件处理器或是通道。&#x2F;*如果你需要控制多个线程之间的同步，你可能需要实现自己的轻量级的锁，内存映射文件可能是个适合的选择*&#x2F;\npublic abstract class FileChannel extends AbstractChannel implements ByteChannel, GatheringByteChannel, ScatteringByteChannel &#123;    public final FileLock lock()  public abstract FileLock lock (long position, long size, boolean shared)  public final FileLock tryLock()  public abstract FileLock tryLock(long position, long size, boolean shared)&#125;\n先看带参数的lock方法，获得给定区域的锁，自position开始，size大小，第三个布尔参数代表是锁是否共享。锁的区域并不受到文件大小的限制，锁可以超过文件的大小，也就是说在一段区域被写入数据之前锁住，是可行的。相反的，如果文件的大小超出了锁的限制，也就将不受到锁的限制。不带参数的lock方法，等效于fileChannel.lock(0L,Long.MAX_VALUE, false);如果你的请求是有效的，那么lock方法就会生效，但是要等待前一个锁(如果存在的话)释放。\ntryLock方法是lock方法非阻塞的变种，功能和lock相似，但是如果不能立刻获得锁的话，tryLock会返回null。从创建开始，直到调用FileLock的release方法，FileLock对象都是有效的。可以通过isValid方法测试。一个锁是否有效可能会改变，但锁的位置，大小，是否共享，是不变的。\n你可以通过isShared判断锁是否为共享锁，如果内在的文件系统操作系统不支持共享，那么这个方法总是会返回false，就算你传递true作为构造函数也一样。FileLock是线程安全的，多个线程可以通过一个FileLock进行操作。尽管FileLock对象和一个Channel相关，但是其实锁是和内在的文件联系的。这有可能造成冲突，也有可能死锁，如果你完成了操作而没有释放锁的话。一个典型的代码如下所示:\nFileLock lock = fileChannel.lock();try&#123;  &lt;perform read/write/whatever on channel&gt;&#125; catch (IOException e) &#123;  &lt;handle unexcepted exception&gt;&#125; finally &#123;  lock.release();&#125;\n下面是一个使用FileLock进行操作的例子\n    private static final int SIZEOF_INT = 4;    private static final int INDEX_START = 0;    private static final int INDEX_COUNT = 10;    private static final int INDEX_SIZE = INDEX_COUNT * SIZEOF_INT;    private ByteBuffer buffer = ByteBuffer.allocate(INDEX_SIZE);    private IntBuffer indexBuffer = buffer.asIntBuffer();    private Random rand = new Random();    public static void main(String[] args) throws Exception&#123;        boolean writer = false;        String filename;        //决定你所做的操作，读或者写        if(args.length!=2) &#123;            System.out.println(&quot;Usage: [-r|-w] filename&quot;);            return;        &#125;        writer = args[0].equals(&quot;-w&quot;);//true写false读        filename = args[1];        RandomAccessFile raf = new RandomAccessFile(filename,writer?&quot;rw&quot;:&quot;r&quot;);        FileChannel fc = raf.getChannel();//通过RandomAccessFile拿到fileChannel        LockTest lockTest = new LockTest();        if(writer) &#123;            lockTest.doUpdates(fc);        &#125; else &#123;            lockTest.doQueries(fc);        &#125;    &#125;    void doQueries (FileChannel fc) throws Exception &#123;        //如果是单次操作的话，没有这个循环，这里使用这个循环，为了多次        //运行程序，发现锁的工作原理        while (true) &#123;            FileLock lock = fc.lock(INDEX_START,INDEX_SIZE,true);            int reps = rand.nextInt(60) + 20;            for(int i=0; i&lt;reps; i++) &#123;                int n = rand.nextInt(INDEX_COUNT);                int position = INDEX_START + (n*SIZEOF_INT);                buffer.clear();                fc.read(buffer,position);                int value = indexBuffer.get(n);                Thread.sleep(100);//doing some work            &#125;            lock.release();            Thread.sleep(rand.nextInt(3000)+500);        &#125;    &#125;    void doUpdates (FileChannel fc) throws Exception &#123;        while (true) &#123;            FileLock lock = fc.lock(INDEX_START,INDEX_SIZE,false);            updateIndex(fc);            lock.release();            Thread.sleep(rand.nextInt(2000)+500);        &#125;    &#125;    private int idxval = 1;    private void updateIndex (FileChannel fc) throws Exception&#123;        indexBuffer.clear();        for(int i=0; i&lt;INDEX_COUNT; i++) &#123;            idxval++;            indexBuffer.put(idxval);            Thread.sleep(500);        &#125;        buffer.clear();        fc.write(buffer,INDEX_START);    &#125;&#125;\n\n"},{"title":"Ignite Java客户端最佳实践","url":"/2023/10/10/Ignite%20Java%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/","content":"Ignite Java 客户端最佳实践背景本文总结了在使用Apache Ignite（Ignite2.0）的Java客户端时，需要注意的一些问题，以及一些最佳实践。值得一提的是 Ignite的Java客户端有一些跟直觉上不太一样的地方，需要注意下。\n客户端相关Ignite客户端有两处跟直觉上相差较大：\n\nIgnite客户端连接没有默认超时时间，如果连接不上，有概率会导致创建客户端一直阻塞，所以一定要设置timeout参数\nIgnite客户端默认不会重连，更不用说无限重连了。并且Ignite客户端重连的实现方式是预先计算出所有重连的时间戳，然后在这些时间戳到达时重连，由于要预先计算出重连的时间戳存入数组，这也就意味着不能无限重连。如果您的应用程序需要无限重连（在云原生环境下，这是非常常见的场景），那么您需要自己实现重连逻辑。\n\nClientConfiguration里的重要参数\nClientConfiguration timeout控制连接超时的参数，单位是毫秒。必须设置！如果不设置，有概率会导致创建客户端一直阻塞。\nSQL相关SQL查询典型用法\nSqlFieldsQuery query = new SqlFieldsQuery(&quot;SELECT 42&quot;).setTimeout(5, TimeUnit.SECONDS);FieldsQueryCursor&lt;List&lt;?&gt;&gt; cursor = igniteClient.query(query))List&lt;List&lt;?&gt;&gt; result = cursor.getAll();\n\n注意：Ignite query出来的cursor如果自己通过iterator遍历则必须要close，否则会导致内存泄漏。\nQuery相关参数\nSqlFieldsQuery timeoutSqlQuery的超时时间，必须设置。默认是0，表示永不超时。如果不设置，有概率会导致查询一直阻塞。\n","tags":["Ignite","Java"]},{"title":"Java Ping命令心跳探测 InetAddress isReachable分析","url":"/2020/01/12/Java%20Ping%E5%91%BD%E4%BB%A4%E5%BF%83%E8%B7%B3%E6%8E%A2%E6%B5%8B%20InetAddress%20isReachable%E5%88%86%E6%9E%90/","content":"业务需求分析与解决方案在业务场景中，当需要利用ping命令对主机进行心跳探测时，直接在代码中fork进程执行ping命令虽然可行，但这种方法开销较大，并且处理流程易出错，与使用标准库相比缺乏优雅性。因此，本文探讨了使用Java的InetAddress类的isReachable方法作为替代方案。\n根据资料指出，Java的InetAddress类在root用户权限下通过执行ping命令进行探测，在非root用户权限下则通过访问TCP端口7进行探测。为验证这一点，本文撰写了相应的demo代码并进行了测试（详见：GitHub - heart-beat）。\nimport lombok.extern.slf4j.Slf4j;import java.net.InetAddress;@Slf4jpublic class PingTestMain &#123;    public static void main(String[] args) throws Exception &#123;        String testIp = System.getProperty(&quot;TestIp&quot;);        InetAddress inetAddress = InetAddress.getByName(testIp);        boolean addressReachable = inetAddress.isReachable(500);        log.info(&quot;address is reachable is &#123;&#125;&quot;, addressReachable);    &#125;&#125;\n测试实验root用户下执行程序\njava程序打印结果也是true\n在普通用户权限下的测试\n此时可以看到,我们的客户端程序向目标tcp7端口发送了一个报文,虽然java程序打印结果为true,但是因为收到了RST包导致的.在当今的网络安全要求下,7端口往往不会开放\n在目标网络屏蔽TCP端口7的情况下执行程序iptables -A INPUT -p tcp --dport 7 -j DROP\n\n发送的报文没有收到RST包,此时java程序返回false.不是我们预期的结果\n普通用户权限下携带特权的测试进一步的研究发现，Java程序发送ping命令需要创建raw socket，这要求程序具有root权限或cap_net_raw权限。赋予Java程序创建raw socket的权限后重新测试，发现程序能够正确发送ping命令，达到预期效果。\nsetcap cap_net_raw+ep /usr/java/jdk-13.0.1/bin/java\n发现如下报错\njava: error while loading shared libraries: libjli.so: cannot open shared object file: No such file or directory\n使用https://askubuntu.com/questions/334365/how-to-add-a-directory-to-linker-command-line-in-linux规避添加so文件权限\n随后抓包,发现还是发送了ping命令,达到了我们预期的效果\n总结本文通过一系列测试得出结论，root用户权限下的Java程序会使用ping命令进行探测。若普通用户不具备相应权限，则会尝试探测TCP端口7，但在安全组未开启该端口的情况下会导致预期结果不一致。推荐赋予java程序特权,使得InetAddress类能够使用ping命令进行探测\n","tags":["Java"]},{"title":"Java Maven lint推荐配置","url":"/2021/12/16/Java%20maven%20lint%E6%8E%A8%E8%8D%90%E9%85%8D%E7%BD%AE/","content":"maven checkstyle添加maven plugin依赖&lt;plugin&gt;    &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;    &lt;artifactId&gt;maven-checkstyle-plugin&lt;/artifactId&gt;    &lt;version&gt;3.1.2&lt;/version&gt;    &lt;configuration&gt;        &lt;configLocation&gt;config/checkstyle.xml&lt;/configLocation&gt;        &lt;suppressionsLocation&gt;config/suppressions.xml&lt;/suppressionsLocation&gt;        &lt;includeTestSourceDirectory&gt;true&lt;/includeTestSourceDirectory&gt;        &lt;encoding&gt;UTF-8&lt;/encoding&gt;        &lt;excludes&gt;**/proto/*&lt;/excludes&gt;    &lt;/configuration&gt;&lt;/plugin&gt;\n\n\nconfigLocation 存放checkstyle的规则配置文件，附录有样例内容\nSuppressionsLocation 存放屏蔽规则配置文件，附录有样例内容\nincludeTestSourceDirectory 是否检测测试文件夹，建议配置为true\n\n\n结束最后就可以通过mvn checkstyle:check来检查您的工程啦。如果有违反了checkstyle的地方，命令行会提示出错的地方和违反的规则，如下图所示\n\n\n附录规则配置文件举例&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE module PUBLIC        &quot;-//Puppy Crawl//DTD Check Configuration 1.3//EN&quot;        &quot;https://checkstyle.org/dtds/configuration_1_3.dtd&quot;&gt;&lt;!-- This is a checkstyle configuration file. For descriptions ofwhat the following rules do, please see the checkstyle configurationpage at http://checkstyle.sourceforge.net/config.html --&gt;&lt;module name=&quot;Checker&quot;&gt;    &lt;module name=&quot;FileTabCharacter&quot;&gt;        &lt;!-- Checks that there are no tab characters in the file. --&gt;    &lt;/module&gt;    &lt;!-- All Java AST specific tests live under TreeWalker module. --&gt;    &lt;module name=&quot;TreeWalker&quot;&gt;        &lt;module name=&quot;SuppressionCommentFilter&quot;&gt;            &lt;property name=&quot;offCommentFormat&quot; value=&quot;CHECKSTYLE.OFF\\: ([\\w\\|]+)&quot;/&gt;            &lt;property name=&quot;onCommentFormat&quot; value=&quot;CHECKSTYLE.ON\\: ([\\w\\|]+)&quot;/&gt;            &lt;property name=&quot;checkFormat&quot; value=&quot;$1&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;SuppressWarningsHolder&quot; /&gt;        &lt;!--        IMPORT CHECKS        --&gt;        &lt;module name=&quot;RedundantImport&quot;&gt;            &lt;!-- Checks for redundant import statements. --&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;            &lt;message key=&quot;import.redundancy&quot;                     value=&quot;Redundant import &#123;0&#125;.&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;AvoidStarImport&quot;&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;RedundantModifier&quot;&gt;            &lt;!-- Checks for redundant modifiers on various symbol definitions.              See: http://checkstyle.sourceforge.net/config_modifier.html#RedundantModifier            --&gt;            &lt;property name=&quot;tokens&quot; value=&quot;METHOD_DEF, VARIABLE_DEF, ANNOTATION_FIELD_DEF, INTERFACE_DEF, CLASS_DEF, ENUM_DEF&quot;/&gt;        &lt;/module&gt;        &lt;!--            IllegalImport cannot blacklist classes, and c.g.api.client.util is used for some shaded            code and some useful code. So we need to fall back to Regexp.        --&gt;        &lt;module name=&quot;RegexpSinglelineJava&quot;&gt;            &lt;property name=&quot;format&quot; value=&quot;com\\.google\\.api\\.client\\.util\\.(ByteStreams|Charsets|Collections2|Joiner|Lists|Maps|Objects|Preconditions|Sets|Strings|Throwables)&quot;/&gt;        &lt;/module&gt;        &lt;!--             Require static importing from Preconditions.        --&gt;        &lt;module name=&quot;RegexpSinglelineJava&quot;&gt;            &lt;property name=&quot;format&quot; value=&quot;^import com.google.common.base.Preconditions;$&quot;/&gt;            &lt;property name=&quot;message&quot; value=&quot;Static import functions from Guava Preconditions&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;UnusedImports&quot;&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;            &lt;property name=&quot;processJavadoc&quot; value=&quot;true&quot;/&gt;            &lt;message key=&quot;import.unused&quot;                     value=&quot;Unused import: &#123;0&#125;.&quot;/&gt;        &lt;/module&gt;        &lt;!--        JAVADOC CHECKS        --&gt;        &lt;!-- Checks for Javadoc comments.                     --&gt;        &lt;!-- See http://checkstyle.sf.net/config_javadoc.html --&gt;        &lt;module name=&quot;JavadocMethod&quot;&gt;            &lt;property name=&quot;scope&quot; value=&quot;protected&quot;/&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;            &lt;property name=&quot;allowMissingParamTags&quot; value=&quot;true&quot;/&gt;            &lt;property name=&quot;allowMissingReturnTag&quot; value=&quot;true&quot;/&gt;        &lt;/module&gt;        &lt;!-- Check that paragraph tags are used correctly in Javadoc. --&gt;        &lt;!--        &lt;module name=&quot;JavadocParagraph&quot;/&gt;--&gt;        &lt;module name=&quot;JavadocType&quot;&gt;            &lt;property name=&quot;scope&quot; value=&quot;protected&quot;/&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;            &lt;property name=&quot;allowMissingParamTags&quot; value=&quot;true&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;JavadocStyle&quot;&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;            &lt;property name=&quot;checkHtml&quot; value=&quot;true&quot;/&gt;        &lt;/module&gt;        &lt;!--        NAMING CHECKS        --&gt;        &lt;!-- Item 38 - Adhere to generally accepted naming conventions --&gt;        &lt;module name=&quot;PackageName&quot;&gt;            &lt;!-- Validates identifiers for package names against the              supplied expression. --&gt;            &lt;!-- Here the default checkstyle rule restricts package name parts to              seven characters, this is not in line with common practice at Google.            --&gt;            &lt;property name=&quot;format&quot; value=&quot;^[a-z]+(\\.[a-z][a-z0-9]&#123;1,&#125;)*$&quot;/&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;TypeNameCheck&quot;&gt;            &lt;!-- Validates static, final fields against the            expression &quot;^[A-Z][a-zA-Z0-9]*$&quot;. --&gt;            &lt;metadata name=&quot;altname&quot; value=&quot;TypeName&quot;/&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;ConstantNameCheck&quot;&gt;            &lt;!-- Validates non-private, static, final fields against the supplied            public/package final fields &quot;^[A-Z][A-Z0-9]*(_[A-Z0-9]+)*$&quot;. --&gt;            &lt;metadata name=&quot;altname&quot; value=&quot;ConstantName&quot;/&gt;            &lt;property name=&quot;applyToPublic&quot; value=&quot;true&quot;/&gt;            &lt;property name=&quot;applyToProtected&quot; value=&quot;true&quot;/&gt;            &lt;property name=&quot;applyToPackage&quot; value=&quot;true&quot;/&gt;            &lt;property name=&quot;applyToPrivate&quot; value=&quot;false&quot;/&gt;            &lt;property name=&quot;format&quot; value=&quot;^([A-Z][A-Za-z0-9_]*|FLAG_.*)$&quot;/&gt;            &lt;message key=&quot;name.invalidPattern&quot;                     value=&quot;Variable &#x27;&#x27;&#123;0&#125;&#x27;&#x27; should be in ALL_CAPS (if it is a constant) or be private (otherwise).&quot;/&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;StaticVariableNameCheck&quot;&gt;            &lt;!-- Validates static, non-final fields against the supplied            expression &quot;^[a-z][a-zA-Z0-9]*_?$&quot;. --&gt;            &lt;metadata name=&quot;altname&quot; value=&quot;StaticVariableName&quot;/&gt;            &lt;property name=&quot;applyToPublic&quot; value=&quot;true&quot;/&gt;            &lt;property name=&quot;applyToProtected&quot; value=&quot;true&quot;/&gt;            &lt;property name=&quot;applyToPackage&quot; value=&quot;true&quot;/&gt;            &lt;property name=&quot;applyToPrivate&quot; value=&quot;true&quot;/&gt;            &lt;property name=&quot;format&quot; value=&quot;^[a-z][a-zA-Z0-9]*_?$&quot;/&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;MemberNameCheck&quot;&gt;            &lt;!-- Validates non-static members against the supplied expression. --&gt;            &lt;metadata name=&quot;altname&quot; value=&quot;MemberName&quot;/&gt;            &lt;property name=&quot;applyToPublic&quot; value=&quot;true&quot;/&gt;            &lt;property name=&quot;applyToProtected&quot; value=&quot;true&quot;/&gt;            &lt;property name=&quot;applyToPackage&quot; value=&quot;true&quot;/&gt;            &lt;property name=&quot;applyToPrivate&quot; value=&quot;true&quot;/&gt;            &lt;property name=&quot;format&quot; value=&quot;^[a-z][a-zA-Z0-9]*$&quot;/&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;MethodNameCheck&quot;&gt;            &lt;!-- Validates identifiers for method names. --&gt;            &lt;metadata name=&quot;altname&quot; value=&quot;MethodName&quot;/&gt;            &lt;property name=&quot;format&quot; value=&quot;(^[a-z][a-zA-Z0-9]*(_[a-zA-Z0-9]+)*$|Void)&quot;/&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;ParameterName&quot;&gt;            &lt;!-- Validates identifiers for method parameters against the              expression &quot;^[a-z][a-zA-Z0-9]*$&quot;. --&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;LocalFinalVariableName&quot;&gt;            &lt;!-- Validates identifiers for local final variables against the              expression &quot;^[a-z][a-zA-Z0-9]*$&quot;. --&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;LocalVariableName&quot;&gt;            &lt;!-- Validates identifiers for local variables against the              expression &quot;^[a-z][a-zA-Z0-9]*$&quot;. --&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;        &lt;/module&gt;        &lt;!-- Type parameters must be either one of the four blessed letters        T, K, V, W, X or else be capital-case terminated with a T,        such as MyGenericParameterT --&gt;        &lt;module name=&quot;ClassTypeParameterName&quot;&gt;            &lt;property name=&quot;format&quot; value=&quot;^(((T|K|V|W|X|R)[0-9]*)|([A-Z][a-z][a-zA-Z]*))$&quot;/&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;MethodTypeParameterName&quot;&gt;            &lt;property name=&quot;format&quot; value=&quot;^(((T|K|V|W|X|R)[0-9]*)|([A-Z][a-z][a-zA-Z]*T))$&quot;/&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;InterfaceTypeParameterName&quot;&gt;            &lt;property name=&quot;format&quot; value=&quot;^(((T|K|V|W|X|R)[0-9]*)|([A-Z][a-z][a-zA-Z]*T))$&quot;/&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;LeftCurly&quot;&gt;            &lt;!-- Checks for placement of the left curly brace (&#x27;&#123;&#x27;). --&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;RightCurly&quot;&gt;            &lt;!-- Checks right curlies on CATCH, ELSE, and TRY blocks are on            the same line. e.g., the following example is fine:            &lt;pre&gt;              if &#123;                ...              &#125; else            &lt;/pre&gt;            --&gt;            &lt;!-- This next example is not fine:            &lt;pre&gt;              if &#123;                ...              &#125;              else            &lt;/pre&gt;            --&gt;            &lt;property name=&quot;option&quot; value=&quot;same&quot;/&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;        &lt;/module&gt;        &lt;!-- Checks for braces around if and else blocks --&gt;        &lt;module name=&quot;NeedBraces&quot;&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;            &lt;property name=&quot;tokens&quot; value=&quot;LITERAL_IF, LITERAL_ELSE, LITERAL_FOR, LITERAL_WHILE, LITERAL_DO&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;UpperEll&quot;&gt;            &lt;!-- Checks that long constants are defined with an upper ell.--&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;FallThrough&quot;&gt;            &lt;!-- Warn about falling through to the next case statement.  Similar to            javac -Xlint:fallthrough, but the check is suppressed if a single-line comment            on the last non-blank line preceding the fallen-into case contains &#x27;fall through&#x27; (or            some other variants that we don&#x27;t publicized to promote consistency).            --&gt;            &lt;property name=&quot;reliefPattern&quot;                      value=&quot;fall through|Fall through|fallthru|Fallthru|falls through|Falls through|fallthrough|Fallthrough|No break|NO break|no break|continue on&quot;/&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;        &lt;/module&gt;        &lt;!-- Checks for over-complicated boolean expressions. --&gt;        &lt;module name=&quot;SimplifyBooleanExpression&quot;/&gt;        &lt;!-- Detects empty statements (standalone &quot;;&quot; semicolon). --&gt;        &lt;module name=&quot;EmptyStatement&quot;/&gt;        &lt;!--        WHITESPACE CHECKS        --&gt;        &lt;module name=&quot;WhitespaceAround&quot;&gt;            &lt;!-- Checks that various tokens are surrounded by whitespace.                 This includes most binary operators and keywords followed                 by regular or curly braces.            --&gt;            &lt;property name=&quot;tokens&quot; value=&quot;ASSIGN, BAND, BAND_ASSIGN, BOR,        BOR_ASSIGN, BSR, BSR_ASSIGN, BXOR, BXOR_ASSIGN, COLON, DIV, DIV_ASSIGN,        EQUAL, GE, GT, LAND, LE, LITERAL_CATCH, LITERAL_DO, LITERAL_ELSE,        LITERAL_FINALLY, LITERAL_FOR, LITERAL_IF, LITERAL_RETURN,        LITERAL_SYNCHRONIZED, LITERAL_TRY, LITERAL_WHILE, LOR, LT, MINUS,        MINUS_ASSIGN, MOD, MOD_ASSIGN, NOT_EQUAL, PLUS, PLUS_ASSIGN, QUESTION,        SL, SL_ASSIGN, SR_ASSIGN, STAR, STAR_ASSIGN&quot;/&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;WhitespaceAfter&quot;&gt;            &lt;!-- Checks that commas, semicolons and typecasts are followed by                 whitespace.            --&gt;            &lt;property name=&quot;tokens&quot; value=&quot;COMMA, SEMI, TYPECAST&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;NoWhitespaceAfter&quot;&gt;            &lt;!-- Checks that there is no whitespace after various unary operators.                 Linebreaks are allowed.            --&gt;            &lt;property name=&quot;tokens&quot; value=&quot;BNOT, DEC, DOT, INC, LNOT, UNARY_MINUS,        UNARY_PLUS&quot;/&gt;            &lt;property name=&quot;allowLineBreaks&quot; value=&quot;true&quot;/&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;NoWhitespaceBefore&quot;&gt;            &lt;!-- Checks that there is no whitespace before various unary operators.                 Linebreaks are allowed.            --&gt;            &lt;property name=&quot;tokens&quot; value=&quot;SEMI, DOT, POST_DEC, POST_INC&quot;/&gt;            &lt;property name=&quot;allowLineBreaks&quot; value=&quot;true&quot;/&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;OperatorWrap&quot;&gt;            &lt;!-- Checks that operators like + and ? appear at newlines rather than                 at the end of the previous line.            --&gt;            &lt;property name=&quot;option&quot; value=&quot;NL&quot;/&gt;            &lt;property name=&quot;tokens&quot; value=&quot;BAND, BOR, BSR, BXOR, DIV, EQUAL,        GE, GT, LAND, LE, LITERAL_INSTANCEOF, LOR, LT, MINUS, MOD,        NOT_EQUAL, PLUS, QUESTION, SL, SR, STAR &quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;OperatorWrap&quot;&gt;            &lt;!-- Checks that assignment operators are at the end of the line. --&gt;            &lt;property name=&quot;option&quot; value=&quot;eol&quot;/&gt;            &lt;property name=&quot;tokens&quot; value=&quot;ASSIGN&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;ParenPad&quot;&gt;            &lt;!-- Checks that there is no whitespace before close parens or after                 open parens.            --&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;ModifierOrder&quot;/&gt;    &lt;/module&gt;&lt;/module&gt;\n\n屏蔽规则配置文件举例&lt;?xml version=&quot;1.0&quot;?&gt;&lt;!DOCTYPE suppressions PUBLIC        &quot;-//Puppy Crawl//DTD Suppressions 1.1//EN&quot;        &quot;https://checkstyle.org/dtds/configuration_1_3.dtd&quot;&gt;&lt;suppressions&gt;    &lt;!-- suppress all checks in the generated directories --&gt;    &lt;suppress checks=&quot;.*&quot; files=&quot;.+[\\\\/]generated[\\\\/].+\\.java&quot;/&gt;    &lt;suppress checks=&quot;.*&quot; files=&quot;.+[\\\\/]generated-sources[\\\\/].+\\.java&quot;/&gt;    &lt;suppress checks=&quot;.*&quot; files=&quot;.+[\\\\/]generated-test-sources[\\\\/].+\\.java&quot;/&gt;&lt;/suppressions&gt;\n\nmaven dependency-check引入dependnecy-check插件项目中原有的依赖是这样的\n&lt;dependency&gt;    &lt;groupId&gt;io.netty&lt;/groupId&gt;    &lt;artifactId&gt;netty-all&lt;/artifactId&gt;    &lt;version&gt;4.1.41.Final&lt;/version&gt;&lt;/dependency&gt;\n\n&lt;plugin&gt;    &lt;groupId&gt;org.owasp&lt;/groupId&gt;    &lt;artifactId&gt;dependency-check-maven&lt;/artifactId&gt;    &lt;version&gt;$&#123;dependency-check-maven.version&#125;&lt;/version&gt;    &lt;configuration&gt;        &lt;suppressionFiles&gt;            &lt;suppressionFile&gt;src/owasp-dependency-check-suppressions.xml&lt;/suppressionFile&gt;        &lt;/suppressionFiles&gt;        &lt;failBuildOnCVSS&gt;7&lt;/failBuildOnCVSS&gt;        &lt;msbuildAnalyzerEnabled&gt;false&lt;/msbuildAnalyzerEnabled&gt;        &lt;nodeAnalyzerEnabled&gt;false&lt;/nodeAnalyzerEnabled&gt;        &lt;yarnAuditAnalyzerEnabled&gt;false&lt;/yarnAuditAnalyzerEnabled&gt;        &lt;pyDistributionAnalyzerEnabled&gt;false&lt;/pyDistributionAnalyzerEnabled&gt;        &lt;pyPackageAnalyzerEnabled&gt;false&lt;/pyPackageAnalyzerEnabled&gt;        &lt;pipAnalyzerEnabled&gt;false&lt;/pipAnalyzerEnabled&gt;        &lt;pipfileAnalyzerEnabled&gt;false&lt;/pipfileAnalyzerEnabled&gt;        &lt;retireJsAnalyzerEnabled&gt;false&lt;/retireJsAnalyzerEnabled&gt;        &lt;msbuildAnalyzerEnabled&gt;false&lt;/msbuildAnalyzerEnabled&gt;        &lt;mixAuditAnalyzerEnabled&gt;false&lt;/mixAuditAnalyzerEnabled&gt;        &lt;nugetconfAnalyzerEnabled&gt;false&lt;/nugetconfAnalyzerEnabled&gt;        &lt;assemblyAnalyzerEnabled&gt;false&lt;/assemblyAnalyzerEnabled&gt;        &lt;skipSystemScope&gt;true&lt;/skipSystemScope&gt;    &lt;/configuration&gt;    &lt;executions&gt;        &lt;execution&gt;            &lt;goals&gt;                &lt;goal&gt;aggregate&lt;/goal&gt;            &lt;/goals&gt;        &lt;/execution&gt;    &lt;/executions&gt;&lt;/plugin&gt;\n\n然后可以通过mvn clean install verify -DskipTests来检测。这个demo下，会输出\n[ERROR] One or more dependencies were identified with vulnerabilities that have a CVSS score greater than or equal to &#x27;7.0&#x27;: [ERROR] [ERROR] netty-all-4.1.41.Final.jar: CVE-2019-16869(7.5), CVE-2021-37136(7.5), CVE-2020-11612(7.5), CVE-2021-37137(7.5), CVE-2019-20445(9.1), CVE-2019-20444(9.1), CVE-2020-7238(7.5)[ERROR] [ERROR] See the dependency-check report for more details.\n\n实际使用时，由于dependency-check检查相对耗时，一般通过单独的profile来控制开关\n屏蔽CVE漏洞如果出现dependency-check误报或者是评估该漏洞不涉及，可以通过supression file来屏蔽\n屏蔽单一CVE漏洞&lt;suppress&gt;  &lt;notes&gt;&lt;![CDATA[ file name: zookeeper-prometheus-metrics-3.8.0.jar ]]&gt;&lt;/notes&gt;  &lt;sha1&gt;849e8ece2845cb0185d721233906d487a7f1e4cf&lt;/sha1&gt;  &lt;cve&gt;CVE-2021-29425&lt;/cve&gt;&lt;/suppress&gt;\n\n通过文件正则来屏蔽CVE漏洞&lt;suppress&gt;    &lt;notes&gt;CVE-2011-1797 FP, see https://github.com/jeremylong/DependencyCheck/issues/4154&lt;/notes&gt;    &lt;filePath regex=&quot;true&quot;&gt;.*netty-tcnative-boringssl-static.*\\.jar&lt;/filePath&gt;    &lt;cve&gt;CVE-2011-1797g&lt;/cve&gt;&lt;/suppress&gt;\n","tags":["Java"]},{"title":"Java 项目结构组织","url":"/2023/10/08/Java%20%E9%A1%B9%E7%9B%AE%E7%BB%93%E6%9E%84%E7%BB%84%E7%BB%87/","content":"简单的library对于简单的library来说，我更推荐将所有的文件都放在同一个package下面，如简单的client封装\npackage:com.xxx.yyy/|-- XxClient|-- XxDTO|-- XxException|-- XxUtil\n\n复杂的SpringBoot项目，负责多个业务模块备注:\n\nxxx、yyy代表大块的业务区分：如用户、订单、支付\naaa、bbb代表小块的业务区分：如(用户的)登录、注册、查询\n\n方案一：多业务模块通过子包来区分，不分子modulemodule视图:\nexample(maven artifactId: example-parent)/|-- example-service(业务逻辑)|-- example-spring-ignite(依赖spring，常见为中间件client，适配spring模块用于方便单元测试)|-- example-spring-ignite-test(依赖spring，不依赖test-common，spring模块单元测试用)|-- example-starter(启动类)|-- example-test-common(不依赖example-common)|-- example-util(不依赖Spring框架，可选模块，为service与其他spring集成组件共用)\n\n依赖关系图:\ngraph TD\nservice[example-service]\nspringIgnite[example-spring-ignite]\nspringIgniteTest[example-spring-ignite-test]\nstarter[example-starter]\ntestCommon[example-test-common]\nutil[example-util]\n\nstarter --> service\n\nservice --> springIgnite\nservice --> util\nservice -.-> testCommon\n\ntestCommon --> springIgniteTest\n\nspringIgniteTest --> springIgnite\n\nspringIgnite --> util\n\nservice包内视图:\nio.hezhangjian.example/|-- service/|   |-- common/|   |-- module/|   |   |-- aaaModule|   |   |-- bbbModule|   |-- mapper/|   |   |-- aaaMapper|   |   |-- bbbMapper|   |-- repo/|   |   |-- aaaRepo|   |   |-- bbbRepo|   |-- service/|   |   |-- aaaService|   |   |-- bbbService\n\n方案二：根据业务模块拆分子module适用于大型项目，每个业务模块都比较大。\nmodule视图：\nexample(maven artifactId: example-parent)/|-- example-common(可依赖spring模块)|-- example-rest-xxx(xxx功能模块的rest接口)|-- example-rest-yyy(yyy功能模块的rest接口)|-- example-service-xxx(xxx功能的业务逻辑)|-- example-service-yyy(yyy功能的业务逻辑)|-- example-spring-ignite(依赖spring，常见为中间件client，适配spring模块用于方便单元测试)|-- example-spring-ignite-test(依赖spring，不依赖test-common，spring模块单元测试用)|-- example-starter(启动类)|-- example-test-common(不依赖example-common)|-- example-util(不依赖example-common，可选模块，为service、common与其他spring集成组件共用)\n\n依赖关系图:\ngraph TD\ncommon[example-common]\nrest-xxx[example-rest-xxx]\nrest-yyy[example-rest-yyy]\nservice-xxx[example-service-xxx]\nservice-yyy[example-service-yyy]\nspringIgnite[example-spring-ignite]\nspringIgniteTest[example-spring-ignite-test]\nstarter[example-starter]\ntestCommon[example-test-common]\nutil[example-util]\n\nstarter --> rest-xxx\nstarter --> rest-yyy\n\nrest-xxx --> common\nrest-xxx --> service-xxx\n\nrest-yyy --> common\nrest-yyy --> service-yyy\n\nservice-xxx --> common\nservice-xxx --> springIgnite\n\nservice-yyy --> common\nservice-yyy --> util\n\ncommon -.-> testCommon\n\ntestCommon --> springIgniteTest\n\nspringIgniteTest --> springIgnite\n\nspringIgnite --> util\n\n关于service模块引不引用rest模块的DTO，我的想法：\n如果确实service模块和rest模块DTO差距比较大，可以拆分做转换，如果差距很小&#x2F;没有差距，可以复用同一个DTO，放在service模块或者更底层的依赖。\nservice-xxx包内视图:\nio.hezhangjian.example.service/|-- xxx/|   |-- common/|   |-- module/|   |   |-- aaaModule|   |   |-- bbbModule|   |-- mapper/|   |   |-- aaaMapper|   |   |-- bbbMapper|   |-- repo/|   |   |-- aaaRepo|   |   |-- bbbRepo|   |-- service/|   |   |-- aaaService|   |   |-- bbbService\n\n\n import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs';\tmermaid.initialize({startOnLoad: true, flowchart: {curve: 'linear'}}); ","tags":["Java"]},{"title":"Java依赖不同版本冲突解决方案之shade包","url":"/2020/12/30/Java%E4%BE%9D%E8%B5%96%E4%B8%8D%E5%90%8C%E7%89%88%E6%9C%AC%E5%86%B2%E7%AA%81%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E4%B9%8Bshade%E5%8C%85/","content":"我们在很多场景下会碰到java包冲突的问题：\n\n代码由第三方开发，无法对包名或依赖做管控\n跑在同一个进程里的代码，更新步调不一致。比如底层sdk，jvm agent。这些组件更新频率较低\n\n最出名的解决路数还是类加载机制，诸如flink，osgi都给我们提供了很多方案，这些方案都非常重型。在代码可信任的情况下，其中有一个很轻量级的解决方案就是maven-shade包。\n举个例子，比方说我想在java agent中打印日志，但是又不希望和业务代码中的log4j等冲突，agent里依赖的pom文件是这样子的:\n&lt;dependencies&gt;       &lt;dependency&gt;           &lt;groupId&gt;org.slf4j&lt;/groupId&gt;           &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;           &lt;version&gt;1.7.30&lt;/version&gt;       &lt;/dependency&gt;       &lt;dependency&gt;           &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;           &lt;artifactId&gt;log4j-api&lt;/artifactId&gt;           &lt;version&gt;2.13.3&lt;/version&gt;       &lt;/dependency&gt;       &lt;dependency&gt;           &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;           &lt;artifactId&gt;log4j-core&lt;/artifactId&gt;           &lt;version&gt;2.13.3&lt;/version&gt;       &lt;/dependency&gt;       &lt;dependency&gt;           &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;           &lt;artifactId&gt;log4j-slf4j-impl&lt;/artifactId&gt;           &lt;version&gt;2.13.3&lt;/version&gt;       &lt;/dependency&gt;       &lt;dependency&gt;           &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;           &lt;artifactId&gt;log4j-jcl&lt;/artifactId&gt;           &lt;version&gt;2.13.3&lt;/version&gt;       &lt;/dependency&gt;   &lt;/dependencies&gt;\n\n这里我们log4j,slf4j可能用的版本太高或者太低，我们就可以通过打shade包的方式修改log4j和slf4j的包名,避免和业务冲突\n&lt;plugin&gt;                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;                &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt;                &lt;version&gt;3.2.4&lt;/version&gt;                &lt;executions&gt;                    &lt;execution&gt;                        &lt;phase&gt;package&lt;/phase&gt;                        &lt;goals&gt;                            &lt;goal&gt;shade&lt;/goal&gt;                        &lt;/goals&gt;                        &lt;configuration&gt;                            &lt;artifactSet&gt;                                &lt;includes&gt;                                    &lt;include&gt;org.slf4j:slf4j-api&lt;/include&gt;                                    &lt;include&gt;org.apache.logging.log4j:log4j-api&lt;/include&gt;                                    &lt;include&gt;org.apache.logging.log4j:log4j-core&lt;/include&gt;                                    &lt;include&gt;org.apache.logging.log4j:log4j-slf4j-impl&lt;/include&gt;                                    &lt;include&gt;org.apache.logging.log4j:log4j-jcl&lt;/include&gt;                                &lt;/includes&gt;                            &lt;/artifactSet&gt;                            &lt;filters&gt;                                &lt;filter&gt;                                    &lt;artifact&gt;*:*&lt;/artifact&gt;                                    &lt;excludes&gt;                                        &lt;exclude&gt;META-INF/*.SF&lt;/exclude&gt;                                        &lt;exclude&gt;META-INF/*.DSA&lt;/exclude&gt;                                        &lt;exclude&gt;META-INF/*.RSA&lt;/exclude&gt;                                    &lt;/excludes&gt;                                &lt;/filter&gt;                            &lt;/filters&gt;                            &lt;relocations&gt;                                &lt;relocation&gt;                                    &lt;pattern&gt;org.slf4j&lt;/pattern&gt;                                    &lt;shadedPattern&gt;com.github.hezhangjian.org.slf4j&lt;/shadedPattern&gt;                                &lt;/relocation&gt;                                &lt;relocation&gt;                                    &lt;pattern&gt;org.apache.logging&lt;/pattern&gt;                                    &lt;shadedPattern&gt;com.github.hezhangjian.org.apache.logging&lt;/shadedPattern&gt;                                &lt;/relocation&gt;                            &lt;/relocations&gt;                        &lt;/configuration&gt;                    &lt;/execution&gt;                &lt;/executions&gt;            &lt;/plugin&gt;\n\n通过上面的配置，artifactSet选择要修改的pom依赖，通过relocation修改包名，达到不冲突的效果。mvn clean package 后查看效果\n\n可以发现，包名已经被修改完成,达到了避免冲突的目的。\n","tags":["Java"]},{"title":"java指标统计方案及代码","url":"/2021/08/10/Java%E6%8C%87%E6%A0%87%E7%BB%9F%E8%AE%A1%E6%96%B9%E6%A1%88%E5%8F%8A%E4%BB%A3%E7%A0%81/","content":"java 根据线程统计CPU设计思路java的ThreadMXBean可以获取每个线程CPU执行的nanoTime，那么可以以这个为基础，除以中间系统经过的纳秒数，就获得了该线程的CPU占比\n编码首先，我们定义一个结构体，用来存放一个线程上次统计时的纳秒数和当时的系统纳秒数\nimport lombok.Data;@Datapublic class ThreadMetricsAux &#123;    private long usedNanoTime;    private long lastNanoTime;    public ThreadMetricsAux() &#123;    &#125;    public ThreadMetricsAux(long usedNanoTime, long lastNanoTime) &#123;        this.usedNanoTime = usedNanoTime;        this.lastNanoTime = lastNanoTime;    &#125;    &#125;\n\n然后我们在SpringBoot中定义一个定时任务，它将定时地统计计算每个线程的CPU信息，并输出到MeterRegistry，当你调用SpringActuator的接口时，你将能获取到这个指标。\nimport com.google.common.util.concurrent.AtomicDouble;import io.micrometer.core.instrument.Meter;import io.micrometer.core.instrument.MeterRegistry;import io.micrometer.core.instrument.Tags;import lombok.extern.slf4j.Slf4j;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.scheduling.annotation.Scheduled;import org.springframework.stereotype.Service;import java.lang.management.ManagementFactory;import java.lang.management.ThreadInfo;import java.lang.management.ThreadMXBean;import java.util.HashMap;@Slf4j@Servicepublic class ThreadMetricService &#123;    @Autowired    private MeterRegistry meterRegistry;    private final ThreadMXBean threadBean = ManagementFactory.getThreadMXBean();    private final HashMap&lt;Long, ThreadMetricsAux&gt; map = new HashMap&lt;&gt;();    private final HashMap&lt;Meter.Id, AtomicDouble&gt; dynamicGauges = new HashMap&lt;&gt;();    /**     * one minutes     */    @Scheduled(cron = &quot;0 * * * * ?&quot;)    public void schedule() &#123;        final long[] allThreadIds = threadBean.getAllThreadIds();        for (long threadId : allThreadIds) &#123;            final ThreadInfo threadInfo = threadBean.getThreadInfo(threadId);            if (threadInfo == null) &#123;                continue;            &#125;            final long threadNanoTime = getThreadCPUTime(threadId);            if (threadNanoTime == 0) &#123;                // 如果threadNanoTime为0，则识别为异常数据，不处理，并清理历史数据                map.remove(threadId);            &#125;            final long nanoTime = System.nanoTime();            ThreadMetricsAux oldMetrics = map.get(threadId);            // 判断是否有历史的metrics信息            if (oldMetrics != null) &#123;                // 如果有，则计算CPU信息并上报                double percent = (double) (threadNanoTime - oldMetrics.getUsedNanoTime()) / (double) (nanoTime - oldMetrics.getLastNanoTime());                handleDynamicGauge(&quot;jvm.threads.cpu&quot;, &quot;threadName&quot;, threadInfo.getThreadName(), percent);            &#125;            map.put(threadId, new ThreadMetricsAux(threadNanoTime, nanoTime));        &#125;    &#125;    // meter Gauge相关代码    private void handleDynamicGauge(String meterName, String labelKey, String labelValue, double snapshot) &#123;        Meter.Id id = new Meter.Id(meterName, Tags.of(labelKey, labelValue), null, null, Meter.Type.GAUGE);        dynamicGauges.compute(id, (key, current) -&gt; &#123;            if (current == null) &#123;                AtomicDouble initialValue = new AtomicDouble(snapshot);                meterRegistry.gauge(key.getName(), key.getTags(), initialValue);                return initialValue;            &#125; else &#123;                current.set(snapshot);                return current;            &#125;        &#125;);    &#125;    long getThreadCPUTime(long threadId) &#123;        long time = threadBean.getThreadCpuTime(threadId);        /* thread of the specified ID is not alive or does not exist */        return time == -1 ? 0 : time;    &#125;&#125;\n\n其他配置依赖配置pom文件中\n&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;io.micrometer&lt;/groupId&gt;    &lt;artifactId&gt;micrometer-registry-prometheus&lt;/artifactId&gt;&lt;/dependency&gt;\n\nPrometheus接口配置application.yaml中\nmanagement:  endpoints:    web:      exposure:        include: health,info,prometheus\n\n效果通过curl命令调用curl localhost:20001/actuator/prometheus|grep cpu\njvm_threads_cpu&#123;threadName=&quot;RMI Scheduler(0)&quot;,&#125; 0.0jvm_threads_cpu&#123;threadName=&quot;http-nio-20001-exec-10&quot;,&#125; 0.0jvm_threads_cpu&#123;threadName=&quot;Signal Dispatcher&quot;,&#125; 0.0jvm_threads_cpu&#123;threadName=&quot;Common-Cleaner&quot;,&#125; 3.1664628758074733E-7jvm_threads_cpu&#123;threadName=&quot;http-nio-20001-Poller&quot;,&#125; 7.772143763853949E-5jvm_threads_cpu&#123;threadName=&quot;http-nio-20001-Acceptor&quot;,&#125; 8.586978352515361E-5jvm_threads_cpu&#123;threadName=&quot;DestroyJavaVM&quot;,&#125; 0.0jvm_threads_cpu&#123;threadName=&quot;Monitor Ctrl-Break&quot;,&#125; 0.0jvm_threads_cpu&#123;threadName=&quot;AsyncHttpClient-timer-8-1&quot;,&#125; 2.524386571545477E-4jvm_threads_cpu&#123;threadName=&quot;Attach Listener&quot;,&#125; 0.0jvm_threads_cpu&#123;threadName=&quot;scheduling-1&quot;,&#125; 1.2269694160981585E-4jvm_threads_cpu&#123;threadName=&quot;container-0&quot;,&#125; 1.999795692406262E-6jvm_threads_cpu&#123;threadName=&quot;http-nio-20001-exec-9&quot;,&#125; 0.0jvm_threads_cpu&#123;threadName=&quot;http-nio-20001-exec-7&quot;,&#125; 0.0jvm_threads_cpu&#123;threadName=&quot;http-nio-20001-exec-8&quot;,&#125; 0.0jvm_threads_cpu&#123;threadName=&quot;http-nio-20001-exec-5&quot;,&#125; 0.0jvm_threads_cpu&#123;threadName=&quot;Notification Thread&quot;,&#125; 0.0jvm_threads_cpu&#123;threadName=&quot;http-nio-20001-exec-6&quot;,&#125; 0.0jvm_threads_cpu&#123;threadName=&quot;http-nio-20001-exec-3&quot;,&#125; 0.0jvm_threads_cpu&#123;threadName=&quot;http-nio-20001-exec-4&quot;,&#125; 0.0jvm_threads_cpu&#123;threadName=&quot;Reference Handler&quot;,&#125; 0.0jvm_threads_cpu&#123;threadName=&quot;http-nio-20001-exec-1&quot;,&#125; 0.0012674719289349648jvm_threads_cpu&#123;threadName=&quot;http-nio-20001-exec-2&quot;,&#125; 6.542541277148053E-5jvm_threads_cpu&#123;threadName=&quot;RMI TCP Connection(idle)&quot;,&#125; 1.3998786340454562E-6jvm_threads_cpu&#123;threadName=&quot;Finalizer&quot;,&#125; 0.0jvm_threads_cpu&#123;threadName=&quot;Catalina-utility-2&quot;,&#125; 7.920883054498174E-5jvm_threads_cpu&#123;threadName=&quot;RMI TCP Accept-0&quot;,&#125; 0.0jvm_threads_cpu&#123;threadName=&quot;Catalina-utility-1&quot;,&#125; 6.80101662787773E-5\n\nJava计算磁盘使用率https://support.huaweicloud.com/bestpractice-bms/bms_bp_2009.html\n华为云文档上的材料值得学习。\n翻阅资料\nhttps://www.kernel.org/doc/Documentation/ABI/testing/procfs-diskstats13 - time spent doing I/Os (ms)\n\n这就意味着如果我想统计一个磁盘在一定周期内的利用率，只需要对这两个数字做差，除以统计的间隔，即就是这段时间内磁盘的利用率\ncat /proc/diskstats 253       0 vda 24046 771 2042174 180187 20689748 21411881 527517532 18028256 0 14610513 18201352 253       1 vda1 23959 771 2038022 180153 20683957 21411881 527517532 18028066 0 14610312 18201129\n\n样例代码\npackage com.github.hezhangjian.demo.metrics;import com.github.hezhangjian.demo.base.module.ShellResult;import com.github.hezhangjian.demo.base.util.LogUtil;import com.github.hezhangjian.demo.base.util.ShellUtil;import com.github.hezhangjian.demo.base.util.StringUtil;import lombok.extern.slf4j.Slf4j;import java.util.concurrent.Executors;import java.util.concurrent.ScheduledExecutorService;import java.util.concurrent.TimeUnit;/** * @author hezhangjian */@Slf4jpublic class DiskUtilizationMetrics &#123;    private static final ScheduledExecutorService scheduledExecutor = Executors.newSingleThreadScheduledExecutor();    private static long lastTime = -1;    public static void main(String[] args) &#123;        LogUtil.configureLog();        String diskName = &quot;vda1&quot;;        scheduledExecutor.scheduleAtFixedRate(() -&gt; metrics(diskName), 0, 10, TimeUnit.SECONDS);    &#125;    private static void metrics(String diskName) &#123;        //假设统计vda磁盘        String[] cmd = &#123;                &quot;/bin/bash&quot;,                &quot;-c&quot;,                &quot;cat /proc/diskstats |grep &quot; + diskName + &quot;|awk &#x27;&#123;print $13&#125;&#x27;&quot;        &#125;;        ShellResult shellResult = ShellUtil.executeCmd(cmd);        String timeStr = shellResult.getInputContent().substring(0, shellResult.getInputContent().length() - 1);        long time = Long.parseLong(timeStr);        if (lastTime == -1) &#123;            log.info(&quot;first time cal, usage time is [&#123;&#125;]&quot;, time);        &#125; else &#123;            double usage = (time - lastTime) / (double) 10_000;            log.info(&quot;usage time is [&#123;&#125;]&quot;, usage);        &#125;        lastTime = time;    &#125;&#125;\n\n打印CPU使用private static void printCpuUsage() &#123;        final com.sun.management.OperatingSystemMXBean platformMXBean = ManagementFactory.getPlatformMXBean(com.sun.management.OperatingSystemMXBean.class);        double cpuLoad = platformMXBean.getProcessCpuLoad();        System.out.println(cpuLoad);    &#125;\n\n打印线程堆栈private static void printThreadDump() &#123;        final StringBuilder dump = new StringBuilder();        final ThreadMXBean threadMXBean = ManagementFactory.getThreadMXBean();        // 100代表线程堆栈的层级        final ThreadInfo[] threadInfos = threadMXBean.getThreadInfo(threadMXBean.getAllThreadIds(), 100);        for (ThreadInfo threadInfo : threadInfos) &#123;            dump.append(&#x27;&quot;&#x27;);            dump.append(threadInfo.getThreadName());            dump.append(&quot;\\&quot; &quot;);            final Thread.State state = threadInfo.getThreadState();            dump.append(&quot;\\n   java.lang.Thread.State: &quot;);            dump.append(state);            final StackTraceElement[] stackTraceElements = threadInfo.getStackTrace();            for (final StackTraceElement stackTraceElement : stackTraceElements) &#123;                dump.append(&quot;\\n        at &quot;);                dump.append(stackTraceElement);            &#125;            dump.append(&quot;\\n\\n&quot;);        &#125;        System.out.println(dump);    &#125;\n\n打印内存统计信息引入依赖\n&lt;dependency&gt;           &lt;groupId&gt;com.jerolba&lt;/groupId&gt;           &lt;artifactId&gt;jmnemohistosyne&lt;/artifactId&gt;           &lt;version&gt;0.2.3&lt;/version&gt;       &lt;/dependency&gt;\n\nprivate static void printClassHisto() &#123;       Histogramer histogramer = new Histogramer();       MemoryHistogram histogram = histogramer.createHistogram();       HistogramEntry arrayList = histogram.get(&quot;java.util.ArrayList&quot;);       System.out.println(arrayList.getInstances());       System.out.println(arrayList.getSize());       for (HistogramEntry entry : histogram) &#123;           System.out.println(entry);       &#125;   &#125;\n\n打印死锁javadoc中指出，这是一个开销较大的操作\nprivate static void printDeadLock() &#123;       final ThreadMXBean threadMXBean = ManagementFactory.getThreadMXBean();       final long[] deadlockedThreads = threadMXBean.findDeadlockedThreads();       for (long deadlockedThread : deadlockedThreads) &#123;           final ThreadInfo threadInfo = threadMXBean.getThreadInfo(deadlockedThread);           System.out.println(threadInfo + &quot;deadLocked&quot;);       &#125;   &#125;\n","tags":["Java"]},{"title":"java日志打印心得","url":"/2024/04/09/Java%E6%97%A5%E5%BF%97%E6%89%93%E5%8D%B0%E5%BF%83%E5%BE%97/","content":"对于一个组件来说，日志打印常见的有三种选择：\n\n不打印日志，只提供回调函数。将打印日志还是忽略的权利交给组件的使用者\n可以由使用者设置一些参数，但组件自己管理整个日志的生命周期\n适配生态内的日志框架，组件打印日志，但将输出的控制权控制反转给使用者\n\njava生态slf4j已经成为事实上的标准，像Apache Ignite在最开始的时候也将日志作为自己的Spi定义，是向着2来发展的，但在Ignite3版本也去掉。Go生态由于去没有这样的标准，很多library只能选择2，导致引入了一个go library，它的日志会怎么出来，对于使用者来说是一个未知数。\njava生态的基本原则如下：\n\nlibrary，不会独立部署的组件，只引入slf4j-api，不引入具体的实现，可以在单元测试里面引入某个实现，用于测试打印日志。\n简单的sdk不打印日志，复杂的sdk可以打印一些关键日志，但QPS级别的日志不要打印，不要替用户做选择。\n\n\n如果在一个高度一致的团队内，可以无视上面两条\n\n","tags":["Java","log"]},{"title":"Java时间相关类转换","url":"/2024/03/28/Java%E6%97%B6%E9%97%B4%E7%9B%B8%E5%85%B3%E7%B1%BB%E8%BD%AC%E6%8D%A2/","content":"\n","tags":["Java"]},{"title":"java进行数据库操作的并发控制","url":"/2023/12/25/Java%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E5%BA%93%E6%93%8D%E4%BD%9C%E7%9A%84%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6/","content":"在现代应用编码中，从数据库里面find出来，进行一些业务逻辑操作，最后再save回去。即：\nPerson person = personRepo.findById(id);person.setAge(18);personRepo.save(person);\n\n但是这样的业务操作，如果一个线程修改年龄，另一个线程修改昵称，最后save回去，可能会导致年龄&#x2F;昵称某一个的修改被覆盖。\nsequenceDiagram\n    participant A as Thread A\n    participant B as Thread B\n    participant DB as Database\n\n    A->>DB: find person by id\n    Note over A: person.setAge(18)\n    B->>DB: find person by id\n    Note over B: person.setNickname(\"NewName\")\n\n    A->>DB: save person\n    B->>DB: save person\n\n    Note over DB: Potential Overwrite Issue\n\n常见的解决方案有两种\n执行前添加悲观锁通过分布式锁等方式，保证同一时间只有一个线程能够对数据进行修改。\n乐观锁思路实现版本控制是另一种流行的处理并发问题的方法。它通过在每次更新记录时递增版本号来确保数据的一致性。\n这在JPA中，可以通过在field上添加@Version注解来实现，但这也就要求①数据库中必须有version字段，②对于查找后更新类操作，必须使用JPA的save方法来进行更新。\n当然也可以通过update_time来模拟乐观锁实现，这可能需要你在更新的时候添加update_time的条件，并且，update_time在极端场景下，理论正确性没那么严谨。\n import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs';\tmermaid.initialize({startOnLoad: true, flowchart: {curve: 'linear'}}); ","tags":["Java","database"]},{"title":"Kubernetes pod内调用API","url":"/2021/04/13/Kubernetes%20pod%E5%86%85%E8%B0%83%E7%94%A8API/","content":"Kubernetes pod内调用API的流程总体分为以下步骤\n\n创建role\n创建serviceaccount\n绑定role到serviceaccount\n指定pod使用serviceaccount\n\n我们以查pod为例，演示一下整个流程\n创建role# role.yamlapiVersion: rbac.authorization.k8s.io/v1kind: Rolemetadata:  name: role-hzj  namespace: defaultrules:  - apiGroups: [&quot;&quot;]    resources: [&quot;pods&quot;]    verbs: [&quot;get&quot;,&quot;list&quot;]\n\nkubectl apply -f role.yaml\n\n创建serviceaccount# serviceaccount.yamlapiVersion: v1kind: ServiceAccountmetadata:  name: serviceaccount-hzj  namespace: default\n\nkubectl apply -f serviceaccount.yaml\n\n绑定role# rolebinding.yamlapiVersion: rbac.authorization.k8s.io/v1kind: RoleBindingmetadata:  name: rolebinding-hzj  namespace: defaultsubjects:  - kind: ServiceAccount    name: serviceaccount-hzj    namespace: defaultroleRef:  kind: Role  name: role-hzj  apiGroup: rbac.authorization.k8s.io\n\nkubectl apply -f rolebinding.yaml\n\n部署pod进行测试部署一个zookeeper进行测试手上刚好有zookeeper的模板文件\napiVersion: apps/v1kind: Deploymentmetadata:  name: zookeeper  labels:    app: zookeeperspec:  replicas: 1  selector:    matchLabels:      app: zookeeper  template:    metadata:      labels:        app: zookeeper    spec:      hostNetwork: true      dnsPolicy: ClusterFirstWithHostNet      containers:      - name: zookeeper        image: ttbb/zookeeper:stand-alone        imagePullPolicy: IfNotPresent        resources:          limits:            memory: 2G            cpu: 1000m          requests:            memory: 2G            cpu: 1000m        env:        - name: NODE_NAME          valueFrom:            fieldRef:                fieldPath: spec.nodeName        - name: POD_NAME          valueFrom:            fieldRef:                fieldPath: metadata.name        - name: PS1          value: &#x27;[\\u@zookeeper@\\W]\\$ &#x27;\n\n\n\n调用API# Point to the internal API server hostnameAPISERVER=https://kubernetes.default.svc# Path to ServiceAccount tokenSERVICEACCOUNT=/var/run/secrets/kubernetes.io/serviceaccount# Read this Pod&#x27;s namespaceNAMESPACE=$(cat $&#123;SERVICEACCOUNT&#125;/namespace)# Read the ServiceAccount bearer tokenTOKEN=$(cat $&#123;SERVICEACCOUNT&#125;/token)# Reference the internal certificate authority (CA)CACERT=$&#123;SERVICEACCOUNT&#125;/ca.crt# Explore the API with TOKENcurl --cacert $&#123;CACERT&#125; --header &quot;Authorization: Bearer $&#123;TOKEN&#125;&quot; -X GET $&#123;APISERVER&#125;/apicurl --cacert $&#123;CACERT&#125; --header &quot;Authorization: Bearer $&#123;TOKEN&#125;&quot; -X GET $&#123;APISERVER&#125;/api/v1/namespaces/default/pods\n\n\n发现这里，调用后面的api，403错误。第一个api不报错，是因为该接口不需要鉴权。\n修改pod对应的serviceaccount让我们修改部署模板对应的ServiceAccountName，注入权限。在pod的spec下，设置serviceAccountName\n\n修改部署模板重启后调用api正常再次尝试上述命令，api结果返回正常\n\n","tags":["Kubernetes"]},{"title":"kubernetes容器获取IP地址","url":"/2023/01/06/Kubernetes%E5%AE%B9%E5%99%A8%E8%8E%B7%E5%8F%96IP%E5%9C%B0%E5%9D%80/","content":"kubernetes中容器获取IP地址是一个常见的需求，常见的有两种获取IP地址的方式\nkubernetes环境变量注入通过在部署时，container下的env中配置如下yaml\n- name: POD_IP  valueFrom:    fieldRef:      apiVersion: v1      fieldPath: status.podIP\n\n进入容器就可以根据环境变量获取到容器IP\n# echo $POD_IP172.17.0.2\n\n通过shell脚本获取通过ip命令（推荐）# ip addr show eth0 | grep &quot;inet\\b&quot; | awk &#x27;&#123;print $2&#125;&#x27; | cut -d/ -f1172.17.0.2\n\n注意这里一定要用inet\\b，不要用inet。使用inet的话，在Ipv6双栈场景下会因为匹配到inet6获取到错误的结果, Ipv6双栈场景下ip命令的部分输出结果如下图所示\ninet 172.17.0.2/16 brd 172.17.255.255 scope global eth0inet6 fe80::ffff prefixlen 64 scopeid 0x20&lt;lin&gt;\n\n通过ifconfig命令（不推荐）不推荐使用ifconfig命令的原因是，这个命令已经废弃，将会逐步删除\nifconfig eth0 | grep &#x27;inet\\b&#x27; | awk &#x27;&#123;print $2&#125;&#x27; | cut -d/ -f1\n\n同样需要使用inet\\b，不要使用inet\nTLDR优先配置如下yaml进行环境变量注入，其次使用ip addr show eth0 | grep “inet\\b” | awk ‘{print $2}’ | cut -d&#x2F; -f1命令获取\n- name: POD_IP  valueFrom:    fieldRef:      apiVersion: v1      fieldPath: status.podIP\n","tags":["Kubernetes"]},{"title":"LVS persistent timeout和connection timeout解析","url":"/2021/03/19/LVS%20persistent%20timeout%E5%92%8Cconnection%20timeout%E8%A7%A3%E6%9E%90/","content":"两个超时的注释首先看一下一下ipvsadm -h对这两个参数的注释\npersistent timeout--persistent  -p [timeout]     persistent serviceSpecify that a virtual service is persistent. If this option is specified, multiple requests from a client are redirected to the same real server selected for the first request. Optionally, the timeout of persistent sessions may be specified given in seconds, otherwise the default of 300 seconds will be used. This option may be used in conjunction with protocols such as SSL or FTP where it is important that clients consistently connect with the same real server.\n\n说明这个VS是否是持久的。如果配置了这个选项，来自同一个客户端的链接（这里注意：这里的同一个客户端指的是同一个IP）会转发向相同的服务器。注释中特意提到了FTP协议。我查阅了一下资料，可能像FTP协议这种，客户端通过21端口打开控制连接，再通过20端口打开数据连接，这种协议，要求来自同一个客户端ip，不同端口的请求也送向同一个服务器，估计是这个参数存在的核心原因。如果是现在的系统，比如k8s使用ipvs，这个参数是完全没必要配置的\nconnection timeout--set tcp tcpfin udpChange the timeout values used for IPVS connections. This command always takes 3 parameters, representing the timeout values (in seconds) for TCP sessions, TCP sessions after receiving a FIN packet, and UDP packets, respectively. A timeout value 0 means that the current timeout value of the corresponding entry is preserved.\n\n更改用于ipvs连接的超时值。此命令始终使用3个参数，分别表示tcp会话，接收到FIN包的TCP会话和UDP包的超时值。单位为秒。设置为0并不代表将超时值设置为0，而是保持原有不变。顺便来说，timeout的默认值是900、120、300.\n区别一个以客户端ip为维度，一个以客户端ip+port为维度\n联系：\npersistent值大于等于set时，persistent timeout以persistent的设置为准。\npersistent值小于set时，当set超时，但persistent超时后，会将persistent再次设置为60。只到set超时为止。所以这个时候，真实生效的persistent timeout是(s/60)*60 + p%60 + 60\n\n","tags":["LVS"]},{"title":"lvs 性能手册","url":"/2022/08/01/LVS%20%E6%80%A7%E8%83%BD%E6%89%8B%E5%86%8C/","content":"lvs是做什么的lvs通常用做tcp&#x2F;udp协议的四层负载均衡\n\n相比也可以用于四层负载的Nginx组件，Lvs因为运行在内核态，性能高是它的主要优势，同样，因为运行在内核态中，无法像Nginx那样，对四层的tls做卸载等动作。\nlvs性能相关指标(用户视角)客户端的连接数\nUDP模式下，按连接超时时间计算（根据业务需求决定）。可通过ipvsadm -l --timeout来查看udp超时时间\nTCP模式下，即为tcp连接数\n\n客户端请求流量即client与lvs、lvs与RS之间交互的流量\n客户端请求平均包大小即client与lvs、lvs与RS之间的平均包大小\nlvs性能相关参数会话超时时间查看ipvsadm -l --timeout\n\n修改ipvsadm --set $&#123;tcptimeout&#125; $&#123;tcpfintimeout&#125; $&#123;udptimeout&#125;\n\nvm conntrack最大个数查看sysctl -a |grep net.netfilter.nf_conntrack_max\n\n查看当前nf_conntrack个数# 方式一conntrack -C# 方式二cat /proc/net/nf_conntrack | wc -l\n\n修改sysctl -w net.netfilter.nf_conntrack_max=1024\n\nhashsize什么是hashsizehashsize也就是nf_conntrack_buckets，如果不手动指定。linux会根据机器的内存计算。如果要支持海量的nf_conntrack，则可以适当调大。\n  // nf_conntrack_core.c  nf_conntrack_htable_size\t= (((nr_pages &lt;&lt; PAGE_SHIFT) / 16384)\t   / sizeof(struct hlist_head));if (BITS_PER_LONG &gt;= 64 &amp;&amp;    nr_pages &gt; (4 * (1024 * 1024 * 1024 / PAGE_SIZE)))\tnf_conntrack_htable_size = 262144;else if (nr_pages &gt; (1024 * 1024 * 1024 / PAGE_SIZE))\tnf_conntrack_htable_size = 65536;if (nf_conntrack_htable_size &lt; 1024)\tnf_conntrack_htable_size = 1024;\n\nhlist_head的大小在64位的机器下大小为16\n查看cat /sys/module/nf_conntrack/parameters/hashsize\n\n修改 （方式一）echo 65536 &gt; /sys/module/nf_conntrack/parameters/hashsize\n\n修改（方式二）永久生效# exmaple file, you can modify this config if exists. File name doesn&#x27;t matter.# 样例文件，你可以修改已存在的这个文件。文件名称并不重要。touch /etc/modprobe.d/lvs.confecho &quot;options nf_conntrack hashsize=65536&quot; &gt;&gt; /etc/modprobe.d/lvs.conf# then you need reboot# 需要重试来使配置生效\n\n文件句柄数查看ulimit -n\n\n修改不同的linux发行版，修改方式不太一样，以RedHat为例\nnum=`ulimit -n`sed -i &quot;s|$num|65536|g&quot; /etc/security/limits.d/*-nofile.conf\n\nlvs性能瓶颈虚拟机内存contnrack使用slab分配内存，可以通过slabtop命令查看nf_conntrack模块占用的内存。当连接数较高时，Lvs的内存瓶颈在于会话管理。\nconntrack最大理论内存占用为\nmax_mem_used = conntrack * max * sizeof (struct nf_conntrack) + conntrack_buckets * sizeof (struct list_head)\n\n使用如下python代码计算\nimport ctypes# 这个是nf_conntrack的动态库所在路径# libnetfilter git地址 git://git.netfilter.org/libnetfilter_conntrackLIBNETFILTER_CONNTRACK = &#x27;/usr/lib/aarch64-linux-gnu/libnetfilter_conntrack.so.3.7.0&#x27;nfct = ctypes.CDLL(LIBNETFILTER_CONNTRACK)print(&quot;max size of struct nf_conntrack:&quot;)print(nfct.nfct_maxsize())print(&quot;sizeof(struct list_head):&quot;)print(ctypes.sizeof(ctypes.c_void_p) * 2)\n\n其中nfct_maxsize出自于git://git.netfilter.org/libnetfilter_conntrack中的src/conntrack/api.c\n/** * nfct_maxsize - return the maximum size in bytes of a conntrack object */\n\n在如下操作系统下\nuname -a&gt; Linux primary 5.4.0-122-generic #138-Ubuntu SMP Wed Jun 22 15:05:39 UTC 2022 aarch64 aarch64 aarch64 GNU/Linux\n\n以100万conntrack_max，65536buckets为例，占用的内存为\n1_000_000 * 392 + 65536 * 16 约等于 373.84 + 1 为374M内存\n网卡流量最大进出带宽。在云上，通常由云厂商限制。如果你将lvs上面的浮动Ip通过EIP的方式暴露出去（这很常见），还需要考虑EIP自身的带宽\n网卡进出包个数（PPS)最大进出包个数\n虚拟机能支持的最大网络连接数ECS上可以支持的最大网络连接数。在云上，通常由云厂商限制\nLvs监控&amp;扩容cpu使用率可在超过百分之80的时候告警。处理方式：\n\n如果内存还没有到达瓶颈，可以通过扩大hashsize的方式，降低hash链上元素的个数，减少匹配消耗的cpu\n如果内存水位也较高。对CPU进行扩容\n\n内存使用率可在超过内存容量百分之80的时候告警。处理方式：扩容内存\nconntrack个数通过conntrack -C或cat /proc/net/nf_conntrack | wc -l, 定期进行统计，使用sysctl -w net.netfilter.nf_conntrack_max进行扩容\n网卡流量、网卡进出包个数可以利用云厂商的监控或nicstat命令查看。处理方式：扩容网卡\n最大网络连接数可以利用云厂商的监控或netstat -an|egrep &quot;tcp|udp&quot;|grep -v &quot;LISTEN&quot;|wc -l或ss -tun state all | grep -v LISTEN | wc -l查看。处理方式：扩容ECS规格\nEIP带宽通过云厂商的指标来监控。处理方式，扩容EIP的BGP带宽\n","tags":["LVS"]},{"title":"linux umask 解析","url":"/2022/11/08/Linux%20umask%20%E8%A7%A3%E6%9E%90/","content":"什么是umask， umask即user file-creation mask. 用来控制最终创建文件的权限。\numask是进程级属性，通常是由login shell设置，可以通过系统调用umask()或者命令umask permission来修改，通过umask命令来查询，linux内核版本4.7之后，还可以通过cat &#x2F;proc&#x2F;self&#x2F;status|grep -i umask 查询，示例如下\nhezhangjian:~/masktest $ umask0022hezhangjian:~/masktest $ umask 0077hezhangjian:~/masktest $ umask0077hezhangjian:~/masktest $ umask 0022hezhangjian:~/masktest $ umask0022hezhangjian:~/masktest $\n\n一般来说，umask的系统默认值在**&#x2F;etc&#x2F;login.defs** 中设置\nhezhangjian:~ $cat /etc/login.defs|grep -i umask#\tUMASK\t\tDefault &quot;umask&quot; value.# UMASK is the default umask value for pam_umask and is used by# 022 is the &quot;historical&quot; value in Debian for UMASK# If USERGROUPS_ENAB is set to &quot;yes&quot;, that will modify this UMASK default valueUMASK\t\t022# Other former uses of this variable such as setting the umask when\n\n\n最常见的默认的umask值是022，目录权限755，文件权限644\n077 的 umask 适用于私有的系统，则其他用户无法读取或写入您的数据。\n\n针对标准函数open来说，最终写入磁盘的权限位是由mode参数和用户的文件创建掩码(umask)执行按位与操作而得到。\n假设当umask为0022时，创建一个具有0666权限的文件，就会进行运算决定文件的最终权限，先对掩码取非，再和指定的权限进行binary-And操作，如图所示\n\n示例代码如下\n#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;#include &lt;fcntl.h&gt;#include &lt;unistd.h&gt;int main(int argc, char *argv[]) &#123;    int fd;    if (argc != 2) &#123;        fprintf(stderr, &quot;usage: %s &lt;file&gt;&quot;, argv[0]);        exit(1);    &#125;    fprintf(stdout, &quot;create file %s&quot;, argv[1]);    fd = open(argv[1], O_WRONLY | O_CREAT | O_TRUNC, 0666);    if (fd == -1) &#123;        perror(&quot;open&quot;);        exit(1);    &#125;    close(fd);&#125;\n\n结果如下，权限644，符合预期\nlltotal 8drwxr-xr-x  2 hezhangjian hezhangjian 4096 Nov  8 06:25 .drwxr-xr-x 15 hezhangjian hezhangjian 4096 Nov  8 06:18 ..-rw-r--r--  1 hezhangjian hezhangjian    0 Nov  8 06:25 my.txt\n","tags":["Linux"]},{"title":"Linux根据源地址ip路由","url":"/2020/09/10/Linux%E6%A0%B9%E6%8D%AE%E6%BA%90%E5%9C%B0%E5%9D%80ip%E8%B7%AF%E7%94%B1/","content":"Hash-based multipath routing该特性在Linux4.4版本引入，一个难以被大家发现的好处是，基于源地址路由，没有做地址转换，并不会在nf_conntrack中添加记录它是对源IP和目标IP进行哈希处理(端口不参与哈希的计算)计算选路。配置的命令如下:weight代表权重\n通过网关负载均衡ip route add default  proto static scope global \\nexthop  via &lt;gw_1&gt; weight 1 \\nexthop  via &lt;gw_2&gt; weight 1\n通过网卡负载均衡ip route add default  proto static scope global \\ nexthop  dev &lt;if_1&gt; weight 1 \\ nexthop  dev &lt;if_2&gt; weight 1\n","tags":["Linux"]},{"title":"MySQL异步复制中的数据不一致问题","url":"/2024/07/09/MySQL%E5%BC%82%E6%AD%A5%E5%A4%8D%E5%88%B6%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B8%8D%E4%B8%80%E8%87%B4%E9%97%AE%E9%A2%98/","content":"前提Mysql8.0.X版本，且核心配置如下\ngtid_mode=ONbinlog_format=rowslave_skip_errors=all\n\n数据不一致的根本原因在于MySQL在设计上不具备分布式系统的完整语义，这导致主从复制在面对网络分区和延迟时无法保持数据一致性。（又不可能采取全同步的模式，那就变成一个CP系统了）。根据数据冲突的内容，如果是**“不同主键，不触发唯一键约束的数据冲突”**，那么后续很容易可以同步到一致。如果触发了主键或者唯一键的冲突，无法互相同步，场景会变得复杂一些，简而言之，只有当后续的操作可以同时在主&#x2F;备两个数据库中抹平这个差距，数据才能恢复，并且约束越多，抹平也就变得愈困难。举例\n\n仅存在主键约束，数据内容不同，通过下次操作主键(update&#x2F;delete)，则可以恢复\n数据库自增主键（两条数据主键不同），触发了唯一字段约束，后续的操作要同时抹平主键、唯一字段、其他内容才能恢复一致（比如根据相同的条件删除掉这条数据等）\n\n下文将分别以插入为例讨论这几个场景，用红色叉号代表同步延迟或者断开。\n注：由于Mysql主备同步时会将upsert类的sql转换为实际执行的insert、update语句，也就是说upsert的语义在主备同步不稳定&#x2F;切换时，容易丢失。\n不同主键，不触发唯一键约束的数据冲突设想表结构，仅有一个name字段，且name为主键。比如我们先在MysqlA中插入了数据name&#x3D;tt，假设发生了切换，又向MysqlB插入了数据name&#x3D;wtt。\n\n这就导致MysqlA与MysqlB里面的数据存在着不一致，但是一旦同步恢复，数据就会一致。\n\n仅主键约束，内容不一致冲突表结构，拥有两个字段，name为主键，age为字段。\n同样，插入了两条数据，导致冲突。\n\n即使MysqlA和MysqlB之间同步恢复，后续insert语句也会由于主键冲突同步失败。\n\n这种不一致要等到后续对主键进行update操作后，才能恢复一致\n\n包含主键、唯一约束在内的冲突场景主键为数据库自增主键，其中一个库为奇数，另一个库为偶数。同时还有唯一约束name\n\n这时候插入数据，就会导致不一致，并且主键也不相同，由于业务不感知主键，使用不存在则更新的语法也会导致主键不一致。\n\n可以预想到即使恢复同步，MysqlA和MysqlB数据也无法一致。\n\n在这种场景下，任何针对id的SQL操作都无法在双方数据库中成功同步。例如，MysqlB数据库中不存在id为0的记录，而MysqlA中不存在id为1的记录，导致同步操作失败。\n想要恢复一致，可以通过业务唯一约束来删除记录或者是根据业务约束把Mysql主键id也一并更新（不过这很困难，一般这种业务是不会直接操作id的）\n那么可能会有人有疑问，为什么不像之前那样，用name作为唯一主键呢？\n答：业务的需求多种多样，而且如果唯一约束由多个字段组成，使用Mysql自增主键是唯一的选择。\n总结本文探讨了Mysql异步复制模式下的数据不一致问题，容易在什么时候产生，什么时候恢复。总的来说，业务如果只有一个唯一主键，出现不一致的概率更小。如果业务用数据库自增作为主键，同时伴有唯一约束的插入操作（如upsert等），更容易出现长期的不一致。\n","tags":["MySQL"]},{"title":"Mysql是如何隐藏ps命令行中的密码的","url":"/2021/04/26/MySQL%E6%98%AF%E5%A6%82%E4%BD%95%E9%9A%90%E8%97%8Fps%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%AD%E7%9A%84%E5%AF%86%E7%A0%81%E7%9A%84/","content":"参考\nhttp://northernmost.org/blog/how-does-mysql-hide-the-command-line-password-in-ps/index.html\n\n之前就在环境上ps -ef看到过xxxxxx的密码，一直没搞明白怎么回事，今天整理了一下，核心内容均来自于上述连接，作了一些额外的测试和查阅资料。\n测试运行Mysql实例# 自己做的Mysql8的镜像docker run ttbb/mysql:stand-alone\n\n使用密码连接Mysql服务器mysql -u hzj -p Mysql@123 -e &quot;select 1&quot;\n\nps -ef查看[root@91bcbd15a82e mysql]# ps -efUID        PID  PPID  C STIME TTY          TIME CMDroot         1     0  0 07:34 ?        00:00:00 /usr/local/bin/dumb-init bash -vx /opt/sh/mysql/hzj/scripts/start.shroot         8     1  0 07:34 ?        00:00:00 bash -vx /opt/sh/mysql/hzj/scripts/start.shroot        17     1  0 07:34 ?        00:00:00 mysqld --daemonize --user=rootroot        62     8  0 07:34 ?        00:00:00 tail -f /dev/nullroot        63     0  0 07:34 pts/0    00:00:00 bashroot        98    63  0 07:37 pts/0    00:00:00 mysql -h 127.0.0.1 -u hzj -px xxxxxxxroot        99     0  1 07:37 pts/1    00:00:00 bashroot       122    99  0 07:37 pts/1    00:00:00 ps -ef\n\nMysql隐藏密码原理改写了args系统参数，demo如下\n//// Created by 张俭 on 2021/4/26.//#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;string.h&gt;int main(int argc, char *argv[]) &#123;    int i = 0;    pid_t mypid = getpid();    if (argc == 1)        return 1;    printf(&quot;argc = %d and arguments are:\\n&quot;, argc);    for (i; i &lt; argc; i++) &#123;        printf(&quot;%d = %s\\n&quot;, i, argv[i]);    &#125;    fflush(stdout);    sleep(30);    printf(&quot;Replacing first argument with x:es... Now open another terminal and run: ps p %d\\n&quot;, (int)mypid);    memset(argv[1], &#x27;x&#x27;, strlen(argv[1]));    getc(stdin);    return 0;&#125;\n\n编译并运行\ngcc password_hide.c[root@c77dc365cd1a sh]# ./a.out abcdargc = 2 and arguments are:0 = ./a.out1 = abcdReplacing first argument with x:es... Now open another terminal and run: ps p 55\n观测结果，开始看的确有明文密码\n[root@c77dc365cd1a sh]# ps -efUID        PID  PPID  C STIME TTY          TIME CMDroot         1     0  0 07:49 pts/0    00:00:00 bashroot        32     0  0 07:51 pts/1    00:00:00 bashroot        64     1  0 07:56 pts/0    00:00:00 ./a.out abcdroot        66    32  0 07:56 pts/1    00:00:00 ps -ef\n经过30秒后，已经被复写\n[root@c77dc365cd1a sh]# ps p 55  PID TTY      STAT   TIME COMMAND   55 pts/0    S+     0:00 ./a.out xxxx\nMysql源码地址mysql-server&#x2F;client&#x2F;mysql.cc line 2054\nif (argument) &#123;  char *start = argument;  my_free(opt_password);  opt_password = my_strdup(PSI_NOT_INSTRUMENTED, argument, MYF(MY_FAE));  while (*argument) *argument++ = &#x27;x&#x27;;  // Destroy argument  if (*start) start[1] = 0;  tty_password = false;&#125; else  tty_password = true;\n\nPS: 后面，我还在OSX上用go程序尝试修改参数，估摸go程序的args传入是值拷贝，修改完成之后args没有生效，看来这个黑科技只有c程序能使用呀。\n","tags":["MySQL"]},{"title":"Nginx支持SNI转发","url":"/2020/12/05/Nginx%E6%94%AF%E6%8C%81SNI%E8%BD%AC%E5%8F%91/","content":"SNI是一个TLS的扩展字段，经常用于访问域名跳转到不同的后端地址。\n配置方式如下：打开nginx.conf文件，以ttbb&#x2F;nginx:nake镜像为例&#x2F;usr&#x2F;local&#x2F;openresty&#x2F;nginx&#x2F;conf&#x2F;nginx.conf\n如下为默认的nginx.conf配置\n#user  nobody;worker_processes  1;#error_log  logs/error.log;#error_log  logs/error.log  notice;#error_log  logs/error.log  info;#pid        logs/nginx.pid;events &#123;    worker_connections  1024;&#125;http &#123;    include       mime.types;    default_type  application/octet-stream;    #log_format  main  &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27;    #                  &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27;    #                  &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;;    #access_log  logs/access.log  main;    sendfile        on;    #tcp_nopush     on;    #keepalive_timeout  0;    keepalive_timeout  65;    #gzip  on;    server &#123;        listen       80;        server_name  localhost;        #charset koi8-r;        #access_log  logs/host.access.log  main;        location / &#123;            root   html;            index  index.html index.htm;        &#125;        #error_page  404              /404.html;        # redirect server error pages to the static page /50x.html        #        error_page   500 502 503 504  /50x.html;        location = /50x.html &#123;            root   html;        &#125;        # proxy the PHP scripts to Apache listening on 127.0.0.1:80        #        #location ~ \\.php$ &#123;        #    proxy_pass   http://127.0.0.1;        #&#125;        # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000        #        #location ~ \\.php$ &#123;        #    root           html;        #    fastcgi_pass   127.0.0.1:9000;        #    fastcgi_index  index.php;        #    fastcgi_param  SCRIPT_FILENAME  /scripts$fastcgi_script_name;        #    include        fastcgi_params;        #&#125;        # deny access to .htaccess files, if Apache&#x27;s document root        # concurs with nginx&#x27;s one        #        #location ~ /\\.ht &#123;        #    deny  all;        #&#125;    &#125;    # another virtual host using mix of IP-, name-, and port-based configuration    #    #server &#123;    #    listen       8000;    #    listen       somename:8080;    #    server_name  somename  alias  another.alias;    #    location / &#123;    #        root   html;    #        index  index.html index.htm;    #    &#125;    #&#125;    # HTTPS server    #    #server &#123;    #    listen       443 ssl;    #    server_name  localhost;    #    ssl_certificate      cert.pem;    #    ssl_certificate_key  cert.key;    #    ssl_session_cache    shared:SSL:1m;    #    ssl_session_timeout  5m;    #    ssl_ciphers  HIGH:!aNULL:!MD5;    #    ssl_prefer_server_ciphers  on;    #    location / &#123;    #        root   html;    #        index  index.html index.htm;    #    &#125;    #&#125;&#125;\n\n在最后面添加上\nstream &#123;map $ssl_preread_server_name $name &#123;    backend.example.com      backend;    default                  backend2;&#125;upstream backend &#123;    server 192.168.0.3:12345;    server 192.168.0.4:12345;&#125;upstream backend2 &#123;    server 127.0.0.1:8071;&#125;server &#123;    listen      12346;    proxy_pass  $name;    ssl_preread on;&#125;&#125;\n这个时候，我们已经开启了SNI转发的功能，如果你使用backend.example.com的域名访问服务器，就会转发到backend，如果使用其他域名，就会转发到backend2\n测试的时候，让我们在&#x2F;etc&#x2F;hosts里进行设置，添加\n127.0.0.1 backend.example.com\n\n然后进行请求\ncurl https://backend.example.com:12346\n\n这里注意请求要使用https，http协议或者是tcp可没有SNI的说法\n\n发现请求的确实是backend\n然后测试请求127.0.0.1:12346\ncurl https://127.0.0.1:12346\n\n\n","tags":["Nginx"]},{"title":"Palantir Foundry技术演进：从定制代码到AIP智能决策","url":"/2025/10/10/Palantir%20Foundry%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%EF%BC%9A%E4%BB%8E%E5%AE%9A%E5%88%B6%E4%BB%A3%E7%A0%81%E5%88%B0AIP%E6%99%BA%E8%83%BD%E5%86%B3%E7%AD%96/","content":"TLDR笔者推测Palantir起初以支持定制代码运行为基础，在构筑自己部署平台（Apollo，Palantir GitHub上也有很多开发者构建、Lint工具）的同时，逐渐抽象出Dataset、本体、Function、Action API，打造了坚实的Foundry平台，让应用从定制化开发逐步“长在平台上”。最终，Palantir 推出人工智能平台（AIP），实现数据驱动的智能决策。\n前言近年来，Palantir 无疑成为数据分析领域的焦点之一。作为一家以解决复杂问题为核心的公司，Palantir 为政府、国防和企业客户提供了强大的数据整合与分析能力。Palantir 的核心产品 Foundry 是一个面向数据整合与分析的平台，它如何从最初的定制化开发逐渐演变为如今的通用数据智能平台？笔者尝试基于公开资源推测梳理 Palantir Foundry技术平台的演进路线，分享一些分析与推测。本文仅代表个人观点，欢迎读者交流探讨。\n阶段0 定制代码运行从Palantir的Offering来看，其核心始终是为客户解决复杂问题，拥有大量的FDE。合理推测Palantir最早其实以定制代码运行交付作为基础，通过高度定制化的软件开发满足客户在政府、国防和企业领域的特定需求。阶段0，此时都处于定制开发状态。\n阶段1 从定制代码运行到Palantir平台运行正如《人月神话》中所说，优秀的程序员都会有自己的library库，优秀的定制开发商也倾向于提炼可复用的技术框架。\n对于定制代码来说，我们把定制代码分为编写态和运行态\n\n编写态，对应Palantir Code Repositories，可以看到Palantir的很多东西，其实跟Git很相似，有分支、合并等等。\n运行态，将Palantir Code Repositories的代码构建运行，支持多种触发方式，比如通过API调用来执行，定时执行等。Apollo 平台进一步支持多环境部署（如云和边缘）。\n\n阶段2 数据的平台化存储和管理当开发工作逐渐迁移到 Palantir 平台后，数据的存储和管理成为下一个重点。如果代码已经运行在平台上，那么数据为什么不能也存储在平台中呢？\nPalantir 在这一阶段引入了 Dataset 和本体（Ontology）模型，构建了平台化的数据管理能力。Dataset 作为数据的核心容器，支持结构化和非结构化数据的存储；本体则定义了数据之间的语义关系，为数据提供了更高级的抽象层。此外，Palantir 接入了时序数据库，增加了对时间序列数据的支持，满足了金融、工业等领域对实时数据处理的需求。\n同时，也把数据集的变更增加为一个触发条件。例如，当某个 Dataset 发生变化时，平台可以自动触发预定义的操作，如运行一段代码或更新其他数据集。\n\n阶段3 抽象Action Function在本体已经定义了DataSet以及数据集之间关系的基础上，通过Action、Function的定义，同时Action、Function可以通过拖拉拽简单地生成，无需书写代码。对于难以无码的复杂逻辑，还可以通过定制代码来书写。\n其实Workflow和Pipeline都是在更高层次、更简便地操作代码的手段而存在，底层实现上：\n\nPipeline &#x3D; Datasets+Builds+Schedules\nWorkflow &#x3D; Schedules + Builds + Jobs\n\n\n阶段 4：AIP 的智能决策赋能在Foundry坚实的基础上，Palantir 2023 年推出了 AIP（人工智能平台）整合大语言模型（LLM）与 Foundry 数据，自动化复杂决策。其核心功能包括：\n\n自然语言处理：用户通过对话界面查询数据或生成分析，如“预测下季度库存需求”。\n自动化工作流：基于 Ontology，AIP 驱动智能决策，例如优化供应链或调度资源。\n实时推理：结合时序数据，AIP 支持动态预测，如医疗资源分配或工业故障检测。\n\n总结图：笔者设想的企业使用Foundry路线图\n本文分析了Palantir Foundry的技术实现路径，笔者认为Palantir Foundry 的技术演进展现了一个从“定制”到“平台原生”的清晰路径。应用从分散的定制代码，逐步迁移到平台上运行，扎根于平台的数据和触发机制，最终成为完全依赖平台功能的原生应用。\n","tags":["Palantir"]},{"title":"Pulsar消息积压topic级别策略老化的两种方案","url":"/2023/05/11/Pulsar%E6%B6%88%E6%81%AF%E7%A7%AF%E5%8E%8Btopic%E7%BA%A7%E5%88%AB%E7%AD%96%E7%95%A5%E8%80%81%E5%8C%96%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E6%A1%88/","content":"Pulsar像大多数消息中间件一样,支持按时间和大小对消息积压进行老化。但是默认的策略只能在namespace级别配置。本文将介绍如何在topic级别实现老化策略的两种方案。\n方案一：开启 TopicLevelPolicy 来实现默认的策略配置通过在Zookeeper上配置对应的策略，可以通过./pulsar zookeeper-shell命令来登录zookeeper集群查询。但是如果将这一实现方式扩展到topic级别，将会产生大量的（百万、千万级别）的ZooKeeper节点，这对于ZooKeeper集群来说几乎是不可接受的。因此，Pulsar提供了一种新的实现方式，即通过Topic来存储策略配置，而不是通过ZooKeeper来存储。\nPulsar，从2.7.0版本开始，引入了SystemTopic，用于存储Topic的元数据信息，包括Topic的策略配置。主题级策略使用户可以更灵活地管理主题,并不会给 ZooKeeper 带来额外负担。\n您可以通过如下配置来开启TopicLevelPolicy：\nsystemTopicEnabled=truetopicLevelPoliciesEnabled=true\n\n然后通过set-backlog-quota命令来设置您想要的老化时间和老化大小\nPS: 完整的一些功能，如命令行set-backlog-quota，在3.0.0版本中支持\n方案二：通过自定义代码来实现Pulsar的TopicLevelPolicy实现需要通过topic存储策略配置，而不是通过ZooKeeper来存储。在实际的极端场景下，Topic中存储的内容可能会丢失（因为未开启Bookkeeper立即落盘或磁盘文件损坏等原因），这将导致策略配置丢失，从而导致策略失效。因此，我们可以通过自定义代码来实现topic级别的策略配置，这样可以避免策略配置丢失的问题。\n举个例子，业务可以将策略存放在Mysql中，然后通过Pulsar的Admin API来让策略生效\n自定义代码实现Backlog时间策略sequenceDiagram\n    participant C as Client\n    participant B as Broker\n    loop\n        C ->> B: expire-messages-all-subscriptions Request\n        B -->> C: expire-messages-all-subscriptions Response\n    end\n\n自定义代码实现Backlog大小策略sequenceDiagram\n    participant C as Client\n    participant B as Broker\n    loop\n        C ->> B: stats-internal Request\n        B -->> C: stats-internal Response\n        alt messageBacklogSize < maxMessageBacklogSize\n        else messageBacklogSize >= maxMessageBacklogSize\n            Note over B,C: estimate the backlog position\n            C ->> B: get-message-by-id Request\n            B -->> C: get-message-by-id\n            Note over B,C: get the timestamp of the message\n            C ->> B: expire-messages-all-subscriptions Request\n            B -->> C: expire-messages-all-subscriptions Response\n        end\n    end\n\n\n import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs';\tmermaid.initialize({startOnLoad: true, flowchart: {curve: 'linear'}}); ","tags":["Pulsar"]},{"title":"Python Http SDK设计","url":"/2023/10/28/Python%20Http%20SDK%E8%AE%BE%E8%AE%A1/","content":"根据Python项目的需求和特性，可以为Python的Http SDK项目选择以下命名方式：\n\nxxx-client-python：如果这个项目只有Http SDK，没有其他协议的SDK，推荐使用这个命名方式。\nxxx-http-client-python：当存在其他协议的SDK时，可以使用这个命名方式，以区分不同协议的SDK。\nxxx-admin-python：当项目使用其他协议作为数据通道，使用HTTP协议作为管理通道时，可以使用这个命名方式。\n\n由于Python的调用方式通常是模块名.类名.方法名。\n","tags":["SDK","Python"]},{"title":"SaaS服务功能权限控制是怎么做的","url":"/2024/07/23/SaaS%E6%9C%8D%E5%8A%A1%E5%8A%9F%E8%83%BD%E6%9D%83%E9%99%90%E6%8E%A7%E5%88%B6%E6%98%AF%E6%80%8E%E4%B9%88%E5%81%9A%E7%9A%84/","content":"SaaS服务全局级别的功能前端调用SaaS服务一个全局级别的接口\nsequenceDiagram\n    participant User as 用户\n    participant Frontend as 前端\n    participant Backend as 后端\n\n    User->>Frontend: 点击页面\n    Frontend->>Backend: 请求当前功能集\n    Backend->>Backend: 返回当前功能集\n    alt 用户有权限\n        Backend->>Frontend: 返回全局数据\n        Frontend->>User: 显示数据\n    else 用户无权限\n        Backend->>Frontend: 返回错误信息\n        Frontend->>User: 显示错误信息\n    end\n\nSaaS服务用户级别的功能前端调用SaaS服务一个用户权限的接口\nsequenceDiagram\n    participant User as 用户\n    participant Frontend as 前端\n    participant Backend as 后端\n\n    User->>Frontend: 点击页面\n    Frontend->>Backend: 查看用户权限\n    Backend->>Backend: 验证用户权限\n    alt 用户有权限\n        Backend->>Frontend: 返回用户项目数据\n        Frontend->>User: 显示数据\n    else 用户无权限\n        Backend->>Frontend: 返回错误信息\n        Frontend->>User: 显示错误信息\n    end\n\n\n import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs';\tmermaid.initialize({startOnLoad: true, flowchart: {curve: 'linear'}}); "},{"title":"SpringCloud ZooKeeper 详解，以及与Go、Rust等非Java服务的集成","url":"/2023/10/24/SpringCloud%20ZooKeeper%20%E8%AF%A6%E8%A7%A3%EF%BC%8C%E4%BB%A5%E5%8F%8A%E4%B8%8EGo%E3%80%81Rust%E7%AD%89%E9%9D%9EJava%E6%9C%8D%E5%8A%A1%E7%9A%84%E9%9B%86%E6%88%90/","content":"ZooKeeper，是一个开源的分布式协调服务，不仅支持分布式选举、任务分配，还可以用于微服务的注册中心和配置中心。本文，我们将深入探讨ZooKeeper用做微服务注册中心的场景。\nZooKeeper中的服务注册路径SpringCloud ZooKeeper遵循特定的路径结构进行服务注册\n/services/$&#123;spring.application.name&#125;/$&#123;serviceId&#125;\n示例：\n/services/provider-service/d87a3891-1173-45a0-bdfa-a1b60c71ef4e\n\n/services和/${spring.application.name}是ZooKeeper中的永久节点，/${serviceId}是临时节点，当服务下线时，ZooKeeper会自动删除该节点。\n注：当微服务的最后一个实例下线时，SpringCloud ZooKeeper框架会删除/${spring.application.name}节点。\nZooKeeper中的服务注册数据下面是一个典型的服务注册内容示例：\n&#123;    &quot;name&quot;:&quot;provider-service&quot;,    &quot;id&quot;:&quot;d87a3891-1173-45a0-bdfa-a1b60c71ef4e&quot;,    &quot;address&quot;:&quot;192.168.0.105&quot;,    &quot;port&quot;:8080,    &quot;sslPort&quot;:null,    &quot;payload&quot;:&#123;        &quot;@class&quot;:&quot;org.springframework.cloud.zookeeper.discovery.ZookeeperInstance&quot;,        &quot;id&quot;:&quot;provider-service&quot;,        &quot;name&quot;:&quot;provider-service&quot;,        &quot;metadata&quot;:&#123;            &quot;instance_status&quot;:&quot;UP&quot;        &#125;    &#125;,    &quot;registrationTimeUTC&quot;:1695401004882,    &quot;serviceType&quot;:&quot;DYNAMIC&quot;,    &quot;uriSpec&quot;:&#123;        &quot;parts&quot;:[            &#123;                &quot;value&quot;:&quot;scheme&quot;,                &quot;variable&quot;:true            &#125;,            &#123;                &quot;value&quot;:&quot;://&quot;,                &quot;variable&quot;:false            &#125;,            &#123;                &quot;value&quot;:&quot;address&quot;,                &quot;variable&quot;:true            &#125;,            &#123;                &quot;value&quot;:&quot;:&quot;,                &quot;variable&quot;:false            &#125;,            &#123;                &quot;value&quot;:&quot;port&quot;,                &quot;variable&quot;:true            &#125;        ]    &#125;&#125;\n其中，address、port和uriSpec是最核心的数据。uriSpec中的parts区分了哪些内容是可变的，哪些是固定的。\nSpringCloud 服务使用OpenFeign互相调用一旦两个微服务都注册到了ZooKeeper，那么它们就可以通过OpenFeign互相调用了。简单的示例如下\n服务提供者创建SpringBoot项目创建SpringBoot项目，并添加spring-cloud-starter-zookeeper-discovery和spring-boot-starter-web依赖。\n配置application.yamlspring:  application:    name: provider-service  cloud:    zookeeper:      connect-string: localhost:2181server:  port: 8082\n\n注册到ZooKeeper在启动类上添加@EnableDiscoveryClient注解。\n创建一个简单的REST接口@RestControllerpublic class ProviderController &#123;    @GetMapping(&quot;/hello&quot;)    public String hello() &#123;        return &quot;Hello from Provider Service!&quot;;    &#125;&#125;\n\n服务消费者创建SpringBoot项目创建SpringBoot项目，并添加spring-cloud-starter-zookeeper-discovery、spring-cloud-starter-openfeign和spring-boot-starter-web依赖。\n配置application.yamlspring:  application:    name: consumer-service  cloud:    zookeeper:      connect-string: localhost:2181server:  port: 8081\n\n注册到ZooKeeper在启动类上添加@EnableDiscoveryClient注解。\n创建一个REST接口，通过OpenFeign调用服务提供者@RestControllerpublic class ConsumerController &#123;        @Autowired    private ProviderClient providerClient;    @GetMapping(&quot;/getHello&quot;)    public String getHello() &#123;        return providerClient.hello();    &#125;&#125;\n\n运行效果curl localhost:8081/getHello -iHTTP/1.1 200Content-Type: text/plain;charset=UTF-8Content-Length: 28Date: Wed, 18 Oct 2023 02:40:57 GMTHello from Provider Service!\n\n非Java服务在SpringCloud ZooKeeper中注册可能有些读者乍一看觉得有点奇怪，为什么要在SpringCloud ZooKeeper中注册非Java服务呢？没有这个应用场景。\n当然，这样的场景比较少，常见于大部分项目都是用SpringCloud开发，但有少部分项目因为种种原因，不得不使用其他语言开发，比如Go、Rust等。这时候，我们就需要在SpringCloud ZooKeeper中注册非Java服务了。\n对于非JVM语言开发的服务，只需确保它们提供了Rest&#x2F;HTTP接口并正确地注册到ZooKeeper，就可以被SpringCloud的Feign客户端所调用。\nGo服务在SpringCloud ZooKeeperexample代码组织：\n├── consumer│   └── consumer.go├── go.mod├── go.sum└── provider    └── provider.go\n\nGo服务提供者在SpringCloud ZooKeeper注：该代码的质量为demo级别，实际生产环境需要更加严谨的代码，如重连机制、超时机制、更优秀的服务ID生成算法等。\npackage mainimport (\t&quot;fmt&quot;\t&quot;log&quot;\t&quot;net/http&quot;\t&quot;time&quot;\t&quot;encoding/json&quot;\t&quot;github.com/gin-gonic/gin&quot;\t&quot;github.com/samuel/go-zookeeper/zk&quot;)const (\tzkServers = &quot;localhost:2181&quot; // Zookeeper服务器地址)func main() &#123;\t// 初始化gin框架\tr := gin.Default()\t// 添加一个简单的hello接口\tr.GET(&quot;/hello&quot;, func(c *gin.Context) &#123;\t\tc.String(http.StatusOK, &quot;Hello from Go service!&quot;)\t&#125;)\t// 注册服务到zookeeper\tregisterToZookeeper()\t// 启动gin服务器\tr.Run(&quot;:8080&quot;)&#125;func registerToZookeeper() &#123;\tconn, _, err := zk.Connect([]string&#123;zkServers&#125;, time.Second*5)\tif err != nil &#123;\t\tpanic(err)\t&#125;\t// 检查并创建父级路径\tensurePathExists(conn, &quot;/services&quot;)\tensurePathExists(conn, &quot;/services/provider-service&quot;)\t// 构建注册的数据\tdata, _ := json.Marshal(map[string]interface&#123;&#125;&#123;\t\t&quot;name&quot;:        &quot;provider-service&quot;,\t\t&quot;address&quot;:     &quot;127.0.0.1&quot;,\t\t&quot;port&quot;:        8080,\t\t&quot;sslPort&quot;:     nil,\t\t&quot;payload&quot;:     map[string]interface&#123;&#125;&#123;&quot;@class&quot;: &quot;org.springframework.cloud.zookeeper.discovery.ZookeeperInstance&quot;, &quot;id&quot;: &quot;provider-service&quot;, &quot;name&quot;: &quot;provider-service&quot;, &quot;metadata&quot;: map[string]string&#123;&quot;instance_status&quot;: &quot;UP&quot;&#125;&#125;,\t\t&quot;serviceType&quot;: &quot;DYNAMIC&quot;,\t\t&quot;uriSpec&quot;: map[string]interface&#123;&#125;&#123;\t\t\t&quot;parts&quot;: []map[string]interface&#123;&#125;&#123;\t\t\t\t&#123;&quot;value&quot;: &quot;scheme&quot;, &quot;variable&quot;: true&#125;,\t\t\t\t&#123;&quot;value&quot;: &quot;://&quot;, &quot;variable&quot;: false&#125;,\t\t\t\t&#123;&quot;value&quot;: &quot;address&quot;, &quot;variable&quot;: true&#125;,\t\t\t\t&#123;&quot;value&quot;: &quot;:&quot;, &quot;variable&quot;: false&#125;,\t\t\t\t&#123;&quot;value&quot;: &quot;port&quot;, &quot;variable&quot;: true&#125;,\t\t\t&#125;,\t\t&#125;,\t&#125;)\t// 在zookeeper中注册服务\tpath := &quot;/services/provider-service/&quot; + generateServiceId()\t_, err = conn.Create(path, data, zk.FlagEphemeral, zk.WorldACL(zk.PermAll))\tif err != nil &#123;\t\tlog.Fatalf(&quot;register service error: %s&quot;, err)\t&#125; else &#123;\t\tlog.Println(path)\t&#125;&#125;func ensurePathExists(conn *zk.Conn, path string) &#123;\texists, _, err := conn.Exists(path)\tif err != nil &#123;\t\tlog.Fatalf(&quot;check path error: %s&quot;, err)\t&#125;\tif !exists &#123;\t\t_, err := conn.Create(path, []byte&#123;&#125;, 0, zk.WorldACL(zk.PermAll))\t\tif err != nil &#123;\t\t\tlog.Fatalf(&quot;create path error: %s&quot;, err)\t\t&#125;\t&#125;&#125;func generateServiceId() string &#123;\t// 这里简化为使用当前时间生成ID，实际生产环境可能需要更复杂的算法\treturn fmt.Sprintf(&quot;%d&quot;, time.Now().UnixNano())&#125;\n\n调用效果\ncurl localhost:8081/getHello -iHTTP/1.1 200Content-Type: text/plain;charset=UTF-8Content-Length: 28Date: Wed, 18 Oct 2023 02:43:52 GMTHello from Go Service!\n\nGo服务消费者在SpringCloud ZooKeeperpackage mainimport (\t&quot;encoding/json&quot;\t&quot;fmt&quot;\t&quot;io&quot;\t&quot;log&quot;\t&quot;net/http&quot;\t&quot;time&quot;\t&quot;github.com/samuel/go-zookeeper/zk&quot;)const (\tzkServers = &quot;localhost:2181&quot; // Zookeeper服务器地址)var conn *zk.Connfunc main() &#123;\t// 初始化ZooKeeper连接\tinitializeZookeeper()\t// 获取服务信息\tserviceInfo := getServiceInfo(&quot;/services/provider-service&quot;)\tfmt.Println(&quot;Fetched service info:&quot;, serviceInfo)\tport := int(serviceInfo[&quot;port&quot;].(float64))\tresp, err := http.Get(fmt.Sprintf(&quot;http://%s:%d/hello&quot;, serviceInfo[&quot;address&quot;], port))\tif err != nil &#123;\t\tpanic(err)\t&#125;\tbody, err := io.ReadAll(resp.Body)\tif err != nil &#123;\t\tpanic(err)\t&#125;\tfmt.Println(string(body))&#125;func initializeZookeeper() &#123;\tvar err error\tconn, _, err = zk.Connect([]string&#123;zkServers&#125;, time.Second*5)\tif err != nil &#123;\t\tlog.Fatalf(&quot;Failed to connect to ZooKeeper: %s&quot;, err)\t&#125;&#125;func getServiceInfo(path string) map[string]interface&#123;&#125; &#123;\tchildren, _, err := conn.Children(path)\tif err != nil &#123;\t\tlog.Fatalf(&quot;Failed to get children of %s: %s&quot;, path, err)\t&#125;\tif len(children) == 0 &#123;\t\tlog.Fatalf(&quot;No services found under %s&quot;, path)\t&#125;\t// 这里只获取第一个服务节点的信息作为示例，实际上可以根据负载均衡策略选择一个服务节点\tdata, _, err := conn.Get(fmt.Sprintf(&quot;%s/%s&quot;, path, children[0]))\tif err != nil &#123;\t\tlog.Fatalf(&quot;Failed to get data of %s: %s&quot;, children[0], err)\t&#125;\tvar serviceInfo map[string]interface&#123;&#125;\tif err := json.Unmarshal(data, &amp;serviceInfo); err != nil &#123;\t\tlog.Fatalf(&quot;Failed to unmarshal data: %s&quot;, err)\t&#125;\treturn serviceInfo&#125;\n\nRust服务在SpringCloud ZooKeeperexample代码组织：\n├── Cargo.lock├── Cargo.toml└── src    └── bin        ├── consumer.rs        └── provider.rs\n\nRust服务提供者在SpringCloud ZooKeeperuse std::collections::HashMap;use std::time::Duration;use serde_json::Value;use warp::Filter;use zookeeper::&#123;Acl, CreateMode, WatchedEvent, Watcher, ZooKeeper&#125;;static ZK_SERVERS: &amp;str = &quot;localhost:2181&quot;;static mut ZK_CONN: Option&lt;ZooKeeper&gt; = None;struct LoggingWatcher;impl Watcher for LoggingWatcher &#123;    fn handle(&amp;self, e: WatchedEvent) &#123;        println!(&quot;WatchedEvent: &#123;:?&#125;&quot;, e);    &#125;&#125;#[tokio::main]async fn main() &#123;    let hello = warp::path!(&quot;hello&quot;).map(|| warp::reply::html(&quot;Hello from Rust service!&quot;));    register_to_zookeeper().await;    warp::serve(hello).run(([127, 0, 0, 1], 8083)).await;&#125;async fn register_to_zookeeper() &#123;    unsafe &#123;        ZK_CONN = Some(ZooKeeper::connect(ZK_SERVERS, Duration::from_secs(5), LoggingWatcher).unwrap());        let zk = ZK_CONN.as_ref().unwrap();        let path = &quot;/services/provider-service&quot;;        if zk.exists(path, false).unwrap().is_none() &#123;            zk.create(path, vec![], Acl::open_unsafe().clone(), CreateMode::Persistent).unwrap();        &#125;        let service_data = get_service_data();        let service_path = format!(&quot;&#123;&#125;/&#123;&#125;&quot;, path, generate_service_id());        zk.create(&amp;service_path, service_data, Acl::open_unsafe().clone(), CreateMode::Ephemeral).unwrap();    &#125;&#125;fn get_service_data() -&gt; Vec&lt;u8&gt; &#123;    let mut data: HashMap&lt;&amp;str, Value&gt; = HashMap::new();    data.insert(&quot;name&quot;, serde_json::Value::String(&quot;provider-service&quot;.to_string()));    data.insert(&quot;address&quot;, serde_json::Value::String(&quot;127.0.0.1&quot;.to_string()));    data.insert(&quot;port&quot;, serde_json::Value::Number(8083.into()));    serde_json::to_vec(&amp;data).unwrap()&#125;fn generate_service_id() -&gt; String &#123;    format!(&quot;&#123;&#125;&quot;, chrono::Utc::now().timestamp_nanos())&#125;\n\nRust服务消费者在SpringCloud ZooKeeperuse std::collections::HashMap;use std::time::Duration;use zookeeper::&#123;WatchedEvent, Watcher, ZooKeeper&#125;;use reqwest;use serde_json::Value;static ZK_SERVERS: &amp;str = &quot;localhost:2181&quot;;struct LoggingWatcher;impl Watcher for LoggingWatcher &#123;    fn handle(&amp;self, e: WatchedEvent) &#123;        println!(&quot;WatchedEvent: &#123;:?&#125;&quot;, e);    &#125;&#125;#[tokio::main]async fn main() &#123;    let provider_data = fetch_provider_data_from_zookeeper().await;    let response = request_provider(&amp;provider_data).await;    println!(&quot;Response from provider: &#123;&#125;&quot;, response);&#125;async fn fetch_provider_data_from_zookeeper() -&gt; HashMap&lt;String, Value&gt; &#123;    let zk = ZooKeeper::connect(ZK_SERVERS, Duration::from_secs(5), LoggingWatcher).unwrap();    let children = zk.get_children(&quot;/services/provider-service&quot;, false).unwrap();    if children.is_empty() &#123;        panic!(&quot;No provider services found!&quot;);    &#125;    // For simplicity, we just take the first child (i.e., service instance).     // In a real-world scenario, load balancing strategies would determine which service instance to use.    let data = zk.get_data(&amp;format!(&quot;/services/provider-service/&#123;&#125;&quot;, children[0]), false).unwrap();    serde_json::from_slice(&amp;data.0).unwrap()&#125;async fn request_provider(provider_data: &amp;HashMap&lt;String, Value&gt;) -&gt; String &#123;    let address = provider_data.get(&quot;address&quot;).unwrap().as_str().unwrap();    let port = provider_data.get(&quot;port&quot;).unwrap().as_i64().unwrap();    let url = format!(&quot;http://&#123;&#125;:&#123;&#125;/hello&quot;, address, port);    let response = reqwest::get(&amp;url).await.unwrap();    response.text().await.unwrap()&#125;\n","tags":["ZooKeeper","Spring"]},{"title":"Spring单元测试总结","url":"/2023/08/12/Spring%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%E6%80%BB%E7%BB%93/","content":"目录\n模块组织\n测试手段\n依赖组件\n\n典型Spring单元测试模块组织-- xxx-app-- xxx-util-- test-common\n\ntest-common尽量减少依赖，仅依赖必须的非spring组件。也可以统一将需要使用的resources文件放到test-common中。由test-common统一管理，避免每个模块测试都需要拷贝必须的文件。所需的maven配置如下：\n&lt;build&gt;    &lt;resources&gt;        &lt;resource&gt;            &lt;directory&gt;src/main/resources&lt;/directory&gt;            &lt;includes&gt;                &lt;include&gt;**&lt;/include&gt;                &lt;include&gt;**/**&lt;/include&gt;            &lt;/includes&gt;        &lt;/resource&gt;    &lt;/resources&gt;    &lt;plugins&gt;        &lt;plugin&gt;            &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;            &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt;            &lt;version&gt;$&#123;maven-resources-plugin.version&#125;&lt;/version&gt;            &lt;executions&gt;                &lt;execution&gt;                    &lt;id&gt;copy-resources&lt;/id&gt;                    &lt;phase&gt;process-resources&lt;/phase&gt;                    &lt;goals&gt;                        &lt;goal&gt;copy-resources&lt;/goal&gt;                    &lt;/goals&gt;                    &lt;configuration&gt;                        &lt;outputDirectory&gt;$&#123;project.build.directory&#125;/resources&lt;/outputDirectory&gt;                        &lt;resources&gt;                            &lt;resource&gt;                                &lt;directory&gt;src/main/resources&lt;/directory&gt;                            &lt;/resource&gt;                        &lt;/resources&gt;                    &lt;/configuration&gt;                &lt;/execution&gt;            &lt;/executions&gt;        &lt;/plugin&gt;    &lt;/plugins&gt;&lt;/build&gt;\n\n一些典型的配置文件，比如log4j2配置文件，同时，由于test-common不属于测试代码，可能在某些组织下会有更高的要求（如不能存在敏感信息等），如组织有这样的要求，则这类内容不适合放在test-common里统一复用:\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;Configuration status=&quot;info&quot; monitorInterval=&quot;10&quot;&gt;    &lt;Appenders&gt;        &lt;Console name=&quot;Console&quot; target=&quot;SYSTEM_OUT&quot;&gt;            &lt;PatternLayout pattern=&#x27;%d&#123;yyyy-MM-dd,HH:mm:ss,SSSXXX&#125;(%C:%L):%4p%X[%t#%T]--&gt;%m%n&#x27;/&gt;        &lt;/Console&gt;    &lt;/Appenders&gt;    &lt;Loggers&gt;        &lt;Root level=&quot;INFO&quot;&gt;            &lt;AppenderRef ref=&quot;Console&quot;/&gt;        &lt;/Root&gt;    &lt;/Loggers&gt;&lt;/Configuration&gt;\n\n测试手段利用RestAssured端到端测试http接口添加依赖\n&lt;dependency&gt;    &lt;groupId&gt;io.rest-assured&lt;/groupId&gt;    &lt;artifactId&gt;rest-assured&lt;/artifactId&gt;    &lt;version&gt;5.3.1&lt;/version&gt;    &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;\n\n为了在SpringBoot测试中使用 RestAssured, 需要配置端口 webEnvironment &#x3D; SpringBootTest.WebEnvironment.RANDOM_PORT。如：\n@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT)public class MyRestControllerTest &#123;    @LocalServerPort    int port;    @BeforeEach    public void setUp() &#123;        RestAssured.port = port;    &#125;&#125;\n\n随后可以使用RestAssured来请求接口\nRestAssured.given().contentType(ContentType.JSON).body(&quot;&#123;&#125;&quot;).post(&quot;url&quot;).then().statusCode(200);\n\n依赖组件mariadbmariadb可以使用mariadb4j\n&lt;dependency&gt;    &lt;groupId&gt;ch.vorburger.mariaDB4j&lt;/groupId&gt;    &lt;artifactId&gt;mariaDB4j&lt;/artifactId&gt;    &lt;version&gt;3.0.1&lt;/version&gt;    &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;\n\n书写Extension并使用\nimport ch.vorburger.mariadb4j.DB;import ch.vorburger.mariadb4j.DBConfigurationBuilder;import org.junit.jupiter.api.extension.AfterAllCallback;import org.junit.jupiter.api.extension.BeforeAllCallback;import org.junit.jupiter.api.extension.ExtensionContext;public class MariaDBExtension implements BeforeAllCallback, AfterAllCallback &#123;    private DB database;    @Override    public void beforeAll(ExtensionContext context) throws Exception &#123;        DBConfigurationBuilder configBuilder = DBConfigurationBuilder.newBuilder();        configBuilder.setPort(3306);        database = DB.newEmbeddedDB(configBuilder.build());    &#125;    @Override    public void afterAll(ExtensionContext context) throws Exception &#123;        if (database != null) &#123;            database.stop();        &#125;    &#125;&#125;\n\nigniteIgnite可以使用现有的junit5集成\n&lt;dependency&gt;    &lt;groupId&gt;io.github.embedded-middleware&lt;/groupId&gt;    &lt;artifactId&gt;embedded-ignite-junit5&lt;/artifactId&gt;    &lt;version&gt;0.0.3&lt;/version&gt;&lt;/dependency&gt;\n\n可以直接使用EmbeddedIgniteExtension，还可以使用EmbeddedIgnitePorts自定义Ignite的关键端口号\n","tags":["Java","Spring"]},{"title":"Spring记录数据库操作时间的几种方式","url":"/2023/12/15/Spring%E8%AE%B0%E5%BD%95%E6%95%B0%E6%8D%AE%E5%BA%93%E6%93%8D%E4%BD%9C%E6%97%B6%E9%97%B4%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F/","content":"Spring记录数据库操作时间的几种方式\nSpring Jpa@EnableJpaAuditing注解开启Jpa的审计功能，然后在实体类上使用@CreatedDate和@LastModifiedDate注解即可\n@Column(name = &quot;create_time&quot;)@CreatedDateprivate LocalDateTime createTime;@Column(name = &quot;update_time&quot;)@LastModifiedDateprivate LocalDateTime updateTime;\n\nSpring R2dbcSpring R2dbc可以使用@CreatedDate和@LastModifiedDate注解来实现。但是需要在Application上开启@EnableR2dbcAuditing\n@Column(&quot;created_time&quot;)@CreatedDateprivate LocalDateTime createdTime;@Column(&quot;updated_time&quot;)@LastModifiedDateprivate LocalDateTime updatedTime;\n\n应用程序修改应用程序修改就比较简单，简单设置一下即可,以PersonPo类为例\nPersonPo personPo = new PersonPo();personPo.setCreateTime(LocalDateTime.now());personPo.setUpdateTime(LocalDateTime.now());\n\nMysql场景下利用TIMESTAMP能力CREATE TABLE person (    id INT PRIMARY KEY,    // ... 其他字段 ...    create_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,    update_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP);\n","tags":["Java","Spring"]},{"title":"TypeScript Http SDK设计","url":"/2023/10/28/TypeScript%20Http%20SDK%E8%AE%BE%E8%AE%A1/","content":"TypeScript的调用方式通常是\nimport &#123; ClassName &#125; from &#x27;moduleName&#x27;;const object = new ClassName();\n\n根据TypeScript项目的需求和特性，可以为TypeScript的Http SDK项目选择以下命名方式：\n\nxxx-client-ts：如果这个项目只有Http SDK，没有其他协议的SDK，推荐使用这个命名方式。在npm可以注册为”xxx”。\nxxx-http-client-ts：当存在其他协议的SDK时，可以使用这个命名方式，以区分不同协议的SDK。\nxxx-admin-ts：当项目使用其他协议作为数据通道，使用HTTP协议作为管理通道时，可以使用这个命名方式。\n\n","tags":["SDK","TypeScript"]},{"title":"WebFlux最佳实践","url":"/2024/06/08/WebFlux%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/","content":"WebFlux是Spring 5引入的新的响应式编程框架，它提供了一种基于反应式流的编程模型，可以用于构建高性能、高吞吐量的Web应用程序。\n防止大量请求堆积限制同一时间的并发处理个数由于WebFlux可以处理大量的请求，如果后端处理较慢（如写db较慢等），可能会导致大量的请求堆积，可以通过限制同一时间的并发处理个数来防止请求堆积。\nimport org.springframework.http.HttpStatus;import org.springframework.stereotype.Component;import org.springframework.web.server.ServerWebExchange;import org.springframework.web.server.WebFilter;import org.springframework.web.server.WebFilterChain;import reactor.core.publisher.Mono;import java.util.concurrent.Semaphore;@Componentpublic class ConcurrencyLimitingFilter implements WebFilter &#123;    private final Semaphore semaphore;    public ConcurrencyLimitingFilter() &#123;        this.semaphore = new Semaphore(10);    &#125;    @Override    public Mono&lt;Void&gt; filter(ServerWebExchange exchange, WebFilterChain chain) &#123;        if (semaphore.tryAcquire()) &#123;            return chain.filter(exchange)                    .doFinally(sig -&gt; semaphore.release());        &#125; else &#123;            exchange.getResponse().setStatusCode(HttpStatus.TOO_MANY_REQUESTS);            return exchange.getResponse().setComplete();        &#125;    &#125;&#125;\n\n配置超时时间网络编程中，任何操作都应该有超时时间。WebFlux允许大量的请求进入，如果不设置超时时间，可能会导致大量的请求排队处理（可能客户端早已放弃），可以通过统一Filter来设置最大超时时间。\nimport lombok.extern.slf4j.Slf4j;import org.springframework.http.HttpStatus;import org.springframework.stereotype.Component;import org.springframework.web.server.ResponseStatusException;import org.springframework.web.server.ServerWebExchange;import org.springframework.web.server.WebFilter;import org.springframework.web.server.WebFilterChain;import reactor.core.publisher.Mono;import java.time.Duration;import java.util.concurrent.TimeoutException;@Slf4j@Componentpublic class WebRequestTimeoutFilter implements WebFilter &#123;    @Override    public Mono&lt;Void&gt; filter(ServerWebExchange exchange, WebFilterChain chain) &#123;        return chain.filter(exchange)                .timeout(Duration.ofSeconds(10))                .onErrorResume(TimeoutException.class, e -&gt; &#123;                    log.error(&quot;Request timeout&quot;, e);                    return Mono.error(new ResponseStatusException(HttpStatus.GATEWAY_TIMEOUT, &quot;Request timeout&quot;));                &#125;);    &#125;&#125;\n","tags":["Java","Spring","WebFlux"]},{"title":"Wireshark 安装及基本操作","url":"/2018/09/07/WireShark%20%E5%AE%89%E8%A3%85%E5%8F%8A%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/","content":"WireShark安装wireshark在windows和mac上的安装方式都比较简单,下面是Linux下的安装方式\nsudo apt-add-repository ppa:wireshark-dev/stablesudo apt-get updatesudo apt-get install wireshark#以root权限启动sudo wireshark\n\nWireShark的名字解析\n\nL2层的名字解析，对Mac地址进行解析，返回机器名\nL3层 ip解析为域名\nL4层 端口号解析为协议端口号\n\nWireshark抓到的包更改时间格式\n查看EndPoint点击Statistics-&gt;EndPoints，可以查看每一个捕获文件里的每个端点\n\n查看网络会话Statistics-&gt;Conversations. 查看地址A和地址B，以及每个设备发送或收到的数据包和字节数\n\n基于协议分层结构的统计数据Statistics-&gt;Protocol Hierarchy\n\n跟随流功能右键选中一个数据包，然后右键，follow。比如我在这里跟随一个tcp流\n\n&#x2F;&#x2F;这里也可以使用decode as解码功能，但是没有例子，暂不附图\n查看IO图Statistics-&gt;IO Graphs\n\n双向时间图Statistics-&gt;TCP Stream Graph -&gt; Round Trip Time Graph\n数据流图Statistics-&gt;Flow Graph\n专家信息Analyze-&gt;Expert Info Composite\n触发的专家信息对话消息窗口更新 由接收者发送，用来通知发送者TCP接收窗口的大小已被改变注意消息TCP重传输 数据包丢失的结果，发生在收到重复的ACK，或者数据包的重传输计时器超时的时候重复ACK 当一台主机没有收到下一个期望序列的数据包时，它会生成最近收到一次数据的重复ACK零窗口探查ACK 用来响应零窗口探查数据包窗口已满 用来通知传输主机及其接收者的TCP接收窗口已满警告消息上一段丢失 指明数据包丢失,发生在当数据流中一个期望的序列号被跳过时。收到丢失数据包的ACK 发生在当一个数据包已经确认丢失但受到了其ACK数据包时保活 当一个连接的保活数据包出现时触发零窗口 当接收方已经达到TCP接收窗口大小时，发出一个零窗口通知，要求发送方停止传输数据乱序 当数据包被乱序接收时，会利用序列号进行检测快速重传输 一次重传会在收到一个重复ACK的20ms内进行WireShark性能Statistics -&gt; Summary 查看平均速度Analyze -&gt; Expert InfosStatistics -&gt; TCP StreamGraph -&gt; TCP Sequence Graph(Stenens)TCP Previous segment not captured在TCP传输过程中,同一台主机发出的数据段应该是连续的,即后一个包的Seq号等于前一个包的Seq + Len. 如果在网络包中没有找到,就会出现这个错误\nTCP ACKed unseen segmentWireshark发现被Ack的那个包没被wireshark捕获\nTCP Out-of-Order在TCP传输过程中,同一台主机发出的数据段应该是连续的,即后一个包的Seq号等于前一个包的Seq +Len.当Wireshark发现后一个包的Seq号小于前一个包的Seq+Len 就乱序le\nTCP Dup ACK当乱序或者丢包的时候,接收方会收到Seq号比期望值大的包,每收到一个这种包就会Ack一次期望的Seq值\nTCP Fast Retransmission当发送方收到3个或以上TCP Dup ACK,就意识到之前发的包可能丢了,触发快速重传\nTCP Retransmission没有触发tcp超时重传,超时重传\nTCP zerowindow缓存区已满,不能再接收数据了\nTCP window FUllWireshark检测到,发送方发送的数据会把接收方的接收窗口耗尽\n","tags":["Wireshark"]},{"title":"Wireshark 捕获过滤器","url":"/2018/09/09/WireShark%20%E6%8D%95%E8%8E%B7%E8%BF%87%E6%BB%A4%E5%99%A8/","content":"如何使用捕获过滤器点击捕获，选项，然后在所选择的捕获过滤器上输入对应的捕获表达式\n\n\n抓包过滤器\ntype(类型) 限定符: 比如host，net，port限定符等\ndir(方向) 限定符: src dst\nProto(协议类型)限定符: ether ip arp\n\n二层过滤器举例tcp dst port 135 //tcp协议，目标端口为135的数据包ether host &lt;Ethernet host&gt; //让wireshark只抓取这个地址相关的以太网帧ether dst &lt;Ethernet host&gt;ether src &lt;Ethernet src&gt;ether broadcast //Wireshark只抓取所有以太网广播流量ether multicast //只抓取多播流量ether proto &lt;protocol&gt;vlan &lt;vlan_id&gt;\n\n三层过滤器举例ip #只抓取ipv4流量ipv6host 10.0.0.2dest host &lt;host&gt;src host &lt;host&gt;broadcast #ip广播包multicast #ip多播包ip proto &lt;protocol code&gt; #ip数据包有多种类型，比如TCP(6), UDP(17) ICMP(1)\n\n只抓取源于或者发往IPv6 2001::&#x2F;16的数据包net 2001::&#x2F;16\n只抓取ICMP流量ip proto 1\n只抓取ICMP echo request流量icmp[icmptype]&#x3D;&#x3D;icmp-echoicmp[icmptype]&#x3D;&#x3D;8\n只抓取特定长度的IP数据包ip[2:2] &#x3D;&#x3D; \n只抓取具有特定TTL的IP数据包ip[8] &#x3D;&#x3D; \n抓取数据包的源和目的IP地址相同ip[12:4] &#x3D;&#x3D;1 ip[16:4]\n四层抓包过滤器举例port &lt;port&gt;dst port &lt;port&gt;src port &lt;port&gt;tcp portrange &lt;p1&gt;-&lt;p2&gt;\n\n只抓取TCP中SYN或者FIN的数据包tcp [tcpflags] &amp; (tcp-syn | tcp-fin) !&#x3D; 0\n只抓所有RST标记位置为1的TCP数据包tcp[tcpflags] &amp; (tcp-rst) !&#x3D; 0\ntcp头部的常用标记位\nSYN: 用来表示打开连接\nFIN: 用来表示拆除连接\nACK: 用来确认收到的数据\nRST: 用来表示立刻拆除连接\nPSH: 用来表示应将数据提交给末端应用程序处理\n\n抓取所有标记位都未置1的TCP流量该报文可能用于端口探测,即如果tcp[13] &amp; 0x00 &#x3D; 0\n设置了URG位的TCP数据包URG位,表示该数据包十分紧急,不进入缓冲区,直接送给进程tcp[13] &amp; 32 &#x3D;&#x3D; 32\n设置了ACK位的TCP数据包tcp[13] &amp; 16 &#x3D;&#x3D; 16\n设置了PSH位的TCP数据包PSH代表这个消息要从缓冲区立刻发送给应用程序tcp[13] &amp; 8 &#x3D;&#x3D; 8\n设置了RST位的TCP数据包tcp[13] &amp; 4 &#x3D;&#x3D; 4\n设置了SYN位的TCP数据包tcp[13] &amp; 2 &#x3D;&#x3D; 2\n设置了FIN位的TCP数据包tcp[13] &amp; 1 &#x3D;&#x3D; 1\nTCP SYN-ACK数据包tcp[13] &#x3D;&#x3D; 18\n抓取目的端口范围的数据包tcp portrange 2000-2500\n###tcpdump捕获过滤器\n常见命令介绍\ntcpdump -w hzj.pcap -s0 -iany port 1028\n\n上面的命令代表-w hzj.pcap 存储在hzj.pcap这个文件中-s 0 代表抓取字节数不限制,在大多数linux系统下,默认捕获每个帧的前96个字节\ntcpdump捕获一定范围的端口(9200-9400)tcpdump portrange 9200-9400\ntcpdump -r 可以阅读捕获的文件(建议拷贝到wireshark中分析)","tags":["Wireshark"]},{"title":"Wireshark 显示过滤器","url":"/2018/09/09/WireShark%20%E6%98%BE%E7%A4%BA%E8%BF%87%E6%BB%A4%E5%99%A8/","content":"如何使用显示过滤器或者按住 CTRL + F，输入显示过滤器\n二层显示过滤器举例长度小于128字节的数据包frame.len&lt;&#x3D;128\n排除ARP流量!arp\n三层显示过滤器举例只显示192.168.0.1 IP相关数据包ip.addr&#x3D;&#x3D;192.168.0.1\n四层显示过滤器举例排除RDP流量!tcp.port&#x3D;&#x3D;3389\n具有SYN标志的TCP数据包tcp.flags.syn&#x3D;&#x3D;1\n具有RST标志的TCP数据包tcp.flags.rst&#x3D;&#x3D;1\nTCP确认时间较久tcp.analysis.ack_rtt &gt; 0.2 and tcp.len &#x3D;&#x3D; 0###启用TCP Relative Sequence Number的情况如何启用?Edit -&gt; Preferences -&gt; Protocols -&gt; TCP Relative Sequence Numbers\n握手被对方拒绝的包tcp.flags.reset &#x3D;&#x3D; 1 &amp;&amp; tcp.seq &#x3D;&#x3D; 1\n客户端重传tcp.flags.syn &#x3D;&#x3D; 1 &amp;&amp; tcp.analysis.retransmission\nTcp包含tcp contains {str}\n应用层显示过滤器举例所有http流量http\n文本管理流量tcp.port &#x3D;&#x3D; 23 || tcp.port &#x3D;&#x3D; 21\n文本email流量email || pop || imap\n只显示访问某指定主机名的HTTP协议数据包http.host &#x3D;&#x3D; &lt;”hostname”&gt;\n只显示包含HTTP GET方法的HTTP协议数据包http.request.method &#x3D;&#x3D; ‘GET’\n只显示HTTP 客户端发起的包含指定URI请求的HTTP协议数据包http.request.uri &#x3D;&#x3D; &lt;”Full request URI”&gt;\n只显示包含ZIP文件的数据包http matches “.zip” &amp;&amp; http.request.method &#x3D;&#x3D; ‘GET’\n","tags":["Wireshark"]},{"title":"Wireshark 书写Lua插件","url":"/2022/02/24/Wireshark%20%E4%B9%A6%E5%86%99Lua%E6%8F%92%E4%BB%B6/","content":"未书写插件前wireshark的协议不支持之前，报文几乎难以分析，举例如下\n\nWireshark插件路径MAC\n重新加载Wireshark中的lua插件MAC\n从一个新协议的样板开始pulsar_protocol = Proto(&quot;Pulsar&quot;, &quot;Pulsar Protocol&quot;)pulsar_protocol.fields = &#123;&#125;function pulsar_protocol.dissector(buffer, pinfo, tree)    length = buffer:len()    if length == 0 then        return    end    pinfo.cols.protocol = pulsar_protocol.name    local subtree = tree:add(pulsar_protocol, buffer(), &quot;Pulsar Protocol Data&quot;)endlocal tcp_port = DissectorTable.get(&quot;tcp.port&quot;)tcp_port:add(6650, pulsar_protocol)\n\n我们从协议对象开始，命名为pulsar_protocol。构造函数两个参数分别为名称和描述。协议需要一个fields表和dissecotr函数。我们现在还没有任何field，所以fields表为空。对于每一个报文，dissctor函数都会被调用一次。\ndissector函数有三个入参，buffer，pinfo，和tree。buffer包含了网络包的内容，是一个Tvb对象。pinfo包含了wireshark中展示packet的列信息，是一个Pinfo对象。tree是wireshark报文详情显示的内容，是TreeItem对象。\n在dissector函数中，我们检查buffer的长度，如果长度为0，则立即返回\npinfo对象包含着列信息，我们可以将pinfo的protocol设置为pulsar，显示在wireshark的界面中。接下来在packet的结构中创建一个子树，最后，我们把协议绑定到6650端口上。让我们加载这个lua插件\nmkdir -p ~/.local/lib/wireshark/pluginscp $DIR/../../pulsar_dissector.lua ~/.local/lib/wireshark/plugins/pulsar_dissector.lua\n\n结果符合预期\n\n添加长度字段让我们添加一个长度字段，pulsar协议中,长度字段即就是前4个字节，定义字段\nmessage_length = ProtoField.int32(&quot;pulsar.message_length&quot;, &quot;messageLength&quot;, base.DEC)pulsar_protocol.fields = &#123; message_length &#125;\n\npulsar.message_length可以用在过滤器字段中。messageLength是子树中的label。第三个字段决定了这个值会被如何展示\n最后，我们把长度值加入到Wireshark的tree中\nsubtree:add(message_length, buffer(0,4))\n\npulsar的协议是大端序，我们使用add函数。如果协议是小端序，我们就可以使用addle函数。\n\n我们添加的message_length字段已经可以显示在Wireshark中了\n添加额外信息protoc加入到wireshark参考及附录proto field函数列表https://www.wireshark.org/docs/wsdg_html_chunked/lua_module_Proto.html#lua_fn_ProtoField_char_abbr___name____base____valuestring____mask____desc__\nwireshark解析protobufhttps://ask.wireshark.org/question/15787/how-to-decode-protobuf-by-wireshark/\n","tags":["Wireshark"]},{"title":"Java DefaultUncaughtExceptionHandler 详解","url":"/2023/06/15/java%20DefaultUncaughtExceptionHandler%20%E8%AF%A6%E8%A7%A3/","content":"在Java程序运行时，一些非受检异常可能会导致程序崩溃，比如NullPointerException、ArrayIndexOutOfBoundsException等等，这些异常都是由JVM抛出的，如果不对这些异常进行处理，小则线程运行中突然退出，大则整个程序崩溃。理想的场景下，每一个非受检异常都应该被捕获并进行处理，但是在实际开发中，我们往往会忽略一些异常，这些异常可能是由于程序员的疏忽导致的，也可能是由于程序员无法预知的原因导致的，比如第三方库抛出的异常。\n为了避免这些异常导致程序崩溃，Java提供了一个全局的异常处理器，即DefaultUncaughtExceptionHandler，它可以捕获所有未被捕获的异常，从而避免程序崩溃。\nDefaultUncaught的使用示例如下：\npublic class UncaughtExceptionHandle &#123;    public static void main(String[] args) &#123;        Thread.setDefaultUncaughtExceptionHandler((t, e) -&gt; log.error(&quot;Uncaught exception: &quot;, e));    &#125;&#125;\n\n上述的代码会将未捕获的异常打印到日志中，如果你希望打印至标准输出或标准输出，可以将log替换为：\n// 标准输出System.out.println(&quot;Uncaught exception: &quot; + e);// 错误输出System.err.println(&quot;Uncaught exception: &quot; + e);\n","tags":["Java"]},{"title":"jetty servlet的代码字符集选择","url":"/2023/06/02/jetty%20servlet%E7%9A%84%E7%BC%96%E7%A0%81%E5%AD%97%E7%AC%A6%E9%9B%86%E9%80%89%E6%8B%A9/","content":"记一次中文指标乱码问题，问题也很简单，如下图所示：\n\n从metricbeat开始找原因，发现其实只要是UTF-8的编码格式就都可以解析，最终发现是webServer返回的数据非UTF-8格式，修改方案也很简单。将servlet中的content-type里面的text&#x2F;plain修改成text&#x2F;plain; charset&#x3D;utf-8就可以了，如下面代码所示:\nprotected void doGet(HttpServletRequest request, HttpServletResponse response)        throws IOException &#123;    response.setContentType(&quot;text/plain&quot;);    response.setStatus(HttpServletResponse.SC_OK);    response.getWriter().write(&quot;&lt;h1&gt;哈哈&lt;/h1&gt;&quot;);&#125;\n\n我们可以轻易使用一个demo来复现这个问题，在maven中添加如下依赖\n&lt;dependency&gt;    &lt;groupId&gt;org.eclipse.jetty&lt;/groupId&gt;    &lt;artifactId&gt;jetty-server&lt;/artifactId&gt;    &lt;version&gt;9.4.35.v20201120&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;org.eclipse.jetty&lt;/groupId&gt;    &lt;artifactId&gt;jetty-servlet&lt;/artifactId&gt;    &lt;version&gt;9.4.35.v20201120&lt;/version&gt;&lt;/dependency&gt;\n\npackage com.hezhangjian.jetty;import org.eclipse.jetty.server.Server;import org.eclipse.jetty.servlet.ServletContextHandler;import org.eclipse.jetty.servlet.ServletHolder;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.IOException;public class SimpleJettyServer &#123;    public static void main(String[] args) throws Exception &#123;        Server server = new Server(8080);        ServletContextHandler context = new ServletContextHandler(ServletContextHandler.SESSIONS);        context.setContextPath(&quot;/&quot;);        server.setHandler(context);        context.addServlet(new ServletHolder(new HelloDefaultServlet()), &quot;/hello-default&quot;);        context.addServlet(new ServletHolder(new HelloUTF8Servlet()), &quot;/hello-utf8&quot;);        server.start();        server.join();    &#125;    public static class HelloDefaultServlet extends HttpServlet &#123;        @Override        protected void doGet(HttpServletRequest request, HttpServletResponse response)                throws IOException &#123;            response.setContentType(&quot;text/plain&quot;);            response.setStatus(HttpServletResponse.SC_OK);            response.getWriter().write(&quot;&lt;h1&gt;哈哈&lt;/h1&gt;&quot;);        &#125;    &#125;    public static class HelloUTF8Servlet extends HttpServlet &#123;        @Override        protected void doGet(HttpServletRequest request, HttpServletResponse response)                throws IOException &#123;            response.setContentType(&quot;text/plain; charset=UTF-8&quot;);            response.setStatus(HttpServletResponse.SC_OK);            response.getWriter().write(&quot;&lt;h1&gt;哈哈&lt;/h1&gt;&quot;);        &#125;    &#125;&#125;\n\n通过curl命令来复现这个问题\ncurl localhost:8080/hello-default&lt;h1&gt;??&lt;/h1&gt;%curl localhost:8080/hello-utf8&lt;h1&gt;哈哈&lt;/h1&gt;%\n\n那么servlet里面的数据如何编码，我们可以dive一下，首先servlet里面有一个函数叫**response.setCharacterEncoding();**这个函数可以指定编码格式。其次，servlet还会通过上面的setContentType函数来做一定的推断，比如content-type中携带了charset，就使用content-type中的charset。还有些特定的content-type，比如text&#x2F;json，在没有设置的情况下，servlet容器会假设它使用utf-8编码。在推断不出来，也没有手动设置的情况下，jetty默认的编码是iso-8859-1，这就解释了乱码的问题。\n","tags":["Java","Jetty"]},{"title":"Prometheus tsdb索引布局及查询流程","url":"/2022/07/18/prometheus%20tsdb%E7%B4%A2%E5%BC%95%E5%B8%83%E5%B1%80%E5%8F%8A%E6%9F%A5%E8%AF%A2%E6%B5%81%E7%A8%8B/","content":"prometheus 磁盘布局采集到的数据每两个小时形成一个block。每个block由一个目录组成，并存放在data路径下。该目录包含一个包含该时间窗口的所有时间序列样本的块子目录、一个元数据文件和一个索引文件（将metric_name和label索引到目录下的时间序列）。 chunks 目录中的样本默认组合成一个或多个段文件，每个段文件最大为 512MB。 当通过 API 删除系列时，删除记录存储在单独的 tombstone 文件中（而不是立即从块段中删除数据）。\n当前正在写入的块保存在内存中，没有完全持久化。通过WAL日志来防止崩溃丢失数据。预写日志分为数节(segments)保存在wal文件夹中。这些文件包含尚未压缩的原始数据； 因此它们比常规块文件大得多。 Prometheus 将至少保留三个预写日志文件。在高流量下，会保留三个以上的 WAL 文件，以便保留至少两个小时的原始数据。\n./data├── 01BKGV7JBM69T2G1BGBGM6KB12│   └── meta.json├── 01BKGTZQ1SYQJTR4PB43C8PD98│   ├── chunks│   │   └── 000001│   ├── tombstones│   ├── index│   └── meta.json├── 01BKGTZQ1HHWHV8FBJXW1Y3W0K│   └── meta.json├── 01BKGV7JC0RY8A6MACW02A2PJD│   ├── chunks│   │   └── 000001│   ├── tombstones│   ├── index│   └── meta.json├── chunks_head│   └── 000001└── wal    ├── 000000002    └── checkpoint.00000001        └── 00000000\n\nprometheus概念\nLabel: 标签，string格式的kv组合\nseries: 时间序列，label的组合\nchunk: 时间，value的数据\n\nprometheus索引格式┌────────────────────────────┬─────────────────────┐│ magic(0xBAAAD700) &lt;4b&gt;     │ version(1) &lt;1 byte&gt; │├────────────────────────────┴─────────────────────┤│ ┌──────────────────────────────────────────────┐ ││ │                 Symbol Table                 │ ││ ├──────────────────────────────────────────────┤ ││ │                    Series                    │ ││ ├──────────────────────────────────────────────┤ ││ │                   Postings 1                 │ ││ ├──────────────────────────────────────────────┤ ││ │                      ...                     │ ││ ├──────────────────────────────────────────────┤ ││ │                   Postings N                 │ ││ ├──────────────────────────────────────────────┤ ││ │             Postings Offset Table            │ ││ ├──────────────────────────────────────────────┤ ││ │                      TOC                     │ ││ └──────────────────────────────────────────────┘ │└──────────────────────────────────────────────────┘\n\n写入索引时，可以在上面列出的主要部分之间添加任意数量的0字节作为填充。顺序扫描文件时，必须跳过部分间的任意0字节。\n下面描述的大部分部分都以 len 字段开头。 它总是指定就在尾随 CRC32 校验和之前的字节数。 校验和就计算这些字节的校验和（不包含len字段）\n符号表符号表包含已存储序列的标签对中出现的重复数据删除字符串的排序列表。 它们可以从后续部分中引用，并显着减少总索引大小。\n该部分包含一系列字符串entry，每个entry都以字符串的原始字节长度为前缀。 所有字符串均采用 utf-8 编码。 字符串由顺序索引引用。 字符串按字典顺序升序排序。\n┌────────────────────┬─────────────────────┐│ len &lt;4b&gt;           │ #symbols &lt;4b&gt;       │├────────────────────┴─────────────────────┤│ ┌──────────────────────┬───────────────┐ ││ │ len(str_1) &lt;uvarint&gt; │ str_1 &lt;bytes&gt; │ ││ ├──────────────────────┴───────────────┤ ││ │                . . .                 │ ││ ├──────────────────────┬───────────────┤ ││ │ len(str_n) &lt;uvarint&gt; │ str_n &lt;bytes&gt; │ ││ └──────────────────────┴───────────────┘ │├──────────────────────────────────────────┤│ CRC32 &lt;4b&gt;                               │└──────────────────────────────────────────┘\n序列 series保存一个具体的时间序列，其中包含系列的label集合和block中的chunks。\n每个series都是16字节对齐。series的id为偏移量除以16。series ID 的排序列表也就是series label的字典排序列表。\n┌───────────────────────────────────────┐│ ┌───────────────────────────────────┐ ││ │   series_1                        │ ││ ├───────────────────────────────────┤ ││ │                 . . .             │ ││ ├───────────────────────────────────┤ ││ │   series_n                        │ ││ └───────────────────────────────────┘ │└───────────────────────────────────────┘\n\n每一个series先保存label的数量，然后是包含label键值对的引用。 标签对按字典顺序排序。然后是series涉及的索引块的个数，然后是一系列元数据条目，其中包含块的最小 (mint) 和最大 (maxt) 时间戳以及对其在块文件中位置的引用。mint 是第一个样本的时间，maxt 是块中最后一个样本的时间。 在索引中保存时间范围数据, 允许按照时间范围删除数据时，如果时间范围匹配，不需要直接访问时间数据。\n空间大小优化: 第一个块的 mint 被存储，它的 maxt 被存储为一个增量，并且 mint 和 maxt 被编码为后续块的前一个时间的增量。 类似的，第一个chunk的引用被存储，下一个引用被存储为前一个chunk的增量。\n┌──────────────────────────────────────────────────────────────────────────┐│ len &lt;uvarint&gt;                                                            │├──────────────────────────────────────────────────────────────────────────┤│ ┌──────────────────────────────────────────────────────────────────────┐ ││ │                     labels count &lt;uvarint64&gt;                         │ ││ ├──────────────────────────────────────────────────────────────────────┤ ││ │              ┌────────────────────────────────────────────┐          │ ││ │              │ ref(l_i.name) &lt;uvarint32&gt;                  │          │ ││ │              ├────────────────────────────────────────────┤          │ ││ │              │ ref(l_i.value) &lt;uvarint32&gt;                 │          │ ││ │              └────────────────────────────────────────────┘          │ ││ │                             ...                                      │ ││ ├──────────────────────────────────────────────────────────────────────┤ ││ │                     chunks count &lt;uvarint64&gt;                         │ ││ ├──────────────────────────────────────────────────────────────────────┤ ││ │              ┌────────────────────────────────────────────┐          │ ││ │              │ c_0.mint &lt;varint64&gt;                        │          │ ││ │              ├────────────────────────────────────────────┤          │ ││ │              │ c_0.maxt - c_0.mint &lt;uvarint64&gt;            │          │ ││ │              ├────────────────────────────────────────────┤          │ ││ │              │ ref(c_0.data) &lt;uvarint64&gt;                  │          │ ││ │              └────────────────────────────────────────────┘          │ ││ │              ┌────────────────────────────────────────────┐          │ ││ │              │ c_i.mint - c_i-1.maxt &lt;uvarint64&gt;          │          │ ││ │              ├────────────────────────────────────────────┤          │ ││ │              │ c_i.maxt - c_i.mint &lt;uvarint64&gt;            │          │ ││ │              ├────────────────────────────────────────────┤          │ ││ │              │ ref(c_i.data) - ref(c_i-1.data) &lt;varint64&gt; │          │ ││ │              └────────────────────────────────────────────┘          │ ││ │                             ...                                      │ ││ └──────────────────────────────────────────────────────────────────────┘ │├──────────────────────────────────────────────────────────────────────────┤│ CRC32 &lt;4b&gt;                                                               │└──────────────────────────────────────────────────────────────────────────┘\n\nPostingPosting这一节存放着关于series引用的单调递增列表，简单来说就是存放id和时间序列的对应关系\n┌────────────────────┬────────────────────┐│ len &lt;4b&gt;           │ #entries &lt;4b&gt;      │├────────────────────┴────────────────────┤│ ┌─────────────────────────────────────┐ ││ │ ref(series_1) &lt;4b&gt;                  │ ││ ├─────────────────────────────────────┤ ││ │ ...                                 │ ││ ├─────────────────────────────────────┤ ││ │ ref(series_n) &lt;4b&gt;                  │ ││ └─────────────────────────────────────┘ │├─────────────────────────────────────────┤│ CRC32 &lt;4b&gt;                              │└─────────────────────────────────────────┘\n\nPosting sections的顺序由postings offset table决定。\nPosting Offset Tablepostings offset table包含着一系列posting offset entry，根据label的名称和值排序。每一个posting offset entry存放着label的键值对以及在posting sections中其series列表的偏移量。用来跟踪posting sections。当index文件加载时，它们将部分加载到内存中。\n┌─────────────────────┬──────────────────────┐│ len &lt;4b&gt;            │ #entries &lt;4b&gt;        │├─────────────────────┴──────────────────────┤│ ┌────────────────────────────────────────┐ ││ │  n = 2 &lt;1b&gt;                            │ ││ ├──────────────────────┬─────────────────┤ ││ │ len(name) &lt;uvarint&gt;  │ name &lt;bytes&gt;    │ ││ ├──────────────────────┼─────────────────┤ ││ │ len(value) &lt;uvarint&gt; │ value &lt;bytes&gt;   │ ││ ├──────────────────────┴─────────────────┤ ││ │  offset &lt;uvarint64&gt;                    │ ││ └────────────────────────────────────────┘ ││                    . . .                   │├────────────────────────────────────────────┤│  CRC32 &lt;4b&gt;                                │└────────────────────────────────────────────┘\n\nTOCtable of contents是整个索引的入口点，并指向文件中的各个部分。 如果引用为零，则表示相应的部分不存在，查找时应返回空结果。\n┌─────────────────────────────────────────┐│ ref(symbols) &lt;8b&gt;                       │├─────────────────────────────────────────┤│ ref(series) &lt;8b&gt;                        │├─────────────────────────────────────────┤│ ref(label indices start) &lt;8b&gt;           │├─────────────────────────────────────────┤│ ref(label offset table) &lt;8b&gt;            │├─────────────────────────────────────────┤│ ref(postings start) &lt;8b&gt;                │├─────────────────────────────────────────┤│ ref(postings offset table) &lt;8b&gt;         │├─────────────────────────────────────────┤│ CRC32 &lt;4b&gt;                              │└─────────────────────────────────────────┘\n\nchunks 磁盘格式chunks文件创建在block中的chunks/目录中。 每个段文件的最大大小为 512MB。文件中的chunk由uint64的索引组织，索引低四位为文件内偏移，高四位为段序列号。\n┌──────────────────────────────┐│  magic(0x85BD40DD) &lt;4 byte&gt;  │├──────────────────────────────┤│    version(1) &lt;1 byte&gt;       │├──────────────────────────────┤│    padding(0) &lt;3 byte&gt;       │├──────────────────────────────┤│ ┌──────────────────────────┐ ││ │         Chunk 1          │ ││ ├──────────────────────────┤ ││ │          ...             │ ││ ├──────────────────────────┤ ││ │         Chunk N          │ ││ └──────────────────────────┘ │└──────────────────────────────┘\n\nchunks中的Chunk格式┌───────────────┬───────────────────┬──────────────┬────────────────┐│ len &lt;uvarint&gt; │ encoding &lt;1 byte&gt; │ data &lt;bytes&gt; │ CRC32 &lt;4 byte&gt; │└───────────────┴───────────────────┴──────────────┴────────────────┘\n\n查询数据code查询的prometheus方法签名\nSelect(sortSeries bool, hints *SelectHints, matchers ...*labels.Matcher) SeriesSet\n\n支持从block中，remote等各种地方查询获取数据\nprometheus会在内存中维护一个数据结构\n// Map of LabelName to a list of some LabelValues&#x27;s position in the offset table.// The first and last values for each name are always present.postings map[string][]postingOffset\n\n在内存中，保留每个label name，并且每n个保存label值，降低内存的占用。但是第一个和最后一个值总是保存在内存中。\n查询数据流程\n参考资料\nhttps://prometheus.io/docs/prometheus/latest/storage/\nhttps://github.com/prometheus/prometheus/blob/release-2.37/tsdb/docs/format/README.md\nhttps://github.com/prometheus/prometheus/blob/release-2.37/tsdb/docs/format/index.md\n\n","tags":["Prometheus"]},{"title":"一些微服务开发规范","url":"/2024/12/08/%E4%B8%80%E4%BA%9B%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%BC%80%E5%8F%91%E8%A7%84%E8%8C%83/","content":"消费组名称\n共享消费者使用微服务名称，比如(DeviceManager)\n广播消费者使用微服务名称+唯一标识，比如\nkubernetes部署场景下可以将pod名称的唯一部分作为唯一标识，比如下图的nginx可以使用5d4f5c59f8-7hztx作为唯一标识$ kubectl get podNAME                          READY   STATUS    RESTARTS   AGEnginx-deployment-5d4f5c59f8-7hztx   1/1     Running   0          2d3hnginx-deployment-5d4f5c59f8-xvbnm   1/1     Running   0          2d3hredis-5f67c8d8c9-4g2h3              1/1     Running   0          10h\n\npod的IP地址\nUUID\n\n\n\n数据库表\n数据库表名使用单数。\n数据库的主键，要考虑对应实体物理上是否唯一。\n数据库可以分为多个列组合唯一、单列唯一、是否有唯一索引、是否有二级索引。\n\n","tags":["微服务"]},{"title":"一步一步教你写kubernetes sidecar","url":"/2022/03/31/%E4%B8%80%E6%AD%A5%E4%B8%80%E6%AD%A5%E6%95%99%E4%BD%A0%E5%86%99kubernetes%20sidecar/","content":"什么是sidecar？\nsidecar，直译为边车。 如上图所示，边车就是加装在摩托车旁来达到拓展功能的目的，比如行驶更加稳定，可以拉更多的人和货物，坐在边车上的人可以给驾驶员指路等。边车模式通过给应用服务加装一个“边车”来达到控制和逻辑的分离的目的。\n对于微服务来讲，我们可以用边车模式来做诸如 日志收集、服务注册、服务发现、限流、鉴权等不需要业务服务实现的控制面板能力。通常和边车模式比较的就是像spring-cloud那样的sdk模式，像上面提到的这些能力都通过sdk实现。\n\n这两种实现模式各有优劣，sidecar模式会引入额外的性能损耗以及延时，但传统的sdk模式会让代码变得臃肿并且升级复杂，控制面能力和业务面能力不能分开升级。\n本文的代码已经上传到gitee\nsidecar 实现原理介绍了sidecar的诸多功能，但是，sidecar是如何做到这些能力的呢？\n原来，在kubernetes中，一个pod是部署的最小单元，但一个pod里面，允许运行多个container(容器)，多个container(容器)之间共享存储卷和网络栈。这样子，我们就可以多container来做sidecar，或者init-container（初始化容器）来调整挂载卷的权限\n\n日志收集sidecar日志收集sidecar的原理是利用多个container间可以共用挂载卷的原理实现的，通过将应用程序的日志路径挂出，用另一个程序访问路径下的日志来实现日志收集，这里用cat来替代了日志收集，部署yaml模板如下\napiVersion: v1kind: Podmetadata:  name: webserverspec:  volumes:    - name: shared-logs      emptyDir: &#123;&#125;  containers:    - name: nginx      image: ttbb/nginx:mate      volumeMounts:        - name: shared-logs          mountPath: /opt/sh/openresty/nginx/logs    - name: sidecar-container      image: ttbb/base      command: [&quot;sh&quot;,&quot;-c&quot;,&quot;while true; do cat /opt/sh/openresty/nginx/logs/nginx.pid; sleep 30; done&quot;]      volumeMounts:        - name: shared-logs          mountPath: /opt/sh/openresty/nginx/logs\n\n使用kubectl create -f 创建pod，通过kubectl logs命令就可以看到sidecar-container打印的日志输出\nkubectl logs webserver sidecar-container\n\n转发请求sidecar这一节我们来实现，一个给应用程序转发请求的sidecar，应用程序代码如下\nuse std::io::prelude::*;use std::net::&#123;TcpListener, TcpStream&#125;;fn main() &#123;    let listener = TcpListener::bind(&quot;127.0.0.1:7878&quot;).unwrap();    for stream in listener.incoming() &#123;        let stream = stream.unwrap();        handle_connection(stream);    &#125;    println!(&quot;Hello, world!&quot;);&#125;fn handle_connection(mut stream: TcpStream) &#123;    let mut buffer = [0; 1024];    stream.read(&amp;mut buffer).unwrap();    let contents = &quot;Hello&quot;;    let response = format!(        &quot;HTTP/1.1 200 OK\\r\\nContent-Length: &#123;&#125;\\r\\n\\r\\n&#123;&#125;&quot;,        contents.len(),        contents    );    println!(&quot;receive a request!&quot;);    stream.write(response.as_bytes()).unwrap();    stream.flush().unwrap();&#125;\n\n我们再来写一个sidecar，它会每15秒向应用程序发出请求\nuse std::thread;use std::time::Duration;fn main() &#123;    loop &#123;        thread::sleep(Duration::from_secs(15));        let response = reqwest::blocking::get(&quot;http://localhost:7878&quot;).unwrap();        println!(&quot;&#123;&#125;&quot;, response.text().unwrap())    &#125;&#125;\n\n通过仓库下的intput/build.sh脚本构造镜像，运行yaml如下\napiVersion: v1kind: Podmetadata:  name: webserverspec:  containers:    - name: input-server      image: sidecar-examples:input-http-server    - name: input-sidecar      image: sidecar-examples:sidecar-input\n通过查看kubectl logs input input-http-server可以看到input-http-server收到了请求\nreceive a request!receive a request!\n拦截请求sidecar应用程序代码，它会每15s向localhost发出请求\npackage com.hezhangjian.sidecarimport akka.actor.typed.ActorSystemimport akka.actor.typed.scaladsl.Behaviorsimport akka.http.scaladsl.Httpimport akka.http.scaladsl.model._import scala.concurrent.&#123;ExecutionContextExecutor, Future&#125;import scala.util.&#123;Failure, Success&#125;object HttpClient &#123;    def main(args: Array[String]): Unit = &#123;        while (true) &#123;            Thread.sleep(15_000L)            implicit val system: ActorSystem[Nothing] = ActorSystem(Behaviors.empty, &quot;SingleRequest&quot;)            // needed for the future flatMap/onComplete in the end            implicit val executionContext: ExecutionContextExecutor = system.executionContext            val responseFuture: Future[HttpResponse] = Http().singleRequest(HttpRequest(uri = &quot;http://localhost:7979/hello&quot;))            responseFuture                    .onComplete &#123;                        case Success(res) =&gt; println(res)                        case Failure(_) =&gt; sys.error(&quot;something wrong&quot;)                    &#125;        &#125;    &#125;&#125;\n\n我们再来写一个sidecar，它会拦截http请求并打印日志\npackage com.hezhangjian.sidecarimport akka.actor.typed.ActorSystemimport akka.actor.typed.scaladsl.Behaviorsimport akka.http.scaladsl.Httpimport akka.http.scaladsl.model._import akka.http.scaladsl.server.Directives._import scala.concurrent.ExecutionContextExecutorimport scala.io.StdInobject HttpServer &#123;    def main(args: Array[String]): Unit = &#123;        implicit val system: ActorSystem[Nothing] = ActorSystem(Behaviors.empty, &quot;my-system&quot;)        // needed for the future flatMap/onComplete in the end        implicit val executionContext: ExecutionContextExecutor = system.executionContext        val route =            path(&quot;hello&quot;) &#123;                get &#123;                    println(&quot;receive a request&quot;)                    complete(HttpEntity(ContentTypes.`text/html(UTF-8)`, &quot;&lt;h1&gt;Say hello to akka-http&lt;/h1&gt;&quot;))                &#125;            &#125;        val bindingFuture = Http().newServerAt(&quot;localhost&quot;, 7979).bind(route)        while (true) &#123;            Thread.sleep(15_000L)        &#125;    &#125;&#125;\n\n通过仓库下的output/build.sh脚本构造镜像，运行yaml如下\napiVersion: v1kind: Podmetadata:  name: outputspec:  volumes:    - name: shared-logs      emptyDir: &#123;&#125;  containers:    - name: output-workload      image: sidecar-examples:output-workload      imagePullPolicy: Never    - name: sidecar-output      image: sidecar-examples:sidecar-output      imagePullPolicy: Never\n\n通过查看kubectl logs output output-workload可以看到output-sidecar收到了请求\nHttpResponse(200 OK,List(Server: akka-http/10.2.9, Date: Tue, 29 Mar 2022 00:15:47 GMT),HttpEntity.Strict(text/html; charset=UTF-8,31 bytes total),HttpProtocol(HTTP/1.1))HttpResponse(200 OK,List(Server: akka-http/10.2.9, Date: Tue, 29 Mar 2022 00:16:02 GMT),HttpEntity.Strict(text/html; charset=UTF-8,31 bytes total),HttpProtocol(HTTP/1.1))HttpResponse(200 OK,List(Server: akka-http/10.2.9, Date: Tue, 29 Mar 2022 00:16:17 GMT),HttpEntity.Strict(text/html; charset=UTF-8,31 bytes total),HttpProtocol(HTTP/1.1))HttpResponse(200 OK,List(Server: akka-http/10.2.9, Date: Tue, 29 Mar 2022 00:16:32 GMT),HttpEntity.Strict(text/html; charset=UTF-8,31 bytes total),HttpProtocol(HTTP/1.1))HttpResponse(200 OK,List(Server: akka-http/10.2.9, Date: Tue, 29 Mar 2022 00:16:47 GMT),HttpEntity.Strict(text/html; charset=UTF-8,31 bytes total),HttpProtocol(HTTP/1.1))HttpResponse(200 OK,List(Server: akka-http/10.2.9, Date: Tue, 29 Mar 2022 00:17:02 GMT),HttpEntity.Strict(text/html; charset=UTF-8,31 bytes total),HttpProtocol(HTTP/1.1))HttpResponse(200 OK,List(Server: akka-http/10.2.9, Date: Tue, 29 Mar 2022 00:17:17 GMT),HttpEntity.Strict(text/html; charset=UTF-8,31 bytes total),HttpProtocol(HTTP/1.1))HttpResponse(200 OK,List(Server: akka-http/10.2.9, Date: Tue, 29 Mar 2022 00:17:32 GMT),HttpEntity.Strict(text/html; charset=UTF-8,31 bytes total),HttpProtocol(HTTP/1.1))\n","tags":["Kubernetes"]},{"title":"业务配置中心的实现","url":"/2021/05/13/%E4%B8%9A%E5%8A%A1%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83%E7%9A%84%E5%AE%9E%E7%8E%B0/","content":"前言之前在InfoQ的《华为云物联网四年配置中心实践》文章中分享了业务配置中心。\n本文讲述业务配置中心（下文简述为配置中心）的关键技术和实现方式。华为云物联网平台按照本文的实现方式实现了一个业务配置中心，该配置中心2020年1月上线，平稳运行至今。\n概念运维配置和用户无关，通常为集群界级别的配置，程序只会进行读取，如数据库配置、邮箱服务器配置、网卡配置、子网地址配置等。\n业务配置作为SaaS 服务，每个用户在上面都有一些业务配置。如用户的证书配置、用户服务器的流控配置等，这些业务配置相对运维配置来说更加复杂，且可能会有唯一性限制，如按用户 id 唯一。这部分配置数据一般由用户操作触发，代码动态写入，并且通知到各个微服务实例。通常，我们希望这些配置能在界面展示，且支持人为修改。上述逻辑如果由各微服务自己实现，会存在大量重复代码，并且质量无法保证。我们希望由一个公共组件来统一实现这个能力。开源或体量较小的项目就不会选择依赖一个配置中心，而是直接通过连接数据库或etcd来解决问题\nenv代表一个部署环境。\ncluster代表环境下的集群。常见于单环境下蓝绿发布，蓝集群、绿集群、金丝雀集群等。\n配置配置名称，如用户证书配置、用户流控配置等。\nKey配置的唯一键，如用户id。\nValue配置唯一键对应的值。\n配置中心设计梗概业务配置特点\n虽然业务配置写入可能存在并发，但并发量不大，频率较低。\n业务配置常常以用户为id，单集群用户量有限，一般不超过5万。\n\n配置中心要解决的问题\n设计要点\n单配置要求有配置id，每个id上通过version的乐观并发控制来解决多版本冲突问题\n通知不追求可靠，应用程序和配置中心断链无法接收通知的场景下，通过定期同步数据来保证数据的可靠\n支持Schema的变更，因Schema变更不频繁，也采用version的乐观并发控制来解决多版本冲突问题\n\n通知是否包含消息内容我认为应该只通知Key，具体的数值让应用程序再去配置中心查询。仅通知Key实现简洁易懂。同时通知Key&amp;Value需要多考虑定期同步和通知两条通道并发，可能引起的竞态冲突。\n配置中心业务流程本小节描述业务配置中心的所有业务流程，并试图从交互中抽象出与具体实现无关的接口\n配置的增删改查\n配置值的增删改查\n定期同步分布式场景下，通知有可能无法送达，如程序陷入网络中断（或长gc），通知消息送达超时，待程序恢复后，数据不再准确。因此需要对数据做定期同步，提高可靠性。\n\n同步过程中，仅仅请求交互id和version，避免传输大量数据。应用程序接收到需要同步的数据后：\n\n删除操作，触发删除通知，从本地缓存中移除数据。\n添加、修改操作，向配置中心查询最新数据，触发通知并写入本地缓存。\n\n服务启动服务启动也可看做是一个同步的流程，只是需要同步大量的数据添加。为了避免向配置中心频繁大量的请求，引入批量操作来减轻压力\n\n限制该配置中心设计思路依赖客户端可把数据全量放入到内存中，如用户量太大，则不适合采用这种模式。\n注：一个节省内存的思路是，内存中只放置全量的id和version，数据只有当用到的时候再去查询。这个思路要求配置中心持久化一些老旧数据以供以下场景的查询使用\n\n业务流程中，需要使用该配置值的。\n\n回调业务程序修改的时候，需要提供旧值的。\n\n\n除此之外没有任何区别。\n业务配置抽象实现从上述描述的业务场景，我们抽象出业务配置中心的交互接口和抽象实现。接口的Swagger Yaml已上传到Github：https://gist.github.com/hezhangjian/68c9c2ecae72cc2a125184e95b0a741e\n配置相关接口\n提供env、cluster、配置名称、配置Schema、配置版本号添加配置\n提供env、cluster、配置名称删除配置\n提供env、cluster、配置名称、新Schema、新Version来修改配置\n提供env、cluster、配置名称来查询配置\n\n配置值相关接口\n提供env、cluster、配置名称、Key、Value来添加配置值\n提供env、cluster、Key、ValueVersion（可选）来删除配置值\n提供env、cluster、Key、Value、ValueVersion（可选）修改配置值\n提供env、cluster、Key查询配置值\n根据env、cluster、应用程序当前的配置数据来做定期同步\n根据Key列表批量查询配置值\n\n通知相关接口\n通知某env某cluster下，配置项中的一个Key发生变化，新增、修改或是删除。可选方式有HTTP长链接（Inspired by Apollo）、Mqtt、WebSocket等。\n\n配置中心存储层抽象实现配置中心存储层需要存储配置和配置值数据，支持UpdateByVersion，且需要捕捉数据的变化，用来通知到应用程序\n服务发现抽象实现为了使应用程序连接到配置中心，需要一个发现机制可以让应用程序感知到配置中心的地址。高可用的方式很多，如K8s发现、ZooKeeper、Etcd、ServiceComb、业务环境变量注入ELB地址（ELB后端挂载配置中心的地址）等。\n抽象总结\n根据这个抽象，我们可以进行关键技术点选型，来实现业务配置中心。\n配置中心实现华为云物联网配置中心实现\n\nenv+cluster+config组成数据表的名称\n一个key、value对应一行数据\n\n另一种实现方式只要实现上述接口和抽象能力，都可以实现业务配置中心，也可以这么实现\n\n\nenv+cluster+config+key 组合成etcd的key\n一个key、value对应一个键值对\n\n又一种实现方式当然也可以\n\n\nenv+cluster+config+key 组合成RocksDB的key\n一个key、value对应一个键值对\n\n"},{"title":"中间件是开箱即用的吗？为什么要开发中间件adapter？","url":"/2021/08/09/%E4%B8%AD%E9%97%B4%E4%BB%B6%E6%98%AF%E5%BC%80%E7%AE%B1%E5%8D%B3%E7%94%A8%E7%9A%84%E5%90%97%EF%BC%9F%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%BC%80%E5%8F%91%E4%B8%AD%E9%97%B4%E4%BB%B6adapter%EF%BC%9F/","content":"中间件在很多系统中都存在在一个系统里面，或多或少地都会有中间件的存在，总会有数据库吧，其他的如消息队列，缓存，大数据组件。即使是基于公有云构筑的系统，公有云厂商只提供广泛使用的中间件，假如你的系统里面有很多组件没那么泛用，那么就只能自己维护，如ZooKeeper、Etcd、Pulsar、Prometheus、Lvs等\n什么是中间件adapter中间件adapter指的是和中间件运行在一起（同一个物理机或同一个容器），使得中间件和商用系统中已有的组件进行对接，最终使得该中间件达到在该系统商用的标准。像Prometheus的众多exporter，就是将中间件和已有的监控系统（Prometheus）进行对接的adpater。\n为什么不修改中间件源码直接集成原因可以有很多，这里我列出几点\n源码修改容易，维护困难很多时候不是社区通用需求，无法合并到社区主干。后续每次中间件版本升级，源码的修改就要重新进行一次。社区大版本代码重构，有的甚至不知道如何修改下去。并且对研发人员的技能要求高。\n源码与团队技术栈不同，修改困难这是最常见的，像java团队维护erlang写的rabbitmq\n和其他系统对接，有语言要求XX监控系统，只能使用X语言接入，但中间件使用Y语言写的，怎么办？adapter的能力就体现出来了。\n为什么在商用系统中中间件做不到开箱即用在商用系统中，对一个新引入的中间件，往往有如下能力上的诉求，原生的中间件很难满足\n\n适配原有的监控系统\n适配原有的告警系统\n适配原有的证书系统\n适配原有的备份系统（如果该中间件有状态）\n适配原有的容灾系统（如果该中间件有状态）\n自动化能力（适配部署、账号创建、权限策略创建）\n对外暴露时封装一层接口\n应用程序和中间件的服务发现\n\n有时候，业务也会根据业务的需求对中间件做一些能力增强，这部分需求比较定制，这里无法展开讨论了。\n我们来逐一讨论上面列出的能力诉求，凡是adapter能实现的功能，对中间件做修改也能实现，只不过因为上一节列出的原因，选择不在中间件处侵入式修改。\n适配原有的监控系统监控系统获取数据，往往是推拉两种模式，如果该中间件原生不支持和该监控系统对接。我们就可以让adapter先从中间件处取得监控数据，再和监控系统对接\n适配原有的告警系统如果中间件发生了不可恢复的错误，如写事务文件失败，操作ZooKeeper元数据失败，可以通过adapter来识别中间件是否发生了上述不可恢复的错误，并和告警系统对接，发出告警。\n适配原有的证书系统这一点也很关键，开源的中间件，根据我的了解，几乎没有项目做了动态证书轮换的方案，证书基本都不支持变更。而出色的商用系统是一定要支持证书轮换的。不过很遗憾的是，这些涉及到TLS握手的关键流程，adapter无法干涉这个流程，只能对中间件进行侵入式修改。\n适配原有的备份系统通过adapter对中间件进行定期备份、按照配置中心的策略备份、备份文件自动上传到文件服务器等。\n适配原有的容灾系统这个视中间件而定，有些中间件如Pulsar原生支持跨地域容灾的话，我们可能做一做配置就好了。另外一些，像mysql和mongo这种，可能我们还需要通过adapter来进行数据同步。不过这个时候adapter负责的职责就大了，还包括了容灾能力。\n自动化能力自动化部署比如ZooKeeper、Kafka、filebeat在安装的时候，要求填写配置文件，我们就可以让adapter来自动化生成配置或更新配置\n账号和策略的创建更新像kubernetes、mysql、mongo，我们可以在安装的时候通过adapter来自动化创建或更新\n对外暴露时封装一层接口封装接口常用于中间件的提供者，出于种种原因，如中间件原本接口能力太大、中间件原本接口未做权限控制、中间件原本接口未适配期望的权限框架等。我们可以用adapter封装实现一层新的接口对外暴露。\n应用程序和中间件的服务发现应用程序发现中间件应用程序与中间件的连接，说的简单一点就是如何获取Ip，如果是基于kubernetes的部署，那么不推荐配置Ip，最好是配置域名，因为Ip会跟着容器的生命周期变化。首先，你的应用程序并不会因为中间件的一个容器重启了来重建客户端，往往是通过一个简单重连的方式连接到新的中间件容器继续工作。其次，我们的运维人员也不会每时每刻盯着容器Ip是否变化来进行配置吧。以下图为例，域名的配置要优于Ip的配置。\n\n截止到目前，我们只需要一个静态配置，使得应用程序可以连接到中间件。最好这个配置是可以修改的，这样我们还可以继承蓝绿、灰度发布的能力。\n中间件到业务程序的发现这个模式常用于负载均衡中间件如Lvs、Nginx自动维护后端列表，我们可以通过adapter来从注册中心获取后端服务的实例信息，并实时更新。\n总结在商用系统中，中间件并没有想象中的那么开箱即用，本文讲述了一些中间件集成到商用系统中需要具备的能力。在对中间件侵入式修改没有技术能力或不想对中间件进行侵入式修改的场景。选用团队常用的、占用资源少的语言来开发中间件adapter应该是更好的选择。\n","tags":["middleware"]},{"title":"为什么Netty的FastThreadLocal这么快【翻译】","url":"/2020/12/27/%E4%B8%BA%E4%BB%80%E4%B9%88Netty%E7%9A%84FastThreadLocal%E8%BF%99%E4%B9%88%E5%BF%AB%E3%80%90%E7%BF%BB%E8%AF%91%E3%80%91/","content":"性能测试ThreadLocal一般在多线程环境用来保存当前线程的数据。用户可以很方便地使用，并且不关心、不感知多线程的问题。下面我会用两个场景来展示多线程的问题：\n\n多个线程同时操作一个ThreadLocal\n一个线程操作多个ThreadLocal\n\n1. 多个线程同时操作一个ThreadLocal测试代码分别用于ThreadLocal和FastThreadLocal。 代码如下:\n\npackage com.github.shoothzj.demo.netty;import lombok.extern.slf4j.Slf4j;import org.junit.Test;import java.util.concurrent.CountDownLatch;/** * @author hezhangjian */@Slf4jpublic class ThreadLocalTest &#123;    @Test    public void testThreadLocal() throws Exception &#123;        CountDownLatch cdl = new CountDownLatch(10000);        ThreadLocal&lt;String&gt; threadLocal = new ThreadLocal&lt;String&gt;();        long starTime = System.currentTimeMillis();        for (int i = 0; i &lt; 10000; i++) &#123;            new Thread(new Runnable() &#123;                @Override                public void run() &#123;                    threadLocal.set(Thread.currentThread().getName());                    for (int k = 0; k &lt; 100000; k++) &#123;                        threadLocal.get();                    &#125;                    cdl.countDown();                &#125;            &#125;, &quot;Thread&quot; + (i + 1)).start();        &#125;        cdl.await();        System.out.println(System.currentTimeMillis() - starTime + &quot;ms&quot;);    &#125;&#125;\n上述的代码创建了一万个线程，并将线程名设置在ThreadLocal中，随后获取这个值十万次，然后通过CountDownLoatch计算总耗时。运行这个程序大概耗时1000ms。\n接下来，测试FastThreadLocal，代码基本上相似:\n\npackage com.github.shoothzj.demo.netty;import io.netty.util.concurrent.FastThreadLocal;import io.netty.util.concurrent.FastThreadLocalThread;import lombok.extern.slf4j.Slf4j;import org.junit.Test;import java.util.concurrent.CountDownLatch;/** * @author hezhangjian */@Slf4jpublic class FastThreadLocalTest &#123;    @Test    public void testFastThreadLocal() throws Exception &#123;        CountDownLatch cdl = new CountDownLatch(10000);        FastThreadLocal&lt;String&gt; threadLocal = new FastThreadLocal&lt;String&gt;();        long starTime = System.currentTimeMillis();        for (int i = 0; i &lt; 10000; i++) &#123;            new FastThreadLocalThread(new Runnable() &#123;                @Override                public void run() &#123;                    threadLocal.set(Thread.currentThread().getName());                    for (int k = 0; k &lt; 100000; k++) &#123;                        threadLocal.get();                    &#125;                    cdl.countDown();                &#125;            &#125;, &quot;Thread&quot; + (i + 1)).start();        &#125;        cdl.await();        System.out.println(System.currentTimeMillis() - starTime);    &#125;&#125;\n跑完之后，用时还是差不多1000ms。这证明了两者在这个场景下没有什么差别\n2. 单个线程操作多个ThreadLocal先看ThreadLocal的:\n\npackage com.github.shoothzj.demo.netty;import lombok.extern.slf4j.Slf4j;import org.junit.Test;import java.util.concurrent.CountDownLatch;/** * @author hezhangjian */@Slf4jpublic class ThreadLocalSingleThreadTest &#123;    @Test    public void testThreadLocal() throws Exception &#123;        CountDownLatch cdl = new CountDownLatch(1);        int size = 10000;        ThreadLocal&lt;String&gt; tls[] = new ThreadLocal[size];        for (int i = 0; i &lt; size; i++) &#123;            tls[i] = new ThreadLocal&lt;String&gt;();        &#125;        new Thread(new Runnable() &#123;            @Override            public void run() &#123;                long starTime = System.currentTimeMillis();                for (int i = 0; i &lt; size; i++) &#123;                    tls[i].set(&quot;value&quot; + i);                &#125;                for (int i = 0; i &lt; size; i++) &#123;                    for (int k = 0; k &lt; 100000; k++) &#123;                        tls[i].get();                    &#125;                &#125;                System.out.println(System.currentTimeMillis() - starTime + &quot;ms&quot;);                cdl.countDown();            &#125;        &#125;).start();        cdl.await();    &#125;&#125;\n上述的代码创建了一万个ThreadLocal，然后设置一个值，随后获取十万次数值，大概耗时2000ms\n接下来我们测试FastThreadLocal\n\npublic static void test1() &#123;    int size = 10000;    FastThreadLocal&lt;String&gt; tls[] = new FastThreadLocal[size];    for (int i = 0; i &lt; size; i++) &#123;        tls[i] = new FastThreadLocal&lt;String&gt;();    &#125;        new FastThreadLocalThread(new Runnable() &#123;        @Override        public void run() &#123;            long starTime = System.currentTimeMillis();            for (int i = 0; i &lt; size; i++) &#123;                tls[i].set(&quot;value&quot; + i);            &#125;            for (int i = 0; i &lt; size; i++) &#123;                for (int k = 0; k &lt; 100000; k++) &#123;                    tls[i].get();                &#125;            &#125;            System.out.println(System.currentTimeMillis() - starTime + &quot;ms&quot;);        &#125;    &#125;).start();&#125;\n运行结果大概只有30ms; 可以发现存在了数量级的差距。接下来重点分析ThreadLocal的机制和FastThreadLocal为什么比ThreadLocal快\nThreadLocal机制我们经常会使用到set和get方法，我们分别查看一下源代码:\n\npublic void set(T value) &#123;    Thread t = Thread.currentThread();    ThreadLocalMap map = getMap(t);    if (map != null)        map.set(this, value);    else        createMap(t, value);&#125;ThreadLocalMap getMap(Thread t) &#123;    return t.threadLocals;&#125;\n首先，获取当前的线程，然后获取存储在当前线程中的ThreadLocal变量。变量其实是一个ThreadLocalMap。最后，查看ThreadLocalMap是否为空，如果为空，则创建一个新的空Map，如果key不为空，则以ThreadLocal为key，存储这个数据\n\nprivate void set(ThreadLocal&lt;?&gt; key, Object value) &#123;            // We don&#x27;t use a fast path as with get() because it is at            // least as common to use set() to create new entries as            // it is to replace existing ones, in which case, a fast            // path would fail more often than not.            Entry[] tab = table;            int len = tab.length;            int i = key.threadLocalHashCode &amp; (len-1);            for (Entry e = tab[i];                 e != null;                 e = tab[i = nextIndex(i, len)]) &#123;                ThreadLocal&lt;?&gt; k = e.get();                if (k == key) &#123;                    e.value = value;                    return;                &#125;                if (k == null) &#123;                    replaceStaleEntry(key, value, i);                    return;                &#125;            &#125;            tab[i] = new Entry(key, value);            int sz = ++size;            if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold)                rehash();        &#125;\n一般来说，ThreadLocal Map使用数组来存储数据，类似于HashMap。 每个ThreadLocal在初始化时都会分配一个threadLocal HashCode，然后按照数组的长度执行模块化操作，因此会发生哈希冲突。 在HashMap中，使用数组+链表来处理冲突，而在ThreadLocal Map中，也是一样的。 Next索引用于执行遍历操作，这显然具有较差的性能。 让我们再次看一下get方法。\n\npublic T get() &#123;    Thread t = Thread.currentThread();    ThreadLocalMap map = getMap(t);    if (map != null) &#123;        ThreadLocalMap.Entry e = map.getEntry(this);        if (e != null) &#123;            @SuppressWarnings(&quot;unchecked&quot;)            T result = (T)e.value;            return result;        &#125;    &#125;    return setInitialValue();&#125;\n同样，首先获取当前线程，然后获取当前线程中的ThreadLocal映射，然后以当前ThreadLocal作为键来获取ThreadLocal映射中的值：\n\nprivate Entry getEntry(ThreadLocal&lt;?&gt; key) &#123;    int i = key.threadLocalHashCode &amp; (table.length - 1);    Entry e = table[i];    if (e != null &amp;&amp; e.get() == key)        return e;    else        return getEntryAfterMiss(key, i, e);&#125; private Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e) &#123;    Entry[] tab = table;    int len = tab.length;    while (e != null) &#123;        ThreadLocal&lt;?&gt; k = e.get();        if (k == key)            return e;        if (k == null)            expungeStaleEntry(i);        else            i = nextIndex(i, len);        e = tab[i];    &#125;    return null;&#125;\n在相同的设置模式下，数组下标通过模块化获取来获取，否则，如果没有冲突，将遍历数据，因此可以通过分析大致了解以下问题：\n\nThreadLocal Map是存储在Thread下的，ThreadLocal是键，因此多个线程在同一个ThreadLocal上进行操作实际上是在每个ThreadLocal Map线程中插入的一条记录，没有冲突问题；\nThreadLocalMap在解决冲突时会通过遍历极大地影响性能。\nFastThreadLocal通过其他方式解决冲突以优化性能让我们继续看看FastThreadLocal如何实现性能优化\n\n译者说：为什么set的时候不适用fastPath()，因为往往大家使用完ThreadLocal都会remove，这个时候，经常是createEntry，而非updateEntry\n为什么Netty的FastThreadLocal这么快Netty分别提供了两类FastThreadLocal和FastThreadLocalThread。 FastThreadLocalThread继承自Thread。 以下也是常用的set和get方法的源代码分析：\n\npublic final void set(V value) &#123;     if (value != InternalThreadLocalMap.UNSET) &#123;         set(InternalThreadLocalMap.get(), value);     &#125; else &#123;         remove();     &#125; &#125; public final void set(InternalThreadLocalMap threadLocalMap, V value) &#123;     if (value != InternalThreadLocalMap.UNSET) &#123;         if (threadLocalMap.setIndexedVariable(index, value)) &#123;             addToVariablesToRemove(threadLocalMap, this);         &#125;     &#125; else &#123;         remove(threadLocalMap);     &#125; &#125;\n首先，将值确定为Internal ThreadLocalMap。 UNSET，然后内部ThreadLocalMap也用于存储数据:\n\npublic static InternalThreadLocalMap get() &#123;    Thread thread = Thread.currentThread();    if (thread instanceof FastThreadLocalThread) &#123;        return fastGet((FastThreadLocalThread) thread);    &#125; else &#123;        return slowGet();    &#125;&#125;private static InternalThreadLocalMap fastGet(FastThreadLocalThread thread) &#123;    InternalThreadLocalMap threadLocalMap = thread.threadLocalMap();    if (threadLocalMap == null) &#123;        thread.setThreadLocalMap(threadLocalMap = new InternalThreadLocalMap());    &#125;    return threadLocalMap;&#125;\n可以发现内部ThreadLocal映射也存储在FastThreadLocalThread中。 不同之处在于，它直接使用FastThreadLocal的index属性，而不是使用ThreadLocal的相应哈希值对位置进行建模。 实例化时初始化索引：\n\nprivate final int index;public FastThreadLocal() &#123;    index = InternalThreadLocalMap.nextVariableIndex();&#125;\nThen enter the nextVariableIndex method:\n\nstatic final AtomicInteger nextIndex = new AtomicInteger(); public static int nextVariableIndex() &#123;    int index = nextIndex.getAndIncrement();    if (index &lt; 0) &#123;        nextIndex.decrementAndGet();        throw new IllegalStateException(&quot;too many thread-local indexed variables&quot;);    &#125;    return index;&#125;\n内部ThreadLocal映射中有一个静态nextIndex对象，用于生成数组下标，因为它是静态的，所以每个FastThreadLocal生成的索引都是连续的。 让我们看看如何在内部ThreadLocal映射中设置索引变量：\n\npublic boolean setIndexedVariable(int index, Object value) &#123;    Object[] lookup = indexedVariables;    if (index &lt; lookup.length) &#123;        Object oldValue = lookup[index];        lookup[index] = value;        return oldValue == UNSET;    &#125; else &#123;        expandIndexedVariableTableAndSet(index, value);        return true;    &#125;&#125;\n索引变量是存储值s的对象数组； 直接使用index作为数组下标进行存储； 如果index大于数组的长度，则将其展开； get方法通过FastThreadLocal中的索引快速读取：\n\npublic final V get(InternalThreadLocalMap threadLocalMap) &#123;     Object v = threadLocalMap.indexedVariable(index);     if (v != InternalThreadLocalMap.UNSET) &#123;         return (V) v;     &#125;     return initialize(threadLocalMap); &#125;  public Object indexedVariable(int index) &#123;     Object[] lookup = indexedVariables;     return index &lt; lookup.length? lookup[index] : UNSET; &#125;\n通过下标直接阅读非常快，这是牺牲空间换来的速度\n总结通过以上分析，我们可以知道，当有很多ThreadLocal读写操作时，我们可能会遇到性能问题； 另外，FastThreadLocal实现了O（1）通过空间读取数据的时间； 还有一个问题，为什么不直接使用HashMap（数组+黑红树林）代替ThreadLocalMap。\n"},{"title":"为什么我们想要业务主键，想要幂等","url":"/2020/08/19/%E4%B8%BA%E4%BB%80%E4%B9%88%E6%88%91%E4%BB%AC%E6%83%B3%E8%A6%81%E4%B8%9A%E5%8A%A1%E4%B8%BB%E9%94%AE%EF%BC%8C%E6%83%B3%E8%A6%81%E5%B9%82%E7%AD%89/","content":"为什么我们想要业务主键，想要幂等​\t在分布式微服务场景下，有太多的环节可以引发错误的处理（包括丢失或者重复处理），如果业务本身有幂等的特性，我们可以以较低的代价解决大部分问题。\n​\t我们假设我们在k8s集群中维护着下面的系统，部署了数个网关实例，数个业务处理服务，一套Kafka集群，数个消费者服务，一个数据库，平时的业务流程是这样子的：\n客户---&gt;(step1) 网关---&gt;(step2) 业务处理服务--&gt;(step3)消息中间件如Kafka--&gt;(step4)消费者消费--&gt;(step5) 写入数据库\n\n\n\n而我们希望做到的是，在海量数据量的情况下，仅仅付出较小的代价，使得客户的每一条消息都存入到我们的数据库，没有丢失或者重复。\n在分布式的环境下，有很多地方都会出错，会引发消息的丢失或者重复，我们先假设上述系统没有做太多的可靠性加固，是如下工作的：\n1. 客户简单地发送到网关2. 网关发送到后端处理服务3. 后端处理服务接收到请求，做简单校验后直接返回成功/失败，异步发送消息到Kafka4. 消费者从Kafka拉取消息，拉取到消息就提交，不考虑写入数据库的成功或失败5. 写入到数据库\n\n举几个例子，那么我们会碰到类似这样的问题:\n1. 客户发送到网关不考虑结果，即时我们返回失败，也不处理。显然会丢失消息，我们的系统并不能保证100%的消息处理成功2. 网关在与业务处理服务的TCP的四次挥手阶段处理异常，导致业务处理成功(已发送到Kafka)，但实际返回客户失败。导致消息重复3. 消费者拉取到消息后，写入数据库失败，但此时offset已提交。消息丢失\n\n我们先不考虑客户，先看平台侧，我们构筑了一个什么样的系统呢？\n它既不能保证至少发一次(AT_LEAST_ONCE),也不能保证最多发一次(AT_MOST_ONCE)，我们构筑了一个即可能多发也有可能少发的系统，当然，现在的基础设施很好，照着这样跑，可能丢失的数据也就是万中一二，但我们做技术，还是要有点追求，实现别人难以实现的事情才是我们的竞争力。\n平台如何实现精确一次实现端到端一次的技术核心是两阶段提交，以上述业务流程为例，实现了两阶段提交的流程应该是这样的:\n1. 消费者从Kafka消费到一批数据，但并不commit提交2. 消费者向数据库prepare这批数据3. 消费者向Kafka提交Offset4. 消费者向数据库commit这批数据\n\n按照这个流程，还会有一些异常场景，比如\n1.消费者向Kafka提交Offset后，突然宕机，重启的消费者无法恢复事务，消息丢失2.消费者commit失败，消息丢失\n\n第二种情况属于极端场景，因为我们执行的业务简单，只是insert操作，prepare成功，commit失败，可以打日志，报告警人工处理。但第一种情况是需要自动化解决的，因为我们不能对每条提交失败的事务都人工处理。那么我们需要的是：\n我们需要消费者在进程级失败的时候，可以判断处于prepare阶段的事务是否需要恢复，这个可以对比Mysql，Mysql也使用了两阶段提交协议，每次重启的时候会判断redolog处于prepare状态，binlog是否完整，如果binlog完整，则恢复。这里redo log就像我们的数据库，binlog就是kafka。但我们现在的业务没有主键，每条消息都是独立的，我们无法区分，那些是要被正常放弃的事务，那些是重启的时候需要恢复的事务。这种情况我们无法处理。\n但如果这时候我们有了主键，我们有了幂等，我们只要做到至少一次就可以保证平台达到端到端一次。因为多次向数据库插入相同的数据，并不会发生什么事。\n平台如何实现至少一次实现至少一次的核心技术是如果处理不成功就打死不提交，报告警等人工操作都不提交! 其他队列，缓存区，滑窗只不过是提升性能的手段。\n1. 消费者从Kafka消费到一批数据，但并不commit提交2. 消费者向数据库prepare这批数据3. 消费者向数据库commit这批数据4. 消费者向Kafka提交Offset\n\n接下来我们来看与客户的通信，这次我们先看如何做到至少一次\n与客户侧通信如何做到至少一次前面说到客户可能不处理你的返回值，碰到这样的客户其实是你赚了，客户的系统连这个都不重视，那想必也不会在意你是否做到了端到端一次吧，丢失了数据想必也不是特别在意。一个端到端一次的系统，一定需要输入端和输出端的配合，正如我前面举例:\n客户发送到网关不考虑结果，即时我们返回失败，也不处理。显然会丢失消息，\n\n那么我们也需要客户的配合，客户检测到我们回复的结果是失败，重试一下，确保成功。现在我们已经实现了至少一次了吗？\n没有，还记得我前面说的这个吗？\n3. 后端处理服务接收到请求，做简单校验后直接返回成功/失败，异步发送消息到Kafka\n\n我们需要后端处理服务接收到请求后，确保发送Kafka成功，再回复用户成功\n与客户侧通信做到精确一次假设前面的方案我都已经做了，在什么情况下我们会重复呢？\n1. 网关在与业务处理服务的TCP的四次挥手阶段处理异常，导致业务处理成功(已发送到Kafka)，但实际返回客户失败。导致消息重复2. 业务处理服务与网关的TCP的四次挥手阶段处理异常，导致业务处理成功，但实际返回客户失败3. 客户的系统重启，成功应答并没有成功传达\n\n为了实现两阶段提交协议，客户在发送前需要确认这个消息是否已经处理过了，但是没有主键，我们无法提供给客户这样子的信息。（如果考虑性能的话，整个系统端到端的事务，基本与高吞吐无缘了）而且，两阶段提交协议也需要客户做很多的工作，实际中也很难落地。\n总结\n我们需要一个业务上的主键，它可以是组合主键(mysql, mongo)，或者是single主键(更适合cassandra和redis)，使得我们可以提供更高QOS的保证，为此，仅需付出极小的代码，可能仅仅是数据库的主键一致性检查。\n如果系统和业务无关，任谁也难言真正的端到端一次。Flink无疑是流系统里面端到端一次的佼佼者，但上面也有着诸多限制。\n\n备注\n事实上，要实现精确一次，系统的每两个环节之间都要做两阶段提交，为行文方便，省去网关，业务处理服务之间的两阶段提交\n推荐书籍 《基于Apache Flink的流处理》\n\n"},{"title":"从ASCII到Unicode，以及UTF-8、UTF-16、UTF-32","url":"/2024/11/24/%E4%BB%8EASCII%E5%88%B0Unicode%EF%BC%8C%E4%BB%A5%E5%8F%8AUTF-8%E3%80%81UTF-16%E3%80%81UTF-32/","content":"Unicode起源ASCIIASCII（American Standard Code for Information Interchange）是一种字符编码标准，它使用7位二进制数来表示128个字符，包括大小写字母、数字、标点符号、控制字符等。ASCII编码是由美国国家标准协会（ANSI）制定的，于1963年发布，是最早的字符编码标准之一。\nASCII不够用了随着计算机不仅仅用于英文，而是用于全球各种语言，ASCII编码已经不能满足需求，针对不同语言的编码方案也应运而生，这其中诞生了很多编码方案，比如GB2312、BIG5、ISO-8859等，这些字符集典型的就是将ASCII的最高位利用起来，将7位扩展到8位，这样就可以表示256个字符。比如ISO-8859-1就是将ASCII的最高位利用起来，表示了拉丁字母。ISO-8859-5表示了西里尔字母。\n这些字符集各自不包含全部的字符，而且不兼容，这就导致了字符集混乱。这导致在一个文件中混用多种字符成为了不可能完成的事情。而Unicode改变了这一切，它的愿景就是Unicode官网中说到的。\nEveryone in the world should be able to use their own language on phones and computers.\n\n在早期，Unicode曾想过固定使用16位来表示字符，这就是UCS-2编码，也是UTF-16的前身，后面发现固定16位字符还是不够用，这才发展成了我们现在熟知的Unicode。\nUnicode介绍Unicode是一个文本编码标准。Unicode通过一个唯一的数字来定义每个字符，不管平台、程序或语言。这个数字叫做码点（code point）。Unicode码点是从0x000000到0x10FFFF（十六进制），书写上通常使用U+打头，跟上至少4位十六进制数（不足则补0），如U+0041（字母A）、U+1F600（emoji 😀），理论上，Unicode可以定义1114112个字符。\nUnicode的码点跟字符是怎么对应的呢？Unicode将这些码点分成了若干个区段，每个区段称为一个平面（plane），每个平面包含65536（对应低位的0x0000~0xffff）个码点。Unicode总共有17个平面，编号从0到16。Unicode的码点分布如下：\n\n\n\n平面编号\n码点区间\n英文缩写\n英文名\n中文名\n\n\n\n0 号平面\nU+000000 - U+00FFFF\nBMP\nBasic Multilingual Plane\n基本多文种平面\n\n\n1 号平面\nU+010000 - U+01FFFF\nSMP\nSupplementary Multilingual Plane\n多文种补充平面\n\n\n2 号平面\nU+020000 - U+02FFFF\nSIP\nSupplementary Ideographic Plane\n表意文字补充平面\n\n\n3 号平面\nU+030000 - U+03FFFF\nTIP\nTertiary Ideographic Plane\n表意文字第三平面\n\n\n4 号平面 ~ 13 号平面\nU+040000 - U+0DFFFF\n&#x2F;\n已分配，但尚未使用\n&#x2F;\n\n\n14 号平面\nU+0E0000 - U+0EFFFF\nSSP\nSupplementary Special-purpose Plane\n特别用途补充平面\n\n\n15 号平面\nU+0F0000 - U+0FFFFF\nPUA-A\nPrivate Use Area-A\n保留作为私人使用区 (A区)\n\n\n16 号平面\nU+100000 - U+10FFFF\nPUA-B\nPrivate Use Area-B\n保留作为私人使用区 (B区)\n\n\n中文、英文均在0号平面，详细的分配可以参考Unicode的RoadMap。\n那么Unicode先定义了码点和字符之间的对应关系，但是如何存储在磁盘上，如何在网络中传输，这就引入了编码方式，编码方式决定了Unicode的码点如何转换为字节流。这就是Unicode定义的三种编码方式：UTF-32、UTF-16、UTF-8。\nUTF-32（32-bit Unicode Transformation Format）在介绍完Unicode之后，UTF-32是最简单、最容易想到的一种编码方式，直接将Unicode的码点以32位整数的方式存储起来。其中Rust的字符类型char，就使用32位值来表示Unicode字符。\n但是这种方式也有很显然的缺点，就是浪费空间，实际Unicode的范围，只需要21位就可以表示了，变长编码就应运而生。\nUTF-16（16-bit Unicode Transformation Format）这里我想给大家讲一个背景知识，编码方案的扩展，通常会尝试去兼容旧的编码方案，这使得新的编辑器可以打开旧的文件，如果没有用到新的字符，那么新的文件也可以被旧的编辑器打开。这使得演进更加平滑，更易落地。\n那就不得不先说一下UCS-2编码方案，如前所述，UCS-2想通过固定16位来表示字符，虽然它最终失败了，但是也影响了很多的系统，比如Windows、Jdk。\nUTF-16编码就以兼容UCS-2编码、变长为两个目标，UTF-16的编码规则\n\n① 对于码点小于等于U+FFFF的字符，直接使用16位表示，兼容UCS-2\n② 对于码点小于等于U+10FFFF的字符，使用两个16位表示\n\n\n这个补丁机制也常被人称作是surrogate。\n\n对于变长编码来说，对于文件中的任意一个字符，怎么能判断出来这是场景①的字符，还是场景②的第一个字符？抑或是场景②的第二个字符？\nUnicode给出的答案是，通过在BMP中舍弃U+D800到U+DFFF的码点，这个区间被称为代理对（surrogate pair），这个区间的码点不会被分配给字符，这样就可以通过这个区间来判断是场景①还是场景②。如果读取的时候，发现前两个字节是D8到DB，那么就是场景②的第一个字符；如果是DC到DF，那么就是场景②的第二个字符；否则就是场景①的字符。\n\n高代理（High-half surrogates）：范围是0xD800~0xDBFF，二进制范围为1101 1000 0000 ~ 1101 1111 1111，这也代表着高代理的前六位一定是110110。\n低代理（Low-half surrogates）：范围是0xDC00~0xDFFF，二进制范围为1101 1100 0000 ~ 1101 1111 1111，这也代表着低代理的前六位一定是110111。\n\n那么聪明的读者应该分析出来了，使用两个16位表示，由于存在代理对的固定部分，剩余的有效位还剩下20位。这20位恰好可以覆盖从U+010000到U+10FFFF的码点范围。由于U+0000-U+FFFF已经在场景①中覆盖，通过将码点减去0x10000，范围就变成了0x000000~0x0FFFFF，恰好是20位整数。\nUTF-8（8-bit Unicode Transformation Format）UTF-8的编码规则\n\n① 对于码点小于等于U+007F的字符，直接使用8位表示，兼容ASCII。\n② 对于码点小于等于U+07FF的字符，使用两个8位表示，其中有效位为11位。\n③ 对于码点小于等于U+FFFF的字符，使用三个8位表示，其中有效位为16位。\n④ 对于码点小于等于U+10FFFF的字符，使用四个8位表示，其中有效位为21位。\n⑤ 使用n个字节（n&gt;1）来表示一个字符时，第一个字节的前n位都是1，第n+1位是0，后面的字节的前两位都是10\n\n那么对于一个字节，就可以通过首位是不是1，来判断是1个字节还是n个字节，再通过第二个字节判断是否是首位，最后通过首位来判断字节的个数。\n由于UTF-8的有效位最大可达21位，这也就使得UTF-8不用像UTF-16那样减去0x10000。\n通过兼容ASCII，最短只用1个字节，这使得UTF-8成为了堪称最流行的编码方式，如果不需要兼容UCS-2，那么几乎可以说UTF-8是最好的选择，堪称当前事实上的标准。值得一提的是，UTF-8的主要设计者，也是Unix的创始人之一，Go语言的设计者之一，Ken Thompson。\n扩展知识JDK17中英文字符集内存占用量降低了一半读者可能会觉得JDK17中中文字符内存占用降低一半是从UTF-16切换到UTF-8导致的，但实则不然，对于JDK来说，切换一种编码方式可谓是伤筋动骨，JDK17通过了JEP254提案，通过添加一个标志位，如果字符串的字符都是ISO-8859-1&#x2F;Latin-1字符，那么就使用一个字节进行存储。\n","tags":["Unicode"]},{"title":"优雅启停VS重试，谁能更好地保证RPC无损","url":"/2021/03/22/%E4%BC%98%E9%9B%85%E5%90%AF%E5%81%9CVS%E9%87%8D%E8%AF%95%EF%BC%8C%E8%B0%81%E8%83%BD%E6%9B%B4%E5%A5%BD%E5%9C%B0%E4%BF%9D%E8%AF%81RPC%E6%97%A0%E6%8D%9F/","content":"背景我们的业务有些时候总是在升级期间rpc业务有一些呼损，想总结一下让rpc调用零呼损的两种方式：重试和优雅启停。我先介绍这两种方式，再描述一下这两种方式的优缺点\n\nA是一个微服务\nB也是一个微服务\n蓝色的是常见的注册中心，有zookeeper、eureka等实现。\n重试重试，在发生可重试错误的时候，重试一次。什么是可重试错误呢？就是重试一次，可能会成功。比如400 BadRequest，那出现这种错误，基本上重试也没有用，就不要浪费我们宝贵的服务器资源了。常见的如servicecomb框架就有重试几次、重试间隔这样的参数。值得一提的是，如果你指望通过重试让升级零呼损，那么你的重试次数，要比你的并行升级实例数大才行。\n这也很容易理解，比如A服务调用B服务，B服务有5个实例,B1~B5。这个时候，同时升级B1和B2，A第一次调用了B1，接下来重试，如果运气不好，恰好重试到了B2节点，那么业务还是会失败的。如果防异常故障，就得重试三次才行。\n如果是防止单数据中心宕机，重试次数大于同时宕机节点数，这个规则可能就没那么靠谱了。现在，企业部署十几个乃至二十几个微服务实例，已经不是什么新闻了，假设分3数据中心部署，总不能重试接近10次吧，这种时候，最好重试策略和数据中心相关，重试的时候，选择另一个az的实例。目前servicecomb还不支持这种功能。\n优雅启停优雅停止优雅停止，就是说当微服务快要宕机的时候，先从注册中心进行去注册，然后把发送给微服务的消息，处理完毕后，再彻底关闭。这个方式，可以有效地防止升级期间，发送到老节点的呼损。\n优雅启动优雅启动，当微服务实例，能够处理rpc请求的时候，再将实例自己注册到注册中心。避免请求发进来，实例却无法处理。\n这里有一个要求，就是调用方发现被调用方（即A发现B）的注册中心，要和B注册、去注册的注册中心是一个注册中心。有案例是，发现采用k8s发现，注册、去注册却使用微服务引擎，导致呼损。\n优劣对比可预知节点升级的场景重试相对于优雅启停，在预知节点升级的场景没那么优雅，重试次数可能还要和并行升级的节点挂钩，非常的不优雅，且难以维护\n不可预知节点升级的场景优雅启停无法对不可预知节点升级的场景生效。只有重试能在这个场景发挥作用\n其他场景重试可以很好地处理网络闪断、长链接中断等场景\n总结想要实现rpc调用零呼损，重试和优雅启停都不可或缺，都需要实现。\n","tags":["RPC"]},{"title":"修改运行中kubernetes集群中etcd的参数","url":"/2023/01/04/%E4%BF%AE%E6%94%B9%E8%BF%90%E8%A1%8C%E4%B8%ADkubernetes%E9%9B%86%E7%BE%A4%E4%B8%ADetcd%E7%9A%84%E5%8F%82%E6%95%B0/","content":"在一些场景下，您的kubernetes集群已经搭建完成了，但是还需要修改一些核心组件的参数，如etcd、kube-apiserver、kube-scheduler、kube-controller-manager等。\n通过kubectl get pod -owide -n kube-system 可以查看到这些核心容器。\nNAME                               READY   STATUS    RESTARTS       AGEcoredns-78fcd69978-rdmjm           1/1     Running   11 (23s ago)   281detcd-$NODE1                        1/1     Running   13 (23s ago)   281detcd-$NODE2                        1/1     Running   13 (23s ago)   281detcd-$NODE3                        1/1     Running   13 (23s ago)   281d.....\n\n以etcd为例，etcd的参数就在pod中的commands参数里。可以通过kubectl describe pod etcd-$NODENAME -n kube-system来查看(省略部分参数)\nName: etcd-$NODENAMENamespace: kube-systemContainers:etcd:Command:--client-cert-auth=true--trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt\n\n然而，如果您尝试编辑pod中的参数，会发现它们是不可修改的。\n不过，如果您需要修改参数，还有另一个办法，通过修改/etc/kubernetes/manifests/下的yaml文件来修改运行中kubernetes集群中”系统”Pod的参数。原理是，当您把yaml文件修改后，kubelet会自动监听yaml文件的变更，并重新拉起本机器上的pod。\n举个例子，如果您希望关闭etcd集群对客户端的认证，那么您可以修改/etc/kubernetes/mainfiest/etcd.yaml,将client-cert-auth设置为false，把trusted-ca-file去掉。注意：三台master机器节点都需要执行此操作\n","tags":["Kubernetes"]},{"title":"分页实践：前后端多种分页方式实现对比","url":"/2023/12/16/%E5%88%86%E9%A1%B5%E5%AE%9E%E8%B7%B5%EF%BC%9A%E5%89%8D%E5%90%8E%E7%AB%AF%E5%A4%9A%E7%A7%8D%E5%88%86%E9%A1%B5%E6%96%B9%E5%BC%8F%E5%AE%9E%E7%8E%B0%E5%AF%B9%E6%AF%94/","content":"在软件开发中，分页没有统一的规范，实现方式也各不相同，有的会返回总页数，有的会返回总条数，有的可以任意翻页。本文对比一下几种常见的分页方式。\n总体来说，分页的实现方案分为四种：\n\n后端全部返回，由前端分页\nlimit offset方案\ncursor方案\ncursor方案与offset结合\n\n后端全部返回，由前端分页sequenceDiagram\n    participant 前端\n    participant 后端\n    前端 ->> 后端: 请求资源集数据\n    后端 -->> 前端: 返回全部数据\n\n\n\n\n前端功能\n支持情况\n\n\n\n显示总页\n🙂\n\n\n任意页码跳转\n🙂\n\n\n跳转附近数页\n🙂\n\n\n大量数据集\n😭完全不可用\n\n\n实现难度\n简单\n\n\nlimit offset方案sequenceDiagram\n    participant 前端\n    participant 后端\n    前端 ->> 后端: 请求满足条件的资源总数\n    后端 -->> 前端: 返回满足条件的资源总数\n    前端 ->> 后端: 请求资源集数据、PageNo\n    后端 -->> 前端: 部分数据\n\n\n\n\n前端功能\n支持情况\n\n\n\n显示总页\n🙂\n\n\n任意页码跳转\n🙂\n\n\n跳转附近数页\n🙂\n\n\n大量数据集\n😭海量数据集下性能差\n\n\n实现难度\n相对简单\n\n\ncursor方案sequenceDiagram\n    participant 前端\n    participant 后端\n    前端 ->> 后端: 请求满足条件的资源总数\n    后端 -->> 前端: 返回满足条件的资源总数\n    前端 ->> 后端: 请求资源集数据、cursor、limit\n    后端 -->> 前端: 部分数据、prevCursor、nextCursor\n\n\n\n\n前端功能\n支持情况\n\n\n\n显示总页\n🙂\n\n\n任意页码跳转\n😭\n\n\n跳转附近数页\n🙂\n\n\n大量数据集\n🙂\n\n\n实现难度\n相对复杂\n\n\n如果每一次翻页都返回总页数的话，对性能来讲也是不小的开销。\n相对动态的数据来说，如果不一直翻到没有数据为止，也不好确定是否到了最后一页。为了解决这个问题，以及跳转附近数页的问题，可以演进为这样的方案。\n假定前端最多显示最近6页，每页50条数据，那么前端可以直接尝试预读300条数据，根据返回的数据来做局部的分页。一言以蔽之：读取更多的数据来进行局部分页。\n\n这里可以再简化一下前端的实现，添加offset参数，这样子前端只需要判断当前页前后数据条数是否足够，附近页的跳转可以通过携带offset字段请求得到。\ncursor方案与offset结合\n import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs';\tmermaid.initialize({startOnLoad: true, flowchart: {curve: 'linear'}}); ","tags":["Pagination"]},{"title":"创建自解压的可执行文件","url":"/2023/10/23/%E5%88%9B%E5%BB%BA%E8%87%AA%E8%A7%A3%E5%8E%8B%E7%9A%84%E5%8F%AF%E6%89%A7%E8%A1%8C%E6%96%87%E4%BB%B6/","content":"为什么需要自解压的可执行文件大部分软件的安装包是一个压缩包，用户需要自己解压，然后再执行安装脚本。常见的两种格式是tar.gz和zip。常见的解压执行脚本如下\ntar.gz#!/bin/bashtar -zxvf xxx.tar.gzcd xxx./install.sh\n\nzip#!/bin/bashunzip xxx.zipcd xxx./install.sh\n\n在有些场景下，为了方便分发、安装，我们需要将多个文件和目录打包并与一个启动脚本结合。这样子就可以实现一键安装，而不需要用户自己解压文件，然后再执行启动脚本。\n核心原理是，通过固定分隔符分隔脚本和压缩包部分，脚本通过分隔符将压缩包部分提取出来，然后解压，执行安装脚本，脚本不会超过固定分隔符。解压可以通过临时文件(zip)或流式解压(tar.gz)的方式实现。\n创建包含zip压缩包的自解压可执行文件构造一个zip压缩包echo &quot;hello zip&quot; &gt; temp.txtzip -r temp.zip temp.txtrm -f temp.txt\n\n构造可执行文件 self_extracting.sh以使用__ARCHIVE_BELOW__做分隔符为例，self_extracting.sh里面内容:\n推荐把临时文件放在内存文件路径下，这样子可以避免磁盘IO\n#!/bin/bashCURRENT_DIR=&quot;$(dirname &quot;$0&quot;)&quot;ARCHIVE_START_LINE=$(awk &#x27;/^__ARCHIVE_BELOW__/ &#123;print NR + 1; exit 0; &#125;&#x27; $0)tail -n+$ARCHIVE_START_LINE $0 &gt; /tmp/temp.zipunzip /tmp/temp.zip&quot; -d &quot;$CURRENT_DIR&quot;rm &quot;$CURRENT_DIR/temp.zip&quot;# replace the following line with your own codecat temp.txtexit 0__ARCHIVE_BELOW__\n\n将zip文件追加到self_extracting.sh文件的尾部\ncat temp.zip &gt;&gt; self_extracting.shchmod +x self_extracting.sh\n\n创建包含tar.gz压缩包的自解压可执行文件构造一个tar.gz压缩包echo &quot;hello tar.gz&quot; &gt; temp.txttar -czf temp.tar.gz temp.txtrm -f temp.txt\n\n构造可执行文件 self_extracting.sh以使用__ARCHIVE_BELOW__做分隔符为例，self_extracting.sh里面内容:\n#!/bin/bashCURRENT_DIR=&quot;$(dirname &quot;$0&quot;)&quot;ARCHIVE_START_LINE=$(awk &#x27;/^__ARCHIVE_BELOW__/ &#123;print NR + 1; exit 0; &#125;&#x27; $0)tail -n+$ARCHIVE_START_LINE $0 | tar xz -C &quot;$CURRENT_DIR&quot;# replace the following line with your own codecat temp.txtexit 0__ARCHIVE_BELOW__\n"},{"title":"利用Lombok的@RequiredArgsConstructor简化Spring构造函数","url":"/2024/03/11/%E5%88%A9%E7%94%A8Lombok%E7%9A%84@RequiredArgsConstructor%E7%AE%80%E5%8C%96Spring%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0/","content":"从Spring的新版本开始，推荐使用构造函数的注入方式，通过构造函数注入有很多优点，诸如不变性等等。同时在构造函数上，也不需要添加@Autowire注解就可以完成注入\n// Beforepublic class ABC &#123;    private final A a;    private final B b;    private final C c;    public ABC(@Autowire A a, @Autowire B b, @Autowire C c) &#123;        this.a = a;        this.b = b;        this.c = c;    &#125;&#125;// Afterpublic class ABC &#123;    private final A a;    private final B b;    private final C c;    public ABC(A a, B b, C c) &#123;        this.a = a;        this.b = b;        this.c = c;    &#125;&#125;\n\n但是，这种注入方式会导致变动代码的时候，需要同时修改field以及构造函数，在项目早期发展时期，这种变动显得有一些枯燥，再加上已经不需要@Autowire注解。这时，我们可以用Lombok的@RequiredArgsConstructor来简化这个流程。\nLombok的@RequiredArgsConstructor会包含这些参数：\n\n所有未初始化的 final 字段\n被标记为 @NonNull 但在声明时未初始化的字段。\n\n对于那些被标记为 @NonNull的字段，还会生成一个显式的空检查（不过在Spring框架里这个没什么作用）。通过应用@RequiredArgsConstructor，代码可以简化为如下模样，同时添加新的字段也不需要修改多行。\n@RequiredArgsConstructorpublic class ABC &#123;    private final A a;    private final B b;    private final C c;&#125;\n","tags":["Java","Spring","Lombok"]},{"title":"华为云物联网四年配置中心实践","url":"/2021/04/14/%E5%8D%8E%E4%B8%BA%E4%BA%91%E7%89%A9%E8%81%94%E7%BD%91%E5%9B%9B%E5%B9%B4%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83%E5%AE%9E%E8%B7%B5/","content":"前言  自17年入职华为之后，一直在使用配置中心，4年期间经历了自研配置中心到Apollo再到自研配置中心和Apollo并存的场景。总结了一下这几年的配置中心演进流程，想把我们在配置中心上的一些实践分享给大家，实现共同进步。Apollo是一款非常优秀的开源软件，是国人的骄傲。如果对Apollo存在理解错误，还望大家不吝赐教，谢谢。\n使用到的配置分类从场景分类运维配置，即程序只读的配置人工配置。通过人工在配置中心界面进行配置，而程序只进行读取，如数据库配置、邮箱服务器配置、网卡配置、子网地址配置等。这部分配置数据不要求代码动态写入。\n业务配置，即程序可写的配置我们是一个SaaS服务，每个用户在上面都有一些业务配置。如用户的证书配置、用户服务器的流控配置等，这些业务配置相对运维配置来说更加复杂，且可能会有唯一性限制，如按用户id唯一。这部分配置数据一般由用户操作触发，代码动态写入，并且通知到各个微服务实例。通常，我们希望这些配置能在界面展示，且支持人为修改。上述逻辑如果由各微服务自己实现，会存在大量重复代码，并且质量无法保证。我们希望由一个公共组件来统一实现这个能力。\n从配置是否会有列表可分为单值配置或多值配置单值配置整个配置下只是多对key、value。value不是很复杂的格式，往往是整数或字符串。\n\n多值配置多值配置更加复杂，往往是单值配置在不同的key下，有不同的值。比如下面的配置，用户一和用户二的线程池大小和队列不同\n\n第一阶段 自研配置中心在做云服务之前，我们的配置中心层级数较少。我们以软件的形式交付给客户，软件运行时分为管理面和业务面，配置中心管理着管理面和业务面的配置，最为复杂的场景是多套业务面，这个时候需要保证不同集群、不同微服务下的配置不冲突，配置层级为 集群、微服务、配置。\n\n此时的配置中心是完全自研的，不包含蓝绿、灰度配置这些功能，它独具特色的地方有以下两点：\n单配置单表\n在存储模型上，每个配置对应一张数据表。\n对多值配置比较友好，尤其是复杂业务配置，可以支持各种主键约束。对单值配置，稍微重型了一些。\n配置的强Schema限制。这些限制包括类型、大小、长度、是否敏感等限制。这种限制既能为界面修改配置提供良好的体验（如：不同格式不同的输入框、敏感字段，前台输入明文，后台入库加密等），也能在通过接口写入配置时做充分的校验。\n\n通过回调方式来确保配置的可靠举个例子，添加一个配置的流程是这样的\n\n可能这里，有读者想要问了，这个流程能确保什么可靠呢。这个流程通过调用微服务接口来校验配置是否可靠，如IP地址是否合法、对端地址是否可达、配置数量是否超过规格等等，来保证配置基本可用。\n总的来说，这个自研的配置中心在当时综合体验还是不错的。但是也有一些问题有待改进，比如单配置下配置项数量过多时，因为底层有部分接口单配置下所有数据都通过一个http请求来承载，会导致响应超时等问题。\n第二阶段 Apollo开始第二阶段实践的原因主要是，我们进行了组织切换，业务重心转向做云服务，同时团队进行DevOps转型。原先的老配置中心是由另一个团队维护的，组织切换完之后，如果还要使用，就要我们自己维护。所以我们需要在继续维护老配置中心和引入开源Apollo中间进行选择。除了上文中提到的运维配置和业务配置，这个时候我们的需求还有改变：\n\n配置的层级愈发丰富了\n要构建灰度发布微服务的能力\n\n老配置中心一方面由于组织切换原因不提供维护了，另一方面不能支撑丰富的配置层级，也不具备灰度发布的能力。这个时候，Apollo的一些特性吸引了我们，这些特性正是老配置中心所缺乏的，例如（部分引用自Apollogithub主页）\n\n丰富的层级，从app_id到cluster,namespace,key-value的层级能满足我们region、集群、微服务的层级诉求\n支持配置的灰度发布，比如点了发布后，只对部分应用实例生效，等观察一段时间没问题后再推给所有应用实例。\n所有的配置发布都有版本概念，从而可以方便的支持配置的回滚。\n应用和配置的管理都有完善的权限管理机制，对配置的管理还分为了编辑和发布两个环节，从而减少人为的错误。\n所有的操作都有审计日志，可以方便的追踪问题。\n\n因此我们选型引入了Apollo，我和我的主管，还有一个其他同事参与了这项工作。我们在Apollo开源代码的基础上做了比较大的改动，主要原因有以下几点\n\n节约成本，将注册中心、数据库替换成我们当前正在使用的组件，因为这两个依赖不是Apollo的核心依赖\n继承老配置中心强Schema的优点。\n保留回调确认配置的流程，提前拦截错误的配置，降低代码处理异常配置的复杂度\n通过spi或环境变量的方式兼容存量老局点使用老配置中心的场景\n\n结合上述原因，我们最终是这么实践的\n\n数据库切换为postgre数据库、注册中心切换到servicecomb\n\n在namespace上实现了Schema，每个namespace都可以注册对应的Schema，Schema要求数据必须是json格式，且json内对应的value必须满足Schema定义的规范（如ip地址、小数、整数等）\nSchema举例\n\n\n[    &#123;        &quot;name&quot;:&quot;name&quot;,        &quot;type&quot;:&quot;string&quot;    &#125;,    &#123;        &quot;name&quot;:&quot;age&quot;,        &quot;type&quot;:&quot;int&quot;,        &quot;max&quot;:120    &#125;,    &#123;        &quot;name&quot;:&quot;ip&quot;,        &quot;type&quot;:&quot;ipv4&quot;    &#125;]\n 那么数据应该是这样的\n&#123;    &quot;name&quot;:&quot;hezhangjian&quot;,    &quot;age&quot;:23,    &quot;ip&quot;:&quot;127.0.0.1&quot;&#125;\n\n\n在添加或修改配置的时候，实现了回调功能，由回调业务服务确认配置能否添加或修改\n配置分层：云服务对应Apollo的app_id，把内部的环境对应到Apollo上的集群，然后将微服务名+配置名拼接成配置名称。\n\n下图展示了业务概念和Apollo概念的对应关系，有些配置是单值配置，有些是多值配置，所以配置项这一层级是可选的。\n\n在这段时间的实践中，我们也发现如下问题\n并发问题其中最致命的就是并发问题，首先Apollo所有配置都存在一张表中，其次由于Apollo设计之初主要考虑的是运维人员手动在界面上操作，代码无并发语义（或者说没给客户端并发语义），使得我们通过代码写入配置时难以解决并发问题。\n性能问题打开namespace列表页面，需要显示这个app_id下的所有namespace,因为我们单app_id会存放单个云服务的所有配置，这个量很大，且界面不支持分页，导致页面加载缓慢\n体验问题Apollo的namespace界面未提供搜索功能（可能Apollo设计之初也没想支持这么多），想要从namespace中定位到我们想要查看或修改的namespace，只能借助浏览器的搜索能力。\n第三阶段 Apollo与自研配置中心并存除了上述几个问题，还有一些原因使得我们开始了第三阶段的实践\n\n原来自上而下的配置分层模型，微服务间配置没隔离，不仅不易进行权限管理，而且不适合DevOps 单微服务自治的发布理念。\n第二阶段对Apollo改动太多，组织结构变动，没有足够的人力维护\n随着集群越来越多，回调功能需要网络的双向打通，网络维护不太方便\n我们对Apollo界面以及接口基于业务做的改动较多，导致其他兄弟部门难以共用Apollo\n\n当时大家对是否保留Schema、回调检查、代码写配置这三个功能点有较大的争议。我个人最希望保留Schema、回调检查，因为它们优点显著，而且接口是兼容的，可以与其他部门共用，但是增加了Schema这个概念和回调检查这个流程，会增加学习成本。而代码写配置，由于要解决并发问题，代码改动量较大，我不建议保留。\n大家经过激烈的讨论，最终还是废弃了Schema、回调检查、代码写配置这三个功能点，仅仅把运维配置放在Apollo。\n然后，我们把业务配置，放在了一个自研的强Schema的配置中心上，这个配置中心，仅负责单集群的配置，每个集群部署一套，满足了我们的业务需求。自研强Schema配置中心的核心要点有，单配置单表、通过注册中心回调来检测配置是否合法、借助mqtt协议来实现长链接推送，无单点瓶颈。\n而我们的运维配置中心Apollo回归到了开源的版本，重整了配置的结构，\n\n对运维配置而言好处有\n\n配置模型适合单微服务发布\n配置按微服务组织，一个页面上的namespace不会很多\n\n缺点\n\nSchema缺失后，不会对操作人员在界面的配置进行校验，即使配置格式或者内容错误也能配置成功。界面上配置密码不支持明文（Apollo无法感知是否为敏感字段），必须提前使用其他工具将明文转换为密文，然后再进行配置。\n回调检查功能去掉后，有些配置，如网卡网段配错，操作人员不能即时得到响应\n\n最佳实践业务配置经过我们的实践，确实不适合使用开源的Apollo。运维配置使用原生的Apollo，但是现在还不具备回调检查和Schema的功能，希望Apollo能在后续版本中支持Schema，或者弱化的json格式检查功能。下面是我们在如下场景下的最佳实践\nSRE在界面上的运维配置通过Apollo来实现功能，至于配置如何组织，根据大家的组织结构、技术架构来对应Apollo上的概念，可按照微服务-&gt;部署环境或部署环境 -&gt; 微服务的层级来组织配置\n复杂的参数校验建议在Apollo上面自建portal包裹一层，后端服务可先进行一层处理，这一层处理可以做比较复杂的格式化校验甚至回调检查，再调用Apollo OpenApi将配置写入Apollo。\n业务配置的技术选型最大的挑战是业务配置由用户触发，请求的并发不易处理。思路有两个，一个是在Apollo原生代码的基础上，通过数据库分布式锁来解决并发问题。第二个是借鉴我们的思路，通过单配置单表、mqtt协议实现通知等核心技术点，自研业务配置中心。\n业务配置的部署需要根据业务配置的数量来考虑是否合设业务配置中心。单集群场景下，毫无疑问只需要一个业务配置中心，甚至如果使用Apollo实现，可以考虑和运维配置中心合设。多集群场景下，部署一个业务配置中心，还是多个业务配置中心，我们自己的实践中，一个集群往往要支撑数万用户，我们采取了每个业务集群部署一套业务配置中心的策略。\n","tags":["HuaweiCloud"]},{"title":"后端开发实体命名","url":"/2023/12/25/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91%E5%AE%9E%E4%BD%93%E5%91%BD%E5%90%8D/","content":"对于一个资源实体来说，在解决方案里，常见的操作场景有：\n\n由外部&#x2F;客户发起的增删改查、列表查询，访问协议一般为HTTP协议。\n由系统内部组件发起的增删改查、列表查询，协议可能为HTTP协议，也可能是RPC协议如gRPC等。\n由资源实体的owner服务跟数据库进行实体读写。\n由资源实体的owner服务将变更广播到消息中间件里。\n\n可以将实体命名如下：\n实体类详细说明：\n\nCreateXxxReq 创建资源请求，包含除资源id之外的所有字段，有些变种里面可能会包含id字段。\nUpdateXxxReq 更新资源请求，包含除资源id之外支持更新的所有字段。\nXxxResp 资源响应，可用于Crate、Update接口的返回，包含所有字段。\nListXxxsResp 资源列表响应，包含资源列表。\nList 资源列表响应，包含资源列表，每个资源包含部分字段，一般是id、name、createdTime、updatedTime等。\n\n出于复杂性的考虑，可以将XxxNotify类跟InnerXxx进行简化合并，转化为:\n\nswagger&#x2F;openapi里，operationId可使用如下\n\n\n\n操作\noperationId\n\n\n\n创建资源\nCreateXxx\n\n\n删除资源\nDeleteXxx\n\n\n更新资源\nUpdateXxx\n\n\n查询单个资源\nShowXxx\n\n\n查询资源列表\nListXxx\n\n\n内部创建资源\nCreateInnerXxx\n\n\n内部删除资源\nDeleteInnerXxx\n\n\n内部更新资源\nUpdateInnerXxx\n\n\n内部查询单个资源\nShowInnerXxx\n\n\n内部查询资源列表\nListInnerXxx\n\n\n"},{"title":"多语言SDK设计","url":"/2023/11/12/%E5%A4%9A%E8%AF%AD%E8%A8%80SDK%E8%AE%BE%E8%AE%A1/","content":"多语言SDK设计的常见问题日志打印的设计策略在SDK的关键节点，比如初始化完成、连接建立或者连接断开，都可以打印日志。如果是PerRequest的日志，一般默认不会打印INFO级别的日志。\nSDK应该避免仅仅打印错误日志然后忽略异常；相反，它应该提供机制让调用者能够捕获并处理异常信息。这种做法有助于保持错误处理的透明性，并允许调用者根据需要采取适当的响应措施。正如David J. Wheeler所说”Put the control in the hands of those who know how to handle the information, not those who know how to manage the computers, because encapsulated details will eventually leak out.”把控制权放到那些知道如何处理信息的人手中，而不是放在那些知道如何管理计算机的人手中，因为封装的细节最终都会暴露。\n是否需要使用显式的start&#x2F;connect方法？像go这样的语言，一般来说不太在意特定的时间内，某个协程是否处于阻塞等待连接的状态。而在java这样的语言，特别是在采用响应式编程模型的场景下，通常需要通过异步操作来管理连接的建立。这可以通过显式的start&#x2F;connect方法来或者是异步的工厂方法来实现。\n","tags":["SDK","Code"]},{"title":"多语言编程 TLS配置参数设计","url":"/2023/11/06/%E5%A4%9A%E8%AF%AD%E8%A8%80%E7%BC%96%E7%A8%8B%20TLS%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0%E8%AE%BE%E8%AE%A1/","content":"背景TLS(Transport Layer Security)是一种安全协议，用于在两个通信应用程序之间提供保密性和数据完整性。TLS是SSL(Secure Sockets Layer)的继任者。\n不同的编程语言处理TLS配置的方式各有千秋, 本文针对TLS配置参数的设计进行探讨。\n代码配置中，建议使用反映状态的参数名。\n通用参数\ntlsEnable: 是否启用TLS\n\nGo推荐使用方式一\n方式一：\n\ntlsConfig *tls.Config: Go标准库的内置TLS结构体\n\n方式二：\n由于Go不支持加密的私钥文件，推荐使用文件内容，而不是文件路径，避免敏感信息泄露。\n\ntlsCertContent []byte: 证书文件内容\ntlsPrivateKeyContent []byte: 私钥文件内容\ntlsMinVersion uint16: TLS最低版本\ntlsMaxVersion uint16: TLS最高版本\ntlsCipherSuites []uint16: TLS加密套件列表\n\nJavaJava的TLS参数基本上都是基于keystore和truststore来配置的。一般常见设计如下参数：\n\nkeyStorePath: keystore文件路径\nkeyStorePassword: keystore密码\ntrustStorePath: truststore文件路径\ntrustStorePassword: truststore密码\ntlsVerificationDisabled: 是否禁用TLS校验\ntlsHostnameVerificationDisabled: 是否禁用TLS主机名校验，仅部分框架支持。\ntlsVersions: TLS版本列表\ntlsCipherSuites: TLS加密套件列表\n\nJavaScriptJavaScript可以使用标准库里的tls.SecureContextOptions\nKotlinkotlin的Tls与Java相同：\n\nkeyStorePath: keystore文件路径\nkeyStorePassword: keystore密码\ntrustStorePath: truststore文件路径\ntrustStorePassword: truststore密码\ntlsVerificationDisabled: 是否禁用TLS校验\ntlsHostnameVerificationDisabled: 是否禁用TLS主机名校验，仅部分框架支持。\ntlsVersions: TLS版本列表\ntlsCipherSuites: TLS加密套件列表\n\nPython推荐使用方式一\n方式一\n\nssl.SSLContext: Python标准库的内置TLS结构体\n\n方式二\nPython可以使用文件路径以及加密的私钥文件。\n\ntlsCertPath: 证书文件路径\ntlsPrivateKeyPath: 私钥文件路径\ntlsPrivateKeyPassword: 私钥密码\ntlsMinVersion: TLS最低版本\ntlsMaxVersion: TLS最高版本\ntlsCipherSuites: TLS加密套件列表\n\nRust由于常见的Rust TLS实现不支持加密的私钥文件，推荐使用文件内容，而不是文件路径，避免敏感信息泄露。 一般常见如下设计参数:\n\ntls_cert_content Vec: 证书内容\ntsl_private_key_content Vec: 私钥内容\ntls_versions: TLS版本列表\ntls_cipher_suites: TLS加密套件列表\ntls_verification_disabled: 是否禁用TLS校验\n\n","tags":["Code","多语言编程"]},{"title":"多语言编程 各大Http库配置指南","url":"/2023/11/18/%E5%A4%9A%E8%AF%AD%E8%A8%80%E7%BC%96%E7%A8%8B%20%E5%90%84%E5%A4%A7Http%E5%BA%93%E9%85%8D%E7%BD%AE%E6%8C%87%E5%8D%97/","content":"GoGo标准库timeoutclient := http.Client&#123;    Timeout: timeout,&#125;\n\nconnection timeoutclient := http.Client&#123;    Transport: &amp;http.Transport&#123;        Dial: (&amp;net.Dialer&#123;            Timeout: timeout,        &#125;).Dial,    &#125;,&#125;\n\nJava标准库(jdk17+)timeoutHttpRequest request = HttpRequest.newBuilder()    .uri(URI.create(&quot;http://example.com&quot;))    .timeout(Duration.ofSeconds(10))    .build();\n\nconnectionTimeoutHttpClient.Builder builder = HttpClient.newBuilder().connectTimeout(Duration.ofSeconds(10)).version(HttpClient.Version.HTTP_1_1);\n\nReactor NettytimeoutHttpClient client = HttpClient.create().responseTimeout(Duration.ofSeconds(10));\n\nconnectionTimeoutHttpClient client = HttpClient.create().option(ChannelOption.CONNECT_TIMEOUT_MILLIS, 5000);\n","tags":["Code"]},{"title":"多语言编程 返回多个不同类型的方法样例","url":"/2023/09/18/%E5%A4%9A%E8%AF%AD%E8%A8%80%E7%BC%96%E7%A8%8B%20%E8%BF%94%E5%9B%9E%E5%A4%9A%E4%B8%AA%E4%B8%8D%E5%90%8C%E7%B1%BB%E5%9E%8B%E7%9A%84%E6%96%B9%E6%B3%95%E6%A0%B7%E4%BE%8B/","content":"背景你可能会在一些场景下碰到需要返回多个不同类型的方法。比如协议解析读取报文时，更具体地像kubernetes在开始解析Yaml的时候，怎么知道这个类型是属于Deployment还是Service？\nCC语言通常通过使用Struct（结构体）和Union（联合体）的方式来实现这个功能，如下文例子\n#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;typedef enum &#123;    MONKEY,    COW,    UNKNOWN&#125; AnimalType;typedef struct &#123;    char* description;&#125; Monkey;typedef struct &#123;    char* description;&#125; Cow;typedef struct &#123;    AnimalType type;    union &#123;        Monkey monkey;        Cow cow;    &#125;;&#125; Animal;Animal createAnimal(const char* animalType) &#123;    Animal animal;    if (strcmp(animalType, &quot;Monkey&quot;) == 0) &#123;        animal.type = MONKEY;        animal.monkey.description = &quot;I am a monkey!&quot;;    &#125; else if (strcmp(animalType, &quot;Cow&quot;) == 0) &#123;        animal.type = COW;        animal.cow.description = &quot;I am a cow!&quot;;    &#125; else &#123;        animal.type = UNKNOWN;    &#125;    return animal;&#125;int main() &#123;    Animal animal1 = createAnimal(&quot;Monkey&quot;);    if (animal1.type == MONKEY) &#123;        printf(&quot;%s\\n&quot;, animal1.monkey.description);    &#125;    Animal animal2 = createAnimal(&quot;Cow&quot;);    if (animal2.type == COW) &#123;        printf(&quot;%s\\n&quot;, animal2.cow.description);    &#125;    Animal animal3 = createAnimal(&quot;Dog&quot;);    if (animal3.type == UNKNOWN) &#123;        printf(&quot;Unknown animal type\\n&quot;);    &#125;    return 0;&#125;\n\nC++在C++中，我们可以使用基类指针来指向派生类的对象。可以使用动态类型识别（RTTI）来在运行时确定对象的类型\n#include &lt;iostream&gt;#include &lt;stdexcept&gt;class Animal &#123;public:    virtual std::string toString() const = 0;&#125;;class Monkey : public Animal &#123;public:    std::string toString() const override &#123;        return &quot;I am a monkey!&quot;;    &#125;&#125;;class Cow : public Animal &#123;public:    std::string toString() const override &#123;        return &quot;I am a cow!&quot;;    &#125;&#125;;Animal* createAnimal(const std::string&amp; animalType) &#123;    if (animalType == &quot;Monkey&quot;) &#123;        return new Monkey();    &#125;    if (animalType == &quot;Cow&quot;) &#123;        return new Cow();    &#125;    throw std::runtime_error(&quot;Unknown animal type: &quot; + animalType);&#125;int main() &#123;    try &#123;        Animal* animal1 = createAnimal(&quot;Monkey&quot;);        if (Monkey* monkey = dynamic_cast&lt;Monkey*&gt;(animal1)) &#123;            std::cout &lt;&lt; monkey-&gt;toString() &lt;&lt; std::endl;        &#125;        delete animal1;        Animal* animal2 = createAnimal(&quot;Cow&quot;);        if (Cow* cow = dynamic_cast&lt;Cow*&gt;(animal2)) &#123;            std::cout &lt;&lt; cow-&gt;toString() &lt;&lt; std::endl;        &#125;        delete animal2;    &#125;    catch (const std::runtime_error&amp; e) &#123;        std::cerr &lt;&lt; e.what() &lt;&lt; std::endl;    &#125;    return 0;&#125;\n\nGoGo的常见处理方式，是返回一个接口或者**interface{}**类型。调用者使用Go语言类型断言来检查具体的类型\npackage mainimport (\t&quot;fmt&quot;)type Animal interface &#123;\tString() string&#125;type Monkey struct&#123;&#125;func (m Monkey) String() string &#123;\treturn &quot;I am a monkey!&quot;&#125;type Cow struct&#123;&#125;func (c Cow) String() string &#123;\treturn &quot;I am a cow!&quot;&#125;func createAnimal(typeName string) (Animal, error) &#123;\tswitch typeName &#123;\tcase &quot;Monkey&quot;:\t\treturn Monkey&#123;&#125;, nil\tcase &quot;Cow&quot;:\t\treturn Cow&#123;&#125;, nil\tdefault:\t\treturn nil, fmt.Errorf(&quot;Unknown animal type: %s&quot;, typeName)\t&#125;&#125;func main() &#123;\tanimal1, err := createAnimal(&quot;Monkey&quot;)\tif err != nil &#123;\t\tfmt.Println(err)\t\treturn\t&#125;\tif monkey, ok := animal1.(Monkey); ok &#123;\t\tfmt.Println(monkey)\t&#125;\tanimal2, err := createAnimal(&quot;Cow&quot;)\tif err != nil &#123;\t\tfmt.Println(err)\t\treturn\t&#125;\tif cow, ok := animal2.(Cow); ok &#123;\t\tfmt.Println(cow)\t&#125;&#125;\n\nJavaJava语言的常见处理方式，是返回Object类型或者一个基础类型。然后由调用方在进行instance of判断。或者Java17之后，可以使用模式匹配的方式来简化转型\npublic class MultiTypeReturnExample &#123;    static class Monkey &#123;        @Override        public String toString() &#123;            return &quot;I am a monkey!&quot;;        &#125;    &#125;    static class Cow &#123;        @Override        public String toString() &#123;            return &quot;I am a cow!&quot;;        &#125;    &#125;    public static Object createAnimal(String type) throws IllegalArgumentException &#123;        switch (type) &#123;            case &quot;Monkey&quot;:                return new Monkey();            case &quot;Cow&quot;:                return new Cow();            default:                throw new IllegalArgumentException(&quot;Unknown animal type: &quot; + type);        &#125;    &#125;    public static void main(String[] args) throws Exception &#123;        Object animal1 = createAnimal(&quot;Monkey&quot;);        // java8 写法，后面如果明确用做精确的类型，需要强制转换        if (animal1 instanceof Monkey) &#123;            System.out.println(animal1);        &#125;        Object animal2 = createAnimal(&quot;Cow&quot;);        if (animal2 instanceof Cow) &#123;            System.out.println(animal2);        &#125;        // java17 写法，不需要强制转换        if (createAnimal(&quot;Monkey&quot;) instanceof Monkey animal3) &#123;            System.out.println(animal3);        &#125;        if (createAnimal(&quot;Cow&quot;) instanceof Cow animal4) &#123;            System.out.println(animal4);        &#125;    &#125;&#125;\n\nJavascript动态类型语言，使用instanceof运算符判断\nclass Animal &#123;    toString() &#123;        return &#x27;I am an animal&#x27;;    &#125;&#125;class Monkey extends Animal &#123;    toString() &#123;        return &#x27;I am a monkey&#x27;;    &#125;&#125;class Cow extends Animal &#123;    toString() &#123;        return &#x27;I am a cow&#x27;;    &#125;&#125;function createAnimal(animalType) &#123;    switch (animalType) &#123;        case &#x27;Monkey&#x27;:            return new Monkey();        case &#x27;Cow&#x27;:            return new Cow();        default:            throw new Error(`Unknown animal type: $&#123;animalType&#125;`);    &#125;&#125;try &#123;    const animal1 = createAnimal(&#x27;Monkey&#x27;);    if (animal1 instanceof Monkey) &#123;        console.log(animal1.toString());    &#125;    const animal2 = createAnimal(&#x27;Cow&#x27;);    if (animal2 instanceof Cow) &#123;        console.log(animal2.toString());    &#125;    const animal3 = createAnimal(&#x27;Dog&#x27;);&#125; catch (error) &#123;    console.error(error.message);&#125;\n\nKotlinKotlin可以使用Sealed Class(密封类)和Any类型两种方式。使用Any的场景，与Java返回Object类似。Sealed Class更加安全、更方便一些。\n使用Any类型open class Animalclass Monkey: Animal() &#123;    override fun toString(): String &#123;        return &quot;I am a monkey!&quot;    &#125;&#125;class Cow: Animal() &#123;    override fun toString(): String &#123;        return &quot;I am a cow!&quot;    &#125;&#125;fun createAnimal(type: String): Any &#123;    return when (type) &#123;        &quot;Monkey&quot; -&gt; Monkey()        &quot;Cow&quot; -&gt; Cow()        else -&gt; throw IllegalArgumentException(&quot;Unknown animal type: $type&quot;)    &#125;&#125;fun main() &#123;    val animal1 = createAnimal(&quot;Monkey&quot;)    when (animal1) &#123;        is Monkey -&gt; println(animal1)        is Cow -&gt; println(animal1)    &#125;    val animal2 = createAnimal(&quot;Cow&quot;)    when (animal2) &#123;        is Monkey -&gt; println(animal2)        is Cow -&gt; println(animal2)    &#125;&#125;\n\n使用SealedClasssealed class Animal &#123;    data class Monkey(val info: String = &quot;I am a monkey!&quot;) : Animal()    data class Cow(val info: String = &quot;I am a cow!&quot;) : Animal()&#125;fun createAnimal(type: String): Animal &#123;    return when (type) &#123;        &quot;Monkey&quot; -&gt; Animal.Monkey()        &quot;Cow&quot; -&gt; Animal.Cow()        else -&gt; throw IllegalArgumentException(&quot;Unknown animal type: $type&quot;)    &#125;&#125;fun main() &#123;    val animal1 = createAnimal(&quot;Monkey&quot;)    when (animal1) &#123;        is Animal.Monkey -&gt; println(animal1.info)        is Animal.Cow -&gt; println(animal1.info)    &#125;    val animal2 = createAnimal(&quot;Cow&quot;)    when (animal2) &#123;        is Animal.Monkey -&gt; println(animal2.info)        is Animal.Cow -&gt; println(animal2.info)    &#125;&#125;\n\nPythonPython是动态类型的语言，可以简单基于一些条件返回不同类型的对象，然后在接收到返回值之后使用type()函数或isinstance()函数来确定其类型\nclass Animal:    def __str__(self):        return &quot;I am an animal&quot;class Monkey(Animal):    def __str__(self):        return &quot;I am a monkey&quot;class Cow(Animal):    def __str__(self):        return &quot;I am a cow&quot;def create_animal(animal_type):    if animal_type == &quot;Monkey&quot;:        return Monkey()    elif animal_type == &quot;Cow&quot;:        return Cow()    else:        raise ValueError(f&quot;Unknown animal type: &#123;animal_type&#125;&quot;)def main():    animal1 = create_animal(&quot;Monkey&quot;)    if isinstance(animal1, Monkey):        print(animal1)    animal2 = create_animal(&quot;Cow&quot;)    if isinstance(animal2, Cow):        print(animal2)if __name__ == &quot;__main__&quot;:    main()\n\nRubyRuby也较为简单，在方法内部直接返回不同类型的对象。然后，可以使用is_a方法或class方法来确定返回对象的实际类型。\nclass Animal  def to_s    &quot;I am an animal&quot;  endendclass Monkey &lt; Animal  def to_s    &quot;I am a monkey&quot;  endendclass Cow &lt; Animal  def to_s    &quot;I am a cow&quot;  endenddef create_animal(animal_type)  case animal_type  when &quot;Monkey&quot;    Monkey.new  when &quot;Cow&quot;    Cow.new  else    raise &quot;Unknown animal type: #&#123;animal_type&#125;&quot;  endendbegin  animal1 = create_animal(&quot;Monkey&quot;)  if animal1.is_a? Monkey    puts animal1  end  animal2 = create_animal(&quot;Cow&quot;)  if animal2.is_a? Cow    puts animal2  endend\n\nRust在Rust中，可以使用enum（枚举）来创建一个持有多种不同类型的数据结构。然后使用match语句来做模式匹配。\nuse std::fmt;enum Animal &#123;    Monkey,    Cow,&#125;impl fmt::Display for Animal &#123;    fn fmt(&amp;self, f: &amp;mut fmt::Formatter&lt;&#x27;_&gt;) -&gt; fmt::Result &#123;        match self &#123;            Animal::Monkey =&gt; write!(f, &quot;I am a monkey!&quot;),            Animal::Cow =&gt; write!(f, &quot;I am a cow!&quot;),        &#125;    &#125;&#125;fn create_animal(animal_type: &amp;str) -&gt; Result&lt;Animal, String&gt; &#123;    match animal_type &#123;        &quot;Monkey&quot; =&gt; Ok(Animal::Monkey),        &quot;Cow&quot; =&gt; Ok(Animal::Cow),        _ =&gt; Err(format!(&quot;Unknown animal type: &#123;&#125;&quot;, animal_type)),    &#125;&#125;fn main() &#123;    match create_animal(&quot;Monkey&quot;) &#123;        Ok(animal) =&gt; match animal &#123;            Animal::Monkey =&gt; println!(&quot;&#123;&#125;&quot;, animal),            _ =&gt; (),        &#125;,        Err(e) =&gt; println!(&quot;&#123;&#125;&quot;, e),    &#125;    match create_animal(&quot;Cow&quot;) &#123;        Ok(animal) =&gt; match animal &#123;            Animal::Cow =&gt; println!(&quot;&#123;&#125;&quot;, animal),            _ =&gt; (),        &#125;,        Err(e) =&gt; println!(&quot;&#123;&#125;&quot;, e),    &#125;    match create_animal(&quot;Dog&quot;) &#123;        Ok(_) =&gt; (),        Err(e) =&gt; println!(&quot;&#123;&#125;&quot;, e),    &#125;&#125;\n\nScalascala中，可以使用sealed trait和case class来创建一个能够返回多种不同类型的方法。Sealed trait可以定义一个有限的子类集合，可以确保类型安全\nsealed trait Animal &#123;  def info: String&#125;case class Monkey() extends Animal &#123;  val info: String = &quot;I am a monkey!&quot;&#125;case class Cow() extends Animal &#123;  val info: String = &quot;I am a cow!&quot;&#125;object MultiTypeReturnExample &#123;  def createAnimal(animalType: String): Animal = &#123;    animalType match &#123;      case &quot;Monkey&quot; =&gt; Monkey()      case &quot;Cow&quot; =&gt; Cow()      case _ =&gt; throw new IllegalArgumentException(s&quot;Unknown animal type: $animalType&quot;)    &#125;  &#125;  def main(args: Array[String]): Unit = &#123;    try &#123;      val animal1 = createAnimal(&quot;Monkey&quot;)      animal1 match &#123;        case Monkey() =&gt; println(animal1.info)        case _ =&gt;      &#125;      val animal2 = createAnimal(&quot;Cow&quot;)      animal2 match &#123;        case Cow() =&gt; println(animal2.info)        case _ =&gt;      &#125;    &#125; catch &#123;      case e: IllegalArgumentException =&gt; println(e.getMessage)    &#125;  &#125;&#125;\n\nTypeScript总得来说，和javascript区别不大\nabstract class Animal &#123;  abstract toString(): string;&#125;class Monkey extends Animal &#123;  toString(): string &#123;    return &#x27;I am a monkey&#x27;;  &#125;&#125;class Cow extends Animal &#123;  toString(): string &#123;    return &#x27;I am a cow&#x27;;  &#125;&#125;function createAnimal(animalType: string): Animal &#123;  switch (animalType) &#123;    case &#x27;Monkey&#x27;:      return new Monkey();    case &#x27;Cow&#x27;:      return new Cow();    default:      throw new Error(`Unknown animal type: $&#123;animalType&#125;`);  &#125;&#125;try &#123;  const animal1 = createAnimal(&#x27;Monkey&#x27;);  if (animal1 instanceof Monkey) &#123;    console.log(animal1.toString());  &#125;  const animal2 = createAnimal(&#x27;Cow&#x27;);  if (animal2 instanceof Cow) &#123;    console.log(animal2.toString());  &#125;  const animal3 = createAnimal(&#x27;Dog&#x27;);&#125; catch (error) &#123;  console.error(error.message);&#125;\n","tags":["Code","多语言编程"]},{"title":"大型系统中的证书管理","url":"/2021/05/30/%E5%A4%A7%E5%9E%8B%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E8%AF%81%E4%B9%A6%E7%AE%A1%E7%90%86/","content":"大型系统中的证书管理随着安全的要求，现在我们在越来越多的通信中使用TLS加密。下图是一个微服务架构下数据流向的例子\n\n\n蓝色部分，即和三方交互时需要TLS加密认证\n红色部分，各个微服务、消息中间件等通信需要TLS加密认证\n绿色部分，各个微服务和存储层通信也需要TLS加密认证\n\n安全上对我们的要求逐步变化为，仅蓝色使用TLS&#x3D;》蓝色和红色使用TLS&#x3D;》全部使用TLS加密\n证书管理的必要性从安全的角度上来说，我们最好能支持证书的更换和热加载。如果您的业务当前使用加密的场景不多，可能暂时看不到证书管理的意义。但是当你在各个方面使用TLS更加频繁之后，会发现证书管理可带来如下好处：\n\n可以通过抽象出场景，通过场景和证书的关联联系，在各个地方通信使用的证书，可以统一更换。\n统一提供证书过期告警等功能\n统一提供证书的变更通知，通知到各个实例\n\n以我在工作中接触到的两个基础PAAS平台，都有证书管理的功能，可见证书管理的必要性。\nPS: 开源组件大多都拥有证书配置能力，没有可对接证书管理的能力，但这个能力很难贡献给社区，需要自己开发。\n证书管理概念在TLS会话中，从依赖的证书文件角度来看，可以分为加密流程和验证流程。\n加密证书TLS加密流程的证书，包含证书链文件和密钥\n验证证书TLS验证流程的证书，仅包含证书链文件\n拆分为加密流程和验证流程的合理性这使得加密流程证书和验证流程证书可以互相独立的替换，更方便在大型场景下复用证书。\n让我们来假设如下的场景：\n\n客户A、客户B、客户C、客户D的验证流程证书自然不相同，但服务跟客户交互的时候，使用的加密流程证书确实同一份。如果将两个阶段的证书合一，那么在更换证书的时候，就需要更新4份数据，当你有1000名用户的时候，这个数字将会是1000，这对于存储和应用程序来说都是不小的冲击。\nSceneScene是在一个会话中，代表会话和请求证书、验证证书的绑定关系。Scene和请求证书、验证证书都是1：1的关系。这使得我们不仅仅可以修改证书文件，也可以对TLS会话中使用的证书进行修改。在证书无法复用，且证书绑定了多个场景的时候，针对单个场景修改其绑定的证书。\n以上图作为例子，假设客户D有特殊的要求，要求加密流程使用特定的证书或密钥，我们就可以将客户D的场景绑定到客户D独有的加密证书\n多集群管理如果证书管理需要管理多个集群，那么证书和Scene前面可以加上层级来隔离，如环境、集群等。\n对小型系统的建议如果规模不大，且TLS场景有限，需要考虑一下有无拆分加密证书和验证证书的必要，可以合一，应用程序直接以合一的证书id来关联，而非场景id。虽不方便复用，但大大降低了复杂性。\n证书管理的功能\n证书管理场景设定一个TLS会话\n使用TLS会话这要求应用程序持久化场景信息\n\n组织架构相关大型系统下，证书管理是一个必须的组件，且一定是由团队最底层的组织架构承接。如若不然，那么由底层组织架构维护的组件，因为依赖关系，无法基于证书管理来统一实现证书的更换和过期告警。除非不基于证书管理自己构筑一套能力。\nTLDR随着组件和使用加密场景的不断扩大，证书管理是一个必须的组件，通过抽象出场景的概念来复用证书，通过变更通知在微服务模式下快速更换所有微服务实例上的证书，并提供统一的证书过期告警功能来提醒管理员更换证书。\n","tags":["cert"]},{"title":"如果不是公有云的供应商，能提供什么样的Pulsar服务体验","url":"/2021/04/20/%E5%A6%82%E6%9E%9C%E4%B8%8D%E6%98%AF%E5%85%AC%E6%9C%89%E4%BA%91%E7%9A%84%E4%BE%9B%E5%BA%94%E5%95%86%EF%BC%8C%E8%83%BD%E6%8F%90%E4%BE%9B%E4%BB%80%E4%B9%88%E6%A0%B7%E7%9A%84Pulsar%E6%9C%8D%E5%8A%A1%E4%BD%93%E9%AA%8C/","content":"需要了解的概念\nVPC：用户的私有网段\npeering：多个VPC之间打通的方式，可跨用户\n\n前言今天微信推送Pulsar社区有个Hackathon比赛, 开始想的idea就是，实现pulsar在华为云上提供服务。因为是社区的比赛，是以一个三方系统的方式在华为云上提供服务，而非是以华为云的名义提供服务。分析了下可行性和能达到的效果，对比了StreamNative的官网上提供的pulsar服务在阿里云托管的能力，能提供的能力差不多，最多只不过是实现了在华为云托管的能力，没有从0到1的突破。\n现在，在公有云上买redis和kafka这类组件已经变得非常普遍，由公有云供应商提供的中间件往往能给你带来良好的体验，相比三方厂家在云上进行托管，我个人认为云厂商的优势主要在以下三点\n网络打通容易下文说一下不是公有云的供应商能以什么样的方式暴露自己的服务。云厂商可以把中间件的ip地址申请在你的vpc内，对任何应用程序来说，连接都是最方便的。无论是容器化部署、虚拟机部署、和其他vpc peering打通的场景，都可以通信。\n低廉的成本不考虑人力成本，云厂商自运营的价格要低于三方厂家。\n监控系统对接方便地和云厂商的告警、统计系统对接，接收告警通知和报表等。\n其中网络打通和成本尤为重要，三方厂家好好做监控统计系统，也能给用户较为良好的体验。\n三方厂家能提供什么样的Pulsar接入统一接入三方厂家自己作为公有云上一个用户，无论这个Region上有多少个租户，都用这一个用户提供服务，这也就意味着无法与每个用户进行私网通信。如果在华为云，利用华为云推出的VPCEP服务（此处应有链接），倒是可以给每个用户提供私网通信，不过这个是做了DNAT地址转换的，跟做了DNAT转换的中间件连接，是非常麻烦的。（懂的自然懂。如果有人想详细了解，可以留言，我可以写一个文章介绍里面的坑）\n如果使用公网，又想避免扩容的时候动态申请EIP，动态申请EIP并不复杂，问题是EIP是有配额限制的，这才是关键。那么就需要一个统一的接入点，就需要部署pulsar proxy。到这一步，是每个用户申请一个EIP的，如果还想继续节省EIP，那么可以统一域名接入，后端通过SNI的方式转发，个别流量大的客户，单独把域名指向单独的集群。\n\nPeering打通Peering打通可以给用户不错的私网体验，需要用户预留一个网段，网段不需要太大，能容纳pulsar所在的vm就行。采用peering打通一般绝不会选择容器化部署，想要两个容器化的集群互通，对网设的要求很高，暂且忽略Service的存在，这要求用户的vpc网段和pod网段和三方厂商的vpc网段和pod网段都不重叠！而且peering打通，给用户私有，再搭建一个k8s集群，对成本影响比较大。主要有如下两个问题\n自动化和客户peering打通，需要较大的权限，如何自动化，最大程度的减少需要的权限。\n客户网段和其他网段又做了peering\n这个问题其实还好，就是路由规则配置麻烦\n总结Peering打通对用户来说已经比较方便了，相信做到自动化也没有太大的技术难度，只是时间和人力投入的问题。统一接入因为网络打通的原因，不好使用kop、mop这些高级特性，此外还有不小的公网带宽成本，羊毛出在羊身上，比较大量的用户也会倾向于Peering打通的模式吧。\n","tags":["Pulsar"]},{"title":"容器内指定特定域名解析结果的几种方式","url":"/2023/07/10/%E5%AE%B9%E5%99%A8%E5%86%85%E6%8C%87%E5%AE%9A%E7%89%B9%E5%AE%9A%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E7%BB%93%E6%9E%9C%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F/","content":"在本篇文章中，我们将探讨如何在容器内指定特定域名解析结果的几种方式。为了方便演示，首先我们创建一个演示用的Deployment配置文件。\napiVersion: apps/v1kind: Deploymentmetadata:  name: busybox-deployment  labels:    app: busyboxspec:  replicas: 1  selector:    matchLabels:      app: busybox  template:    metadata:      labels:        app: busybox    spec:      containers:      - name: busybox        image: busybox        args:        - /bin/sh        - -c        - &quot;while true; do echo Hello, Kubernetes!; sleep 10;done&quot;\n\n这个deployment会创建1个busybox的pod，容器每隔10s会打印“Hello, Kubernetes!”到控制台\nTL;DR\n\n\n方案\n修改级别\n是否推荐\n备注\n\n\n\n修改&#x2F;etc&#x2F;hosts\npod\n否\n\n\n\n添加HostAliases记录\npod&#x2F;deploy&#x2F;statefulset\n是\n\n\n\n修改Coredns配置\n整个kubernetes集群\n是\n\n\n\n自定义DNS策略\npod&#x2F;deploy&#x2F;statefulset\n视情况而定\n如需对接三方的DNS服务器，推荐采用\n\n\n使用三方DNS插件\n整个kubernetes集群\n否\n不推荐，Coredns为业内主流\n\n\n修改&#x2F;etc&#x2F;hosts修改&#x2F;etc&#x2F;hosts是最传统的方式，直接在容器内修改相应的文件来实现域名解析，在Pod级别生效。由于其可维护性较差（每次pod发生重启都需要手动修改），不推荐在生产环境使用。\n例如，我们可以在&#x2F;etc&#x2F;hosts里面添加这样一条记录\n250.250.250.250 four-250\n\n/ # ping four-250PING four-250 (250.250.250.250): 56 data bytes\n\n添加HostAliases记录HostAliases是kubernetes中Pod配置的一个字段，它提供了Pod内容器的/etc/hosts文件的附加记录。这在某些情况下非常有用，特别是当你想要覆盖某个主机名的解析结果，或者提供网络中没有的主机名解析时。\n这个可以在Pod、Replica、Deployment、StatefulSet的级别修改，维护性稍强。举个🌰，我们将上面的yaml修改为\napiVersion: apps/v1kind: Deploymentmetadata:  name: busybox-deployment  labels:    app: busyboxspec:  replicas: 3  selector:    matchLabels:      app: busybox  template:    metadata:      labels:        app: busybox    spec:      hostAliases:      - ip: &quot;250.250.250.250&quot;        hostnames:        - &quot;four-250&quot;      containers:      - name: busybox        image: busybox        args:        - /bin/sh        - -c        - &quot;while true; do echo Hello, Kubernetes!; sleep 10;done&quot;\n\n这个时候我们查看容器的&#x2F;etc&#x2F;hosts，发现它被kubernetes自动插入了一条记录**Entries add by HostAliases。**这就是hostAliases的实现原理\n在kubelet_pods代码中进行了这样的写入动作\nfunc hostsEntriesFromHostAliases(hostAliases []v1.HostAlias) []byte &#123;\tif len(hostAliases) == 0 &#123;\t\treturn []byte&#123;&#125;\t&#125;\tvar buffer bytes.Buffer\tbuffer.WriteString(&quot;\\n&quot;)\tbuffer.WriteString(&quot;# Entries added by HostAliases.\\n&quot;)\t// for each IP, write all aliases onto single line in hosts file\tfor _, hostAlias := range hostAliases &#123;\t\tbuffer.WriteString(fmt.Sprintf(&quot;%s\\t%s\\n&quot;, hostAlias.IP, strings.Join(hostAlias.Hostnames, &quot;\\t&quot;)))\t&#125;\treturn buffer.Bytes()&#125;\n\nCoredns配置我们可以通过修改ConfigMap来实现让容器解析特定域名的目的。\n更改Coredns配置我们可以通过以下命令修改Coredns的配置：\nkubectl edit cm coredns -n kube-system\n\n原有的configmapCorefile: |    .:53 &#123;        log        errors        health &#123;           lameduck 5s        &#125;        ready        kubernetes cluster.local in-addr.arpa ip6.arpa &#123;           pods insecure           fallthrough in-addr.arpa ip6.arpa           ttl 30        &#125;        prometheus :9153        hosts &#123;           192.168.65.2 host.minikube.internal           fallthrough        &#125;        forward . /etc/resolv.conf &#123;           max_concurrent 1000        &#125;        cache 30        loop        reload        loadbalance    &#125;\n\n在hosts里面加上特定的记录\n250.250.250.250 four-250\n\n如果您没有配置reload插件，则需要重启Coredns才能生效，默认的reload时间是30s，在plugin&#x2F;reload&#x2F;setup.go的defaultInterval中定义\n自定义DNS策略通过修改DNS策略。使得对于单个Pod&#x2F;Deploy&#x2F;StatefulSet将特定的域名解析发给特定的服务器来达到效果，如下，可以对pod添加dns的服务器以及search域\nspec:   dnsConfig:     nameservers:       - 1.2.3.4     searches:       - search.prefix   containers:   - name: busybox     image: busybox     args:     - /bin/sh     - -c     - &quot;while true; do echo Hello, Kubernetes!; sleep 10;done&quot;\n\n使用第三方DNS插件不推荐，使用其他的DNS插件，来做一些炫酷的自定义操作。而且目前Coredns也是业内的主流，没有很好的替代\n","tags":["Kubernetes"]},{"title":"开发一个filebeat output websocket插件","url":"/2021/07/04/%E5%BC%80%E5%8F%91%E4%B8%80%E4%B8%AAfilebeat%20output%20websocket%E6%8F%92%E4%BB%B6/","content":"开发一个filebeat的websocket插件， 代码仓地址: https://github.com/hezhangjian/beats_output_websocket\n引入对beat的依赖go get github.com/elastic/beats/v7\n\n定义在filebeat中的配置文件filebeat通常以配置文件的方式加载插件。让我们定义一下必须的配置，就像elasticsearch中的连接地址等等一样。\noutput.websocket:  # worker  # 用于工作的websocket客户端数量  workers: 1  # 日志批量的最大大小  batch_size: 1  # 重试的最大次数，0代表不重试  retry_limit: 1  # conn  # ws/wss  schema: &quot;ws&quot;  # websocket连接地址  addr: &quot;localhost:8080&quot;  # websocket路径  path: &quot;/echo&quot;  # websocket心跳间隔，用于保活  ping_interval: 30\n\ngo文件中的配置type clientConfig struct &#123;\t// Number of worker goroutines publishing log events\tWorkers int `config:&quot;workers&quot; validate:&quot;min=1&quot;`\t// Max number of events in a batch to send to a single client\tBatchSize int `config:&quot;batch_size&quot; validate:&quot;min=1&quot;`\t// Max number of retries for single batch of events\tRetryLimit int `config:&quot;retry_limit&quot;`\t// Schema WebSocket Schema\tSchema string `config:&quot;schema&quot;`\t// Addr WebSocket Addr\tAddr string `config:&quot;addr&quot;`\t// Path WebSocket Path\tPath string `config:&quot;path&quot;`\t// PingInterval WebSocket PingInterval\tPingInterval int `config:&quot;ping_interval&quot;`&#125;\n\n\n\n初始化加载插件加载插件在某个init函数中注册插件\nfunc init() &#123;\toutputs.RegisterType(&quot;websocket&quot;, newWsOutput)&#125;\n\n在newWsOutput中卸载配置，并提供配置给WebSocket客户端\nfunc newWsOutput(_ outputs.IndexManager, _ beat.Info, stats outputs.Observer, cfg *common.Config) (outputs.Group, error) &#123;\tconfig := clientConfig&#123;&#125;\t// 卸载配置，将配置用于初始化WebSocket客户端\tif err := cfg.Unpack(&amp;config); err != nil &#123;\t\treturn outputs.Fail(err)\t&#125;\tclients := make([]outputs.NetworkClient, config.Workers)\tfor i := 0; i &lt; config.Workers; i++ &#123;\t\tclients[i] = &amp;wsClient&#123;\t\t\tstats:  stats,\t\t\tSchema: config.Schema,\t\t\tHost:   config.Addr,\t\t\tPath:   config.Path,\t\t\tPingInterval: config.PingInterval,\t\t&#125;\t&#125;\treturn outputs.SuccessNet(true, config.BatchSize, config.RetryLimit, clients)&#125;\n\n初始化WebSocket客户端WebSocket客户端不仅仅是一个WebSocket客户端，而且还需要实现filebeat中的NetworkClient接口，接下来，让我们来关注接口中的每一个方法的作用及实现\nString()接口String作为客户端的名字，用来标识日志以及指标。是最简单的一个接口\nfunc (w *wsClient) String() string &#123;\treturn &quot;websocket&quot;&#125;\n\nConnect()接口Connect用来初始化客户端\nfunc (w *wsClient) Connect() error &#123;\tu := url.URL&#123;Scheme: w.Schema, Host: w.Host, Path: w.Path&#125;\tdial, _, err := websocket.DefaultDialer.Dial(u.String(), nil)\tif err == nil &#123;\t\tw.conn = dial\t\tticker := time.NewTicker(time.Duration(w.PingInterval) * time.Second)\t\tgo func() &#123;\t\t\tfor range ticker.C &#123;\t\t\t\tw.conn.WriteMessage(websocket.PingMessage, nil)\t\t\t&#125;\t\t&#125;()\t&#125; else &#123;\t\ttime.Sleep(10 * time.Second)\t&#125;\treturn err&#125;\n\n注意，这里初始化失败，需要Sleep一段时间，否则，filebeat会一直重试。这绝非是你想要的。或许对于场景来说，退避重试可能会更好\nClose()接口关闭客户端，也是很简单的接口\nfunc (w *wsClient) Close() error &#123;\treturn w.conn.Close()&#125;\n\nPublish()接口func (w *wsClient) Publish(_ context.Context, batch publisher.Batch) error &#123;\tevents := batch.Events()\t// 记录这批日志\tw.stats.NewBatch(len(events))\tfailEvents, err := w.PublishEvents(events)\tif err != nil &#123;\t\t// 如果发送正常，则ACK\t\tbatch.ACK()\t&#125; else &#123;\t\t// 发送失败，则重试。受RetryLimit的限制\t\tbatch.RetryEvents(failEvents)\t&#125;\treturn err&#125;func (w *wsClient) PublishEvents(events []publisher.Event) ([]publisher.Event, error) &#123;\tfor i, event := range events &#123;\t\terr := w.publishEvent(&amp;event)\t\tif err != nil &#123;\t\t\t// 如果单条消息发送失败，则将剩余的消息直接重试\t\t\treturn events[i:], err\t\t&#125;\t&#125;\treturn nil, nil&#125;func (w *wsClient) publishEvent(event *publisher.Event) error &#123;\tbytes, err := encode(&amp;event.Content)\tif err != nil &#123;\t\t// 如果编码失败，就不重试了，重试也不会成功\t\t// encode error, don&#x27;t retry.\t\t// consider being success\t\treturn nil\t&#125;\terr = w.conn.WriteMessage(websocket.TextMessage, bytes)\tif err != nil &#123;\t\t// 写入WebSocket Server失败\t\treturn err\t&#125;\treturn nil&#125;\n\n编码编码的逻辑因人而异，事实上，这可能是大家最大的差异所在。这里只是做一个简单地例子\ntype LogOutput struct &#123;\tTimestamp time.Time `json:&quot;timestamp&quot;`\tMessage   string    `json:&quot;message&quot;`&#125;func encode(event *beat.Event) ([]byte, error) &#123;\tlogOutput := &amp;LogOutput&#123;&#125;\tvalue, err := event.Fields.GetValue(&quot;message&quot;)\tif err != nil &#123;\t\treturn nil, err\t&#125;\tlogOutput.Timestamp = event.Timestamp\tlogOutput.Message = value.(string)\treturn json.Marshal(logOutput)&#125;\n\n最后是我们的wsclienttype wsClient struct &#123;\t// construct field\tSchema       string\tHost         string\tPath         string\tPingInterval int\tstats outputs.Observer\tconn  *websocket.Conn&#125;\n\n添加额外的功能：大包丢弃你可能会想保护你的WebSocket服务器，避免接收到超级大的日志。我们可以在配置项中添加一个配置\nmaxLen用来限制日志长度，超过maxLen的日志直接丢弃。为什么不使用filebeat中的max_bytes？\n因为filebeat中max_bytes的默认行为是截断，截断的日志在某些场景下不如丢弃。（比如，日志是json格式，截断后格式无法解析）\n配置中添加maxLenmax_len: 1024\n\n省略掉那些重复的添加结构体，读取max_len在encode的时候忽略掉\ns := value.(string)if len(s) &gt;= w.MaxLen &#123;\treturn nil, err&#125;\n","tags":["Go","Filebeat","WebSocket"]},{"title":"异步网络请求编码","url":"/2023/12/10/%E5%BC%82%E6%AD%A5%E7%BD%91%E7%BB%9C%E8%AF%B7%E6%B1%82%E7%BC%96%E7%A0%81/","content":"本文介绍常见的异步网络请求编码手法。尽管像golang这些的语言，支持协程，可以使得Programmer以同步的方式编写代码，大大降低编码者的心智负担。但网络编程中，批量又非常常见，这就导致即使在Golang中，也不得不进行协程的切换来满足批量的诉求，在Golang中往往对外以callback的方式暴露接口。\n无论是callback、还是返回future、还是返回Mono&#x2F;Flux，亦或是从channel中读取，这是不同的异步编程范式，编码的时候，可以从项目整体、团队编码风格、个人喜好来依次考虑。本文将以callback为主，但移植到其他异步编码范式，并不困难。\n使用callback模式后，对外的方法签名类似:\ngo\nfunc (c *Client) Get(ctx context.Context, req *Request, callback func(resp *Response, err error)) error\n\njava\npublic interface Client &#123;    void get(Request req, Callback callback);&#125;\n\n网络编程中的批量对于网络请求来说，批量可以提高性能。 批量处理是指将多个请求或任务组合在一起，作为单一的工作单元进行处理。批量尽量对用户透明，用户只需要简单地对批量进行配置，而不需要关心批量的实现细节。\n常见的批量相关配置\n\nbatch interval: 批量的时间间隔，比如每隔1s，批量一次\nbatch size: 批量的最大大小，比如每次最多批量100个请求\n\n批量可以通过定时任务实现，也可以做一些优化，比如队列中无请求时，暂停定时任务，有请求时，启动定时任务。\n编码细节整体流程大概如下图所示：\n\n一定要先把请求放到队列&#x2F;map中避免网络请求响应过快，导致callback还没注册上，就已经收到响应了。\n队列中的消息一定要有超时机制避免由于丢包等原因，导致请求一直没有响应，而导致队列中的请求越来越多，最终内存溢出。\nwait队列生命周期与底层网络client生命周期一致wait队列中请求一定是依附于client的，一旦client重建，队列也需要重建，并触发callback、future的失败回调。\n","tags":["Code"]},{"url":"/2020/01/23/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E4%BA%B2%E5%92%8C%E5%8F%8D%E4%BA%B2%E5%92%8C%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%BC%8F%E4%B8%8B%E7%9A%84%E6%97%A5%E5%BF%97%E6%89%93%E5%8D%B0%E5%88%86%E6%9E%90/","content":"灵活部署要求常见的微服务开发下,可能会对微服务的日志打印有一些要求.常见的一种模式是,将日志文件挂载在主机路径中,然后在主机上启动filebeat收集日志.\n以我的一个demo工程rabbitmq-adapt为例: \n容器内打印路径: /opt/sh/logs/file.log容器外挂载路径: /opt/log/rabbitmq/file.log\n\n但是这样子,如果我们需要在一个虚拟机上跑两个rabbitmq-adapt的时候,日志路径会重复,这种情况下,不仅我们在虚拟机很难定位问题,而且filebeat也很难给日志标记上不同实例的标签.\n所以首先,我们得把日志路径按pod实例的方式隔离,选择k8s中HOSTNAME环境变量作为文件路径前缀是一个不错的选择\nakka@AkkadeMacBook-Pro ~ % kubectl exec -it rabbitmq-58c5f4ff6b-zthg4 bash[root@rabbitmq-58c5f4ff6b-zthg4 /]# envLANG=en_US.UTF-8HOSTNAME=rabbitmq-58c5f4ff6b-zthg4KUBERNETES_PORT_443_TCP_PROTO=tcpKUBERNETES_PORT_443_TCP_ADDR=10.96.0.1KUBERNETES_PORT=tcp://10.96.0.1:443POD_NAME=rabbitmq-58c5f4ff6b-zthg4PWD=/HOME=/rootNODE_NAME=minikubeKUBERNETES_SERVICE_PORT_HTTPS=443KUBERNETES_PORT_443_TCP_PORT=443KUBERNETES_PORT_443_TCP=tcp://10.96.0.1:443TERM=xtermSHLVL=1KUBERNETES_SERVICE_PORT=443PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/binPOD_IP=172.17.0.2KUBERNETES_SERVICE_HOST=10.96.0.1LESSOPEN=||/usr/bin/lesspipe.sh %s_=/usr/bin/env\n\n\n\nk8s subPathExpr方案: 查阅资料,官方推荐的是这个方案这个时候,你的映射关系是 &#x2F;opt&#x2F;sh&#x2F;logs &lt;&#x3D;&#x3D;&gt; &#x2F;opt&#x2F;log&#x2F;rabbitmq&#x2F;${POD_NAME}\napiVersion: apps/v1kind: Deploymentmetadata:  name: rabbitmq  labels:    app: rabbitmqspec:  replicas: 2  selector:    matchLabels:      app: rabbitmq  template:    metadata:      labels:        app: rabbitmq    spec:      containers:      - name: rabbitmq        env:        - name: NODE_NAME          valueFrom:            fieldRef:                fieldPath: spec.nodeName                - name: POD_NAME          valueFrom:            fieldRef:                fieldPath: metadata.name                    - name: POD_IP          valueFrom:            fieldRef:                fieldPath: status.podIP        image: hezhangjian/rabbitmq-adapt:0.0.1        readinessProbe:          httpGet:            path: /readiness            port: 8083          initialDelaySeconds: 3          periodSeconds: 3        volumeMounts:          - mountPath: /opt/sh/log            name: rabbitmq-log            # subPath的方案很好,但对版本号要求很高,&gt;=1.14            subPathExpr: $(POD_NAME)        resources:          limits:            memory: 4G            cpu: 1000m          requests:            memory: 500M            cpu: 250m        securityContext:            privileged: true      volumes:    #   - name: rabbitmq-data    #     hostPath:     #       path: &quot;/Users/akka/rabbitmq&quot;    #       type: DirectoryOrCreate              - name: rabbitmq-log        hostPath:          path: /opt/log/rabbitmq          type: DirectoryOrCreate\n可以达到如下的效果:\nminikube/                  rabbitmq-6df8f7565c-kh2h6/ rabbitmq-6df8f7565c-ss92l/\n\n\nlog4j2环境变量隔离方案:适用于在你的k8s版本还不够的情况下这个时候,你的文件映射关系还是 &#x2F;opt&#x2F;sh&#x2F;logs &lt;&#x3D;&#x3D;&gt; &#x2F;opt&#x2F;log&#x2F;rabbitmq\n但是真正在打印日志的时候,把日志都打印到&#x2F;opt&#x2F;sh&#x2F;logs&#x2F;${POD_NAME}下,这样子也可以在一台vm上跑多个实例\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;Configuration status=&quot;warn&quot; monitorInterval=&quot;10&quot;&gt;    &lt;Appenders&gt;        &lt;Console name=&quot;Console&quot; target=&quot;SYSTEM_OUT&quot;&gt;            &lt;PatternLayout pattern=&quot;%d&#123;yyyy-MM-dd,HH:mm:ss,SSSXXX&#125;(%r):%4p%X[%t#%T]%l--&gt;%m%n&quot;/&gt;        &lt;/Console&gt;        &lt;File name=&quot;FILE&quot; fileName=&quot;$&#123;env:HOSTNAME&#125;/file.log&quot;&gt;            &lt;PatternLayout pattern=&quot;%d&#123;yyyy-MM-dd,HH:mm:ss,SSSXXX&#125;(%r):%4p%X[%t#%T]%l--&gt;%m%n&quot;/&gt;        &lt;/File&gt;    &lt;/Appenders&gt;    &lt;Loggers&gt;        &lt;Root level=&quot;INFO&quot;&gt;            &lt;AppenderRef ref=&quot;Console&quot;/&gt;            &lt;AppenderRef ref=&quot;FILE&quot;/&gt;        &lt;/Root&gt;    &lt;/Loggers&gt;&lt;/Configuration&gt;\n\n我们解决了两个容器在一个vm上打印日志的问题,紧接着,我们要分析filebeat的能力,filebeat能否区分这两个路径,把这两个路径打上不同的标签\n运行并配置好filebeat,配置文件如下\nfilebeat.inputs:  - type: log    enabled: true    paths:      - /opt/sh/collect/log/es/*/*.log    tags: [&quot;es&quot;]filebeat.config.modules:  path: $&#123;path.config&#125;/modules.d/*.yml  reload.enabled: false  reload.period: 10ssetup.template.settings:  index.number_of_shards: 1fields:  fields_under_root: truesetup.kibana:output.elasticsearch:  hosts: [&quot;localhost:9200&quot;]processors:  - add_host_metadata: ~  - add_docker_metadata: ~  - add_kubernetes_metadata:      kube_config: /opt/sh/collect/log/configlogging.level: debug\n\n\n\n\n\n,查询收集上来的数据\ncurl 127.0.0.1:9200/filebeat-7.5.1-2020.01.23-000001/_search?pretty收集上来的数据存在hostname字段,能区分代表单个实例的信息.\n\n使用ES processor添加实例id信息curl -X PUT &quot;localhost:9200/_ingest/pipeline/attach_instance?pretty&quot; -H &#x27;Content-Type: application/json&#x27; -d&#x27;&#123;  &quot;processors&quot;: [    &#123;      &quot;grok&quot;: &#123;        &quot;field&quot;: &quot;log.file.path&quot;,        &quot;patterns&quot;: [&quot;/opt/sh/collect/log/es/%&#123;WORD:instanceId&#125;/es.log&quot;]      &#125;    &#125;  ]&#125;&#x27;\n\n然后修改filebeat配置文件\nfilebeat.inputs:  - type: log    enabled: true    paths:      - /opt/sh/collect/log/es/*/*.log    tags: [&quot;es&quot;]filebeat.config.modules:  path: $&#123;path.config&#125;/modules.d/*.yml  reload.enabled: false  reload.period: 10ssetup.template.settings:  index.number_of_shards: 1fields:  fields_under_root: truesetup.kibana:output.elasticsearch:  hosts: [&quot;localhost:9200&quot;]  pipeline: attach_instanceprocessors:  - add_host_metadata: ~  - add_docker_metadata: ~  - add_kubernetes_metadata:      kube_config: /opt/sh/collect/log/configlogging.level: debug\n查询结果就会出现在instanceId字段\n总结三种方案均可以方便地实现同一vm上部署两个容器. 方案一只需要修改tosca模板,但要1.14版本才支持.方案二需要修改少量代码. \n但前两种均不适合配置了hostnetwork,即独占主机的网络,原因,主机网络独占之后,两个容器的hostname都相同,实际中,已经独占网络的容器,还需要部署在一个节点的需求,应该比较少.\n如果有,可以使用在es处处理文件路径,加上instanceId字段\n","tags":["Kubernetes"]},{"title":"微服务广播模式实践","url":"/2023/06/01/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%B9%BF%E6%92%AD%E6%A8%A1%E5%BC%8F%E5%AE%9E%E8%B7%B5/","content":"微服务广播模式，指的是在微服务多实例部署的场景下，将消息广播到多个微服务实例的一种模式。\n\n广播模式，一般用来维护微服务的内存数据，根据数据类型的不同，有助于解决两类问题。通常广播模式会使用支持发布订阅的消息中间件实现（如Redis、Kafka、Pulsar等），本文也基于消息中间件进行讨论。\n利用广播模式维护一致的缓存这应该是广播模式利用最多的一种场景，假想一个拥有海量用户的电商网站、或是一个亿级设备连接的IoT平台。势必会存在一些缓存数据，像是用户的购物车信息，或是设备的密钥缓存。如果没有广播模式，可能会存在这样的问题\n\n当用户更新了它的购物车之后，微服务实例1的数据发生了更新，数据库的数据也成功更新。但是微服务实例2中的缓存数据未能更新，那么如果用户的请求均衡到了实例2，就会发生意想不到的后果。\n这种情况下我们可以让微服务1在广播通道中发送一个缓存的invalidate消息，将微服务实例2中该用户的缓存清零，使得微服务实例2在下一次处理该用户的请求时，从数据库中读取最新的消息。\n使用该模式需要注意的点：\n\n每个微服务实例应该使用不同的消费组，可以通过微服务的IP、主机名、UUID等拼装成订阅组名称，这才称得上广播之名\n微服务消费消息的时候，应从Latest开始消费，避免从Earliest开始消费无用的缓存清理消息\n由于每一次微服务重启都会产生一个新的消费组，需要注意消费组的老化，可以通过消息中间件自带的不活跃消费组老化能力兜底，建议通过gracefulExit、监听kill信号等机制来主动删除消费组信息\n\n为什么说消费组老化比较重要呢，因为很多监控系统都会根据消费组的积压来做告警，很容易产生误告警。\n利用广播模式维护内存中的数据这种模式相对比较少见，常见于key的基数不是很大，能够将数据完整地存储在内存中，比如电商平台的企业卖家个数、物联网平台的用户个数等，并且对数据的一致性要求不是很高（因为广播模式情况下，对于两个微服务实例来说没有一致性保障）。像Apache Pulsar设计的TableView，在我看来，就是做这个事的一个最佳实践。Pulsar内部大量使用了topic存储数据，就是采用这个方式。\n使用该模式需要注意的点：\n\n同上，需要使用不同的消费组名称\n微服务消费消息的时候，应该从Earliest开始消费，保证所有微服务内存中的消息视图一致\n同上，需要注意消费组的老化\n\n为什么需要消费组老化作为保底手段因为在极端场景下，无论是graceful的代码，还是监听kill信号的代码，都不能保证代码百分百地被执行。需要兜底。\nKafka消费组老化Kafka通过offsets.retention.minutes参数控制消费组中offsets保留时间，在此时间内如果没有提交offset，offsets将会被删除。Kafka判定消息组中没有在线的消费者（如empty状态），且没有offsets时，将会删除此消费组。\nPulsar消费组老化pulsar的消费组老化策略更加灵活，可以配置到namespace级别。\nbin/pulsar-admin namespaces | grep expiration    get-subscription-expiration-time      Get subscription expiration time for       Usage: get-subscription-expiration-time [options] tenant/namespace    set-subscription-expiration-time      Set subscription expiration time for       Usage: set-subscription-expiration-time [options] tenant/namespace            Subscription expiration time in minutes    remove-subscription-expiration-time      Remove subscription expiration       Usage: remove-subscription-expiration-time [options] tenant/namespace\n\n这里注意要合理地配置消费组的老化时间，在pulsar的当前版本（2.11版本）下，catch up读，也就是说消费组平时积压量不大。如果将消费组的老化时间配置大于等于消息的老化时间，会出现消费组老化不了的现象。\n当然，由于消费组和消息老化都是定时任务，预估时间时，要考虑一定的buffer。\n这里让我们稍稍dive一下原理，消费组的老化是通过判断Cursor游标的LastActive time来判断能否老化的。如果该消费组的游标位置到达了消息老化区域，被老化掉了，消费组的游标位置就会强制更新到一个可用的位置，这个时候会更新游标的LastActive time到当前时间，周而复始，导致消费组无法老化。举个🌰\n假设消费组的老化时间为4h，消息的老化时间为3h，就可能会发生这样的事情\n\n总结广播模式在微服务架构中起到了重要的角色，尤其是在需要在微服务实例之间同步数据的场景中，它具有显著的优势。它能够帮助维护内存数据的缓存一致性。希望本篇文章能提供您全面的广播模式的知识。\n"},{"title":"打造可商用的Java程序之可维护性","url":"/2023/06/15/%E6%89%93%E9%80%A0%E5%8F%AF%E5%95%86%E7%94%A8%E7%9A%84Java%E7%A8%8B%E5%BA%8F%E4%B9%8B%E5%8F%AF%E7%BB%B4%E6%8A%A4%E6%80%A7/","content":"在主函数中捕获未处理的异常在主函数中捕获未处理的异常，防止程序崩溃，同时记录日志，方便排查问题。\npublic class UncaughtExceptionHandle &#123;    public static void main(String[] args) &#123;        Thread.setDefaultUncaughtExceptionHandler((t, e) -&gt; log.error(&quot;Uncaught exception: &quot;, e));    &#125;&#125;\n"},{"title":"提升网络协议服务器的定位能力","url":"/2023/05/30/%E6%8F%90%E5%8D%87%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E5%AE%9A%E4%BD%8D%E8%83%BD%E5%8A%9B/","content":"近期，我再次涉足于协议服务器相关的工作领域，致力于定位并解决各种问题。简单总结一些心得给大家。如果想要定位出协议服务器的问题，那么这些能力可能至关重要。\n注：我这里比较偏向协议本身的问题，不涉及一些通用的网络问题（如网络吞吐量上不去、响应时间长等等）\n对CPU和内存的通用分析能力首先，网络协议服务器本质上也是一个应用程序。因此，需要具备一些关于CPU和内存的通用分析能力。PU&#x2F;内存火焰图，内存dump分析，锁分析，以及远程调试（研发态手段）这些手段都要具备\n日志和网络连接的关联为了有效地定位网络问题，日志需要精确到毫秒级别。没有毫秒级别的精度，定位网络问题就会变得极其困难。所以golang的logrus默认只有秒级别，我觉得不太好，用rfc3339就很好。\n在打印日志时，我们不能太过随意。例如，“connection lost”这样的日志，在调试阶段可能看似无大碍，但当真正的业务量和连接数大幅增加时，这种模糊的日志信息就会让人束手无策。\n理想的日志至少应包含网络地址信息，这样我们可以根据网络地址和时间点来查阅日志。如果有抓包的话，那就更好了，可以从中获取大量信息。\n当然，我们并不需要在所有的日志中都包含网络地址信息。例如，一旦完成了用户身份的鉴定，我们就可以打印用户的身份信息，这样更方便与后续的业务流程进行整合。如果需要查询网络地址信息，可以回溯到建立连接时的日志。举个🌰\n2023-05-30 23:59:01.000 [INFO] 127.0.0.1:62345 connected2023-05-30 23:59:02.000 [INFO] 127.0.0.1:62345 authed, username is Wolverine2023-05-30 23:59:03.000 [INFO] Wolverine killed magneto\n\n假设一条数据链上有大量的消息呢？在现代的网络环境中，一条TCP链接可以轻易达到5M bit&#x2F;s以上的数据流。即使我们提供了时间点信息，仍然很难找到具有问题的报文（在同一秒内可能有上千条报文）。在这种情况下，就需要引入会话的ID信息。许多TCP协议会携带这种信息，换句话说，支持IO复用的协议都会有这种信息（比如MQTT的messageId，Kafka的correlationId等）。此类信息应该被正确地打印在日志中。\n针对特征值的跟踪能力你可能已经在调试日志中包含了非常详尽的信息，然而在实际环境中，这可能并没有太大用处。\n原因是一旦全面开启debug日志，性能消耗会大幅增加。除非你的系统性能冗余极大，否则根本无法正常运行。\n为此，我们可以提升debug的能力，针对特定的特征值开启debug，例如网络地址、mqtt的clientId、消息中间件的topic等。应用程序仅针对这些特征值打印详细的日志，这样的开销就相对较小，而且这种方法已经在生产环境中被我多次验证。\n将网络报文与业务trace关联起来在网络协议服务器中，我们需要将网络报文与业务trace关联起来。这种关联能力的实现可以大大提高我们定位业务端到端问题的效率和准确性。 理想情况下，我们应该能够根据网络报文来查找相关的业务trace，反之亦然，根据业务trace来查找对应的网络报文。但这些手段都需要业务端的配合，比如在报文中携带traceId，或者在业务trace中携带网络地址信息。\n以mqtt协议为例，可以在payload中带上\n&#123;    &quot;traceId&quot;: &quot;xxxx&quot;,    &quot;data&quot;: &quot;xxxx&quot;&#125;\n\n在这个例子中，traceId就是我们为业务trace设定的唯一标识符，而data则是实际的业务数据。通过在网络报文中携带这些信息，我们就可以轻松地将网络报文与其对应的业务trace关联起来。\n然而，这种方法在研发和测试环境中实现相对容易，但在生产环境中可能会遇到更多的困难。首先，对于在网络报文中携带traceId这一做法，业界并未形成统一的规范和实践。这导致在生产环境，极难做到。\n更具挑战性的是，如果你面对的是一个端到端的复杂系统，将traceId从系统的入口传递到出口可能会遇到许多难以预见的问题。例如系统不支持这类数据的专递，这就封死了这条路。\n查看原始报文的能力查看原始报文的能力极其重要，特别是在协议栈的实现尚不成熟的情况下。如果无法查看原始报文，定位问题就会变得非常困难。我曾说过：“如果拿到了原始报文，还是无法复现问题，那我们的研发能力在哪里？”虽然这句话可能有些极端，但它准确地强调了抓包的重要性。\n我们可以从抓包看出网络的连通性、网络的延迟、网络的吞吐量、报文的格式、报文的正确性等等。如果途径了多个网元，那么是谁的错？（一般来说，看抓包，谁先发RST，就从谁身上找原因）\n虽然抓包的命令比较简单tcpdump port 8080 -i eth0 -s0 -w my.pcap就抓了，但实际想做成，最大的阻力是这两个，TLS和复杂的现网环境\n在旧版本的TLS密钥交换算法下，只要有私钥和密码，就可以顺利解包，但现在的tls，都支持前向加密，什么叫前向加密呢？简单地来说，就是给你私钥和密码，你也解不出来。有tls debuginfo和ebpf能解决这两个问题，tls debug-info的原理是将密钥交换时的密钥输出持久化到某个地方，然后拿这个去解，实际很少见有人用这个方案。ebpf一需要linux内核高版本，同时还需要开启功能，安装kernel-debug-info，门槛也比较高。\n现网环境，像抓包嗅探的这种工具，有时候可能是禁止上传的，或者即使能上传成功，也需要很长的时间。\n也许我们可以通过“应用层抓包”来解决上述的问题，在网络层，我们支持受限的抓包能力，比如可以抓针对某个特征值（比如网络地址、messageId）的包，因为我们在应用层，可使用的过滤条件更多，更精细，输出到某个路径，这个报文的组装，完全在应用网络层，虽然看不到物理层的一些信息，但对于应用程序来说，除非我是做nat设备的，一般用不到这些信息。继续用这个报文来分析问题。实现应用层抓包，也要注意对内存的占用等等，不能因为这个功能，把整个进程搞崩溃。\n应用层抓包的一些思考抓包地点的选择在应用层抓包，第一步就是确定抓包的地点。由于我们是在应用层进行操作，因此抓包地点一般位于应用程序与网络协议栈的交接处。例如，你可以在数据包刚被应用接收，还未被处理之前进行抓包，或者在数据包即将被应用发送出去，还未进入网络协议栈之前进行抓包。\n过滤条件的设定设定过滤条件是抓包的关键，因为在实际环境中，数据流量可能非常大，如果没有过滤条件，抓包的数据量可能会非常庞大，对应用和系统的性能产生影响。在应用层，我们可以设置更多更精细的过滤条件，如网络地址、端口、协议类型、特定的字段等。这些过滤条件可以帮助我们更精确地定位问题，减少无效的数据。\n数据存储问题将抓到的数据存储起来也是很重要的一步。可以选择将数据存储到内存或者硬盘。需要注意的是，如果选择存储到内存，要考虑到内存的大小，避免因为抓包数据过大导致内存溢出。如果选择存储到硬盘，要考虑到硬盘的读写速度和容量，避免因为抓包数据过大导致硬盘满载。\n总结本文首先阐述了网络协议服务器的一些问题定位能力，包括CPU内存分析能力、日志和网络连接的关联能力、针对特征值的跟踪能力，以及查看原始报文的能力，也讨论了将网络报文与业务trace有效关联的重要性和实现挑战。强调了抓包的重要性和对于解密TLS报文的挑战。为了解决网络层抓包遇到的困难，我们可以考虑应用层抓包方案。最后，我们讨论了应用层抓包的一些关键问题，包括抓包地点的选择、过滤条件的设定和数据存储问题。\n"},{"title":"揭秘MySQL TLS：通过抓包了解真实的加密通信","url":"/2023/02/09/%E6%8F%AD%E7%A7%98MySQL%20TLS%EF%BC%9A%E9%80%9A%E8%BF%87%E6%8A%93%E5%8C%85%E4%BA%86%E8%A7%A3%E7%9C%9F%E5%AE%9E%E7%9A%84%E5%8A%A0%E5%AF%86%E9%80%9A%E4%BF%A1/","content":"你的mysql客户端和服务端之间开启tls了吗？你的回答可能是No，我没有申请证书，也没有开启mysql客户端，服务端的tls配置。\n可是当你抓取了3306 mysql的端口之后，你会发现，抓出来的包里居然有Client Hello、Server Hello这样的典型TLS报文。\n\n其实，Mysql的通信是否加密，是由客户端和服务端共同协商是否开启的，客户端与服务端都处于默认配置下的话，有些类似于StartTls。\n服务端侧在连接建立时，Mysql服务端会返回一个Server Greeting，其中包含了一些关于服务端的信息，比如协议版本、Mysql版本等等。在其中有一个flag的集合字段，名为Capabilities Flag，顾名思义，这就是用来做兼容性，或者说特性开关的flag，大小为2个字节，其中的第12位，代表着CLIENT_SSL，如果设置为1，那代表着如果客户端具备能力，服务端可以在后面的会话中切换到TLS。可以看到里面还有一些其他的flag，事务、长密码等等相关的兼容性开关。\n\n我们可以测试一下设置为0的行为，只需要在my.cnf中添加\necho &quot;ssl=0&quot; &gt;&gt; /etc/my.cnf\n\n重启mysql。再度进行抓包，就发现没有tls的报文了，都是在使用明文进行通信了。\n\n客户端侧这个协商过程也可以在客户端进行控制，客户端对应的参数是sslMode，可以设置为DISABLED、PREFERRED、REQUIRED、VERIFY_CA、VERIFY_IDENTITY，分别代表不使用ssl、优先使用ssl、必须使用ssl、验证CA、验证身份。默认的行为是PREFERRED，example:\n比如配置sslMode为DISABLED，那么客户端就不会使用ssl进行通信，而是使用明文。\nr2dbc:mysql://localhost:3306/test?sslMode=DISABLED\n\n\n总结\n\n\n客户端\n服务端\n结果\n\n\n\nDISABLED\nssl&#x3D;0\nPLAIN\n\n\nDISABLED\nssl&#x3D;1\nPLAIN\n\n\nPREFERRED\nssl&#x3D;0\nPLAIN\n\n\nPREFERRED\nssl&#x3D;1\nTLS\n\n\nREQUIRED\nssl&#x3D;0\nFail\n\n\nREQUIRED\nssl&#x3D;1\nTLS\n\n\nVERIFY_CA\nssl&#x3D;0\nFail\n\n\nVERIFY_CA\nssl&#x3D;1 + CA配置\nTLS，客户端验证证书\n\n\nVERIFY_IDENTITY\nssl&#x3D;0\nFail\n\n\nVERIFY_IDENTITY\nssl&#x3D;1 + CA配置\nTLS，客户端验证证书和域名\n\n\n注：\n\nVERIFY_CA：确保服务器证书由受信任的CA签发，但不验证证书的主机名或IP地址。\nVERIFY_IDENTITY：不仅验证证书的CA签发，还额外验证证书的主机名或IP地址与服务器的实际地址是否一致。\n\n","tags":["MySQL"]},{"title":"敏感信息打印大全","url":"/2023/07/14/%E6%95%8F%E6%84%9F%E4%BF%A1%E6%81%AF%E6%89%93%E5%8D%B0%E5%A4%A7%E5%85%A8/","content":"JavaApache http clientWire logApache http client会打印请求和响应的wire log，包含请求和响应的header和body，打印在debug级别。\nApache http client的日志都通过org.apache.http.wire这个logger打印，可以通过配置这个logger来控制wire log的打印。\n注：Apache http client默认通过apache common logging来打印日志，可以通过配置\n&lt;dependency&gt;    &lt;groupId&gt;org.slf4j&lt;/groupId&gt;    &lt;artifactId&gt;jcl-over-slf4j&lt;/artifactId&gt;    &lt;version&gt;1.7.32&lt;/version&gt;&lt;/dependency&gt;\n来使用slf4j来打印日志。\n"},{"title":"文件编解码代码设计","url":"/2023/11/20/%E6%96%87%E4%BB%B6%E7%BC%96%E8%A7%A3%E7%A0%81%E4%BB%A3%E7%A0%81%E8%AE%BE%E8%AE%A1/","content":"概述我们以xyz文件格式为例，来说明文件编解码的代码设计。xyz文件格式内容如下：\n\nheader部分：文件头，包含文件版本号、文件类型、文件大小等信息\nbody部分：文件主体\n\n通用设计大概如下\nclassDiagram\n    class XyzHeader {\n        + byte[] content\n    }\n    class XyzBody {\n        + byte[] content\n    }\n    class Xyz{\n        + XyzHeader header\n        + XyzBody body\n    }\n    class XyzReader {\n        + Xyz read(fileName: string)\n        + void process(String fileName, XyzProcessor processor)\n        - XyzHeader readHeader()\n        - XyzBody readBody()\n    }\n    class XyzProcessor {\n        \n        + void processHeader(XyzHeader header)\n        + void processBody(XyzBody body)\n    }\n    class XyzReadCollectProcessor {\n        Xyz getXyz()\n    }\n    Xyz --> XyzHeader: contains\n    Xyz --> XyzBody: contains\n    XyzReader --> Xyz: reads\n    XyzReader --> XyzProcessor: processes\n    XyzReadCollectProcessor --|> XyzProcessor: implements\n\nJava使用java.io.RandomAccessFile和java.nio.channels.FileChannel来实现文件读取，使用io.netty.buffer.ByteBuf来读写文件。\n核心代码举例:\nXyzReader:\npublic class XyzHeader &#123;    private byte[] content;&#125;public class XyzBody &#123;    private byte[] content;&#125;public class Xyz &#123;    private XyzHeader header;    private XyzBody body;&#125;public interface XyzProcessor &#123;    void processHeader(XyzHeader header);    void processBody(XyzBody body);&#125;public class XyzReadCollectProcessor implements XyzProcessor &#123;    private final Xyz xyz = new Xyz();    public Xyz getXyz() &#123;        return xyz;    &#125;&#125;public class XyzReader &#123;    public Xyz read(String fileName) throws Exception &#123;    &#125;    private XyzHeader readHeader(FileChannel fileChannel) throws Exception &#123;    &#125;    private XyzBody readBody(FileChannel fileChannel) throws Exception &#123;    &#125;&#125;\n\n\n import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs';\tmermaid.initialize({startOnLoad: true, flowchart: {curve: 'linear'}}); ","tags":["Codec"]},{"title":"比调用Shell更高效的判断进程是否存在的方式","url":"/2021/08/12/%E6%AF%94%E8%B0%83%E7%94%A8Shell%E6%9B%B4%E9%AB%98%E6%95%88%E7%9A%84%E5%88%A4%E6%96%AD%E8%BF%9B%E7%A8%8B%E6%98%AF%E5%90%A6%E5%AD%98%E5%9C%A8%E7%9A%84%E6%96%B9%E5%BC%8F/","content":"有很多场景需要我们的代码检测一个进程是否存在，常用的一种方式是通过调用脚本通过ps -ef的方式查看，然而其实这种做法并不怎么高效，会fork一个进程出来，还会影响go协程的调度\n一种更好的方式是可以通过解析/proc文件夹来得到想要的信息，其实可以通过strace命令查看，ps -ef也是读取了这个路径下的信息\n\n下面分别是java和go的轮子示例\n使用正则表达式[0-9]+的原因是/proc路径下还有一些其他文件，其中pid都是数字。\njavaprivate static final Pattern numberPattern = Pattern.compile(&quot;[0-9]+&quot;);    public static boolean processExists(String processName) throws Exception &#123;        final File procFile = new File(&quot;/proc&quot;);        if (!procFile.isDirectory()) &#123;            throw new Exception(&quot;why proc dir is not directory&quot;);        &#125;        final File[] listFiles = procFile.listFiles();        if (listFiles == null) &#123;            return false;        &#125;        final List&lt;File&gt; procDir = Arrays.stream(listFiles).filter(f -&gt; numberPattern.matcher(f.getName()).matches()).collect(Collectors.toList());        // find the proc cmdline        for (File file : procDir) &#123;            try &#123;                final byte[] byteArray = FileUtils.readFileToByteArray(new File(file.getCanonicalPath() + File.separator + &quot;cmdline&quot;));                final byte[] bytes = new byte[byteArray.length];                for (int i = 0; i &lt; byteArray.length; i++) &#123;                    if (byteArray[i] != 0x00) &#123;                        bytes[i] = byteArray[i];                    &#125; else &#123;                        bytes[i] = (byte) 0x20;                    &#125;                &#125;                final String cmdLine = new String(bytes, StandardCharsets.UTF_8);                if (cmdLine.contains(processName)) &#123;                    return true;                &#125;            &#125; catch (IOException e) &#123;                // the proc may end during the loop, ignore it                log.error(&quot;read file exception &quot;, e);            &#125;        &#125;        return false;    &#125;\n\ngofunc ProcessExists(processName string) (bool, error) &#123;\tresult := false\tfileInfos, err := ioutil.ReadDir(&quot;/proc&quot;)\tif err != nil &#123;\t\treturn false, err\t&#125;\tfor _, info := range fileInfos &#123;\t\tname := info.Name()\t\tmatched, err := regexp.MatchString(&quot;[0-9]+&quot;, name)\t\tif err != nil &#123;\t\t\treturn false, err\t\t&#125;\t\tif !matched &#123;\t\t\tcontinue\t\t&#125;\t\tcmdLine, err := parseCmdLine(&quot;/proc/&quot; + info.Name() + &quot;/cmdline&quot;)\t\tif err != nil &#123;\t\t\tglog.Error(&quot;read cmd line failed &quot;, err)\t\t\t// the proc may end during the loop, ignore it\t\t\tcontinue\t\t&#125;\t\tif strings.Contains(cmdLine, processName) &#123;\t\t\tresult = true\t\t&#125;\t&#125;\treturn result, err&#125;func parseCmdLine(path string) (string, error) &#123;\tcmdData, err := ioutil.ReadFile(path)\tif err != nil &#123;\t\treturn &quot;&quot;, err\t&#125;\tif len(cmdData) &lt; 1 &#123;\t\treturn &quot;&quot;, nil\t&#125;\tsplit := strings.Split(string(bytes.TrimRight(cmdData, string(&quot;\\x00&quot;))), string(byte(0)))\treturn strings.Join(split, &quot; &quot;), nil&#125;\n","tags":["Linux"]},{"title":"物联网平台规则引擎流转到S3对比","url":"/2021/06/14/%E7%89%A9%E8%81%94%E7%BD%91%E5%B9%B3%E5%8F%B0%E8%A7%84%E5%88%99%E5%BC%95%E6%93%8E%E6%B5%81%E8%BD%AC%E5%88%B0S3%E5%AF%B9%E6%AF%94/","content":"对于物联网平台来说，规则引擎是其中一个很重要的功能，也叫消息流转功能，将消息流转到各类中间件、云产品中。在华为、AWS、Azure、阿里这四个物联网平台中，阿里不支持流转到S3&#x2F;类S3存储中。本文对比一下华为云、AWS、Azure把设备消息流转到S3&#x2F;类S3存储的功能\n参考资料\nhttps://docs.amazonaws.cn/general/latest/gr/iot-core.html#limits_iot\n\n华为云规则粒度和限制\n规则配置粒度到OBS桶\n\n限制单用户配置100条规则，每个规则10个Action\n\n\n功能实现针对华为云，我测试了设备的消息上报转发到华为云OBS的功能。\n流转规则需要指定obs桶，随后运行之后，华为云OBS体现为\n\n设备的每条消息都会在obs中存储为一个文件\n名称采用deviceId+毫秒级时间戳+后面4位数字\n\n关键路径截图配置规则时指定到obs桶\n单条消息单个文件\n优势可以非常轻易地查询出单个设备的消息，因为文件名携带有毫秒级时间戳，还可以指定具体\n劣势用来做MapReduce的话，文件数目太多，由于S3云厂商往往通过API调用次数收费，不仅是速度，成本也会很高。\nAWS规则粒度和限制\n规则配置粒度到桶及Key，相当于华为云OBS桶+文件名\n限制规则每秒进行20k次运算\n限制最多拥有1000条规则\n限制每个规则最多10个action\n\n功能实现再次上报数据触发规则会把obs中的数据替换。（通过版本控制可以获取到老的数据）\n关键路径截图配置规则指定粒度到Key \n仅有一个Key，新值覆盖旧值\n优劣势AWS的这个模式很适合存储每个设备的最新数据。不过由于规则数量上的限制，最多只能在S3上存储1000个键值对。可用性较低。可用于数量小于1000的设备，存储、查询最新数据。\nAzure转发规则粒度限制\n规则配置粒度到存储容器\nAzure可配置存储入存储容器的批量频率和大小限制\n编码支持Avro和Json两种格式\n最多100条路由\n\n功能实现自上报事件，到存储中出现数据，azure是最慢的，azure做了批量的缓冲，达到batch的大小和时间要求后才会写入存储。\n关键路径截图配置路由规则\n存储中批量数据因为选择了avro格式，所以vim打开是乱码，不过明显可以看到是多条数据\n\n优势Azure的这种方式，比较适合做MapReduce类操作，相对华为云来说，Azure的文件数量大大减少，如果用于做MapReduce这类操作，因为文件碎片小，作业速度会比华为云快，而且由于云厂商对存储，通常以api调用次数收费，价格也会比华为云低。\n劣势不易针对单个设备进行查询。\n"},{"title":"现代编程语言中的异常处理","url":"/2024/12/26/%E7%8E%B0%E4%BB%A3%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/","content":"在软件开发中，健壮的异常处理是编写高质量代码的关键。本文将探讨现代编程语言中的通用异常处理方法，帮助你优雅地处理异常并写出健壮的代码。我们将不拘泥于某种语言，而是讨论一些普遍适用的策略。\n异常链概述现代编程语言通常将异常视为一条单向链表，链表中的节点包含根本原因和相关的上下文信息。例如：\ngraph TD\n    C --> D[MicroServiceError, call user service failed]\n    B --> C[DatabaseError, select * from user failed]\n    A --> B[HttpError, http://localhost:6379 failed]\n    A[SocketError, localhost, 6379 connect failed]\n\n异常就这么向外传播也不错，但是抽象是会泄露的，正常的时候顺风顺水，异常就需要判断一下，比如一个很常见的需求，文件已存在异常，就当做成功处理，用Java来写就是这样\nif (exception instanceof FileAlreadyExistsException) &#123;    log.info(&quot;file already exists&quot;);    return SUCCESS;&#125;throw exception;// or wrap it\n\n综上来看，我们对现代编程语言的需求就是，能组织异常链，判断异常是否是某类异常，把异常用字符串的形式打印出来。\n当我们在构筑一个library的时候，应该尽可能保持完整的异常链，除非你认为这个异常在library内可以处理，比如上面的情况。并且应该在项目的README，或者项目的某个文件中，详细地列出本library可能抛出的异常，以及异常的含义。\n我们在opengemini-client-go中就有这样的例子，我们在errors.go中定义了所有可能的异常，以及异常的含义。\n有些时候，我们构筑的不是library，出于隐藏内部实现或者是向终端用户隐藏逻辑上的低级错误，我们会对异常进行处理，比如常见的\nif (exception instanceof DuplicateKeyException) &#123;    log.info(&quot;duplicate key&quot;);    return new ServiceException(&quot;already exists&quot;);&#125;// many if elsethrow new ServiceException(&quot;unknown error&quot;); // or just internal error\n\n题外话，由于Java只能判断本级的异常类型，你会经常看到getCause的代码，比如Apache Pulsar项目中的\nif (exception.getCause() != null                    &amp;&amp; exception.getCause() instanceof PulsarClientException.InvalidServiceURL) &#123;    throw new MalformedURLException(exception.getMessage());&#125;\n包括层次一多，甚至可以看到递归代码\nprivate static Throwable mapToBkException(Throwable ex) &#123;        if (ex instanceof CompletionException || ex instanceof ExecutionException) &#123;            return mapToBkException(ex.getCause());        &#125;        if (ex instanceof MetadataStoreException.NotFoundException) &#123;            BKException bke = BKException.create(BKException.Code.NoSuchLedgerExistsOnMetadataServerException);            bke.initCause(ex);            return bke;        &#125; else if (ex instanceof MetadataStoreException.AlreadyExistsException) &#123;            BKException bke = BKException.create(BKException.Code.LedgerExistException);            bke.initCause(ex);            return bke;        &#125; else if (ex instanceof MetadataStoreException.BadVersionException) &#123;            BKException bke = BKException.create(BKException.Code.MetadataVersionException);            bke.initCause(ex);            return bke;        &#125; else if (ex instanceof MetadataStoreException.AlreadyClosedException) &#123;            BKException bke = BKException.create(BKException.Code.LedgerClosedException);            bke.initCause(ex);            return bke;        &#125;        return ex;    &#125;\n\nGo在这里易用性做的不错，支持了errors.Is和errors.As，可以判断异常链中是否包含某个异常，也可以直接获取异常链中的异常。不过如果异常链里面有两个一模一样类型的异常，你想精准取到其中一个就比较困难，不过这在实际场景中非常少见。\n这里，我们说异常链发生了变更，那么什么时候打印日志也比较明确了，当异常链发生变更的时候打印，保证完整的堆栈信息用于问题分析。这也可以保证在一条链的过程中，有且仅有一次打印日志。\n在异常链发生终止，比如转化为http content，或者是print到console的时候，要不要打印日志呢？这个问题有些见人见智，这取决于你的用户在report问题的时候，会不会携带http content或者是console output，如果不会，那么你就需要打印日志，如果会，那么你就不需要打印日志。\nJava里面，比起将底层的error抛出，我们更倾向于定义一个符合本library抽象层级的异常，并在方法的签名中只返回这个异常，一方面使得下层library的异常如果发生变化，本library依然是编译兼容的，另一方面也更符合抽象层级。\n但是在Go里面，事情就更复杂一些，我愿意称之为类型的细化具备传染性，一旦你将某个方法的签名不返回interface，而是返回一个具体的类型，比如\nfunc (c *Client) CallService() (Result, *ServiceError) &#123;    if failed &#123;        return nil, &amp;ServiceError&#123;Code: 500, Message: &quot;service error&quot;&#125;    &#125;    return result, nil&#125;\n\n然后有一个方法调用了它\nfunc main() &#123;    err := MakeFriend()    if err != nil &#123;        panic(err)    &#125;&#125;func (c *Client) MakeFriend() (Result, error) &#123;    err := io.Read(&quot;friend_list.txt&quot;)    if err != nil &#123;        return nil, err    &#125;    return CallService()    \n\n这下就麻烦了，当*ServiceError转化为error, nil的ServiceError指针转化为error的时候就不是nil了，这很致命，是的，这非常致命。即使CallService()成功了，main函数还是会panic。\n把这个叫做传染性还是比较准确的，异步的代码、鸿蒙的ets都具备一样的性质，他们会不断向上传播，我对这个词还是比较满意。\n综上，Go里面，我们可以构筑具体的异常，但是在不能确保上层一直都是用这个细化类型的情况下，接口还是返回error interface。\n漫谈了许多，我简单做一个总结\n\n现代编程语言的异常是一条链\n现代编程语言应该具备构筑异常链，判断异常是否是某类异常，异常打印的能力\n设计符合抽象层级的异常\n构筑一个library的时候，尽可能保持完整的异常链，在项目的README，或者项目的某个文件中，详细地列出本library可能抛出的异常，以及异常的含义\n在异常链发生变更的时候进行日志打印\n\n import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs';\tmermaid.initialize({startOnLoad: true, flowchart: {curve: 'linear'}}); ","tags":["Code"]},{"title":"线程锁导致的kafka客户端超时问题","url":"/2023/07/08/%E7%BA%BF%E7%A8%8B%E9%94%81%E5%AF%BC%E8%87%B4%E7%9A%84kafka%E5%AE%A2%E6%88%B7%E7%AB%AF%E8%B6%85%E6%97%B6%E9%97%AE%E9%A2%98/","content":"问题背景有一个环境的kafka client发送数据有部分超时，拓扑图也非常简单\n\n定位历程我们先对客户端的环境及JVM情况进行了排查，从JVM所在的虚拟机到kafka server的网络正常，垃圾回收（GC）时间也在预期范围内，没有出现异常。\n紧接着，我们把目光转向了kafka 服务器，进行了一些基础的检查，同时也查看了kafka处理请求的超时日志，其中我们关心的metadata和produce请求都没有超时。\n问题就此陷入了僵局，虽然也搜到了一些kafka server会对连上来的client反解导致超时的问题（ https://github.com/apache/kafka/pull/10059），但通过一些简单的分析，我们确定这并非是问题所在。\n同时，我们在环境上也发现一些异常情况，当时觉得不是核心问题&#x2F;解释不通，没有深入去看\n\n问题JVM线程数较高，已经超过10000，这个线程数量虽然确实较高，但并不会对1个4U的容器产生什么实质性的影响。\n负责指标上报的线程CPU较高，大约占用了1&#x2F;4 ~ 1&#x2F;2 的CPU核，这个对于4U的容器来看问题也不大\n\n当排查陷入僵局，我们开始考虑其他可能的调查手段。我们尝试抓包来找线索，这里的抓包是SASL鉴权+SSL加密的，非常难读，只能靠长度和响应时间勉强来推断报文的内容。\n在这个过程中，我们发现了一个非常重要的线索，客户端竟然发起了超时断链，并且超时的那条消息，实际服务端是有响应回复的。\n随后我们将kafka client的trace级别日志打开，这里不禁感叹kafka client日志打的相对较少，发现的确有log.debug(“Disconnecting from node {} due to request timeout.”, nodeId);的日志打印。\n与网络相关的流程：\ntry &#123;    // 这里发出了请求    client.send(request, time.milliseconds());    while (client.active()) &#123;        List&lt;ClientResponse&gt; responses = client.poll(Long.MAX_VALUE, time.milliseconds());        for (ClientResponse response : responses) &#123;            if (response.requestHeader().correlationId() == request.correlationId()) &#123;                if (response.wasDisconnected()) &#123;                    throw new IOException(&quot;Connection to &quot; + response.destination() + &quot; was disconnected before the response was read&quot;);                &#125;                if (response.versionMismatch() != null) &#123;                    throw response.versionMismatch();                &#125;                return response;            &#125;        &#125;    &#125;    throw new IOException(&quot;Client was shutdown before response was read&quot;);&#125; catch (DisconnectException e) &#123;    if (client.active())        throw e;    else        throw new IOException(&quot;Client was shutdown before response was read&quot;);&#125;\n\n这个poll方法，不是简单的poll方法，而在poll方法中会进行超时判断，查看poll方法中调用的handleTimedOutRequests方法\n@Overridepublic List&lt;ClientResponse&gt; poll(long timeout, long now) &#123;    ensureActive();    if (!abortedSends.isEmpty()) &#123;        // If there are aborted sends because of unsupported version exceptions or disconnects,        // handle them immediately without waiting for Selector#poll.        List&lt;ClientResponse&gt; responses = new ArrayList&lt;&gt;();        handleAbortedSends(responses);        completeResponses(responses);        return responses;    &#125;    long metadataTimeout = metadataUpdater.maybeUpdate(now);    try &#123;        this.selector.poll(Utils.min(timeout, metadataTimeout, defaultRequestTimeoutMs));    &#125; catch (IOException e) &#123;        log.error(&quot;Unexpected error during I/O&quot;, e);    &#125;    // process completed actions    long updatedNow = this.time.milliseconds();    List&lt;ClientResponse&gt; responses = new ArrayList&lt;&gt;();    handleCompletedSends(responses, updatedNow);    handleCompletedReceives(responses, updatedNow);    handleDisconnections(responses, updatedNow);    handleConnections();    handleInitiateApiVersionRequests(updatedNow);    // 关键的超时判断    handleTimedOutRequests(responses, updatedNow);    completeResponses(responses);    return responses;&#125;\n\n由此我们推断，问题可能在于客户端hang住了一段时间，从而导致超时断链。我们通过工具Arthas深入跟踪了Kafka的相关代码，甚至发现一些简单的操作（如A.field）也需要数秒的时间。这进一步确认了我们的猜想：问题可能出在JVM。JVM可能在某个时刻出现问题，导致系统hang住，但这并非由GC引起。\n\n为了解决这个问题，我们又检查了监控线程CPU较高的问题。我们发现线程的执行热点是从”sun.management.ThreadImpl”中的”getThreadInfo”方法。\n&quot;metrics-1@746&quot; prio=5 tid=0xf nid=NA runnable  java.lang.Thread.State: RUNNABLE    at sun.management.ThreadImpl.getThreadInfo(Native Method)\t  at sun.management.ThreadImpl.getThreadInfo(ThreadImpl.java:185)\t  at sun.management.ThreadImpl.getThreadInfo(ThreadImpl.java:149)\n\n进一步发现，在某些版本的JDK8中，读取线程信息是需要加锁的。\n至此，问题的根源已经清晰明了：过高的线程数以及线程监控时JVM全局锁的存在导致了这个问题。您可以使用如下的demo来复现这个问题\nimport java.lang.management.ManagementFactory;import java.lang.management.ThreadInfo;import java.lang.management.ThreadMXBean;import java.util.concurrent.Executors;import java.util.concurrent.ScheduledExecutorService;import java.util.concurrent.TimeUnit;public class ThreadLockSimple &#123;    public static void main(String[] args) &#123;        for (int i = 0; i &lt; 15_000; i++) &#123;            new Thread(new Runnable() &#123;                @Override                public void run() &#123;                    try &#123;                        Thread.sleep(200_000);                    &#125; catch (InterruptedException e) &#123;                        throw new RuntimeException(e);                    &#125;                &#125;            &#125;).start();        &#125;        ScheduledExecutorService executorService = Executors.newSingleThreadScheduledExecutor();        executorService.scheduleAtFixedRate(new Runnable() &#123;            @Override            public void run() &#123;                System.out.println(&quot;take &quot; + &quot; &quot; + System.currentTimeMillis());            &#125;        &#125;, 1, 1, TimeUnit.SECONDS);        ThreadMXBean threadMXBean = ManagementFactory.getThreadMXBean();        ScheduledExecutorService metricsService = Executors.newSingleThreadScheduledExecutor();        metricsService.scheduleAtFixedRate(new Runnable() &#123;            @Override            public void run() &#123;                long start = System.currentTimeMillis();                ThreadInfo[] threadInfoList = threadMXBean.getThreadInfo(threadMXBean.getAllThreadIds());                System.out.println(&quot;threads count &quot; + threadInfoList.length + &quot; cost :&quot; + (System.currentTimeMillis() - start));            &#125;        &#125;, 1, 1, TimeUnit.SECONDS);    &#125;&#125;\n\n为了解决这个问题，我们有以下几个可能的方案：\n\n将不合理的线程数往下降，可能存在线程泄露的场景\n升级jdk到jdk11或者jdk17（推荐）\n将Thread相关的监控临时关闭\n\n这个问题的解决方案应根据实际情况进行选择，希望对你有所帮助。\n","tags":["Kafka"]},{"title":"网络通信超时之后该不该重启客户端","url":"/2023/07/08/%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1%E8%B6%85%E6%97%B6%E4%B9%8B%E5%90%8E%E8%AF%A5%E4%B8%8D%E8%AF%A5%E9%87%8D%E5%90%AF%E5%AE%A2%E6%88%B7%E7%AB%AF/","content":"我写这篇文章来论证“超时之后要不要重启客户端”、“如何重启客户端”。简而言之，重启客户端还是为了让系统能够达到自愈，是比较高的可靠性要求。如果你的软件没有这么高的可靠性要求，像是人机交互程序等对可靠性要求较低的场景，可以选择不考虑这个功能。毕竟实现这个功能的时间至少够300倍你重新点击按钮&#x2F;重启的时间了。\n如果是一些串口协议，通过传输的间隙来判断报文的间隔，比如modbus协议，3.5个时间内不发送，就计算做一个协议报文的开始，那么故障时的报文毫无疑问会处理失败（因为存在CRC校验，奇偶校验等）。等待故障结束，又3.5个时间后，就会恢复正常。\n如果能确保网络通信报文不会遭到篡改、也没有宇宙射线&#x2F;太阳黑子修改你的比特位的场景下，笔者认为没有特别大的必要对客户端进行重启操作，因为不见得重启后就比之前更好，这种超时通常是由服务端处理时间长导致的。没做到建链限制的情况下，贸然重启，还可能会引起建链的波峰。\n但是，在实际复杂的网络环境下，如网络报文遭到篡改、部分字节丢失等的情况下，一切就大不一样了，不重启客户端就无法自愈。这其中的关键在于，切分报文是否正确。\n比如基于TCP的网络协议，这也是本文重点讨论的场景，假设应用协议采用最常见的LengthBasedFrame分包方式，这种协议，通常根据前0~4个字节来判断协议的总长度，比如前面的字节是00000014，那这个报文长度就是1*16 + 4 = 20长度。这种时候，一旦发生了报文篡改&#x2F;丢包，会导致通信端计算报文长度出错，一直在傻等，无法自愈。\n比如上面的例子一旦发生篡改，将4篡改5，那么就会导致客户端&#x2F;服务器一直在等待不存在的第21个字节，这种情况下，如果不做超时重建，那么这条链路就会一直处于等待状态，无法自愈。\n综上所述，实际复杂的网络环境下出现通信超时，这条链路可能会无法自愈。这种情况下，笔者推荐对针对tcp链路做超时重建，业内的一些例子像是：bookkeeper client没有做，kafka client做了。至于重建的触发条件，比如一次超时就重建、多次超时之后才重建、仅当心跳报文超时才重建，这些就交给读者自己把握了。如果区别不大，笔者倾向于一次超时就重建，逻辑简单清晰。\n"},{"title":"记一次kubernetes获取internal Ip错误流程","url":"/2022/11/15/%E8%AE%B0%E4%B8%80%E6%AC%A1kubernetes%E8%8E%B7%E5%8F%96internal%20Ip%E9%94%99%E8%AF%AF%E6%B5%81%E7%A8%8B/","content":"偶尔也回首一下处理的棘手问题吧。问题的现象是，通过kubernetes get node输出的ip不是期望的ip地址。大概如下所示\nip addreth0 ip1eth0:xxx ip2\n\n最终输出的不是预期的ip1地址，而是ip2地址。\n按藤摸瓜，kubernetes把节点信息保存在/registry/minions/$node-name中的InternalIp 字段。\nInternalIp是如何确定的呢，这段代码位于pkg/kubelet/nodestatus/setters.go中\n// 1) Use nodeIP if set (and not &quot;0.0.0.0&quot;/&quot;::&quot;)// 2) If the user has specified an IP to HostnameOverride, use it// 3) Lookup the IP from node name by DNS// 4) Try to get the IP from the network interface used as default gateway//// For steps 3 and 4, IPv4 addresses are preferred to IPv6 addresses// unless nodeIP is &quot;::&quot;, in which case it is reversed.\n\n我们的场景下没有手动设置nodeIp，如需设置通过kubelet命令行即可设置 –node-ip&#x3D;localhost，最终通过如下的go函数获取ip地址\naddrs, _ = net.LookupIP(node.Name)\n\n对这行go函数进行strace追溯，最终调用了c函数，getaddrinfo函数。getaddrinfo底层是发起了netlink请求，开启netlink的抓包\nmodprobe nlmonip link add nlmon0 type nlmonip link set dev nlmon0 uptcpdump -i nlmon0 -w netlinik.pcap# 使用nlmon 驱动模块，这个nlmon 驱动模块会注册一个 netlink tap 口，用户态向内核发送 netlink 消息、内核向用户态发送 netlink 消息，报文都会经过这个 tap 口。\n\n通过抓包我看到通过netlink报文请求返回的ip地址顺序都是合乎预期的，只能是getaddrinfo函数修改了返回的顺序\nGoogle了一下发现是getaddrinfo支持了rfc3484导致了ip的重新排序，代码地址glibc/sysdeps/posix/getaddrinfo.c\nRFC3484 总共有十个规则，比较关键的有\nRule9Rule 9:  Use longest matching prefix.When DA and DB belong to the same address family (both are IPv6 orboth are IPv4): If CommonPrefixLen(DA, Source(DA)) &gt;CommonPrefixLen(DB, Source(DB)), then prefer DA.  Similarly, ifCommonPrefixLen(DA, Source(DA)) &lt; CommonPrefixLen(DB, Source(DB)),then prefer DB.\n\n举个例子，假如机器的ip地址是 172.18.45.2/24，它会更青睐于172.18.45.6而不是172.31.80.8。这个RFC存在较大的争议，它与dns轮询策略不兼容，如：dns服务器轮询返回多个ip地址，客户端总是选择第一个ip连接。与这个策略存在很大的冲突。并且社区内也有投票试图停止对RFC3484 rule9的适配, 但是最终被拒绝了。\n根据分析，认为是ip2的地址小于ip1的地址，最终glibc排序的时候把ip2放在了前面。最终我们给kubelet配置了eth0地址的–node-ip，解决了这个问题。\n","tags":["Kubernetes"]},{"title":"记一次诡异的Java时间戳变化问题","url":"/2024/05/08/%E8%AE%B0%E4%B8%80%E6%AC%A1%E8%AF%A1%E5%BC%82%E7%9A%84Java%E6%97%B6%E9%97%B4%E6%88%B3%E5%8F%98%E5%8C%96%E9%97%AE%E9%A2%98/","content":"问题现象在一个使用Spring R2dbc与Mysql8.x的项目中，当创建 一个REST资源，进行创建，返回的毫秒精度时间戳，和下一瞬间查询的时间戳不一致。sql及代码大概如下\nCREATE TABLE person (    id INT PRIMARY KEY,    name VARCHAR(255),    created_time DATETIME(3),    updated_time DATETIME(3));\n\n实体类定义\n@Entityclass PersonEntity &#123;    @Id    private Long id;    private String name;    @CreatedDate    private LocalDateTime createdTime;    @LastModifiedDate    private LocalDateTime updatedTime;&#125;\n\n这里使用了@CreatedDate、@LastModifiedDate注解，并在Application类上配置了@EnableR2dbcAuditing注解用于在Repo操作实体的时候，自动更新时间戳。\npublic interface PersonRepo extends ReactiveCrudRepository&lt;PersonEntity, Long&gt; &#123;&#125;\n\n创建代码类比如下，大概就是使用r2dbc操作数据，并将r2dbc返回的实体用于转换毫秒时间戳\nreturn createPersonReq               .flatMap(req -&gt; &#123;                   PersonPo personPo = new PersonPo();                   personPo.setAge(18);                   personPo.setName(req.getName());                   return personRepo.save(personPo);               &#125;)               .map(person -&gt; &#123;                   PersonResp personResp = new PersonResp();                   personResp.setName(person.getName());                   personResp.setCreatedTime(TimeUtil.format(person.getCreatedTime()));                   return new ResponseEntity&lt;&gt;(personResp, null, HttpStatus.CREATED);               &#125;);\n\n然而创建的时候返回的时间戳和查询的时间戳不一致，现象举例：创建的时候返回：2024-05-08T08:11:47.333Z，查询的时候却返回：2024-05-08T08:11:47.334Z，\n走读代码，发现代码基本上万无一失，那么问题出在哪里呢？\n通过仔细观察时间戳的区别，发现时间戳的变化都在最后一位，且相差为一，醒悟到这估计是由于内存中纳秒时间戳精度在转化为数据库毫秒时间戳的时候，部分库的行为是截断，部分库的行为是四舍五入，导致了这个问题。\n最终通过写demo，docker抓包复现了这个问题，如下图所示，mysql server会将接收的时间戳进行四舍五入，而java常见的format工具类都是截断，导致了这一不一致。同时，这也体现了，r2dbc返回的entity可能并不是实际存入数据的内容，而是”原始”的entity。\n\nr2dbc与mysql的时间精度失调问题在这个问题里面，存在三个时间精度：\n\n内存中的时间精度\nr2dbc发给mysql的时间精度，有趣的是，r2dbc发给mysql的时间精度，并不是sql中列定义的精度，而是mysql server所能支持的最高精度即微秒精度。\nmysql实际存储的时间精度\n\nr2dbc返回的entity可能并不是实际存入数据的内容，而是经过r2dbc处理之后，发送到数据库之前的entity。问题的关键就在r2dbc并不根据列定义的精度处理数据，而是根据mysql server支持的最高精度处理数据。\n解决问题的方式有几种：\n\n将mysql列定义到微秒级别精度，优选方案\n在进入r2dbc之前，将时间戳截断到mysql列定义的精度\n在r2dbc返回的entity中，将时间戳截断到mysql支持的精度。这其实对开发者的心智负担较重，返回的entity并不是实际存储的，使用前要做进位，限制也比较大。\n\n在进入r2dbc之前，将时间戳截断到数据库表定义的精度，也有两种方式\n\n不使用@CreatedDate、@LastModifiedDate注解，而是在应用程序中手动设置时间戳\n继续使用@CreatedDate、@LastModifiedDate注解，通过拦截器统一进位\n\n通过拦截器的代码如下，定义基类，不然每个实体类都要书写拦截器。一般来说，一个项目里，时间戳的精度都应该统一，所以可以定义一个统一的拦截器。\nimport lombok.ToString;import org.springframework.data.annotation.CreatedDate;import org.springframework.data.annotation.LastModifiedDate;import java.time.LocalDateTime;@ToStringpublic abstract class AuditableEntity &#123;    @CreatedDate    protected LocalDateTime createdTime;    @LastModifiedDate    protected LocalDateTime updatedTime;    public LocalDateTime getCreatedTime() &#123;        return createdTime;    &#125;    public void setCreatedTime(LocalDateTime createdTime) &#123;        this.createdTime = createdTime;    &#125;    public LocalDateTime getUpdatedTime() &#123;        return updatedTime;    &#125;    public void setUpdatedTime(LocalDateTime updatedTime) &#123;        this.updatedTime = updatedTime;    &#125;&#125;\n\nimport org.reactivestreams.Publisher;import org.springframework.data.r2dbc.mapping.OutboundRow;import org.springframework.data.r2dbc.mapping.event.BeforeSaveCallback;import org.springframework.data.relational.core.mapping.event.BeforeConvertCallback;import org.springframework.data.relational.core.sql.SqlIdentifier;import org.springframework.stereotype.Component;import reactor.core.publisher.Mono;import java.time.LocalDateTime;import java.time.temporal.ChronoUnit;@Componentpublic class AuditableEntityCallback implements BeforeSaveCallback&lt;AuditableEntity&gt;, BeforeConvertCallback&lt;AuditableEntity&gt; &#123;    @Override    public Publisher&lt;AuditableEntity&gt; onBeforeSave(AuditableEntity entity, OutboundRow row, SqlIdentifier table) &#123;        System.out.println(&quot;before save &quot; + entity.getCreatedTime());        entity.setCreatedTime(roundToMilliseconds(entity.getCreatedTime()));        entity.setUpdatedTime(roundToMilliseconds(entity.getUpdatedTime()));        System.out.println(&quot;before save &quot; + entity.getCreatedTime());        return Mono.just(entity);    &#125;    @Override    public AuditableEntity onBeforeConvert(AuditableEntity entity) &#123;        System.out.println(&quot;before convert &quot; + entity.getCreatedTime());        entity.setCreatedTime(roundToMilliseconds(entity.getCreatedTime()));        entity.setUpdatedTime(roundToMilliseconds(entity.getUpdatedTime()));        System.out.println(&quot;before convert &quot; + entity.getCreatedTime());        return entity;    &#125;    private static LocalDateTime roundToMilliseconds(LocalDateTime dateTime) &#123;        LocalDateTime localDateTime = dateTime.truncatedTo(ChronoUnit.MILLIS);        int dateTimeNano = dateTime.getNano() % 1000_000;        if (dateTimeNano &gt;= 500_000) &#123;            localDateTime = localDateTime.plusNanos(1_000_000);        &#125;        return localDateTime;    &#125;&#125;\n\njpa有没有问题呢？出于好奇，我也做了jpa的尝试，jpa也是一样的行为\n\n","tags":["Java","mysql","r2dbc"]},{"title":"软件应该以标准的格式来交付","url":"/2025/09/22/%E8%BD%AF%E4%BB%B6%E5%BA%94%E8%AF%A5%E4%BB%A5%E6%A0%87%E5%87%86%E7%9A%84%E6%A0%BC%E5%BC%8F%E6%9D%A5%E4%BA%A4%E4%BB%98/","content":"令人深思的经历曾经历过这样的事情，平台侧要求应用提供满足平台特有格式的交付件，经过多次协商，最终还是应用侧与平台侧一起开会，由平台侧帮助应用侧输出。\n另一件事，Kubernetes Yaml以其独特、强大的合并属性能力闻名于江湖。应用侧对Kubernetes Yaml不熟悉，新手想要把环境上的Yaml导出直接作为标准交付件，虽然也行，但是包含了很多噪音，环境上的id、环境上的annotation、时间戳等等。\n私有化格式的交付困境越来越多的软件将自己定位为”平台”，无论是微信、飞书这样的国民应用，还是各类企业级软件。但平台交付的过程中，一个普遍存在的问题是：许多平台要求合作伙伴或第三方开发者使用其私有化的交付格式。这种私有化格式往往存在诸多问题：\n\n学习成本高，难以掌握。\n文档不完善，依赖平台方支持。\n迁移困难，形成供应商锁定。\n最终往往仍需平台方投入人力协助。\n\n软件交付应该标准化软件交付应该使用标准的格式，这有助于降低合作伙伴的接入成本，提高自身的可扩展性，尤其在AI辅助研发的现状下，采用标准的格式更有利于AI理解和生成代码。\n\n\n\n交付件\n标准格式\n使用场景\n\n\n\nJava库\nJar包\n作为依赖库被其他Java项目引用和集成，需要发布到Maven仓库。\n\n\n应用镜像\n标准镜像包\n以容器方式交付，确保运行的一致性。（但如x86、armv8、armv7）的差异依然存在。\n\n\n应用部署（I层资源已具备）\nhelm、docker compose\n商用场景多用Helm包，单机伪集群&#x2F;组合方式多用docker compose。\n\n\n应用部署及I层资源创建\nTerraform\n需要交付底层基础设施或云服务的场景，如整个应用运行环境。\n\n\n如果实在要使用私有的格式，可以对标准格式做一些裁剪&#x2F;扩展（Kubernetes的annotation），将标准格式转化到私有格式。\n"},{"title":"通用4层获取源IP的负载均衡网关建设","url":"/2020/12/25/%E9%80%9A%E7%94%A84%E5%B1%82%E8%8E%B7%E5%8F%96%E6%BA%90IP%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%BD%91%E5%85%B3%E5%BB%BA%E8%AE%BE/","content":"网关建设今天给大家介绍三种常见的四层负载均衡、网络转发方案，可用于四层的网关建设。\n利用ipvs实现(需要后端服务能连通外部网络)\n该方案需要后端服务器与前端client网络打通，GatewayIp可以采用主备的方式保证高可用\n配置都在GatewayIp上，需要配置的如下:\nipvsadm -A -u $GatewayIp:$port -s rr -p 600# -u表示为udp协议，-t表示为tcp协议# rr 为均衡算法，roundroubin的意思，lc则代表最短连接数ipvsadm -a -u $GatewayIp:$port -r $ServerIp:$port -m\n\nIpvs+Iptables实现如果您不希望后端Server与客户端面对面打通，那么您可能会喜欢这种方式，将GatewayIP设置为ServerIp的默认网关，再由Snat转换将报文转换出去，这样子Server就不需要与客户端面对面打通了，图示如下:\n\n配置默认路由也很简单\nip route add 客户端IP网段 via GateWayIp dev eth0\n配置iptables\niptables -t nat -A POSTROUTING -m iprange -p udp --dst-range $client_ip_range -o eth1  -j SNAT  --to-source $GateWayIp\n\nIpvs+Iptables+Iptunnel实现默认路由有一个限制，就是说Server与Gateway都在一个子网内，有过商用经验的大家都知道DMZ之类的说法，就是说应用服务器和网关服务器在诸如安全组，子网等等上需要隔离。假设你需要将应用服务器和网关放在不同的子网，上面的方案就搞不定啊，这个时候需要使用ip隧道的方式来跨子网，图示如下，仅仅后边红色路线的ip发生了变化，原来的报文被ip隧道Wrap:\n\n配置ip 隧道倒也不难\nip tunnel add $tun_name mode ipip remote $remote_ip local $local_ip ttl 255\n总结以上三种方案均没有单点问题，且都兼容tcp，udp协议。GateWay处的单点问题，通过zk选主、etcd选主，keepalive等 + 浮动IP迁移的方式均能解决。大家可以根据自己的网规网设自由选择\n","tags":["LB"]},{"title":"错误码国际化总结","url":"/2024/03/21/%E9%94%99%E8%AF%AF%E7%A0%81%E5%9B%BD%E9%99%85%E5%8C%96%E6%80%BB%E7%BB%93/","content":"错误信息无模板变量假设我们的错误信息返回如下\nHTTP/1.1 200 OK&#123;&quot;error_code&quot;: &quot;IEEE.754&quot;, &quot;error_msg&quot;: &quot;IEE 754 error&quot;&#125;\n\n无模板变量的错误信息国际化，可以直接在前端对整体字符串根据错误码进行静态国际化。\n// catch the error code firstconst error_code = body.error_codeconst error_msg_map = &#123;    &quot;IEEE.754&quot;: &#123;        &quot;en&quot;: &quot;IEE 754 error&quot;,        &quot;zh&quot;: &quot;IEE 754 错误&quot;    &#125;&#125;const error_msg = error_msg_map[error_code][lang]\n\n错误信息包含模板变量假设我们的错误信息返回如下\nHTTP/1.1 200 OK&#123;&quot;error_code&quot;: &quot;IEEE.754&quot;, &quot;error_msg&quot;: &quot;IEE 754 NbN error, do you mean Nan?&quot;&#125;\n\n包含模板变量的错误信息国际化，可以在前端通过正则表达式提取，并代入到中文字符串模板中实现。如示例代码\n// catch the error code firstconst error_code = body.codeconst error_msg_capture_map = &#123;    &quot;IEEE.754&quot;: &quot;/IEE 754 (\\w+) error, do you mean (\\w+)?/&quot;&#125;;const error_msg_template_map = &#123;    &quot;IEEE.754&quot;: &#123;        &quot;en&quot;: &quot;IEE 754 &#123;&#123;var1&#125;&#125; error, do you mean &#123;&#123;var2&#125;&#125;?&quot;,        &quot;zh&quot;: &quot;IEE 754 &#123;&#123;var1&#125;&#125; 错误，你是指 &#123;&#123;var2&#125;&#125; 吗？&quot;    &#125;&#125;;const matches = error_msg_capture_map[error_code].exec(body.error_msg);const variables = matches.slice(1);let error_msg = error_msg_template_map[error_code][lang];variables.forEach((value, index) =&gt; &#123;    error_msg = error_msg.replace(`&#123;&#123;var$&#123;index + 1&#125;&#125;&#125;`, value);&#125;);\n","tags":["Code"]},{"title":"高可用无单点架构之kubernetes集群","url":"/2021/08/28/%E9%AB%98%E5%8F%AF%E7%94%A8%E6%97%A0%E5%8D%95%E7%82%B9%E6%9E%B6%E6%9E%84%E4%B9%8Bkubernetes%E9%9B%86%E7%BE%A4/","content":"k8s高可用无单点故障涉及那些场景k8s 节点添加、pod添加等增删查改无单点故障需要元数据的存储和处理能力高可用\nk8s对外的apiServer（如worker）无单点故障worker node和其他组件访问apiServer路径高可用\nk8s无单点故障技术关键点元数据存储通过etcd存储元数据，etcd三节点集群保证高可用\n元数据处理通过多个kube-controller和kube-scheduler节点来保证高可用\nworker节点请求数据通过多ip或负载均衡来保证节点请求通信通过多Ip或负载均衡来保证高可用，这里也有几种方式\nIaaS厂商可提供负载均衡的场景下如下图所示，可将worker node的访问地址指向负载均衡的地址\n\n私有化部署KeepAlived私有化部署场景常用keepAlived提供浮动IP来给worker node或其他组件访问，如下图所示\n\n私有化部署加上负载均衡组件如果你觉得同一时刻只有单个apiServer工作会成瓶颈，也可以使用KeepAlived加Nginx或HaProxy来对ApiServer做负载均衡\n\n为了简化图像，只画出了master1上的Nginx向后转发的场景。\n至于Nginx和KeepAlived如何部署，推荐采用容器化的部署模式，方便进行监控和运维；但是镜像不从镜像仓库拉取，而是保存在master节点上，这样虽然升级复杂一点，但是这样子kubernetes的高可用就不依赖镜像仓库了，不会和镜像仓库形成循环依赖，更不会影响镜像仓库的高可用方案，大大简化了后续的技术方案。（因为镜像仓库可能会占据较大的存储空间，可能会和master节点分离部署，这时会作为worker节点连接master节点）。\n","tags":["Kubernetes"]},{"title":"高可用无单点架构之镜像仓库","url":"/2021/08/28/%E9%AB%98%E5%8F%AF%E7%94%A8%E6%97%A0%E5%8D%95%E7%82%B9%E6%9E%B6%E6%9E%84%E4%B9%8B%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93/","content":"本篇文章探讨镜像仓库registry的高可用\n镜像仓库高可用无单点故障涉及那些场景镜像仓库对外提供访问无单点故障镜像仓库对外提供的访问点保持高可用\n镜像仓库的数据存储高可用存储在镜像仓库中的数据都得是高可用的\n镜像仓库无单点故障技术关键点镜像仓库对外提供访问无单点故障和上一篇文章一样，如果IaaS能提供ELB，我们最好是使用ELB，或者使用浮动IP的方式替换\n镜像仓库的数据存储高可用\n配置镜像仓库使用IaaS的S3存储\n配置镜像仓库使用本地存储，通过共享文件路径存储来实现高可用，如Glusterfs等\n配置镜像仓库使用S3存储，自建兼容S3 API的存储Server\n\n通常会使用共享存储来做到镜像仓库存储的高可用\n方案概述那么其实镜像仓库的高可用方案就是对上面方案的组合，下面我们举几个例子\n镜像仓库依赖组件部署方式MinIo、KeepAlived、registry都推荐使用容器部署，方便运维管理，但是镜像推荐内置到虚拟机中，不依赖镜像仓库或其他组件，避免循环依赖\n使用IaaS的S3存储 + 负载均衡组件这是最简单的方案，得益于云厂商提供的S3存储和负载均衡组件，我们可以进行很简单的配置，并部署一台以上的registry,如下图所示\n\n自建兼容S3存储 + KeepAlived浮动Ip我们可以自己搭建MinIo集群来作为兼容S3存储，由于MINIO最低部署4个节点，我们需要根据故障域机器来选择部署MINIO的数目，比如，故障域是三台物理机，我们部署4节点就不妥。原因是，4节点，总会有一台物理机上会部署2个minio节点，如果这台物理机挂掉，就会导致单点故障。所以，如果故障域为三台物理机，我们最好部署6节点，可容忍一台物理机宕机。其他的节点，读者也可以自行测算。\n下图是假设三台物理机，minio6副本场景下的部署示意图\n\n注，为了图的美观，并未画出所有的连线\nMINIO关键配置\n节点数目6个\nEC2\n\n","tags":["Kubernetes"]},{"title":"Android避免费内存泄露【翻译】","url":"/2016/09/08/Andoird%E9%81%BF%E5%85%8D%E5%86%85%E5%AD%98%E6%B3%84%E9%9C%B2%E3%80%90%E7%BF%BB%E8%AF%91%E3%80%91/","content":"原文：http://android-developers.blogspot.sg/2009/01/avoiding-memory-leaks.html\nAndroid中堆的内存是有限的，你应当使用尽量小的内存。因为Android能在内存中保存越多的应用，对于用户来说，切换应用就会十分的迅速。相当多的内存泄漏的原因是因为：保持了一个对context的长引用(long-lived)。    在Android中，Context可以用来做许多事情，不过大部分是用来加载和获取资源。这就是为什么所有的视图组件在构造方法里面需要context作为参数的原因。有两种Context，Activity和Application，通常使用第一个。比如:\nTextView label =new TextView(this);\n这代表着views持有一个对于activity的引用。所以，如果你泄漏了Context(你保留了一个对它的引用，在GC的时候保护了它)。如果你不够小心的话，泄漏掉整个Activity是很容易的。    当屏幕的显示方向发生变化时，系统将会(默认)销毁现在的Activity，维护它的一些数据然后新建一个Activity。如果这样做的话，Android 将会重新读取UI。想象一下，你在你的应用里面使用了一个大bitmap，你不想每次旋转的时候都重新加载它。最简单的方法就是把它放在一个静态域里面。\nprivate static Drawable sBackground;@OverrideProtected void onCreate(Bundle state)&#123;    super.onCreate(state);    TextView label = new TextView(this);    label.setText(&quot;Leaks are bad&quot;);    if(sBackground == null)&#123;        sBackground = getDrawable(R.drawable.hezhangjian);    &#125;    label.setBackgroundDrawable(sBackground);    setContentView(label);&#125;   \n\n\n上述代码很快但是是错误的，它泄漏了在第一次屏幕旋转之前的Activity。当一个Drawable连系在view上时，view就像被设置为drawable的回调一样。对于上面的代码，就是说drawable持有了对于textview的引用，而textview又持有了activity的引用。这就把Activity泄漏掉了。当Activity被销毁的时候，把drawable的回调设置为null。    有两种简单的方式去避免内存泄漏。第一个就是避免context超范围的使用。例子上展示的是静态引用但是内部类以及他们持有的对外部类的明确引用也同样危险。第二个解决方法，利用Application context，这个context的存活时间跟你的应用一样久。如果打算保持一个长久的对象，就用 Context.getApplicationContext() 或者 Activity.getApplication()。\n"}]