[{"title":"Apache Ignite在华为云IoT服务产品部的使用","url":"/2023/12/07/Apache%20Ignite%E5%9C%A8%E5%8D%8E%E4%B8%BA%E4%BA%91IoT%E6%9C%8D%E5%8A%A1%E4%BA%A7%E5%93%81%E9%83%A8%E7%9A%84%E4%BD%BF%E7%94%A8/","content":"Apache Ignite简介Apache Ignite是一个开源分布式的数据库、缓存和计算平台。它的核心是一个内存数据网格，它可以将内存作为分布式的持久化存储，以提供高性能和可扩展性。它还提供了一个分布式的键值存储、SQL数据库、流式数据处理和复杂的事件处理等功能。\nIgnite的核心竞争力包括：\n\n兼容Mysql、Oracle语法\n性能强大，可以水平扩展\n缓存与数据库同源，可通过KV、SQL、JDBC、ODBC等方式访问\n\n同时，为了便于开发，除了jdbc、odbc、restful方式外，Ignite还官方提供了Java、C++、.Net、Python、Node.js、PHP等语言的客户端，可以方便的与Ignite进行交互。\n\nApache Ignite的问题频繁创建删除表，导致IGNITE_DISCOVERY_HISTORY_SIZE超过限制根据Ignite2的拓扑模型，集群的拓扑版本会在创建表&#x2F;删除表的时候发生变化，该变化版本号递增，且仅会保留最近$IgniteDiscoveryHistorySize条记录，程序某处会写死读取版本为0的数据，读取不到时，ignite集群会重启。默认值为500。社区issue: https://github.com/apache/ignite/issues/10894笔者暂时没有时间来修复这个issue，可以通过将IGNITE_DISCOVERY_HISTORY_SIZE设置地比较大，来规避这个问题。\nIgnite2客户端易用性问题Ignite2客户端超时默认值不合理Ignite2客户端的连接超时、执行sql超时默认都是0，没有精心研究过配置的用户在异常场景下，应用程序可能会hang住。从易用性的角度来说，网络通信的任何操作，默认都应该有超时时间。\nIgnite2客户端不支持永远的重试Ignite通过预先计算出所有需要重连的时间点来实现重连，如果想配置成永远的重连，会因为时间点的计算导致内存溢出。从易用性的角度来说，应该支持永远的重连。\nIgnite2客户端在某些异常下无法自愈当client执行sql的时候，碰到如下异常的时候，无法自愈。可以通过执行SQL对client进行定期检查并重建。\nCaused by: org.apache.ignite.internal.client.thin.ClientServerError: Ignite failed to process request [47]: 50000: Can not perform the operation because the cluster is inactive. Note, that the cluster is considered inactive by default if Ignite Persistent Store is used to let all the nodes join the cluster. To activate the cluster call Ignite.cluster.state(ClusterState.ACTIVE)\n\nIgnite2 SocketChannel泄露问题Ignite客户端在连接时，如果对应的Server端没有启动，会导致SocketChannel泄露，已由笔者提交代码修复：https://github.com/apache/ignite/pull/11016/files\n","tags":["Ignite"]},{"title":"Apache ZooKeeper在华为云IoT服务产品部的使用","url":"/2021/04/10/Apache%20ZooKeeper%E5%9C%A8%E5%8D%8E%E4%B8%BA%E4%BA%91IoT%E6%9C%8D%E5%8A%A1%E4%BA%A7%E5%93%81%E9%83%A8%E7%9A%84%E4%BD%BF%E7%94%A8/","content":"前言华为云IoT服务产品部致力于提供极简接入、智能化、安全可信等全栈全场景服务和开发、集成、托管、运营等一站式工具服务，助力合作伙伴&#x2F;客户轻松、快速地构建5G、AI万物互联的场景化物联网解决方案。\n架构方面，华为云IoT服务产品部采用云原生微服务架构，ZooKeeper组件在华为云IoT服务产品部的架构中扮演着重要的角色，本文将介绍华为云IoT服务产品部在ZooKeeper的使用。\nApache ZooKeeper 简介Apache ZooKeeper是一个分布式、开源的分布式协调服务，由Apache Hadoop的子项目发展而来。作为一个分布式原语的基石服务，几乎所有分布式功能都可以借助ZooKeeper来实现，例如：应用的主备选举，分布式锁，分布式任务分配，缓存通知，甚至是消息队列、配置中心等。\n抛开应用场景，讨论某个组件是否适合，并没有绝对正确的答案。尽管Apache ZooKeeper作为消息队列、配置中心时，性能不用想就知道很差。但是，倘若系统里面只有ZooKeeper，应用场景性能要求又不高，那使用ZooKeeper不失为一个好的选择。但ZooKeeper 客户端的编码难度较高，对开发人员的技术水平要求较高，尽量使用一些成熟开源的ZooKeeper客户端、框架，如：Curator、Spring Cloud ZooKeeper等。\nApache ZooKeeper 核心概念ZNodeZNode是ZooKeeper的数据节点，ZooKeeper的数据模型是树形结构，每个ZNode都可以存储数据，同时可以有多个子节点，每个ZNode都有一个路径标识，类似于文件系统的路径，例如：&#x2F;iot-service&#x2F;iot-device&#x2F;iot-device-1。\nApache ZooKeeper在华为云IoT服务产品部的使用\n支撑系统内关键组件很多开源组件都依赖ZooKeeper，如Flink、Ignite、Pulsar等，通过自建和优化ZooKeeper环境，我们能够为这些高级组件提供更加可靠和高效的服务支持，确保服务的平稳运行。\n严格分布式锁分布式锁是非常常见的需求，相比集群Redis、主备Mysql等，ZooKeeper更容易实现理论上的严格分布式锁。\n分布式缓存通知ZooKeeper的分布式缓存通知能够帮助我们实现分布式缓存的一致性，例如：我们可以在ZooKeeper上注册一个节点，然后在其他节点上监听这个节点，当这个节点发生变化时，其他节点就能够收到通知，然后更新本地缓存。\n这种方式的缺点是，ZooKeeper的性能不高，不适合频繁变更的场景，但是，对于一些不经常变更的配置，这种方式是非常适合的。如果系统中存在消息队列，那么可以使用消息队列来实现分布式缓存通知，这种方式的性能会更好、扩展性更强。\n分布式Id生成器直接使用ZooKeeper的有序节点应用程序可以直接使用ZooKeeper的有序节点来生成分布式Id，但是，这种方式的缺点是，ZooKeeper的性能不高，不适合频繁生成的场景。\nimport org.apache.zookeeper.CreateMode;import org.apache.zookeeper.ZooDefs;import org.apache.zookeeper.ZooKeeper;import org.apache.zookeeper.data.Stat;import java.util.Optional;public class ZkDirectIdGenerator &#123;    private ZooKeeper zooKeeper;    private String path = &quot;/zk-direct-id&quot;;    private static final String PATH_PREFIX = &quot;/id-&quot;;    public ZkDirectIdGenerator(String connectionString, int sessionTimeout) throws Exception &#123;        this.zooKeeper = new ZooKeeper(connectionString, sessionTimeout, event -&gt; &#123;&#125;);        initializePath();    &#125;    private void initializePath() throws Exception &#123;        Stat stat = zooKeeper.exists(path, false);        if (stat == null) &#123;            zooKeeper.create(path, new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);        &#125;    &#125;    public Optional&lt;String&gt; generateId() &#123;        try &#123;            String fullPath = zooKeeper.create(path + PATH_PREFIX, new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT_SEQUENTIAL);            return Optional.of(extractId(fullPath));        &#125; catch (Exception e) &#123;            log.error(&quot;create znode failed, exception is &quot;, e);            return Optional.empty();        &#125;    &#125;    private String extractId(String fullPath) &#123;        return fullPath.substring(fullPath.lastIndexOf(PATH_PREFIX) + PATH_PREFIX.length());    &#125;&#125;\n\n使用ZooKeeper生成机器号应用程序可以使用ZooKeeper生成机器号，然后使用机器号+时间戳+序列号来生成分布式Id。来解决ZooKeeper有序节点性能不高的问题。\nimport lombok.extern.slf4j.Slf4j;import org.apache.zookeeper.CreateMode;import org.apache.zookeeper.ZooDefs;import org.apache.zookeeper.ZooKeeper;import java.time.LocalDateTime;import java.util.Optional;import java.util.concurrent.atomic.AtomicInteger;import java.util.concurrent.atomic.AtomicReference;@Slf4jpublic class ZkIdGenerator &#123;    private final String path = &quot;/zk-id&quot;;    private final AtomicInteger atomicInteger = new AtomicInteger();    private final AtomicReference&lt;String&gt; machinePrefix = new AtomicReference&lt;&gt;(&quot;&quot;);    private static final String[] AUX_ARRAY = &#123;&quot;&quot;, &quot;0&quot;, &quot;00&quot;, &quot;000&quot;, &quot;0000&quot;, &quot;00000&quot;&#125;;    /**     * 通过zk获取不一样的机器号，机器号取有序节点最后三位     * id格式：     * 机器号 + 日期 + 小时 + 分钟 + 秒 + 5位递增号码     * 一秒可分近10w个id     * 需要对齐可以在每一位补零     *     * @return     */    public Optional&lt;String&gt; genId() &#123;        if (machinePrefix.get().isEmpty()) &#123;            acquireMachinePrefix();        &#125;        if (machinePrefix.get().isEmpty()) &#123;            // get id failed            return Optional.empty();        &#125;        final LocalDateTime now = LocalDateTime.now();        int aux = atomicInteger.getAndAccumulate(1, ((left, right) -&gt; &#123;            int val = left + right;            return val &gt; 99999 ? 1 : val;        &#125;));        String time = conv2Str(now.getDayOfYear(), 3) + conv2Str(now.getHour(), 2) + conv2Str(now.getMinute(), 2) + conv2Str(now.getSecond(), 2);        String suffix = conv2Str(aux, 5);        return Optional.of(machinePrefix.get() + time + suffix);    &#125;    private synchronized void acquireMachinePrefix() &#123;        if (!machinePrefix.get().isEmpty()) &#123;            return;        &#125;        try &#123;            ZooKeeper zooKeeper = new ZooKeeper(ZooKeeperConstant.SERVERS, 30_000, null);            final String s = zooKeeper.create(path, new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT_SEQUENTIAL);            if (s.length() &gt; 3) &#123;                machinePrefix.compareAndSet(&quot;&quot;, s.substring(s.length() - 3));            &#125;        &#125; catch (Exception e) &#123;            log.error(&quot;connect to zookeeper failed, exception is &quot;, e);        &#125;    &#125;    private static String conv2Str(int value, int length) &#123;        if (length &gt; 5) &#123;            throw new IllegalArgumentException(&quot;length should be less than 5&quot;);        &#125;        String str = String.valueOf(value);        return AUX_ARRAY[length - str.length()] + str;    &#125;&#125;\n\n微服务注册中心相比其他微服务引擎，如阿里云的MSE、Nacos等，已有的Zookeeper集群作为微服务的注册中心，既能满足微服务数量较少时的功能需求，并且更加节约成本\n数据库连接均衡在此前的架构中，我们采用了一种随机策略来分配微服务与数据库的连接地址。下图展示了这种随机分配可能导致的场景。考虑两个微服务：微服务B和微服务C。尽管微服务C的实例较多，但其对数据库的操作相对较少。相比之下，微服务B在运行期间对数据库的操作更为频繁。这种连接方式可能导致数据库Data2节点的连接数和CPU使用率持续居高，从而成为系统的瓶颈。\n\n启发于Kafka中的partition分配算法，我们提出了一种新的连接策略。例如，如果微服务B1连接到了Data1和Data2节点，那么微服务B2将连接到Data3和Data4节点。如果存在B3实例，它将再次连接到Data1和Data2节点。对于微服务C1，其连接将从Data1和Data2节点开始。然而，由于微服务的数量与数据库实例数量的两倍（每个微服务建立两个连接）并非总是能整除，这可能导致Data1和Data2节点的负载不均衡。\n为了解决这一问题，我们进一步优化了策略：第一个微服务实例在选择数据库节点时，将从一个随机起点开始。这种方法旨在确保Data1和Data2节点的负载均衡。具体的分配策略如下图所示。\n\nApache ZooKeeper在华为云IoT产品部的部署&#x2F;运维服务端部署方式我们所有微服务和中间件均采用容器化部署，选择3节点（没有learner）规格。使用statefulset和PVC的模式部署。为什么使用statefulset进行部署？statefulset非常适合用于像Zookeeper这样有持久化存储需求的服务，每个Pod可以和对应的存储资源绑定，保证数据的持久化，同时也简化了部署，如果想使用deploy的部署模式，需要规划、固定每个pod的虚拟机部署。\nZookeeper本身对云硬盘的要求并不高，普通IO，几十G存储就已经能够支撑Zookeeper平稳运行了。Zookeeper本身运行的资源，使用量不是很大，在我们的场景，规格主要取决于Pulsar的topic数量，如果Pulsar的topic不多，那么0.5核、2G内存已经能保证Zookeeper平稳运行了。\n客户端连接方式借助coredns，客户端使用域名的方式连接Zookeeper，这样可以避免Zookeeper的IP地址变更导致客户端连接失败的问题，如zookeeper-0.zookeeper:2181,zookeeper-1.zookeeper:2181,zookeeper-2.zookeeper:2181\n重要监控指标\nreadlantency、updatelantency\nzk的读写延迟\n\napproximate_data_size\nzk中数据的平均大小估计\n\noutstanding_requests\n等待Zookeeper处理的请求数\n\nznode_count\nZookeeper当前的znode总数\n\nnum_alive_connections\nZookeeper当前活跃的连接数\n\n\nApache ZooKeeper在华为云IoT产品部的问题readiness合理设置这是碰到的最有趣的问题，readiness接口是k8s判断pod是否正常的依据，那么对于Zookeeper集群来说，最合理的就是，当这个Zookeeper节点加入集群，获得了属于自己的Leader或Follower状态，就算pod正常。可是，当初次部署的时候，只有一个节点可用，该节点一个实例无法完成选举流程，导致无法部署。\n综上，我们把readiness的策略修改为：\n\nPS：为了让readiness检查不通过时，Zookeeper集群也能选主成功，需要配置publishNotReadyAddresses为true，示例如下\napiVersion: v1kind: Servicemetadata:  name: zookeeperspec:  selector:    app: zookeeper  clusterIP: None  sessionAffinity: None  publishNotReadyAddresses: true  ports:    - protocol: TCP      port: 2181      name: client    - protocol: TCP      port: 2888      name: peer    - protocol: TCP      port: 3888      name: leader\n\njute.maxbuffer超过上限jute.maxbuffer，这个是znode中存储数据大小的上限，在客户端和服务端都需要配置，根据自己在znode上存储的数据合理配置\nzookeeper的Prometheus全0监听不满足网络监听最小可见原则。修改策略，添加一个可配置参数来配置监听的IP metricsProvider.httpHost，PR已合入，见 https://github.com/apache/zookeeper/pull/1574/files\n客户端版本号过低，域名无法及时刷新客户端使用域名进行连接，但在客户端版本号过低的情况下，客户端并不会刷新新的ip，还是会用旧的ip尝试连接。升级客户端版本号到curator-4.3.0以上、zookeeper-3.6.2以上版本后解决。\n总结本文详细介绍了华为云IoT服务产品部如何使用Apache ZooKeeper来优化其云原生微服务架构。ZooKeeper作为分布式协调服务，在华为云IoT服务中发挥了重要作用，用于主备选举、分布式锁、任务分配和缓存通知等。文中还讨论了ZooKeeper在分布式ID生成、微服务注册中心、数据库连接均衡等方面的应用。此外，文章还覆盖了ZooKeeper在华为云IoT产品部的部署、运维策略和所遇到的挑战，包括容器化部署、监控指标和配置问题。\n","tags":["ZooKeeper"]},{"title":"BookKeeper 持久化文件解析","url":"/2021/02/16/BookKeeper%20%E6%8C%81%E4%B9%85%E5%8C%96%E6%96%87%E4%BB%B6%E8%A7%A3%E6%9E%90/","content":"Entry Log File背景测试环境上出现了一些entryLog解析异常的问题，想分析一下磁盘上.log文件的格式，分析分析我们的文件是否有问题\n解析代码地址https://github.com/protocol-laboratory/bookkeeper-codec-java/blob/main/src/main/java/com/github/protocol/EntryLogReader.java\n正文我们采用的配置是singleEntryLog模式，就是说很多ledger的信息都会放在一个log文件内部。\n插一句话：这种log文件，其实和LSM相似，属于不可变的数据结构，这种数据结构，得益于不可变，所以内容可以安排的非常紧凑，不像B树结构，需要预留一定空间给原地更新，随机插入等。\n\n如上图所示，接下来，我们沿着解析的流程，解读每个部分的详细格式\n解析头部首先，我们解析文件的头部字段，bookkeeper的设计中，文件头部预留了1024字节，目前只使用了20个字节前四个字节是BKLO的文件魔数然后紧跟着的4个字节是bk文件的版本号，这里我们仅分析版本号1然后8字节的long类型代表ledgersMap的开始位置，称为ledgersMapOffset。然后4字节的int类型代表ledgersMap的总长度。\n解析ledgerMap部分最前面四个字节，代表这部分的大小\n然后开始的ledgerId和entryId分别为-1，-2，随后是一个ledger的count大小，后面的ledgerId和size才是有效值\n随后的部分非常紧凑，由一个个ledgerId，size组成\n读取完ledgerMap，可以知道，这个文件包含了多少ledger，总大小是多少？\n注：size代表这一段ledger占用的磁盘空间大小\n解析body内容body内容也非常紧凑.最前面4个字节，代表这个entry的大小。然后8个字节，ledgerId然后8个字节，entryId剩下的内容，就是pulsar写数据的编码，不再属于bookkeeper的格式范畴了\nTxn Log File解析代码地址https://github.com/protocol-laboratory/bookkeeper-codec-java/blob/main/src/main/java/com/github/protocol/TxnLogReader.java\n简述bookkeeper中的journal log，和大部分基于LSM的数据结构一样，是用来保证文件一定被写入的。会在数据写入的时候，写入journal log，崩溃恢复的时候从journal log里面恢复。\n\n解析头部首先，我们解析文件的头部字段前四个字节是BKLG的文件魔数然后紧跟着的4个字节是bk文件的版本号\nprivate TxnHeader readHeader(FileChannel fileChannel) throws Exception &#123;    final ByteBuf headers = Unpooled.buffer(HEADER_SIZE);    final int read = fileChannel.read(headers.internalNioBuffer( index: 0, HEADER_SIZE));    headers.writerIndex(read);    final byte[] bklgByte = new byte[4];    headers.readBytes(bklgByte, dstIndex: 0, length: 4);    final int headerVersion = headers.readInt();    return new TxnHeader(headerVersion);&#125;\n\n解析内容内容非常紧凑，由ledgerId，entryId和内容组成。ledgerId一定大于0，entryId在小于0的情况下代表特殊的数据。如\n\n-0x1000即4096 代表ledger的masterKey\n-0x2000即8192 代表ledger是否被fence\n-0x4000即16384 代表ledger的force\n-0x8000即32768 代表ledger的显示LAC\n\n回放流程当bookkeeper启动的时候，他会从data路径下取得lastMark文件，该文件一定为16个字节，前八个字节代表落盘的最新journal log文件，后八个字节代表文件的位置。会从这个位置开始回放。值得一提的是，lastId文件，代表下一个dataLog该使用什么文件名。\n","tags":["BookKeeper"]},{"title":"Calcite Parser代码生成详解","url":"/2022/09/26/Calcite%20Parser%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90%E8%AF%A6%E8%A7%A3/","content":"本文代码均已上传到giteecalcite的parser代码生成分为如下两个步骤  \n  \n生成Parse.jj文件目录如下\n├── pom.xml└── src    ├── main    │   ├── codegen    │   │   ├── config.fmpp    │   │   ├── includes    │   │   │   ├── compoundIdentifier.ftl    │   │   │   └── parserImpls.ftl    │   │   └── templates    │   │       └── Parser.jj\n\n添加calcite dependency\n&lt;dependency&gt;    &lt;groupId&gt;org.apache.calcite&lt;/groupId&gt;    &lt;artifactId&gt;calcite-core&lt;/artifactId&gt;&lt;/dependency&gt;\n\n\n\n配置drill-fmpp-maven-plugin插件如下\n&lt;plugin&gt;    &lt;groupId&gt;org.apache.drill.tools&lt;/groupId&gt;    &lt;artifactId&gt;drill-fmpp-maven-plugin&lt;/artifactId&gt;    &lt;executions&gt;        &lt;execution&gt;            &lt;configuration&gt;                &lt;config&gt;src/main/codegen/config.fmpp&lt;/config&gt;                &lt;output&gt;$&#123;project.build.directory&#125;/generated-sources/fmpp&lt;/output&gt;                &lt;templates&gt;src/main/codegen/templates&lt;/templates&gt;            &lt;/configuration&gt;            &lt;id&gt;generate-fmpp-sources&lt;/id&gt;            &lt;phase&gt;validate&lt;/phase&gt;            &lt;goals&gt;                &lt;goal&gt;generate&lt;/goal&gt;            &lt;/goals&gt;        &lt;/execution&gt;    &lt;/executions&gt;&lt;/plugin&gt;\n\ncodegen 模块的文件都拷贝自对应版本的calclite core&#x2F;src&#x2F;main&#x2F;codegen路径 https://github.com/apache/calcite/tree/main/core/src/main/codegen\n然后把https://github.com/apache/calcite/blob/main/core/src/main/codegen/default_config.fmpp 中的parser属性与config.fmpp中的parser属性合并。就可以通过mvn package命令生成Parser.jj了。当然，如果有定制化修改的需求，也可以在这个阶段修改config.fmpp  \n  \nParser.jj生成java代码文件目录如下\n├── pom.xml├── src│   ├── main│   │   ├── codegen│   │   │   └── Parser.jj\n\nParser.jj就是我们上一步生成的Parser.jj，如果有什么想要的定制化修改，也可以在这个步骤改入到Parser.jj中。\n添加calcite dependency\n&lt;dependency&gt;    &lt;groupId&gt;org.apache.calcite&lt;/groupId&gt;    &lt;artifactId&gt;calcite-core&lt;/artifactId&gt;&lt;/dependency&gt;\n\n配置javacc-maven-plugin如下\n&lt;plugin&gt;    &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt;    &lt;artifactId&gt;javacc-maven-plugin&lt;/artifactId&gt;    &lt;executions&gt;        &lt;execution&gt;            &lt;id&gt;javacc&lt;/id&gt;            &lt;goals&gt;                &lt;goal&gt;javacc&lt;/goal&gt;            &lt;/goals&gt;            &lt;configuration&gt;                &lt;sourceDirectory&gt;$&#123;project.basedir&#125;/src/main/codegen&lt;/sourceDirectory&gt;                &lt;includes&gt;                    &lt;include&gt;**/Parser.jj&lt;/include&gt;                &lt;/includes&gt;            &lt;/configuration&gt;        &lt;/execution&gt;    &lt;/executions&gt;&lt;/plugin&gt;\n\n生成代码  \n  \n无Parser.jj定制化修改，一步生成如果不需要对Parser.jj进行定制化修改，那么可以通过连续运行两个插件来生成代码，这里给出pom文件样例，不再赘述\n&lt;plugin&gt;    &lt;groupId&gt;org.apache.drill.tools&lt;/groupId&gt;    &lt;artifactId&gt;drill-fmpp-maven-plugin&lt;/artifactId&gt;    &lt;executions&gt;        &lt;execution&gt;            &lt;configuration&gt;                &lt;config&gt;src/main/codegen/config.fmpp&lt;/config&gt;                &lt;output&gt;$&#123;project.build.directory&#125;/generated-sources/fmpp&lt;/output&gt;                &lt;templates&gt;src/main/codegen/templates&lt;/templates&gt;            &lt;/configuration&gt;            &lt;id&gt;generate-fmpp-sources&lt;/id&gt;            &lt;phase&gt;validate&lt;/phase&gt;            &lt;goals&gt;                &lt;goal&gt;generate&lt;/goal&gt;            &lt;/goals&gt;        &lt;/execution&gt;    &lt;/executions&gt;&lt;/plugin&gt;&lt;plugin&gt;    &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt;    &lt;artifactId&gt;javacc-maven-plugin&lt;/artifactId&gt;    &lt;executions&gt;        &lt;execution&gt;            &lt;id&gt;javacc&lt;/id&gt;            &lt;goals&gt;                &lt;goal&gt;javacc&lt;/goal&gt;            &lt;/goals&gt;            &lt;configuration&gt;                &lt;sourceDirectory&gt;$&#123;project.build.directory&#125;/generated-sources/fmpp&lt;/sourceDirectory&gt;                &lt;includes&gt;                    &lt;include&gt;**/Parser.jj&lt;/include&gt;                &lt;/includes&gt;                &lt;lookAhead&gt;2&lt;/lookAhead&gt;                &lt;isStatic&gt;false&lt;/isStatic&gt;            &lt;/configuration&gt;        &lt;/execution&gt;        &lt;execution&gt;            &lt;id&gt;javacc-test&lt;/id&gt;            &lt;phase&gt;generate-test-sources&lt;/phase&gt;            &lt;goals&gt;                &lt;goal&gt;javacc&lt;/goal&gt;            &lt;/goals&gt;            &lt;configuration&gt;                &lt;sourceDirectory&gt;$&#123;project.build.directory&#125;/generated-test-sources/fmpp&lt;/sourceDirectory&gt;                &lt;outputDirectory&gt;$&#123;project.build.directory&#125;/generated-test-sources/javacc&lt;/outputDirectory&gt;                &lt;includes&gt;                    &lt;include&gt;**/Parser.jj&lt;/include&gt;                &lt;/includes&gt;                &lt;isStatic&gt;false&lt;/isStatic&gt;                &lt;ignoreCase&gt;true&lt;/ignoreCase&gt;                &lt;unicodeInput&gt;true&lt;/unicodeInput&gt;            &lt;/configuration&gt;        &lt;/execution&gt;    &lt;/executions&gt;&lt;/plugin&gt;\n","tags":["Calcite"]},{"title":"Gin Web项目最佳实践","url":"/2024/10/29/Gin%20Web%E9%A1%B9%E7%9B%AE%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/","content":"本文包含，Gin项目推荐布局，一些最佳实践等等。\nGin项目推荐布局假设项目名称叫Hearth\n\nxxx、yyy代表大块的业务区分：如用户、订单、支付\naaa、bbb代表小块的业务区分：如(用户的)登录、注册、查询\n\nexample/|-- cmd/|   |-- production/|       |-- hearth.go|   |-- local/|       |-- hearth_local.go|-- pkg/|   |-- apimodel/ 存放所有的ApiModel，用oapi-codegen解析uadp yaml来生成|   |-- boot/|       |-- boot.go //装备Struct，用于Lauch整个项目|   |-- handler/|       |-- xxx/|           |-- xxx_aaa_handler.go|           |-- xxx_bbb_handler.go|       |-- yyy/|           |-- yyy_model.go|           |-- yyy_aaa_handler.go|           |-- yyy_bbb_handler.go|   |-- xxx/|       |-- xxx_aaa_model.go // 存放持久化model，如数据库表，消息中间件结构，redis结构等|       |-- xxx_aaa_service.go|   |-- yyy/|       |-- yyy_bbb_model.go|       |-- yyy_bbb_service.go|   |-- ignite/|       |-- ignite.go|       |-- ignite_test.go|   |-- influx/|       |-- influx.go|       |-- influx_test.go|-- docker-build/|   |-- scripts/|       |-- start.sh|-- Dockerfile\n\n放弃的布局方式此种布局比较适合独立的包，对api结构体的操作复用较差example/|-- cmd/|   |-- production/|       |-- hearth.go|   |-- local/|       |-- hearth_local.go|-- pkg/|   |-- boot/|       |-- boot.go //装备Struct，用于Lauch整个项目|   |-- handler/|       |-- xxx/|           |-- xxx_model.go // 将大块业务的model也放在这里，可以使用oapi-codegen来生成结构体|           |-- xxx_aaa_handler.go|           |-- xxx_bbb_handler.go|       |-- yyy/|           |-- yyy_model.go|           |-- yyy_aaa_handler.go|           |-- yyy_bbb_handler.go|   |-- xxx/|       |-- xxx_aaa_model.go // 存放持久化model，如数据库表，消息中间件结构，redis结构等|       |-- xxx_aaa_service.go|   |-- yyy/|       |-- yyy_bbb_model.go|       |-- yyy_bbb_service.go|   |-- ignite/|       |-- ignite.go|       |-- ignite_test.go|   |-- influx/|       |-- influx.go|       |-- influx_test.go|-- docker-build/|   |-- scripts/|       |-- start.sh|-- Dockerfile\n","tags":["Gin","Go"]},{"title":"GitHub Actions 参考大全","url":"/2023/11/24/GitHub%20Actions%20%E5%8F%82%E8%80%83%E5%A4%A7%E5%85%A8/","content":"通用 GitHub Actionscommit lintname: commit linton:  pull_request:    branches:      - mainjobs:  commitlint:    runs-on: ubuntu-latest    steps:      - uses: actions/checkout@v4      - uses: wagoid/commitlint-github-action@v5\n\nline lintname: line linton:  push:    branches:      - main  pull_request:    branches:      - mainjobs:  build:    name: line lint    runs-on: ubuntu-latest    steps:      - uses: actions/checkout@v4      - name: linelint        uses: fernandrone/linelint@master\n\nGogolangci-lintname: go ci Linton:  push:    branches:      - main  pull_request:    branches:      - mainjobs:  golangci:    name: lint    runs-on: ubuntu-latest    steps:      - uses: actions/checkout@v4      - uses: actions/setup-go@v4        with:          go-version: &#x27;1.21&#x27;      - name: golangci-lint        uses: golangci/golangci-lint-action@v3        with:          version: latest          args: --timeout 3m0s\n\ngo mod checkname: go mod checkon:  push:    branches:      - main  pull_request:    branches:      - mainjobs:  go_mod_check:    runs-on: ubuntu-latest    steps:      - uses: actions/checkout@v4      - name: Run Go Mod Check Action        uses: hezhangjian/go-mod-check-action@main        with:          prohibitIndirectDepUpdate: &#x27;true&#x27;\n\ngo unit testsname: go unit teston:  push:    branches:      - main  pull_request:    branches:      - mainjobs:  go_unit_test:    runs-on: ubuntu-latest    steps:      - uses: actions/checkout@v4      - uses: actions/setup-go@v4        with:          go-version: &#x27;1.21&#x27;      - name: setup OpenGemini        uses: hezhangjian/setup-opengemini-action@main      - name: Run coverage        run: go test ./... -coverpkg=./padmin/... -race -coverprofile=coverage.out -covermode=atomic\n\nJava GitHub Actionsmaven checkstylename: java checkstyleon:  push:    branches:      - main  pull_request:    branches:      - mainjobs:  java_checkstyle:    runs-on: ubuntu-latest    steps:      - uses: actions/checkout@v4      - name: Set up Maven Central Repository        uses: actions/setup-java@v3        with:          java-version: &#x27;17&#x27;          distribution: &#x27;temurin&#x27;      - name: checkstyle        run: mvn -B clean checkstyle:check\n\nmaven spotbugsname: java spotbugson:  push:    branches:      - main  pull_request:    branches:      - mainjobs:  java_spotbugs:    runs-on: ubuntu-latest    steps:      - uses: actions/checkout@v4      - name: Set up Maven Central Repository        uses: actions/setup-java@v3        with:          java-version: &#x27;17&#x27;          distribution: &#x27;temurin&#x27;      - name: spotbugs        run: mvn -B -DskipTests clean verify spotbugs:spotbugs\n\nmaven unit testsname: java unit testson:  push:    branches:      - main  pull_request:    branches:      - mainjobs:  java_unit_tests:    runs-on: ubuntu-latest    steps:      - uses: actions/checkout@v4      - name: Set up Maven Central Repository        uses: actions/setup-java@v3        with:          java-version: &#x27;17&#x27;          distribution: &#x27;temurin&#x27;      - name: unit tests        run: mvn -B clean test\n\nTypeScript GitHub Actionsnpm build testname: npm build teston:  push:    branches:      - main  pull_request:    branches:      - mainjobs:  npm_buid_test:    runs-on: ubuntu-latest    steps:      - uses: actions/checkout@v4      - uses: actions/setup-node@v4        with:          node-version: latest      - run: npm install      - run: npm run build      - name: setup pulsar        uses: hezhangjian/setup-pulsar-action@main      - run: npm run test\n\nprettiername: prettieron:  push:    branches:      - main  pull_request:    branches:      - mainjobs:  prettier:    runs-on: ubuntu-latest    steps:      - uses: actions/checkout@v4      - uses: actions/setup-node@v4        with:          node-version: latest      - run: npm install --save-dev prettier      - run: npm install --global prettier      - run: prettier --check &#x27;**/*.ts&#x27;\n","tags":["GitHub Actions"]},{"title":"Go Http SDK设计","url":"/2023/10/28/Go%20Http%20SDK%E8%AE%BE%E8%AE%A1/","content":"根据Go项目的需求和特性，可以为Go的Http SDK项目选择以下命名方式：\n\nxxx-client-go：如果这个项目只有Http SDK，没有其他协议的SDK，推荐使用这个命名方式。\nxxx-http-client-go：当存在其他协议的SDK时，可以使用这个命名方式，以区分不同协议的SDK。\nxxx-admin-go：当项目使用其他协议作为数据通道，使用HTTP协议作为管理通道时，可以使用这个命名方式。\n\n由于Go语言的调用方式是包名.结构体名.方法名，所以在设计SDK时，需要考虑包名、结构体名、方法名的设计。\n以xxx业务为例，假设业务名为xxx，推荐包名也为xxx，结构体名为Client。\n目录布局可以是这样子的：\nxxx-client-go/|-- xxx/|   |-- client.go\n","tags":["Go","SDK"]},{"title":"Go 项目结构组织","url":"/2023/10/08/Go%20%E9%A1%B9%E7%9B%AE%E7%BB%93%E6%9E%84%E7%BB%84%E7%BB%87/","content":"Web后端项目结构组织要点：\n\n使用model、service，而不是modles、services。差别不大，节约一个字母，更加简洁。\n如果是企业内部的微服务，基本不会、极少把部分的功能以library的形式开放出去，internal目录在这个时候就略显鸡肋，可以省略。\n\n备注:\n\nxxx、yyy代表大块的业务区分：如用户、订单、支付\naaa、bbb代表小块的业务区分：如(用户的)登录、注册、查询\n\n方案一：多业务模块通过文件名区分，不分子包适用于小型项目\n注：handler、model、service要留意方法、结构体、接口的命名，避免冲突\nexample/|-- cmd/|   |-- example-server/|       |-- example-server.go (start gin app, manage handler, middleware)|-- pkg/|   |-- handler/|       |-- aaa_handler.go|       |-- bbb_handler.go|   |-- middleware/|       |-- aaa_middleware.go|       |-- bbb_middleware.go|   |-- model/|       |-- aaa_model.go|       |-- bbb_model.go|   |-- service/|       |-- aaa_service.go|       |-- bbb_service.go|   |-- ignite/|       |-- ignite.go|       |-- ignite_test.go|   |-- influx/|       |-- influx.go|       |-- influx_test.go|-- docker-build/|   |-- scripts/|       |-- start.sh|-- Dockerfile\n\n方案二：多业务模块通过包名区分，但不拆分model和service方案二更适用于由多个小模块组合而成的项目，每个小模块不会太大，复用度较高。\nexample/|-- cmd/|   |-- example-server/|       |-- example-server.go (start gin app, manage handler, middleware)|-- pkg/|   |-- handler/|       |-- xxx/|           |-- xxx_aaa_handler.go|           |-- xxx_bbb_handler.go|       |-- yyy/|           |-- yyy_aaa_handler.go|           |-- yyy_bbb_handler.go|   |-- middleware/|       |-- xxx/|           |-- xxx_aaa_middleware.go|       |-- yyy/|           |-- yyy_bbb_middleware.go|   |-- xxx/|       |-- xxx_aaa_model.go|       |-- xxx_aaa_service.go|   |-- yyy/|       |-- yyy_bbb_model.go|       |-- yyy_bbb_service.go|   |-- ignite/|       |-- ignite.go|       |-- ignite_test.go|   |-- influx/|       |-- influx.go|       |-- influx_test.go|-- docker-build/|   |-- scripts/|       |-- start.sh|-- Dockerfile\n\n方案三：多业务模块通过包名区分，并在下层拆分model和service方案三更适用于由多个大模块组合而成的项目，每个大模块都很大，复用度较低，较少的互相调用。\n方案三在service依赖多个service的情况下，会发生命名冲突。\nexample/|-- cmd/|   |-- example-server/|       |-- example-server.go (start gin app, manage handler, middleware)|-- pkg/|   |-- handler/|       |-- xxx/|           |-- xxx_aaa_handler.go|       |-- yyy/|           |-- yyy_bbb_handler.go|   |-- middleware/|       |-- xxx/|           |-- xxx_aaa_middleware.go|       |-- yyy/|           |-- yyy_bbb_middleware.go|   |-- xxx/|       |-- model/|           |-- xxx_aaa_model.go|       |-- service/|           |-- xxx_aaa_service.go|   |-- yyy/|       |-- model/|           |-- yyy_bbb_model.go|       |-- service/|           |-- yyy_bbb_service.go|   |-- ignite/|       |-- ignite.go|       |-- ignite_test.go|   |-- influx/|       |-- influx.go|       |-- influx_test.go|-- docker-build/|   |-- scripts/|       |-- start.sh|-- Dockerfile\n","tags":["Go"]},{"title":"Ignite Java客户端最佳实践","url":"/2023/10/10/Ignite%20Java%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/","content":"Ignite Java 客户端最佳实践背景本文总结了在使用Apache Ignite（Ignite2.0）的Java客户端时，需要注意的一些问题，以及一些最佳实践。值得一提的是 Ignite的Java客户端有一些跟直觉上不太一样的地方，需要注意下。\n客户端相关Ignite客户端有两处跟直觉上相差较大：\n\nIgnite客户端连接没有默认超时时间，如果连接不上，有概率会导致创建客户端一直阻塞，所以一定要设置timeout参数\nIgnite客户端默认不会重连，更不用说无限重连了。并且Ignite客户端重连的实现方式是预先计算出所有重连的时间戳，然后在这些时间戳到达时重连，由于要预先计算出重连的时间戳存入数组，这也就意味着不能无限重连。如果您的应用程序需要无限重连（在云原生环境下，这是非常常见的场景），那么您需要自己实现重连逻辑。\n\nClientConfiguration里的重要参数\nClientConfiguration timeout控制连接超时的参数，单位是毫秒。必须设置！如果不设置，有概率会导致创建客户端一直阻塞。\nSQL相关SQL查询典型用法\nSqlFieldsQuery query = new SqlFieldsQuery(&quot;SELECT 42&quot;).setTimeout(5, TimeUnit.SECONDS);FieldsQueryCursor&lt;List&lt;?&gt;&gt; cursor = igniteClient.query(query))List&lt;List&lt;?&gt;&gt; result = cursor.getAll();\n\n注意：Ignite query出来的cursor如果自己通过iterator遍历则必须要close，否则会导致内存泄漏。\nQuery相关参数\nSqlFieldsQuery timeoutSqlQuery的超时时间，必须设置。默认是0，表示永不超时。如果不设置，有概率会导致查询一直阻塞。\n","tags":["Ignite","Java"]},{"title":"Java Http SDK设计","url":"/2023/10/27/Java%20Http%20SDK%E8%AE%BE%E8%AE%A1/","content":"Java Http SDK设计根据Java项目的需求和特性，可以为Java的Http SDK项目选择以下命名方式：\n\nxxx-client-java：如果这个项目只有Http SDK，没有其他协议的SDK，推荐使用这个命名方式。\nxxx-http-client-java：当存在其他协议的SDK时，可以使用这个命名方式，以区分不同协议的SDK。\nxxx-admin-java：当项目使用其他协议作为数据通道，使用HTTP协议作为管理通道时，可以使用这个命名方式。\n\nmaven模块设计maven module命名可以叫xxx-client或者xxx-http-client，这通常取决于你的项目是否有其他协议的client，如果没有，那么推荐直接使用xxx-client。\n假设包名前缀为com.xxx，module视图如下:\nxxx-client-java(maven artifactId: xxx-client-parent)/|-- xxx-client-api(接口定义，包名com.xxx.client.api，jdk8+)|-- xxx-client-common/core(核心实现，包名com.xxx.client.common，jdk8+)|-- xxx-client-jdk(基于jdk http client的实现，包名com.xxx.client.jdk，jdk17+)|-- xxx-client-okhttp(基于okhttp的实现，包名com.xxx.client.okhttp，jdk8+)|-- xxx-client-reactor(基于reactor-netty的实现，包名com.xxx.client.reactor，jdk8+)\n\n依赖关系图:\ngraph TD\napi[xxx-client-api]\ncommon[xxx-client-common]\njdk[xxx-client-jdk]\nokhttp[xxx-client-okhttp]\nreactor[xxx-client-reactor]\n\ncommon --> api\n\njdk --> common\nokhttp --> common\nreactor --> common\n\n\n import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs';\tmermaid.initialize({startOnLoad: true, flowchart: {curve: 'linear'}}); ","tags":["SDK","Java"]},{"title":"java maven lint推荐配置","url":"/2021/12/16/Java%20maven%20lint%E6%8E%A8%E8%8D%90%E9%85%8D%E7%BD%AE/","content":"maven checkstyle添加maven plugin依赖&lt;plugin&gt;    &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;    &lt;artifactId&gt;maven-checkstyle-plugin&lt;/artifactId&gt;    &lt;version&gt;3.1.2&lt;/version&gt;    &lt;configuration&gt;        &lt;configLocation&gt;config/checkstyle.xml&lt;/configLocation&gt;        &lt;suppressionsLocation&gt;config/suppressions.xml&lt;/suppressionsLocation&gt;        &lt;includeTestSourceDirectory&gt;true&lt;/includeTestSourceDirectory&gt;        &lt;encoding&gt;UTF-8&lt;/encoding&gt;        &lt;excludes&gt;**/proto/*&lt;/excludes&gt;    &lt;/configuration&gt;&lt;/plugin&gt;\n\n\nconfigLocation 存放checkstyle的规则配置文件，附录有样例内容\nSuppressionsLocation 存放屏蔽规则配置文件，附录有样例内容\nincludeTestSourceDirectory 是否检测测试文件夹，建议配置为true\n\n\n结束最后就可以通过mvn checkstyle:check来检查您的工程啦。如果有违反了checkstyle的地方，命令行会提示出错的地方和违反的规则，如下图所示\n\n\n附录规则配置文件举例&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE module PUBLIC        &quot;-//Puppy Crawl//DTD Check Configuration 1.3//EN&quot;        &quot;https://checkstyle.org/dtds/configuration_1_3.dtd&quot;&gt;&lt;!-- This is a checkstyle configuration file. For descriptions ofwhat the following rules do, please see the checkstyle configurationpage at http://checkstyle.sourceforge.net/config.html --&gt;&lt;module name=&quot;Checker&quot;&gt;    &lt;module name=&quot;FileTabCharacter&quot;&gt;        &lt;!-- Checks that there are no tab characters in the file. --&gt;    &lt;/module&gt;    &lt;!-- All Java AST specific tests live under TreeWalker module. --&gt;    &lt;module name=&quot;TreeWalker&quot;&gt;        &lt;module name=&quot;SuppressionCommentFilter&quot;&gt;            &lt;property name=&quot;offCommentFormat&quot; value=&quot;CHECKSTYLE.OFF\\: ([\\w\\|]+)&quot;/&gt;            &lt;property name=&quot;onCommentFormat&quot; value=&quot;CHECKSTYLE.ON\\: ([\\w\\|]+)&quot;/&gt;            &lt;property name=&quot;checkFormat&quot; value=&quot;$1&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;SuppressWarningsHolder&quot; /&gt;        &lt;!--        IMPORT CHECKS        --&gt;        &lt;module name=&quot;RedundantImport&quot;&gt;            &lt;!-- Checks for redundant import statements. --&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;            &lt;message key=&quot;import.redundancy&quot;                     value=&quot;Redundant import &#123;0&#125;.&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;AvoidStarImport&quot;&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;RedundantModifier&quot;&gt;            &lt;!-- Checks for redundant modifiers on various symbol definitions.              See: http://checkstyle.sourceforge.net/config_modifier.html#RedundantModifier            --&gt;            &lt;property name=&quot;tokens&quot; value=&quot;METHOD_DEF, VARIABLE_DEF, ANNOTATION_FIELD_DEF, INTERFACE_DEF, CLASS_DEF, ENUM_DEF&quot;/&gt;        &lt;/module&gt;        &lt;!--            IllegalImport cannot blacklist classes, and c.g.api.client.util is used for some shaded            code and some useful code. So we need to fall back to Regexp.        --&gt;        &lt;module name=&quot;RegexpSinglelineJava&quot;&gt;            &lt;property name=&quot;format&quot; value=&quot;com\\.google\\.api\\.client\\.util\\.(ByteStreams|Charsets|Collections2|Joiner|Lists|Maps|Objects|Preconditions|Sets|Strings|Throwables)&quot;/&gt;        &lt;/module&gt;        &lt;!--             Require static importing from Preconditions.        --&gt;        &lt;module name=&quot;RegexpSinglelineJava&quot;&gt;            &lt;property name=&quot;format&quot; value=&quot;^import com.google.common.base.Preconditions;$&quot;/&gt;            &lt;property name=&quot;message&quot; value=&quot;Static import functions from Guava Preconditions&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;UnusedImports&quot;&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;            &lt;property name=&quot;processJavadoc&quot; value=&quot;true&quot;/&gt;            &lt;message key=&quot;import.unused&quot;                     value=&quot;Unused import: &#123;0&#125;.&quot;/&gt;        &lt;/module&gt;        &lt;!--        JAVADOC CHECKS        --&gt;        &lt;!-- Checks for Javadoc comments.                     --&gt;        &lt;!-- See http://checkstyle.sf.net/config_javadoc.html --&gt;        &lt;module name=&quot;JavadocMethod&quot;&gt;            &lt;property name=&quot;scope&quot; value=&quot;protected&quot;/&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;            &lt;property name=&quot;allowMissingParamTags&quot; value=&quot;true&quot;/&gt;            &lt;property name=&quot;allowMissingReturnTag&quot; value=&quot;true&quot;/&gt;        &lt;/module&gt;        &lt;!-- Check that paragraph tags are used correctly in Javadoc. --&gt;        &lt;!--        &lt;module name=&quot;JavadocParagraph&quot;/&gt;--&gt;        &lt;module name=&quot;JavadocType&quot;&gt;            &lt;property name=&quot;scope&quot; value=&quot;protected&quot;/&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;            &lt;property name=&quot;allowMissingParamTags&quot; value=&quot;true&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;JavadocStyle&quot;&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;            &lt;property name=&quot;checkHtml&quot; value=&quot;true&quot;/&gt;        &lt;/module&gt;        &lt;!--        NAMING CHECKS        --&gt;        &lt;!-- Item 38 - Adhere to generally accepted naming conventions --&gt;        &lt;module name=&quot;PackageName&quot;&gt;            &lt;!-- Validates identifiers for package names against the              supplied expression. --&gt;            &lt;!-- Here the default checkstyle rule restricts package name parts to              seven characters, this is not in line with common practice at Google.            --&gt;            &lt;property name=&quot;format&quot; value=&quot;^[a-z]+(\\.[a-z][a-z0-9]&#123;1,&#125;)*$&quot;/&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;TypeNameCheck&quot;&gt;            &lt;!-- Validates static, final fields against the            expression &quot;^[A-Z][a-zA-Z0-9]*$&quot;. --&gt;            &lt;metadata name=&quot;altname&quot; value=&quot;TypeName&quot;/&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;ConstantNameCheck&quot;&gt;            &lt;!-- Validates non-private, static, final fields against the supplied            public/package final fields &quot;^[A-Z][A-Z0-9]*(_[A-Z0-9]+)*$&quot;. --&gt;            &lt;metadata name=&quot;altname&quot; value=&quot;ConstantName&quot;/&gt;            &lt;property name=&quot;applyToPublic&quot; value=&quot;true&quot;/&gt;            &lt;property name=&quot;applyToProtected&quot; value=&quot;true&quot;/&gt;            &lt;property name=&quot;applyToPackage&quot; value=&quot;true&quot;/&gt;            &lt;property name=&quot;applyToPrivate&quot; value=&quot;false&quot;/&gt;            &lt;property name=&quot;format&quot; value=&quot;^([A-Z][A-Za-z0-9_]*|FLAG_.*)$&quot;/&gt;            &lt;message key=&quot;name.invalidPattern&quot;                     value=&quot;Variable &#x27;&#x27;&#123;0&#125;&#x27;&#x27; should be in ALL_CAPS (if it is a constant) or be private (otherwise).&quot;/&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;StaticVariableNameCheck&quot;&gt;            &lt;!-- Validates static, non-final fields against the supplied            expression &quot;^[a-z][a-zA-Z0-9]*_?$&quot;. --&gt;            &lt;metadata name=&quot;altname&quot; value=&quot;StaticVariableName&quot;/&gt;            &lt;property name=&quot;applyToPublic&quot; value=&quot;true&quot;/&gt;            &lt;property name=&quot;applyToProtected&quot; value=&quot;true&quot;/&gt;            &lt;property name=&quot;applyToPackage&quot; value=&quot;true&quot;/&gt;            &lt;property name=&quot;applyToPrivate&quot; value=&quot;true&quot;/&gt;            &lt;property name=&quot;format&quot; value=&quot;^[a-z][a-zA-Z0-9]*_?$&quot;/&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;MemberNameCheck&quot;&gt;            &lt;!-- Validates non-static members against the supplied expression. --&gt;            &lt;metadata name=&quot;altname&quot; value=&quot;MemberName&quot;/&gt;            &lt;property name=&quot;applyToPublic&quot; value=&quot;true&quot;/&gt;            &lt;property name=&quot;applyToProtected&quot; value=&quot;true&quot;/&gt;            &lt;property name=&quot;applyToPackage&quot; value=&quot;true&quot;/&gt;            &lt;property name=&quot;applyToPrivate&quot; value=&quot;true&quot;/&gt;            &lt;property name=&quot;format&quot; value=&quot;^[a-z][a-zA-Z0-9]*$&quot;/&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;MethodNameCheck&quot;&gt;            &lt;!-- Validates identifiers for method names. --&gt;            &lt;metadata name=&quot;altname&quot; value=&quot;MethodName&quot;/&gt;            &lt;property name=&quot;format&quot; value=&quot;(^[a-z][a-zA-Z0-9]*(_[a-zA-Z0-9]+)*$|Void)&quot;/&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;ParameterName&quot;&gt;            &lt;!-- Validates identifiers for method parameters against the              expression &quot;^[a-z][a-zA-Z0-9]*$&quot;. --&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;LocalFinalVariableName&quot;&gt;            &lt;!-- Validates identifiers for local final variables against the              expression &quot;^[a-z][a-zA-Z0-9]*$&quot;. --&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;LocalVariableName&quot;&gt;            &lt;!-- Validates identifiers for local variables against the              expression &quot;^[a-z][a-zA-Z0-9]*$&quot;. --&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;        &lt;/module&gt;        &lt;!-- Type parameters must be either one of the four blessed letters        T, K, V, W, X or else be capital-case terminated with a T,        such as MyGenericParameterT --&gt;        &lt;module name=&quot;ClassTypeParameterName&quot;&gt;            &lt;property name=&quot;format&quot; value=&quot;^(((T|K|V|W|X|R)[0-9]*)|([A-Z][a-z][a-zA-Z]*))$&quot;/&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;MethodTypeParameterName&quot;&gt;            &lt;property name=&quot;format&quot; value=&quot;^(((T|K|V|W|X|R)[0-9]*)|([A-Z][a-z][a-zA-Z]*T))$&quot;/&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;InterfaceTypeParameterName&quot;&gt;            &lt;property name=&quot;format&quot; value=&quot;^(((T|K|V|W|X|R)[0-9]*)|([A-Z][a-z][a-zA-Z]*T))$&quot;/&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;LeftCurly&quot;&gt;            &lt;!-- Checks for placement of the left curly brace (&#x27;&#123;&#x27;). --&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;RightCurly&quot;&gt;            &lt;!-- Checks right curlies on CATCH, ELSE, and TRY blocks are on            the same line. e.g., the following example is fine:            &lt;pre&gt;              if &#123;                ...              &#125; else            &lt;/pre&gt;            --&gt;            &lt;!-- This next example is not fine:            &lt;pre&gt;              if &#123;                ...              &#125;              else            &lt;/pre&gt;            --&gt;            &lt;property name=&quot;option&quot; value=&quot;same&quot;/&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;        &lt;/module&gt;        &lt;!-- Checks for braces around if and else blocks --&gt;        &lt;module name=&quot;NeedBraces&quot;&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;            &lt;property name=&quot;tokens&quot; value=&quot;LITERAL_IF, LITERAL_ELSE, LITERAL_FOR, LITERAL_WHILE, LITERAL_DO&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;UpperEll&quot;&gt;            &lt;!-- Checks that long constants are defined with an upper ell.--&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;FallThrough&quot;&gt;            &lt;!-- Warn about falling through to the next case statement.  Similar to            javac -Xlint:fallthrough, but the check is suppressed if a single-line comment            on the last non-blank line preceding the fallen-into case contains &#x27;fall through&#x27; (or            some other variants that we don&#x27;t publicized to promote consistency).            --&gt;            &lt;property name=&quot;reliefPattern&quot;                      value=&quot;fall through|Fall through|fallthru|Fallthru|falls through|Falls through|fallthrough|Fallthrough|No break|NO break|no break|continue on&quot;/&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;        &lt;/module&gt;        &lt;!-- Checks for over-complicated boolean expressions. --&gt;        &lt;module name=&quot;SimplifyBooleanExpression&quot;/&gt;        &lt;!-- Detects empty statements (standalone &quot;;&quot; semicolon). --&gt;        &lt;module name=&quot;EmptyStatement&quot;/&gt;        &lt;!--        WHITESPACE CHECKS        --&gt;        &lt;module name=&quot;WhitespaceAround&quot;&gt;            &lt;!-- Checks that various tokens are surrounded by whitespace.                 This includes most binary operators and keywords followed                 by regular or curly braces.            --&gt;            &lt;property name=&quot;tokens&quot; value=&quot;ASSIGN, BAND, BAND_ASSIGN, BOR,        BOR_ASSIGN, BSR, BSR_ASSIGN, BXOR, BXOR_ASSIGN, COLON, DIV, DIV_ASSIGN,        EQUAL, GE, GT, LAND, LE, LITERAL_CATCH, LITERAL_DO, LITERAL_ELSE,        LITERAL_FINALLY, LITERAL_FOR, LITERAL_IF, LITERAL_RETURN,        LITERAL_SYNCHRONIZED, LITERAL_TRY, LITERAL_WHILE, LOR, LT, MINUS,        MINUS_ASSIGN, MOD, MOD_ASSIGN, NOT_EQUAL, PLUS, PLUS_ASSIGN, QUESTION,        SL, SL_ASSIGN, SR_ASSIGN, STAR, STAR_ASSIGN&quot;/&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;WhitespaceAfter&quot;&gt;            &lt;!-- Checks that commas, semicolons and typecasts are followed by                 whitespace.            --&gt;            &lt;property name=&quot;tokens&quot; value=&quot;COMMA, SEMI, TYPECAST&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;NoWhitespaceAfter&quot;&gt;            &lt;!-- Checks that there is no whitespace after various unary operators.                 Linebreaks are allowed.            --&gt;            &lt;property name=&quot;tokens&quot; value=&quot;BNOT, DEC, DOT, INC, LNOT, UNARY_MINUS,        UNARY_PLUS&quot;/&gt;            &lt;property name=&quot;allowLineBreaks&quot; value=&quot;true&quot;/&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;NoWhitespaceBefore&quot;&gt;            &lt;!-- Checks that there is no whitespace before various unary operators.                 Linebreaks are allowed.            --&gt;            &lt;property name=&quot;tokens&quot; value=&quot;SEMI, DOT, POST_DEC, POST_INC&quot;/&gt;            &lt;property name=&quot;allowLineBreaks&quot; value=&quot;true&quot;/&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;OperatorWrap&quot;&gt;            &lt;!-- Checks that operators like + and ? appear at newlines rather than                 at the end of the previous line.            --&gt;            &lt;property name=&quot;option&quot; value=&quot;NL&quot;/&gt;            &lt;property name=&quot;tokens&quot; value=&quot;BAND, BOR, BSR, BXOR, DIV, EQUAL,        GE, GT, LAND, LE, LITERAL_INSTANCEOF, LOR, LT, MINUS, MOD,        NOT_EQUAL, PLUS, QUESTION, SL, SR, STAR &quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;OperatorWrap&quot;&gt;            &lt;!-- Checks that assignment operators are at the end of the line. --&gt;            &lt;property name=&quot;option&quot; value=&quot;eol&quot;/&gt;            &lt;property name=&quot;tokens&quot; value=&quot;ASSIGN&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;ParenPad&quot;&gt;            &lt;!-- Checks that there is no whitespace before close parens or after                 open parens.            --&gt;            &lt;property name=&quot;severity&quot; value=&quot;error&quot;/&gt;        &lt;/module&gt;        &lt;module name=&quot;ModifierOrder&quot;/&gt;    &lt;/module&gt;&lt;/module&gt;\n\n屏蔽规则配置文件举例&lt;?xml version=&quot;1.0&quot;?&gt;&lt;!DOCTYPE suppressions PUBLIC        &quot;-//Puppy Crawl//DTD Suppressions 1.1//EN&quot;        &quot;https://checkstyle.org/dtds/configuration_1_3.dtd&quot;&gt;&lt;suppressions&gt;    &lt;!-- suppress all checks in the generated directories --&gt;    &lt;suppress checks=&quot;.*&quot; files=&quot;.+[\\\\/]generated[\\\\/].+\\.java&quot;/&gt;    &lt;suppress checks=&quot;.*&quot; files=&quot;.+[\\\\/]generated-sources[\\\\/].+\\.java&quot;/&gt;    &lt;suppress checks=&quot;.*&quot; files=&quot;.+[\\\\/]generated-test-sources[\\\\/].+\\.java&quot;/&gt;&lt;/suppressions&gt;\n\nmaven dependency-check引入dependnecy-check插件项目中原有的依赖是这样的\n&lt;dependency&gt;    &lt;groupId&gt;io.netty&lt;/groupId&gt;    &lt;artifactId&gt;netty-all&lt;/artifactId&gt;    &lt;version&gt;4.1.41.Final&lt;/version&gt;&lt;/dependency&gt;\n\n&lt;plugin&gt;    &lt;groupId&gt;org.owasp&lt;/groupId&gt;    &lt;artifactId&gt;dependency-check-maven&lt;/artifactId&gt;    &lt;version&gt;$&#123;dependency-check-maven.version&#125;&lt;/version&gt;    &lt;configuration&gt;        &lt;suppressionFiles&gt;            &lt;suppressionFile&gt;src/owasp-dependency-check-suppressions.xml&lt;/suppressionFile&gt;        &lt;/suppressionFiles&gt;        &lt;failBuildOnCVSS&gt;7&lt;/failBuildOnCVSS&gt;        &lt;msbuildAnalyzerEnabled&gt;false&lt;/msbuildAnalyzerEnabled&gt;        &lt;nodeAnalyzerEnabled&gt;false&lt;/nodeAnalyzerEnabled&gt;        &lt;yarnAuditAnalyzerEnabled&gt;false&lt;/yarnAuditAnalyzerEnabled&gt;        &lt;pyDistributionAnalyzerEnabled&gt;false&lt;/pyDistributionAnalyzerEnabled&gt;        &lt;pyPackageAnalyzerEnabled&gt;false&lt;/pyPackageAnalyzerEnabled&gt;        &lt;pipAnalyzerEnabled&gt;false&lt;/pipAnalyzerEnabled&gt;        &lt;pipfileAnalyzerEnabled&gt;false&lt;/pipfileAnalyzerEnabled&gt;        &lt;retireJsAnalyzerEnabled&gt;false&lt;/retireJsAnalyzerEnabled&gt;        &lt;msbuildAnalyzerEnabled&gt;false&lt;/msbuildAnalyzerEnabled&gt;        &lt;mixAuditAnalyzerEnabled&gt;false&lt;/mixAuditAnalyzerEnabled&gt;        &lt;nugetconfAnalyzerEnabled&gt;false&lt;/nugetconfAnalyzerEnabled&gt;        &lt;assemblyAnalyzerEnabled&gt;false&lt;/assemblyAnalyzerEnabled&gt;        &lt;skipSystemScope&gt;true&lt;/skipSystemScope&gt;    &lt;/configuration&gt;    &lt;executions&gt;        &lt;execution&gt;            &lt;goals&gt;                &lt;goal&gt;aggregate&lt;/goal&gt;            &lt;/goals&gt;        &lt;/execution&gt;    &lt;/executions&gt;&lt;/plugin&gt;\n\n然后可以通过mvn clean install verify -DskipTests来检测。这个demo下，会输出\n[ERROR] One or more dependencies were identified with vulnerabilities that have a CVSS score greater than or equal to &#x27;7.0&#x27;: [ERROR] [ERROR] netty-all-4.1.41.Final.jar: CVE-2019-16869(7.5), CVE-2021-37136(7.5), CVE-2020-11612(7.5), CVE-2021-37137(7.5), CVE-2019-20445(9.1), CVE-2019-20444(9.1), CVE-2020-7238(7.5)[ERROR] [ERROR] See the dependency-check report for more details.\n\n实际使用时，由于dependency-check检查相对耗时，一般通过单独的profile来控制开关\n屏蔽CVE漏洞如果出现dependency-check误报或者是评估该漏洞不涉及，可以通过supression file来屏蔽\n屏蔽单一CVE漏洞&lt;suppress&gt;  &lt;notes&gt;&lt;![CDATA[ file name: zookeeper-prometheus-metrics-3.8.0.jar ]]&gt;&lt;/notes&gt;  &lt;sha1&gt;849e8ece2845cb0185d721233906d487a7f1e4cf&lt;/sha1&gt;  &lt;cve&gt;CVE-2021-29425&lt;/cve&gt;&lt;/suppress&gt;\n\n通过文件正则来屏蔽CVE漏洞&lt;suppress&gt;    &lt;notes&gt;CVE-2011-1797 FP, see https://github.com/jeremylong/DependencyCheck/issues/4154&lt;/notes&gt;    &lt;filePath regex=&quot;true&quot;&gt;.*netty-tcnative-boringssl-static.*\\.jar&lt;/filePath&gt;    &lt;cve&gt;CVE-2011-1797g&lt;/cve&gt;&lt;/suppress&gt;\n","tags":["Java"]},{"title":"Java Ping命令心跳探测 InetAddress isReachable分析","url":"/2020/01/12/Java%20Ping%E5%91%BD%E4%BB%A4%E5%BF%83%E8%B7%B3%E6%8E%A2%E6%B5%8B%20InetAddress%20isReachable%E5%88%86%E6%9E%90/","content":"业务需求分析与解决方案在业务场景中，当需要利用ping命令对主机进行心跳探测时，直接在代码中fork进程执行ping命令虽然可行，但这种方法开销较大，并且处理流程易出错，与使用标准库相比缺乏优雅性。因此，本文探讨了使用Java的InetAddress类的isReachable方法作为替代方案。\n根据资料指出，Java的InetAddress类在root用户权限下通过执行ping命令进行探测，在非root用户权限下则通过访问TCP端口7进行探测。为验证这一点，本文撰写了相应的demo代码并进行了测试（详见：GitHub - heart-beat）。\nimport lombok.extern.slf4j.Slf4j;import java.net.InetAddress;@Slf4jpublic class PingTestMain &#123;    public static void main(String[] args) throws Exception &#123;        String testIp = System.getProperty(&quot;TestIp&quot;);        InetAddress inetAddress = InetAddress.getByName(testIp);        boolean addressReachable = inetAddress.isReachable(500);        log.info(&quot;address is reachable is &#123;&#125;&quot;, addressReachable);    &#125;&#125;\n测试实验root用户下执行程序\njava程序打印结果也是true\n在普通用户权限下的测试\n此时可以看到,我们的客户端程序向目标tcp7端口发送了一个报文,虽然java程序打印结果为true,但是因为收到了RST包导致的.在当今的网络安全要求下,7端口往往不会开放\n在目标网络屏蔽TCP端口7的情况下执行程序iptables -A INPUT -p tcp --dport 7 -j DROP\n\n发送的报文没有收到RST包,此时java程序返回false.不是我们预期的结果\n普通用户权限下携带特权的测试进一步的研究发现，Java程序发送ping命令需要创建raw socket，这要求程序具有root权限或cap_net_raw权限。赋予Java程序创建raw socket的权限后重新测试，发现程序能够正确发送ping命令，达到预期效果。\nsetcap cap_net_raw+ep /usr/java/jdk-13.0.1/bin/java\n发现如下报错\njava: error while loading shared libraries: libjli.so: cannot open shared object file: No such file or directory\n使用https://askubuntu.com/questions/334365/how-to-add-a-directory-to-linker-command-line-in-linux规避添加so文件权限\n随后抓包,发现还是发送了ping命令,达到了我们预期的效果\n总结本文通过一系列测试得出结论，root用户权限下的Java程序会使用ping命令进行探测。若普通用户不具备相应权限，则会尝试探测TCP端口7，但在安全组未开启该端口的情况下会导致预期结果不一致。推荐赋予java程序特权,使得InetAddress类能够使用ping命令进行探测\n","tags":["Java"]},{"title":"Java 项目结构组织","url":"/2023/10/08/Java%20%E9%A1%B9%E7%9B%AE%E7%BB%93%E6%9E%84%E7%BB%84%E7%BB%87/","content":"简单的library对于简单的library来说，我更推荐将所有的文件都放在同一个package下面，如简单的client封装\npackage:com.xxx.yyy/|-- XxClient|-- XxDTO|-- XxException|-- XxUtil\n\n复杂的SpringBoot项目，负责多个业务模块备注:\n\nxxx、yyy代表大块的业务区分：如用户、订单、支付\naaa、bbb代表小块的业务区分：如(用户的)登录、注册、查询\n\n方案一：多业务模块通过子包来区分，不分子modulemodule视图:\nexample(maven artifactId: example-parent)/|-- example-service(业务逻辑)|-- example-spring-ignite(依赖spring，常见为中间件client，适配spring模块用于方便单元测试)|-- example-spring-ignite-test(依赖spring，不依赖test-common，spring模块单元测试用)|-- example-starter(启动类)|-- example-test-common(不依赖example-common)|-- example-util(不依赖Spring框架，可选模块，为service与其他spring集成组件共用)\n\n依赖关系图:\ngraph TD\nservice[example-service]\nspringIgnite[example-spring-ignite]\nspringIgniteTest[example-spring-ignite-test]\nstarter[example-starter]\ntestCommon[example-test-common]\nutil[example-util]\n\nstarter --> service\n\nservice --> springIgnite\nservice --> util\nservice -.-> testCommon\n\ntestCommon --> springIgniteTest\n\nspringIgniteTest --> springIgnite\n\nspringIgnite --> util\n\nservice包内视图:\nio.hezhangjian.example/|-- service/|   |-- common/|   |-- module/|   |   |-- aaaModule|   |   |-- bbbModule|   |-- mapper/|   |   |-- aaaMapper|   |   |-- bbbMapper|   |-- repo/|   |   |-- aaaRepo|   |   |-- bbbRepo|   |-- service/|   |   |-- aaaService|   |   |-- bbbService\n\n方案二：根据业务模块拆分子module适用于大型项目，每个业务模块都比较大。\nmodule视图：\nexample(maven artifactId: example-parent)/|-- example-common(可依赖spring模块)|-- example-rest-xxx(xxx功能模块的rest接口)|-- example-rest-yyy(yyy功能模块的rest接口)|-- example-service-xxx(xxx功能的业务逻辑)|-- example-service-yyy(yyy功能的业务逻辑)|-- example-spring-ignite(依赖spring，常见为中间件client，适配spring模块用于方便单元测试)|-- example-spring-ignite-test(依赖spring，不依赖test-common，spring模块单元测试用)|-- example-starter(启动类)|-- example-test-common(不依赖example-common)|-- example-util(不依赖example-common，可选模块，为service、common与其他spring集成组件共用)\n\n依赖关系图:\ngraph TD\ncommon[example-common]\nrest-xxx[example-rest-xxx]\nrest-yyy[example-rest-yyy]\nservice-xxx[example-service-xxx]\nservice-yyy[example-service-yyy]\nspringIgnite[example-spring-ignite]\nspringIgniteTest[example-spring-ignite-test]\nstarter[example-starter]\ntestCommon[example-test-common]\nutil[example-util]\n\nstarter --> rest-xxx\nstarter --> rest-yyy\n\nrest-xxx --> common\nrest-xxx --> service-xxx\n\nrest-yyy --> common\nrest-yyy --> service-yyy\n\nservice-xxx --> common\nservice-xxx --> springIgnite\n\nservice-yyy --> common\nservice-yyy --> util\n\ncommon -.-> testCommon\n\ntestCommon --> springIgniteTest\n\nspringIgniteTest --> springIgnite\n\nspringIgnite --> util\n\n关于service模块引不引用rest模块的DTO，我的想法：\n如果确实service模块和rest模块DTO差距比较大，可以拆分做转换，如果差距很小&#x2F;没有差距，可以复用同一个DTO，放在service模块或者更底层的依赖。\nservice-xxx包内视图:\nio.hezhangjian.example.service/|-- xxx/|   |-- common/|   |-- module/|   |   |-- aaaModule|   |   |-- bbbModule|   |-- mapper/|   |   |-- aaaMapper|   |   |-- bbbMapper|   |-- repo/|   |   |-- aaaRepo|   |   |-- bbbRepo|   |-- service/|   |   |-- aaaService|   |   |-- bbbService\n\n\n import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs';\tmermaid.initialize({startOnLoad: true, flowchart: {curve: 'linear'}}); ","tags":["Java"]},{"title":"Java依赖不同版本冲突解决方案之shade包","url":"/2020/12/30/Java%E4%BE%9D%E8%B5%96%E4%B8%8D%E5%90%8C%E7%89%88%E6%9C%AC%E5%86%B2%E7%AA%81%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E4%B9%8Bshade%E5%8C%85/","content":"我们在很多场景下会碰到java包冲突的问题：\n\n代码由第三方开发，无法对包名或依赖做管控\n跑在同一个进程里的代码，更新步调不一致。比如底层sdk，jvm agent。这些组件更新频率较低\n\n最出名的解决路数还是类加载机制，诸如flink，osgi都给我们提供了很多方案，这些方案都非常重型。在代码可信任的情况下，其中有一个很轻量级的解决方案就是maven-shade包。\n举个例子，比方说我想在java agent中打印日志，但是又不希望和业务代码中的log4j等冲突，agent里依赖的pom文件是这样子的:\n&lt;dependencies&gt;       &lt;dependency&gt;           &lt;groupId&gt;org.slf4j&lt;/groupId&gt;           &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;           &lt;version&gt;1.7.30&lt;/version&gt;       &lt;/dependency&gt;       &lt;dependency&gt;           &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;           &lt;artifactId&gt;log4j-api&lt;/artifactId&gt;           &lt;version&gt;2.13.3&lt;/version&gt;       &lt;/dependency&gt;       &lt;dependency&gt;           &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;           &lt;artifactId&gt;log4j-core&lt;/artifactId&gt;           &lt;version&gt;2.13.3&lt;/version&gt;       &lt;/dependency&gt;       &lt;dependency&gt;           &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;           &lt;artifactId&gt;log4j-slf4j-impl&lt;/artifactId&gt;           &lt;version&gt;2.13.3&lt;/version&gt;       &lt;/dependency&gt;       &lt;dependency&gt;           &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;           &lt;artifactId&gt;log4j-jcl&lt;/artifactId&gt;           &lt;version&gt;2.13.3&lt;/version&gt;       &lt;/dependency&gt;   &lt;/dependencies&gt;\n\n这里我们log4j,slf4j可能用的版本太高或者太低，我们就可以通过打shade包的方式修改log4j和slf4j的包名,避免和业务冲突\n&lt;plugin&gt;                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;                &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt;                &lt;version&gt;3.2.4&lt;/version&gt;                &lt;executions&gt;                    &lt;execution&gt;                        &lt;phase&gt;package&lt;/phase&gt;                        &lt;goals&gt;                            &lt;goal&gt;shade&lt;/goal&gt;                        &lt;/goals&gt;                        &lt;configuration&gt;                            &lt;artifactSet&gt;                                &lt;includes&gt;                                    &lt;include&gt;org.slf4j:slf4j-api&lt;/include&gt;                                    &lt;include&gt;org.apache.logging.log4j:log4j-api&lt;/include&gt;                                    &lt;include&gt;org.apache.logging.log4j:log4j-core&lt;/include&gt;                                    &lt;include&gt;org.apache.logging.log4j:log4j-slf4j-impl&lt;/include&gt;                                    &lt;include&gt;org.apache.logging.log4j:log4j-jcl&lt;/include&gt;                                &lt;/includes&gt;                            &lt;/artifactSet&gt;                            &lt;filters&gt;                                &lt;filter&gt;                                    &lt;artifact&gt;*:*&lt;/artifact&gt;                                    &lt;excludes&gt;                                        &lt;exclude&gt;META-INF/*.SF&lt;/exclude&gt;                                        &lt;exclude&gt;META-INF/*.DSA&lt;/exclude&gt;                                        &lt;exclude&gt;META-INF/*.RSA&lt;/exclude&gt;                                    &lt;/excludes&gt;                                &lt;/filter&gt;                            &lt;/filters&gt;                            &lt;relocations&gt;                                &lt;relocation&gt;                                    &lt;pattern&gt;org.slf4j&lt;/pattern&gt;                                    &lt;shadedPattern&gt;com.github.hezhangjian.org.slf4j&lt;/shadedPattern&gt;                                &lt;/relocation&gt;                                &lt;relocation&gt;                                    &lt;pattern&gt;org.apache.logging&lt;/pattern&gt;                                    &lt;shadedPattern&gt;com.github.hezhangjian.org.apache.logging&lt;/shadedPattern&gt;                                &lt;/relocation&gt;                            &lt;/relocations&gt;                        &lt;/configuration&gt;                    &lt;/execution&gt;                &lt;/executions&gt;            &lt;/plugin&gt;\n\n通过上面的配置，artifactSet选择要修改的pom依赖，通过relocation修改包名，达到不冲突的效果。mvn clean package 后查看效果\n\n可以发现，包名已经被修改完成,达到了避免冲突的目的。\n","tags":["Java"]},{"title":"java指标统计方案及代码","url":"/2021/08/10/Java%E6%8C%87%E6%A0%87%E7%BB%9F%E8%AE%A1%E6%96%B9%E6%A1%88%E5%8F%8A%E4%BB%A3%E7%A0%81/","content":"java 根据线程统计CPU设计思路java的ThreadMXBean可以获取每个线程CPU执行的nanoTime，那么可以以这个为基础，除以中间系统经过的纳秒数，就获得了该线程的CPU占比\n编码首先，我们定义一个结构体，用来存放一个线程上次统计时的纳秒数和当时的系统纳秒数\nimport lombok.Data;@Datapublic class ThreadMetricsAux &#123;    private long usedNanoTime;    private long lastNanoTime;    public ThreadMetricsAux() &#123;    &#125;    public ThreadMetricsAux(long usedNanoTime, long lastNanoTime) &#123;        this.usedNanoTime = usedNanoTime;        this.lastNanoTime = lastNanoTime;    &#125;    &#125;\n\n然后我们在SpringBoot中定义一个定时任务，它将定时地统计计算每个线程的CPU信息，并输出到MeterRegistry，当你调用SpringActuator的接口时，你将能获取到这个指标。\nimport com.google.common.util.concurrent.AtomicDouble;import io.micrometer.core.instrument.Meter;import io.micrometer.core.instrument.MeterRegistry;import io.micrometer.core.instrument.Tags;import lombok.extern.slf4j.Slf4j;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.scheduling.annotation.Scheduled;import org.springframework.stereotype.Service;import java.lang.management.ManagementFactory;import java.lang.management.ThreadInfo;import java.lang.management.ThreadMXBean;import java.util.HashMap;@Slf4j@Servicepublic class ThreadMetricService &#123;    @Autowired    private MeterRegistry meterRegistry;    private final ThreadMXBean threadBean = ManagementFactory.getThreadMXBean();    private final HashMap&lt;Long, ThreadMetricsAux&gt; map = new HashMap&lt;&gt;();    private final HashMap&lt;Meter.Id, AtomicDouble&gt; dynamicGauges = new HashMap&lt;&gt;();    /**     * one minutes     */    @Scheduled(cron = &quot;0 * * * * ?&quot;)    public void schedule() &#123;        final long[] allThreadIds = threadBean.getAllThreadIds();        for (long threadId : allThreadIds) &#123;            final ThreadInfo threadInfo = threadBean.getThreadInfo(threadId);            if (threadInfo == null) &#123;                continue;            &#125;            final long threadNanoTime = getThreadCPUTime(threadId);            if (threadNanoTime == 0) &#123;                // 如果threadNanoTime为0，则识别为异常数据，不处理，并清理历史数据                map.remove(threadId);            &#125;            final long nanoTime = System.nanoTime();            ThreadMetricsAux oldMetrics = map.get(threadId);            // 判断是否有历史的metrics信息            if (oldMetrics != null) &#123;                // 如果有，则计算CPU信息并上报                double percent = (double) (threadNanoTime - oldMetrics.getUsedNanoTime()) / (double) (nanoTime - oldMetrics.getLastNanoTime());                handleDynamicGauge(&quot;jvm.threads.cpu&quot;, &quot;threadName&quot;, threadInfo.getThreadName(), percent);            &#125;            map.put(threadId, new ThreadMetricsAux(threadNanoTime, nanoTime));        &#125;    &#125;    // meter Gauge相关代码    private void handleDynamicGauge(String meterName, String labelKey, String labelValue, double snapshot) &#123;        Meter.Id id = new Meter.Id(meterName, Tags.of(labelKey, labelValue), null, null, Meter.Type.GAUGE);        dynamicGauges.compute(id, (key, current) -&gt; &#123;            if (current == null) &#123;                AtomicDouble initialValue = new AtomicDouble(snapshot);                meterRegistry.gauge(key.getName(), key.getTags(), initialValue);                return initialValue;            &#125; else &#123;                current.set(snapshot);                return current;            &#125;        &#125;);    &#125;    long getThreadCPUTime(long threadId) &#123;        long time = threadBean.getThreadCpuTime(threadId);        /* thread of the specified ID is not alive or does not exist */        return time == -1 ? 0 : time;    &#125;&#125;\n\n其他配置依赖配置pom文件中\n&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;io.micrometer&lt;/groupId&gt;    &lt;artifactId&gt;micrometer-registry-prometheus&lt;/artifactId&gt;&lt;/dependency&gt;\n\nPrometheus接口配置application.yaml中\nmanagement:  endpoints:    web:      exposure:        include: health,info,prometheus\n\n效果通过curl命令调用curl localhost:20001/actuator/prometheus|grep cpu\njvm_threads_cpu&#123;threadName=&quot;RMI Scheduler(0)&quot;,&#125; 0.0jvm_threads_cpu&#123;threadName=&quot;http-nio-20001-exec-10&quot;,&#125; 0.0jvm_threads_cpu&#123;threadName=&quot;Signal Dispatcher&quot;,&#125; 0.0jvm_threads_cpu&#123;threadName=&quot;Common-Cleaner&quot;,&#125; 3.1664628758074733E-7jvm_threads_cpu&#123;threadName=&quot;http-nio-20001-Poller&quot;,&#125; 7.772143763853949E-5jvm_threads_cpu&#123;threadName=&quot;http-nio-20001-Acceptor&quot;,&#125; 8.586978352515361E-5jvm_threads_cpu&#123;threadName=&quot;DestroyJavaVM&quot;,&#125; 0.0jvm_threads_cpu&#123;threadName=&quot;Monitor Ctrl-Break&quot;,&#125; 0.0jvm_threads_cpu&#123;threadName=&quot;AsyncHttpClient-timer-8-1&quot;,&#125; 2.524386571545477E-4jvm_threads_cpu&#123;threadName=&quot;Attach Listener&quot;,&#125; 0.0jvm_threads_cpu&#123;threadName=&quot;scheduling-1&quot;,&#125; 1.2269694160981585E-4jvm_threads_cpu&#123;threadName=&quot;container-0&quot;,&#125; 1.999795692406262E-6jvm_threads_cpu&#123;threadName=&quot;http-nio-20001-exec-9&quot;,&#125; 0.0jvm_threads_cpu&#123;threadName=&quot;http-nio-20001-exec-7&quot;,&#125; 0.0jvm_threads_cpu&#123;threadName=&quot;http-nio-20001-exec-8&quot;,&#125; 0.0jvm_threads_cpu&#123;threadName=&quot;http-nio-20001-exec-5&quot;,&#125; 0.0jvm_threads_cpu&#123;threadName=&quot;Notification Thread&quot;,&#125; 0.0jvm_threads_cpu&#123;threadName=&quot;http-nio-20001-exec-6&quot;,&#125; 0.0jvm_threads_cpu&#123;threadName=&quot;http-nio-20001-exec-3&quot;,&#125; 0.0jvm_threads_cpu&#123;threadName=&quot;http-nio-20001-exec-4&quot;,&#125; 0.0jvm_threads_cpu&#123;threadName=&quot;Reference Handler&quot;,&#125; 0.0jvm_threads_cpu&#123;threadName=&quot;http-nio-20001-exec-1&quot;,&#125; 0.0012674719289349648jvm_threads_cpu&#123;threadName=&quot;http-nio-20001-exec-2&quot;,&#125; 6.542541277148053E-5jvm_threads_cpu&#123;threadName=&quot;RMI TCP Connection(idle)&quot;,&#125; 1.3998786340454562E-6jvm_threads_cpu&#123;threadName=&quot;Finalizer&quot;,&#125; 0.0jvm_threads_cpu&#123;threadName=&quot;Catalina-utility-2&quot;,&#125; 7.920883054498174E-5jvm_threads_cpu&#123;threadName=&quot;RMI TCP Accept-0&quot;,&#125; 0.0jvm_threads_cpu&#123;threadName=&quot;Catalina-utility-1&quot;,&#125; 6.80101662787773E-5\n\nJava计算磁盘使用率https://support.huaweicloud.com/bestpractice-bms/bms_bp_2009.html\n华为云文档上的材料值得学习。\n翻阅资料\nhttps://www.kernel.org/doc/Documentation/ABI/testing/procfs-diskstats13 - time spent doing I/Os (ms)\n\n这就意味着如果我想统计一个磁盘在一定周期内的利用率，只需要对这两个数字做差，除以统计的间隔，即就是这段时间内磁盘的利用率\ncat /proc/diskstats 253       0 vda 24046 771 2042174 180187 20689748 21411881 527517532 18028256 0 14610513 18201352 253       1 vda1 23959 771 2038022 180153 20683957 21411881 527517532 18028066 0 14610312 18201129\n\n样例代码\npackage com.github.hezhangjian.demo.metrics;import com.github.hezhangjian.demo.base.module.ShellResult;import com.github.hezhangjian.demo.base.util.LogUtil;import com.github.hezhangjian.demo.base.util.ShellUtil;import com.github.hezhangjian.demo.base.util.StringUtil;import lombok.extern.slf4j.Slf4j;import java.util.concurrent.Executors;import java.util.concurrent.ScheduledExecutorService;import java.util.concurrent.TimeUnit;/** * @author hezhangjian */@Slf4jpublic class DiskUtilizationMetrics &#123;    private static final ScheduledExecutorService scheduledExecutor = Executors.newSingleThreadScheduledExecutor();    private static long lastTime = -1;    public static void main(String[] args) &#123;        LogUtil.configureLog();        String diskName = &quot;vda1&quot;;        scheduledExecutor.scheduleAtFixedRate(() -&gt; metrics(diskName), 0, 10, TimeUnit.SECONDS);    &#125;    private static void metrics(String diskName) &#123;        //假设统计vda磁盘        String[] cmd = &#123;                &quot;/bin/bash&quot;,                &quot;-c&quot;,                &quot;cat /proc/diskstats |grep &quot; + diskName + &quot;|awk &#x27;&#123;print $13&#125;&#x27;&quot;        &#125;;        ShellResult shellResult = ShellUtil.executeCmd(cmd);        String timeStr = shellResult.getInputContent().substring(0, shellResult.getInputContent().length() - 1);        long time = Long.parseLong(timeStr);        if (lastTime == -1) &#123;            log.info(&quot;first time cal, usage time is [&#123;&#125;]&quot;, time);        &#125; else &#123;            double usage = (time - lastTime) / (double) 10_000;            log.info(&quot;usage time is [&#123;&#125;]&quot;, usage);        &#125;        lastTime = time;    &#125;&#125;\n\n打印CPU使用private static void printCpuUsage() &#123;        final com.sun.management.OperatingSystemMXBean platformMXBean = ManagementFactory.getPlatformMXBean(com.sun.management.OperatingSystemMXBean.class);        double cpuLoad = platformMXBean.getProcessCpuLoad();        System.out.println(cpuLoad);    &#125;\n\n打印线程堆栈private static void printThreadDump() &#123;        final StringBuilder dump = new StringBuilder();        final ThreadMXBean threadMXBean = ManagementFactory.getThreadMXBean();        // 100代表线程堆栈的层级        final ThreadInfo[] threadInfos = threadMXBean.getThreadInfo(threadMXBean.getAllThreadIds(), 100);        for (ThreadInfo threadInfo : threadInfos) &#123;            dump.append(&#x27;&quot;&#x27;);            dump.append(threadInfo.getThreadName());            dump.append(&quot;\\&quot; &quot;);            final Thread.State state = threadInfo.getThreadState();            dump.append(&quot;\\n   java.lang.Thread.State: &quot;);            dump.append(state);            final StackTraceElement[] stackTraceElements = threadInfo.getStackTrace();            for (final StackTraceElement stackTraceElement : stackTraceElements) &#123;                dump.append(&quot;\\n        at &quot;);                dump.append(stackTraceElement);            &#125;            dump.append(&quot;\\n\\n&quot;);        &#125;        System.out.println(dump);    &#125;\n\n打印内存统计信息引入依赖\n&lt;dependency&gt;           &lt;groupId&gt;com.jerolba&lt;/groupId&gt;           &lt;artifactId&gt;jmnemohistosyne&lt;/artifactId&gt;           &lt;version&gt;0.2.3&lt;/version&gt;       &lt;/dependency&gt;\n\nprivate static void printClassHisto() &#123;       Histogramer histogramer = new Histogramer();       MemoryHistogram histogram = histogramer.createHistogram();       HistogramEntry arrayList = histogram.get(&quot;java.util.ArrayList&quot;);       System.out.println(arrayList.getInstances());       System.out.println(arrayList.getSize());       for (HistogramEntry entry : histogram) &#123;           System.out.println(entry);       &#125;   &#125;\n\n打印死锁javadoc中指出，这是一个开销较大的操作\nprivate static void printDeadLock() &#123;       final ThreadMXBean threadMXBean = ManagementFactory.getThreadMXBean();       final long[] deadlockedThreads = threadMXBean.findDeadlockedThreads();       for (long deadlockedThread : deadlockedThreads) &#123;           final ThreadInfo threadInfo = threadMXBean.getThreadInfo(deadlockedThread);           System.out.println(threadInfo + &quot;deadLocked&quot;);       &#125;   &#125;\n","tags":["Java"]},{"title":"java日志打印心得","url":"/2024/04/09/Java%E6%97%A5%E5%BF%97%E6%89%93%E5%8D%B0%E5%BF%83%E5%BE%97/","content":"对于一个组件来说，日志打印常见的有三种选择：\n\n不打印日志，只提供回调函数。将打印日志还是忽略的权利交给组件的使用者\n可以由使用者设置一些参数，但组件自己管理整个日志的生命周期\n适配生态内的日志框架，组件打印日志，但将输出的控制权控制反转给使用者\n\njava生态slf4j已经成为事实上的标准，像Apache Ignite在最开始的时候也将日志作为自己的Spi定义，是向着2来发展的，但在Ignite3版本也去掉。Go生态由于去没有这样的标准，很多library只能选择2，导致引入了一个go library，它的日志会怎么出来，对于使用者来说是一个未知数。\njava生态的基本原则如下：\n\nlibrary，不会独立部署的组件，只引入slf4j-api，不引入具体的实现，可以在单元测试里面引入某个实现，用于测试打印日志。\n简单的sdk不打印日志，复杂的sdk可以打印一些关键日志，但QPS级别的日志不要打印，不要替用户做选择。\n\n\n如果在一个高度一致的团队内，可以无视上面两条\n\n","tags":["Java","log"]},{"title":"Java时间相关类转换","url":"/2024/03/28/Java%E6%97%B6%E9%97%B4%E7%9B%B8%E5%85%B3%E7%B1%BB%E8%BD%AC%E6%8D%A2/","content":"\n","tags":["Java"]},{"title":"java进行数据库操作的并发控制","url":"/2023/12/25/Java%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E5%BA%93%E6%93%8D%E4%BD%9C%E7%9A%84%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6/","content":"在现代应用编码中，从数据库里面find出来，进行一些业务逻辑操作，最后再save回去。即：\nPerson person = personRepo.findById(id);person.setAge(18);personRepo.save(person);\n\n但是这样的业务操作，如果一个线程修改年龄，另一个线程修改昵称，最后save回去，可能会导致年龄&#x2F;昵称某一个的修改被覆盖。\nsequenceDiagram\n    participant A as Thread A\n    participant B as Thread B\n    participant DB as Database\n\n    A->>DB: find person by id\n    Note over A: person.setAge(18)\n    B->>DB: find person by id\n    Note over B: person.setNickname(\"NewName\")\n\n    A->>DB: save person\n    B->>DB: save person\n\n    Note over DB: Potential Overwrite Issue\n\n常见的解决方案有两种\n执行前添加悲观锁通过分布式锁等方式，保证同一时间只有一个线程能够对数据进行修改。\n乐观锁思路实现版本控制是另一种流行的处理并发问题的方法。它通过在每次更新记录时递增版本号来确保数据的一致性。\n这在JPA中，可以通过在field上添加@Version注解来实现，但这也就要求①数据库中必须有version字段，②对于查找后更新类操作，必须使用JPA的save方法来进行更新。\n当然也可以通过update_time来模拟乐观锁实现，这可能需要你在更新的时候添加update_time的条件，并且，update_time在极端场景下，理论正确性没那么严谨。\n import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs';\tmermaid.initialize({startOnLoad: true, flowchart: {curve: 'linear'}}); ","tags":["Java","database"]},{"title":"Kubernetes pod内调用API","url":"/2021/04/13/Kubernetes%20pod%E5%86%85%E8%B0%83%E7%94%A8API/","content":"Kubernetes pod内调用API的流程总体分为以下步骤\n\n创建role\n创建serviceaccount\n绑定role到serviceaccount\n指定pod使用serviceaccount\n\n我们以查pod为例，演示一下整个流程\n创建role# role.yamlapiVersion: rbac.authorization.k8s.io/v1kind: Rolemetadata:  name: role-hzj  namespace: defaultrules:  - apiGroups: [&quot;&quot;]    resources: [&quot;pods&quot;]    verbs: [&quot;get&quot;,&quot;list&quot;]\n\nkubectl apply -f role.yaml\n\n创建serviceaccount# serviceaccount.yamlapiVersion: v1kind: ServiceAccountmetadata:  name: serviceaccount-hzj  namespace: default\n\nkubectl apply -f serviceaccount.yaml\n\n绑定role# rolebinding.yamlapiVersion: rbac.authorization.k8s.io/v1kind: RoleBindingmetadata:  name: rolebinding-hzj  namespace: defaultsubjects:  - kind: ServiceAccount    name: serviceaccount-hzj    namespace: defaultroleRef:  kind: Role  name: role-hzj  apiGroup: rbac.authorization.k8s.io\n\nkubectl apply -f rolebinding.yaml\n\n部署pod进行测试部署一个zookeeper进行测试手上刚好有zookeeper的模板文件\napiVersion: apps/v1kind: Deploymentmetadata:  name: zookeeper  labels:    app: zookeeperspec:  replicas: 1  selector:    matchLabels:      app: zookeeper  template:    metadata:      labels:        app: zookeeper    spec:      hostNetwork: true      dnsPolicy: ClusterFirstWithHostNet      containers:      - name: zookeeper        image: ttbb/zookeeper:stand-alone        imagePullPolicy: IfNotPresent        resources:          limits:            memory: 2G            cpu: 1000m          requests:            memory: 2G            cpu: 1000m        env:        - name: NODE_NAME          valueFrom:            fieldRef:                fieldPath: spec.nodeName        - name: POD_NAME          valueFrom:            fieldRef:                fieldPath: metadata.name        - name: PS1          value: &#x27;[\\u@zookeeper@\\W]\\$ &#x27;\n\n\n\n调用API# Point to the internal API server hostnameAPISERVER=https://kubernetes.default.svc# Path to ServiceAccount tokenSERVICEACCOUNT=/var/run/secrets/kubernetes.io/serviceaccount# Read this Pod&#x27;s namespaceNAMESPACE=$(cat $&#123;SERVICEACCOUNT&#125;/namespace)# Read the ServiceAccount bearer tokenTOKEN=$(cat $&#123;SERVICEACCOUNT&#125;/token)# Reference the internal certificate authority (CA)CACERT=$&#123;SERVICEACCOUNT&#125;/ca.crt# Explore the API with TOKENcurl --cacert $&#123;CACERT&#125; --header &quot;Authorization: Bearer $&#123;TOKEN&#125;&quot; -X GET $&#123;APISERVER&#125;/apicurl --cacert $&#123;CACERT&#125; --header &quot;Authorization: Bearer $&#123;TOKEN&#125;&quot; -X GET $&#123;APISERVER&#125;/api/v1/namespaces/default/pods\n\n\n发现这里，调用后面的api，403错误。第一个api不报错，是因为该接口不需要鉴权。\n修改pod对应的serviceaccount让我们修改部署模板对应的ServiceAccountName，注入权限。在pod的spec下，设置serviceAccountName\n\n修改部署模板重启后调用api正常再次尝试上述命令，api结果返回正常\n\n","tags":["Kubernetes"]},{"title":"kubernetes容器获取IP地址","url":"/2023/01/06/Kubernetes%E5%AE%B9%E5%99%A8%E8%8E%B7%E5%8F%96IP%E5%9C%B0%E5%9D%80/","content":"kubernetes中容器获取IP地址是一个常见的需求，常见的有两种获取IP地址的方式\nkubernetes环境变量注入通过在部署时，container下的env中配置如下yaml\n- name: POD_IP  valueFrom:    fieldRef:      apiVersion: v1      fieldPath: status.podIP\n\n进入容器就可以根据环境变量获取到容器IP\n# echo $POD_IP172.17.0.2\n\n通过shell脚本获取通过ip命令（推荐）# ip addr show eth0 | grep &quot;inet\\b&quot; | awk &#x27;&#123;print $2&#125;&#x27; | cut -d/ -f1172.17.0.2\n\n注意这里一定要用inet\\b，不要用inet。使用inet的话，在Ipv6双栈场景下会因为匹配到inet6获取到错误的结果, Ipv6双栈场景下ip命令的部分输出结果如下图所示\ninet 172.17.0.2/16 brd 172.17.255.255 scope global eth0inet6 fe80::ffff prefixlen 64 scopeid 0x20&lt;lin&gt;\n\n通过ifconfig命令（不推荐）不推荐使用ifconfig命令的原因是，这个命令已经废弃，将会逐步删除\nifconfig eth0 | grep &#x27;inet\\b&#x27; | awk &#x27;&#123;print $2&#125;&#x27; | cut -d/ -f1\n\n同样需要使用inet\\b，不要使用inet\nTLDR优先配置如下yaml进行环境变量注入，其次使用ip addr show eth0 | grep “inet\\b” | awk ‘{print $2}’ | cut -d&#x2F; -f1命令获取\n- name: POD_IP  valueFrom:    fieldRef:      apiVersion: v1      fieldPath: status.podIP\n","tags":["Kubernetes"]},{"title":"lvs 性能手册","url":"/2022/08/01/LVS%20%E6%80%A7%E8%83%BD%E6%89%8B%E5%86%8C/","content":"lvs是做什么的lvs通常用做tcp&#x2F;udp协议的四层负载均衡\n\n相比也可以用于四层负载的Nginx组件，Lvs因为运行在内核态，性能高是它的主要优势，同样，因为运行在内核态中，无法像Nginx那样，对四层的tls做卸载等动作。\nlvs性能相关指标(用户视角)客户端的连接数\nUDP模式下，按连接超时时间计算（根据业务需求决定）。可通过ipvsadm -l --timeout来查看udp超时时间\nTCP模式下，即为tcp连接数\n\n客户端请求流量即client与lvs、lvs与RS之间交互的流量\n客户端请求平均包大小即client与lvs、lvs与RS之间的平均包大小\nlvs性能相关参数会话超时时间查看ipvsadm -l --timeout\n\n修改ipvsadm --set $&#123;tcptimeout&#125; $&#123;tcpfintimeout&#125; $&#123;udptimeout&#125;\n\nvm conntrack最大个数查看sysctl -a |grep net.netfilter.nf_conntrack_max\n\n查看当前nf_conntrack个数# 方式一conntrack -C# 方式二cat /proc/net/nf_conntrack | wc -l\n\n修改sysctl -w net.netfilter.nf_conntrack_max=1024\n\nhashsize什么是hashsizehashsize也就是nf_conntrack_buckets，如果不手动指定。linux会根据机器的内存计算。如果要支持海量的nf_conntrack，则可以适当调大。\n  // nf_conntrack_core.c  nf_conntrack_htable_size\t= (((nr_pages &lt;&lt; PAGE_SHIFT) / 16384)\t   / sizeof(struct hlist_head));if (BITS_PER_LONG &gt;= 64 &amp;&amp;    nr_pages &gt; (4 * (1024 * 1024 * 1024 / PAGE_SIZE)))\tnf_conntrack_htable_size = 262144;else if (nr_pages &gt; (1024 * 1024 * 1024 / PAGE_SIZE))\tnf_conntrack_htable_size = 65536;if (nf_conntrack_htable_size &lt; 1024)\tnf_conntrack_htable_size = 1024;\n\nhlist_head的大小在64位的机器下大小为16\n查看cat /sys/module/nf_conntrack/parameters/hashsize\n\n修改 （方式一）echo 65536 &gt; /sys/module/nf_conntrack/parameters/hashsize\n\n修改（方式二）永久生效# exmaple file, you can modify this config if exists. File name doesn&#x27;t matter.# 样例文件，你可以修改已存在的这个文件。文件名称并不重要。touch /etc/modprobe.d/lvs.confecho &quot;options nf_conntrack hashsize=65536&quot; &gt;&gt; /etc/modprobe.d/lvs.conf# then you need reboot# 需要重试来使配置生效\n\n文件句柄数查看ulimit -n\n\n修改不同的linux发行版，修改方式不太一样，以RedHat为例\nnum=`ulimit -n`sed -i &quot;s|$num|65536|g&quot; /etc/security/limits.d/*-nofile.conf\n\nlvs性能瓶颈虚拟机内存contnrack使用slab分配内存，可以通过slabtop命令查看nf_conntrack模块占用的内存。当连接数较高时，Lvs的内存瓶颈在于会话管理。\nconntrack最大理论内存占用为\nmax_mem_used = conntrack * max * sizeof (struct nf_conntrack) + conntrack_buckets * sizeof (struct list_head)\n\n使用如下python代码计算\nimport ctypes# 这个是nf_conntrack的动态库所在路径# libnetfilter git地址 git://git.netfilter.org/libnetfilter_conntrackLIBNETFILTER_CONNTRACK = &#x27;/usr/lib/aarch64-linux-gnu/libnetfilter_conntrack.so.3.7.0&#x27;nfct = ctypes.CDLL(LIBNETFILTER_CONNTRACK)print(&quot;max size of struct nf_conntrack:&quot;)print(nfct.nfct_maxsize())print(&quot;sizeof(struct list_head):&quot;)print(ctypes.sizeof(ctypes.c_void_p) * 2)\n\n其中nfct_maxsize出自于git://git.netfilter.org/libnetfilter_conntrack中的src/conntrack/api.c\n/** * nfct_maxsize - return the maximum size in bytes of a conntrack object */\n\n在如下操作系统下\nuname -a&gt; Linux primary 5.4.0-122-generic #138-Ubuntu SMP Wed Jun 22 15:05:39 UTC 2022 aarch64 aarch64 aarch64 GNU/Linux\n\n以100万conntrack_max，65536buckets为例，占用的内存为\n1_000_000 * 392 + 65536 * 16 约等于 373.84 + 1 为374M内存\n网卡流量最大进出带宽。在云上，通常由云厂商限制。如果你将lvs上面的浮动Ip通过EIP的方式暴露出去（这很常见），还需要考虑EIP自身的带宽\n网卡进出包个数（PPS)最大进出包个数\n虚拟机能支持的最大网络连接数ECS上可以支持的最大网络连接数。在云上，通常由云厂商限制\nLvs监控&amp;扩容cpu使用率可在超过百分之80的时候告警。处理方式：\n\n如果内存还没有到达瓶颈，可以通过扩大hashsize的方式，降低hash链上元素的个数，减少匹配消耗的cpu\n如果内存水位也较高。对CPU进行扩容\n\n内存使用率可在超过内存容量百分之80的时候告警。处理方式：扩容内存\nconntrack个数通过conntrack -C或cat /proc/net/nf_conntrack | wc -l, 定期进行统计，使用sysctl -w net.netfilter.nf_conntrack_max进行扩容\n网卡流量、网卡进出包个数可以利用云厂商的监控或nicstat命令查看。处理方式：扩容网卡\n最大网络连接数可以利用云厂商的监控或netstat -an|egrep &quot;tcp|udp&quot;|grep -v &quot;LISTEN&quot;|wc -l或ss -tun state all | grep -v LISTEN | wc -l查看。处理方式：扩容ECS规格\nEIP带宽通过云厂商的指标来监控。处理方式，扩容EIP的BGP带宽\n","tags":["LVS"]},{"title":"LVS persistent timeout和connection timeout解析","url":"/2021/03/19/LVS%20persistent%20timeout%E5%92%8Cconnection%20timeout%E8%A7%A3%E6%9E%90/","content":"两个超时的注释首先看一下一下ipvsadm -h对这两个参数的注释\npersistent timeout--persistent  -p [timeout]     persistent serviceSpecify that a virtual service is persistent. If this option is specified, multiple requests from a client are redirected to the same real server selected for the first request. Optionally, the timeout of persistent sessions may be specified given in seconds, otherwise the default of 300 seconds will be used. This option may be used in conjunction with protocols such as SSL or FTP where it is important that clients consistently connect with the same real server.\n\n说明这个VS是否是持久的。如果配置了这个选项，来自同一个客户端的链接（这里注意：这里的同一个客户端指的是同一个IP）会转发向相同的服务器。注释中特意提到了FTP协议。我查阅了一下资料，可能像FTP协议这种，客户端通过21端口打开控制连接，再通过20端口打开数据连接，这种协议，要求来自同一个客户端ip，不同端口的请求也送向同一个服务器，估计是这个参数存在的核心原因。如果是现在的系统，比如k8s使用ipvs，这个参数是完全没必要配置的\nconnection timeout--set tcp tcpfin udpChange the timeout values used for IPVS connections. This command always takes 3 parameters, representing the timeout values (in seconds) for TCP sessions, TCP sessions after receiving a FIN packet, and UDP packets, respectively. A timeout value 0 means that the current timeout value of the corresponding entry is preserved.\n\n更改用于ipvs连接的超时值。此命令始终使用3个参数，分别表示tcp会话，接收到FIN包的TCP会话和UDP包的超时值。单位为秒。设置为0并不代表将超时值设置为0，而是保持原有不变。顺便来说，timeout的默认值是900、120、300.\n区别一个以客户端ip为维度，一个以客户端ip+port为维度\n联系：\npersistent值大于等于set时，persistent timeout以persistent的设置为准。\npersistent值小于set时，当set超时，但persistent超时后，会将persistent再次设置为60。只到set超时为止。所以这个时候，真实生效的persistent timeout是(s/60)*60 + p%60 + 60\n\n","tags":["LVS"]},{"title":"linux umask 解析","url":"/2022/11/08/Linux%20umask%20%E8%A7%A3%E6%9E%90/","content":"什么是umask， umask即user file-creation mask. 用来控制最终创建文件的权限。\numask是进程级属性，通常是由login shell设置，可以通过系统调用umask()或者命令umask permission来修改，通过umask命令来查询，linux内核版本4.7之后，还可以通过cat &#x2F;proc&#x2F;self&#x2F;status|grep -i umask 查询，示例如下\nhezhangjian:~/masktest $ umask0022hezhangjian:~/masktest $ umask 0077hezhangjian:~/masktest $ umask0077hezhangjian:~/masktest $ umask 0022hezhangjian:~/masktest $ umask0022hezhangjian:~/masktest $\n\n一般来说，umask的系统默认值在**&#x2F;etc&#x2F;login.defs** 中设置\nhezhangjian:~ $cat /etc/login.defs|grep -i umask#\tUMASK\t\tDefault &quot;umask&quot; value.# UMASK is the default umask value for pam_umask and is used by# 022 is the &quot;historical&quot; value in Debian for UMASK# If USERGROUPS_ENAB is set to &quot;yes&quot;, that will modify this UMASK default valueUMASK\t\t022# Other former uses of this variable such as setting the umask when\n\n\n最常见的默认的umask值是022，目录权限755，文件权限644\n077 的 umask 适用于私有的系统，则其他用户无法读取或写入您的数据。\n\n针对标准函数open来说，最终写入磁盘的权限位是由mode参数和用户的文件创建掩码(umask)执行按位与操作而得到。\n假设当umask为0022时，创建一个具有0666权限的文件，就会进行运算决定文件的最终权限，先对掩码取非，再和指定的权限进行binary-And操作，如图所示\n\n示例代码如下\n#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;#include &lt;fcntl.h&gt;#include &lt;unistd.h&gt;int main(int argc, char *argv[]) &#123;    int fd;    if (argc != 2) &#123;        fprintf(stderr, &quot;usage: %s &lt;file&gt;&quot;, argv[0]);        exit(1);    &#125;    fprintf(stdout, &quot;create file %s&quot;, argv[1]);    fd = open(argv[1], O_WRONLY | O_CREAT | O_TRUNC, 0666);    if (fd == -1) &#123;        perror(&quot;open&quot;);        exit(1);    &#125;    close(fd);&#125;\n\n结果如下，权限644，符合预期\nlltotal 8drwxr-xr-x  2 hezhangjian hezhangjian 4096 Nov  8 06:25 .drwxr-xr-x 15 hezhangjian hezhangjian 4096 Nov  8 06:18 ..-rw-r--r--  1 hezhangjian hezhangjian    0 Nov  8 06:25 my.txt\n","tags":["Linux"]},{"title":"MySQL异步复制中的数据不一致问题","url":"/2024/07/09/MySQL%E5%BC%82%E6%AD%A5%E5%A4%8D%E5%88%B6%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B8%8D%E4%B8%80%E8%87%B4%E9%97%AE%E9%A2%98/","content":"前提Mysql8.0.X版本，且核心配置如下\ngtid_mode=ONbinlog_format=rowslave_skip_errors=all\n\n数据不一致的根本原因在于MySQL在设计上不具备分布式系统的完整语义，这导致主从复制在面对网络分区和延迟时无法保持数据一致性。（又不可能采取全同步的模式，那就变成一个CP系统了）。根据数据冲突的内容，如果是**“不同主键，不触发唯一键约束的数据冲突”**，那么后续很容易可以同步到一致。如果触发了主键或者唯一键的冲突，无法互相同步，场景会变得复杂一些，简而言之，只有当后续的操作可以同时在主&#x2F;备两个数据库中抹平这个差距，数据才能恢复，并且约束越多，抹平也就变得愈困难。举例\n\n仅存在主键约束，数据内容不同，通过下次操作主键(update&#x2F;delete)，则可以恢复\n数据库自增主键（两条数据主键不同），触发了唯一字段约束，后续的操作要同时抹平主键、唯一字段、其他内容才能恢复一致（比如根据相同的条件删除掉这条数据等）\n\n下文将分别以插入为例讨论这几个场景，用红色叉号代表同步延迟或者断开。\n注：由于Mysql主备同步时会将upsert类的sql转换为实际执行的insert、update语句，也就是说upsert的语义在主备同步不稳定&#x2F;切换时，容易丢失。\n不同主键，不触发唯一键约束的数据冲突设想表结构，仅有一个name字段，且name为主键。比如我们先在MysqlA中插入了数据name&#x3D;tt，假设发生了切换，又向MysqlB插入了数据name&#x3D;wtt。\n\n这就导致MysqlA与MysqlB里面的数据存在着不一致，但是一旦同步恢复，数据就会一致。\n\n仅主键约束，内容不一致冲突表结构，拥有两个字段，name为主键，age为字段。\n同样，插入了两条数据，导致冲突。\n\n即使MysqlA和MysqlB之间同步恢复，后续insert语句也会由于主键冲突同步失败。\n\n这种不一致要等到后续对主键进行update操作后，才能恢复一致\n\n包含主键、唯一约束在内的冲突场景主键为数据库自增主键，其中一个库为奇数，另一个库为偶数。同时还有唯一约束name\n\n这时候插入数据，就会导致不一致，并且主键也不相同，由于业务不感知主键，使用不存在则更新的语法也会导致主键不一致。\n\n可以预想到即使恢复同步，MysqlA和MysqlB数据也无法一致。\n\n在这种场景下，任何针对id的SQL操作都无法在双方数据库中成功同步。例如，MysqlB数据库中不存在id为0的记录，而MysqlA中不存在id为1的记录，导致同步操作失败。\n想要恢复一致，可以通过业务唯一约束来删除记录或者是根据业务约束把Mysql主键id也一并更新（不过这很困难，一般这种业务是不会直接操作id的）\n那么可能会有人有疑问，为什么不像之前那样，用name作为唯一主键呢？\n答：业务的需求多种多样，而且如果唯一约束由多个字段组成，使用Mysql自增主键是唯一的选择。\n总结本文探讨了Mysql异步复制模式下的数据不一致问题，容易在什么时候产生，什么时候恢复。总的来说，业务如果只有一个唯一主键，出现不一致的概率更小。如果业务用数据库自增作为主键，同时伴有唯一约束的插入操作（如upsert等），更容易出现长期的不一致。\n","tags":["MySQL"]},{"title":"Mysql是如何隐藏ps命令行中的密码的","url":"/2021/04/26/MySQL%E6%98%AF%E5%A6%82%E4%BD%95%E9%9A%90%E8%97%8Fps%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%AD%E7%9A%84%E5%AF%86%E7%A0%81%E7%9A%84/","content":"参考\nhttp://northernmost.org/blog/how-does-mysql-hide-the-command-line-password-in-ps/index.html\n\n之前就在环境上ps -ef看到过xxxxxx的密码，一直没搞明白怎么回事，今天整理了一下，核心内容均来自于上述连接，作了一些额外的测试和查阅资料。\n测试运行Mysql实例# 自己做的Mysql8的镜像docker run ttbb/mysql:stand-alone\n\n使用密码连接Mysql服务器mysql -u hzj -p Mysql@123 -e &quot;select 1&quot;\n\nps -ef查看[root@91bcbd15a82e mysql]# ps -efUID        PID  PPID  C STIME TTY          TIME CMDroot         1     0  0 07:34 ?        00:00:00 /usr/local/bin/dumb-init bash -vx /opt/sh/mysql/hzj/scripts/start.shroot         8     1  0 07:34 ?        00:00:00 bash -vx /opt/sh/mysql/hzj/scripts/start.shroot        17     1  0 07:34 ?        00:00:00 mysqld --daemonize --user=rootroot        62     8  0 07:34 ?        00:00:00 tail -f /dev/nullroot        63     0  0 07:34 pts/0    00:00:00 bashroot        98    63  0 07:37 pts/0    00:00:00 mysql -h 127.0.0.1 -u hzj -px xxxxxxxroot        99     0  1 07:37 pts/1    00:00:00 bashroot       122    99  0 07:37 pts/1    00:00:00 ps -ef\n\nMysql隐藏密码原理改写了args系统参数，demo如下\n//// Created by 张俭 on 2021/4/26.//#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;string.h&gt;int main(int argc, char *argv[]) &#123;    int i = 0;    pid_t mypid = getpid();    if (argc == 1)        return 1;    printf(&quot;argc = %d and arguments are:\\n&quot;, argc);    for (i; i &lt; argc; i++) &#123;        printf(&quot;%d = %s\\n&quot;, i, argv[i]);    &#125;    fflush(stdout);    sleep(30);    printf(&quot;Replacing first argument with x:es... Now open another terminal and run: ps p %d\\n&quot;, (int)mypid);    memset(argv[1], &#x27;x&#x27;, strlen(argv[1]));    getc(stdin);    return 0;&#125;\n\n编译并运行\ngcc password_hide.c[root@c77dc365cd1a sh]# ./a.out abcdargc = 2 and arguments are:0 = ./a.out1 = abcdReplacing first argument with x:es... Now open another terminal and run: ps p 55\n观测结果，开始看的确有明文密码\n[root@c77dc365cd1a sh]# ps -efUID        PID  PPID  C STIME TTY          TIME CMDroot         1     0  0 07:49 pts/0    00:00:00 bashroot        32     0  0 07:51 pts/1    00:00:00 bashroot        64     1  0 07:56 pts/0    00:00:00 ./a.out abcdroot        66    32  0 07:56 pts/1    00:00:00 ps -ef\n经过30秒后，已经被复写\n[root@c77dc365cd1a sh]# ps p 55  PID TTY      STAT   TIME COMMAND   55 pts/0    S+     0:00 ./a.out xxxx\nMysql源码地址mysql-server&#x2F;client&#x2F;mysql.cc line 2054\nif (argument) &#123;  char *start = argument;  my_free(opt_password);  opt_password = my_strdup(PSI_NOT_INSTRUMENTED, argument, MYF(MY_FAE));  while (*argument) *argument++ = &#x27;x&#x27;;  // Destroy argument  if (*start) start[1] = 0;  tty_password = false;&#125; else  tty_password = true;\n\nPS: 后面，我还在OSX上用go程序尝试修改参数，估摸go程序的args传入是值拷贝，修改完成之后args没有生效，看来这个黑科技只有c程序能使用呀。\n","tags":["MySQL"]},{"title":"Nginx支持SNI转发","url":"/2020/12/05/Nginx%E6%94%AF%E6%8C%81SNI%E8%BD%AC%E5%8F%91/","content":"SNI是一个TLS的扩展字段，经常用于访问域名跳转到不同的后端地址。\n配置方式如下：打开nginx.conf文件，以ttbb&#x2F;nginx:nake镜像为例&#x2F;usr&#x2F;local&#x2F;openresty&#x2F;nginx&#x2F;conf&#x2F;nginx.conf\n如下为默认的nginx.conf配置\n#user  nobody;worker_processes  1;#error_log  logs/error.log;#error_log  logs/error.log  notice;#error_log  logs/error.log  info;#pid        logs/nginx.pid;events &#123;    worker_connections  1024;&#125;http &#123;    include       mime.types;    default_type  application/octet-stream;    #log_format  main  &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27;    #                  &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27;    #                  &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;;    #access_log  logs/access.log  main;    sendfile        on;    #tcp_nopush     on;    #keepalive_timeout  0;    keepalive_timeout  65;    #gzip  on;    server &#123;        listen       80;        server_name  localhost;        #charset koi8-r;        #access_log  logs/host.access.log  main;        location / &#123;            root   html;            index  index.html index.htm;        &#125;        #error_page  404              /404.html;        # redirect server error pages to the static page /50x.html        #        error_page   500 502 503 504  /50x.html;        location = /50x.html &#123;            root   html;        &#125;        # proxy the PHP scripts to Apache listening on 127.0.0.1:80        #        #location ~ \\.php$ &#123;        #    proxy_pass   http://127.0.0.1;        #&#125;        # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000        #        #location ~ \\.php$ &#123;        #    root           html;        #    fastcgi_pass   127.0.0.1:9000;        #    fastcgi_index  index.php;        #    fastcgi_param  SCRIPT_FILENAME  /scripts$fastcgi_script_name;        #    include        fastcgi_params;        #&#125;        # deny access to .htaccess files, if Apache&#x27;s document root        # concurs with nginx&#x27;s one        #        #location ~ /\\.ht &#123;        #    deny  all;        #&#125;    &#125;    # another virtual host using mix of IP-, name-, and port-based configuration    #    #server &#123;    #    listen       8000;    #    listen       somename:8080;    #    server_name  somename  alias  another.alias;    #    location / &#123;    #        root   html;    #        index  index.html index.htm;    #    &#125;    #&#125;    # HTTPS server    #    #server &#123;    #    listen       443 ssl;    #    server_name  localhost;    #    ssl_certificate      cert.pem;    #    ssl_certificate_key  cert.key;    #    ssl_session_cache    shared:SSL:1m;    #    ssl_session_timeout  5m;    #    ssl_ciphers  HIGH:!aNULL:!MD5;    #    ssl_prefer_server_ciphers  on;    #    location / &#123;    #        root   html;    #        index  index.html index.htm;    #    &#125;    #&#125;&#125;\n\n在最后面添加上\nstream &#123;map $ssl_preread_server_name $name &#123;    backend.example.com      backend;    default                  backend2;&#125;upstream backend &#123;    server 192.168.0.3:12345;    server 192.168.0.4:12345;&#125;upstream backend2 &#123;    server 127.0.0.1:8071;&#125;server &#123;    listen      12346;    proxy_pass  $name;    ssl_preread on;&#125;&#125;\n这个时候，我们已经开启了SNI转发的功能，如果你使用backend.example.com的域名访问服务器，就会转发到backend，如果使用其他域名，就会转发到backend2\n测试的时候，让我们在&#x2F;etc&#x2F;hosts里进行设置，添加\n127.0.0.1 backend.example.com\n\n然后进行请求\ncurl https://backend.example.com:12346\n\n这里注意请求要使用https，http协议或者是tcp可没有SNI的说法\n\n发现请求的确实是backend\n然后测试请求127.0.0.1:12346\ncurl https://127.0.0.1:12346\n\n\n","tags":["Nginx"]},{"title":"Pulsar消息积压topic级别策略老化的两种方案","url":"/2023/05/11/Pulsar%E6%B6%88%E6%81%AF%E7%A7%AF%E5%8E%8Btopic%E7%BA%A7%E5%88%AB%E7%AD%96%E7%95%A5%E8%80%81%E5%8C%96%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E6%A1%88/","content":"Pulsar像大多数消息中间件一样,支持按时间和大小对消息积压进行老化。但是默认的策略只能在namespace级别配置。本文将介绍如何在topic级别实现老化策略的两种方案。\n方案一：开启 TopicLevelPolicy 来实现默认的策略配置通过在Zookeeper上配置对应的策略，可以通过./pulsar zookeeper-shell命令来登录zookeeper集群查询。但是如果将这一实现方式扩展到topic级别，将会产生大量的（百万、千万级别）的ZooKeeper节点，这对于ZooKeeper集群来说几乎是不可接受的。因此，Pulsar提供了一种新的实现方式，即通过Topic来存储策略配置，而不是通过ZooKeeper来存储。\nPulsar，从2.7.0版本开始，引入了SystemTopic，用于存储Topic的元数据信息，包括Topic的策略配置。主题级策略使用户可以更灵活地管理主题,并不会给 ZooKeeper 带来额外负担。\n您可以通过如下配置来开启TopicLevelPolicy：\nsystemTopicEnabled=truetopicLevelPoliciesEnabled=true\n\n然后通过set-backlog-quota命令来设置您想要的老化时间和老化大小\nPS: 完整的一些功能，如命令行set-backlog-quota，在3.0.0版本中支持\n方案二：通过自定义代码来实现Pulsar的TopicLevelPolicy实现需要通过topic存储策略配置，而不是通过ZooKeeper来存储。在实际的极端场景下，Topic中存储的内容可能会丢失（因为未开启Bookkeeper立即落盘或磁盘文件损坏等原因），这将导致策略配置丢失，从而导致策略失效。因此，我们可以通过自定义代码来实现topic级别的策略配置，这样可以避免策略配置丢失的问题。\n举个例子，业务可以将策略存放在Mysql中，然后通过Pulsar的Admin API来让策略生效\n自定义代码实现Backlog时间策略sequenceDiagram\n    participant C as Client\n    participant B as Broker\n    loop\n        C ->> B: expire-messages-all-subscriptions Request\n        B -->> C: expire-messages-all-subscriptions Response\n    end\n\n自定义代码实现Backlog大小策略sequenceDiagram\n    participant C as Client\n    participant B as Broker\n    loop\n        C ->> B: stats-internal Request\n        B -->> C: stats-internal Response\n        alt messageBacklogSize < maxMessageBacklogSize\n        else messageBacklogSize >= maxMessageBacklogSize\n            Note over B,C: estimate the backlog position\n            C ->> B: get-message-by-id Request\n            B -->> C: get-message-by-id\n            Note over B,C: get the timestamp of the message\n            C ->> B: expire-messages-all-subscriptions Request\n            B -->> C: expire-messages-all-subscriptions Response\n        end\n    end\n\n\n import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs';\tmermaid.initialize({startOnLoad: true, flowchart: {curve: 'linear'}}); ","tags":["Pulsar"]},{"title":"Python Http SDK设计","url":"/2023/10/28/Python%20Http%20SDK%E8%AE%BE%E8%AE%A1/","content":"根据Python项目的需求和特性，可以为Python的Http SDK项目选择以下命名方式：\n\nxxx-client-python：如果这个项目只有Http SDK，没有其他协议的SDK，推荐使用这个命名方式。\nxxx-http-client-python：当存在其他协议的SDK时，可以使用这个命名方式，以区分不同协议的SDK。\nxxx-admin-python：当项目使用其他协议作为数据通道，使用HTTP协议作为管理通道时，可以使用这个命名方式。\n\n由于Python的调用方式通常是模块名.类名.方法名。\n","tags":["SDK","Python"]},{"title":"Palantir Foundry技术演进：从定制代码到AIP智能决策","url":"/2025/10/10/Palantir%20Foundry%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%EF%BC%9A%E4%BB%8E%E5%AE%9A%E5%88%B6%E4%BB%A3%E7%A0%81%E5%88%B0AIP%E6%99%BA%E8%83%BD%E5%86%B3%E7%AD%96/","content":"TLDR笔者推测Palantir起初以支持定制代码运行为基础，在构筑自己部署平台（Apollo，Palantir GitHub上也有很多开发者构建、Lint工具）的同时，逐渐抽象出Dataset、本体、Function、Action API，打造了坚实的Foundry平台，让应用从定制化开发逐步“长在平台上”。最终，Palantir 推出人工智能平台（AIP），实现数据驱动的智能决策。\n前言近年来，Palantir 无疑成为数据分析领域的焦点之一。作为一家以解决复杂问题为核心的公司，Palantir 为政府、国防和企业客户提供了强大的数据整合与分析能力。Palantir 的核心产品 Foundry 是一个面向数据整合与分析的平台，它如何从最初的定制化开发逐渐演变为如今的通用数据智能平台？笔者尝试基于公开资源推测梳理 Palantir Foundry技术平台的演进路线，分享一些分析与推测。本文仅代表个人观点，欢迎读者交流探讨。\n阶段0 定制代码运行从Palantir的Offering来看，其核心始终是为客户解决复杂问题，拥有大量的FDE。合理推测Palantir最早其实以定制代码运行交付作为基础，通过高度定制化的软件开发满足客户在政府、国防和企业领域的特定需求。阶段0，此时都处于定制开发状态。\n阶段1 从定制代码运行到Palantir平台运行正如《人月神话》中所说，优秀的程序员都会有自己的library库，优秀的定制开发商也倾向于提炼可复用的技术框架。\n对于定制代码来说，我们把定制代码分为编写态和运行态\n\n编写态，对应Palantir Code Repositories，可以看到Palantir的很多东西，其实跟Git很相似，有分支、合并等等。\n运行态，将Palantir Code Repositories的代码构建运行，支持多种触发方式，比如通过API调用来执行，定时执行等。Apollo 平台进一步支持多环境部署（如云和边缘）。\n\n阶段2 数据的平台化存储和管理当开发工作逐渐迁移到 Palantir 平台后，数据的存储和管理成为下一个重点。如果代码已经运行在平台上，那么数据为什么不能也存储在平台中呢？\nPalantir 在这一阶段引入了 Dataset 和本体（Ontology）模型，构建了平台化的数据管理能力。Dataset 作为数据的核心容器，支持结构化和非结构化数据的存储；本体则定义了数据之间的语义关系，为数据提供了更高级的抽象层。此外，Palantir 接入了时序数据库，增加了对时间序列数据的支持，满足了金融、工业等领域对实时数据处理的需求。\n同时，也把数据集的变更增加为一个触发条件。例如，当某个 Dataset 发生变化时，平台可以自动触发预定义的操作，如运行一段代码或更新其他数据集。\n\n阶段3 抽象Action Function在本体已经定义了DataSet以及数据集之间关系的基础上，通过Action、Function的定义，同时Action、Function可以通过拖拉拽简单地生成，无需书写代码。对于难以无码的复杂逻辑，还可以通过定制代码来书写。\n其实Workflow和Pipeline都是在更高层次、更简便地操作代码的手段而存在，底层实现上：\n\nPipeline &#x3D; Datasets+Builds+Schedules\nWorkflow &#x3D; Schedules + Builds + Jobs\n\n\n阶段 4：AIP 的智能决策赋能在Foundry坚实的基础上，Palantir 2023 年推出了 AIP（人工智能平台）整合大语言模型（LLM）与 Foundry 数据，自动化复杂决策。其核心功能包括：\n\n自然语言处理：用户通过对话界面查询数据或生成分析，如“预测下季度库存需求”。\n自动化工作流：基于 Ontology，AIP 驱动智能决策，例如优化供应链或调度资源。\n实时推理：结合时序数据，AIP 支持动态预测，如医疗资源分配或工业故障检测。\n\n总结图：笔者设想的企业使用Foundry路线图\n本文分析了Palantir Foundry的技术实现路径，笔者认为Palantir Foundry 的技术演进展现了一个从“定制”到“平台原生”的清晰路径。应用从分散的定制代码，逐步迁移到平台上运行，扎根于平台的数据和触发机制，最终成为完全依赖平台功能的原生应用。\n","tags":["Palantir"]},{"title":"SpringCloud ZooKeeper 详解，以及与Go、Rust等非Java服务的集成","url":"/2023/10/24/SpringCloud%20ZooKeeper%20%E8%AF%A6%E8%A7%A3%EF%BC%8C%E4%BB%A5%E5%8F%8A%E4%B8%8EGo%E3%80%81Rust%E7%AD%89%E9%9D%9EJava%E6%9C%8D%E5%8A%A1%E7%9A%84%E9%9B%86%E6%88%90/","content":"ZooKeeper，是一个开源的分布式协调服务，不仅支持分布式选举、任务分配，还可以用于微服务的注册中心和配置中心。本文，我们将深入探讨ZooKeeper用做微服务注册中心的场景。\nZooKeeper中的服务注册路径SpringCloud ZooKeeper遵循特定的路径结构进行服务注册\n/services/$&#123;spring.application.name&#125;/$&#123;serviceId&#125;\n示例：\n/services/provider-service/d87a3891-1173-45a0-bdfa-a1b60c71ef4e\n\n/services和/${spring.application.name}是ZooKeeper中的永久节点，/${serviceId}是临时节点，当服务下线时，ZooKeeper会自动删除该节点。\n注：当微服务的最后一个实例下线时，SpringCloud ZooKeeper框架会删除/${spring.application.name}节点。\nZooKeeper中的服务注册数据下面是一个典型的服务注册内容示例：\n&#123;    &quot;name&quot;:&quot;provider-service&quot;,    &quot;id&quot;:&quot;d87a3891-1173-45a0-bdfa-a1b60c71ef4e&quot;,    &quot;address&quot;:&quot;192.168.0.105&quot;,    &quot;port&quot;:8080,    &quot;sslPort&quot;:null,    &quot;payload&quot;:&#123;        &quot;@class&quot;:&quot;org.springframework.cloud.zookeeper.discovery.ZookeeperInstance&quot;,        &quot;id&quot;:&quot;provider-service&quot;,        &quot;name&quot;:&quot;provider-service&quot;,        &quot;metadata&quot;:&#123;            &quot;instance_status&quot;:&quot;UP&quot;        &#125;    &#125;,    &quot;registrationTimeUTC&quot;:1695401004882,    &quot;serviceType&quot;:&quot;DYNAMIC&quot;,    &quot;uriSpec&quot;:&#123;        &quot;parts&quot;:[            &#123;                &quot;value&quot;:&quot;scheme&quot;,                &quot;variable&quot;:true            &#125;,            &#123;                &quot;value&quot;:&quot;://&quot;,                &quot;variable&quot;:false            &#125;,            &#123;                &quot;value&quot;:&quot;address&quot;,                &quot;variable&quot;:true            &#125;,            &#123;                &quot;value&quot;:&quot;:&quot;,                &quot;variable&quot;:false            &#125;,            &#123;                &quot;value&quot;:&quot;port&quot;,                &quot;variable&quot;:true            &#125;        ]    &#125;&#125;\n其中，address、port和uriSpec是最核心的数据。uriSpec中的parts区分了哪些内容是可变的，哪些是固定的。\nSpringCloud 服务使用OpenFeign互相调用一旦两个微服务都注册到了ZooKeeper，那么它们就可以通过OpenFeign互相调用了。简单的示例如下\n服务提供者创建SpringBoot项目创建SpringBoot项目，并添加spring-cloud-starter-zookeeper-discovery和spring-boot-starter-web依赖。\n配置application.yamlspring:  application:    name: provider-service  cloud:    zookeeper:      connect-string: localhost:2181server:  port: 8082\n\n注册到ZooKeeper在启动类上添加@EnableDiscoveryClient注解。\n创建一个简单的REST接口@RestControllerpublic class ProviderController &#123;    @GetMapping(&quot;/hello&quot;)    public String hello() &#123;        return &quot;Hello from Provider Service!&quot;;    &#125;&#125;\n\n服务消费者创建SpringBoot项目创建SpringBoot项目，并添加spring-cloud-starter-zookeeper-discovery、spring-cloud-starter-openfeign和spring-boot-starter-web依赖。\n配置application.yamlspring:  application:    name: consumer-service  cloud:    zookeeper:      connect-string: localhost:2181server:  port: 8081\n\n注册到ZooKeeper在启动类上添加@EnableDiscoveryClient注解。\n创建一个REST接口，通过OpenFeign调用服务提供者@RestControllerpublic class ConsumerController &#123;        @Autowired    private ProviderClient providerClient;    @GetMapping(&quot;/getHello&quot;)    public String getHello() &#123;        return providerClient.hello();    &#125;&#125;\n\n运行效果curl localhost:8081/getHello -iHTTP/1.1 200Content-Type: text/plain;charset=UTF-8Content-Length: 28Date: Wed, 18 Oct 2023 02:40:57 GMTHello from Provider Service!\n\n非Java服务在SpringCloud ZooKeeper中注册可能有些读者乍一看觉得有点奇怪，为什么要在SpringCloud ZooKeeper中注册非Java服务呢？没有这个应用场景。\n当然，这样的场景比较少，常见于大部分项目都是用SpringCloud开发，但有少部分项目因为种种原因，不得不使用其他语言开发，比如Go、Rust等。这时候，我们就需要在SpringCloud ZooKeeper中注册非Java服务了。\n对于非JVM语言开发的服务，只需确保它们提供了Rest&#x2F;HTTP接口并正确地注册到ZooKeeper，就可以被SpringCloud的Feign客户端所调用。\nGo服务在SpringCloud ZooKeeperexample代码组织：\n├── consumer│   └── consumer.go├── go.mod├── go.sum└── provider    └── provider.go\n\nGo服务提供者在SpringCloud ZooKeeper注：该代码的质量为demo级别，实际生产环境需要更加严谨的代码，如重连机制、超时机制、更优秀的服务ID生成算法等。\npackage mainimport (\t&quot;fmt&quot;\t&quot;log&quot;\t&quot;net/http&quot;\t&quot;time&quot;\t&quot;encoding/json&quot;\t&quot;github.com/gin-gonic/gin&quot;\t&quot;github.com/samuel/go-zookeeper/zk&quot;)const (\tzkServers = &quot;localhost:2181&quot; // Zookeeper服务器地址)func main() &#123;\t// 初始化gin框架\tr := gin.Default()\t// 添加一个简单的hello接口\tr.GET(&quot;/hello&quot;, func(c *gin.Context) &#123;\t\tc.String(http.StatusOK, &quot;Hello from Go service!&quot;)\t&#125;)\t// 注册服务到zookeeper\tregisterToZookeeper()\t// 启动gin服务器\tr.Run(&quot;:8080&quot;)&#125;func registerToZookeeper() &#123;\tconn, _, err := zk.Connect([]string&#123;zkServers&#125;, time.Second*5)\tif err != nil &#123;\t\tpanic(err)\t&#125;\t// 检查并创建父级路径\tensurePathExists(conn, &quot;/services&quot;)\tensurePathExists(conn, &quot;/services/provider-service&quot;)\t// 构建注册的数据\tdata, _ := json.Marshal(map[string]interface&#123;&#125;&#123;\t\t&quot;name&quot;:        &quot;provider-service&quot;,\t\t&quot;address&quot;:     &quot;127.0.0.1&quot;,\t\t&quot;port&quot;:        8080,\t\t&quot;sslPort&quot;:     nil,\t\t&quot;payload&quot;:     map[string]interface&#123;&#125;&#123;&quot;@class&quot;: &quot;org.springframework.cloud.zookeeper.discovery.ZookeeperInstance&quot;, &quot;id&quot;: &quot;provider-service&quot;, &quot;name&quot;: &quot;provider-service&quot;, &quot;metadata&quot;: map[string]string&#123;&quot;instance_status&quot;: &quot;UP&quot;&#125;&#125;,\t\t&quot;serviceType&quot;: &quot;DYNAMIC&quot;,\t\t&quot;uriSpec&quot;: map[string]interface&#123;&#125;&#123;\t\t\t&quot;parts&quot;: []map[string]interface&#123;&#125;&#123;\t\t\t\t&#123;&quot;value&quot;: &quot;scheme&quot;, &quot;variable&quot;: true&#125;,\t\t\t\t&#123;&quot;value&quot;: &quot;://&quot;, &quot;variable&quot;: false&#125;,\t\t\t\t&#123;&quot;value&quot;: &quot;address&quot;, &quot;variable&quot;: true&#125;,\t\t\t\t&#123;&quot;value&quot;: &quot;:&quot;, &quot;variable&quot;: false&#125;,\t\t\t\t&#123;&quot;value&quot;: &quot;port&quot;, &quot;variable&quot;: true&#125;,\t\t\t&#125;,\t\t&#125;,\t&#125;)\t// 在zookeeper中注册服务\tpath := &quot;/services/provider-service/&quot; + generateServiceId()\t_, err = conn.Create(path, data, zk.FlagEphemeral, zk.WorldACL(zk.PermAll))\tif err != nil &#123;\t\tlog.Fatalf(&quot;register service error: %s&quot;, err)\t&#125; else &#123;\t\tlog.Println(path)\t&#125;&#125;func ensurePathExists(conn *zk.Conn, path string) &#123;\texists, _, err := conn.Exists(path)\tif err != nil &#123;\t\tlog.Fatalf(&quot;check path error: %s&quot;, err)\t&#125;\tif !exists &#123;\t\t_, err := conn.Create(path, []byte&#123;&#125;, 0, zk.WorldACL(zk.PermAll))\t\tif err != nil &#123;\t\t\tlog.Fatalf(&quot;create path error: %s&quot;, err)\t\t&#125;\t&#125;&#125;func generateServiceId() string &#123;\t// 这里简化为使用当前时间生成ID，实际生产环境可能需要更复杂的算法\treturn fmt.Sprintf(&quot;%d&quot;, time.Now().UnixNano())&#125;\n\n调用效果\ncurl localhost:8081/getHello -iHTTP/1.1 200Content-Type: text/plain;charset=UTF-8Content-Length: 28Date: Wed, 18 Oct 2023 02:43:52 GMTHello from Go Service!\n\nGo服务消费者在SpringCloud ZooKeeperpackage mainimport (\t&quot;encoding/json&quot;\t&quot;fmt&quot;\t&quot;io&quot;\t&quot;log&quot;\t&quot;net/http&quot;\t&quot;time&quot;\t&quot;github.com/samuel/go-zookeeper/zk&quot;)const (\tzkServers = &quot;localhost:2181&quot; // Zookeeper服务器地址)var conn *zk.Connfunc main() &#123;\t// 初始化ZooKeeper连接\tinitializeZookeeper()\t// 获取服务信息\tserviceInfo := getServiceInfo(&quot;/services/provider-service&quot;)\tfmt.Println(&quot;Fetched service info:&quot;, serviceInfo)\tport := int(serviceInfo[&quot;port&quot;].(float64))\tresp, err := http.Get(fmt.Sprintf(&quot;http://%s:%d/hello&quot;, serviceInfo[&quot;address&quot;], port))\tif err != nil &#123;\t\tpanic(err)\t&#125;\tbody, err := io.ReadAll(resp.Body)\tif err != nil &#123;\t\tpanic(err)\t&#125;\tfmt.Println(string(body))&#125;func initializeZookeeper() &#123;\tvar err error\tconn, _, err = zk.Connect([]string&#123;zkServers&#125;, time.Second*5)\tif err != nil &#123;\t\tlog.Fatalf(&quot;Failed to connect to ZooKeeper: %s&quot;, err)\t&#125;&#125;func getServiceInfo(path string) map[string]interface&#123;&#125; &#123;\tchildren, _, err := conn.Children(path)\tif err != nil &#123;\t\tlog.Fatalf(&quot;Failed to get children of %s: %s&quot;, path, err)\t&#125;\tif len(children) == 0 &#123;\t\tlog.Fatalf(&quot;No services found under %s&quot;, path)\t&#125;\t// 这里只获取第一个服务节点的信息作为示例，实际上可以根据负载均衡策略选择一个服务节点\tdata, _, err := conn.Get(fmt.Sprintf(&quot;%s/%s&quot;, path, children[0]))\tif err != nil &#123;\t\tlog.Fatalf(&quot;Failed to get data of %s: %s&quot;, children[0], err)\t&#125;\tvar serviceInfo map[string]interface&#123;&#125;\tif err := json.Unmarshal(data, &amp;serviceInfo); err != nil &#123;\t\tlog.Fatalf(&quot;Failed to unmarshal data: %s&quot;, err)\t&#125;\treturn serviceInfo&#125;\n\nRust服务在SpringCloud ZooKeeperexample代码组织：\n├── Cargo.lock├── Cargo.toml└── src    └── bin        ├── consumer.rs        └── provider.rs\n\nRust服务提供者在SpringCloud ZooKeeperuse std::collections::HashMap;use std::time::Duration;use serde_json::Value;use warp::Filter;use zookeeper::&#123;Acl, CreateMode, WatchedEvent, Watcher, ZooKeeper&#125;;static ZK_SERVERS: &amp;str = &quot;localhost:2181&quot;;static mut ZK_CONN: Option&lt;ZooKeeper&gt; = None;struct LoggingWatcher;impl Watcher for LoggingWatcher &#123;    fn handle(&amp;self, e: WatchedEvent) &#123;        println!(&quot;WatchedEvent: &#123;:?&#125;&quot;, e);    &#125;&#125;#[tokio::main]async fn main() &#123;    let hello = warp::path!(&quot;hello&quot;).map(|| warp::reply::html(&quot;Hello from Rust service!&quot;));    register_to_zookeeper().await;    warp::serve(hello).run(([127, 0, 0, 1], 8083)).await;&#125;async fn register_to_zookeeper() &#123;    unsafe &#123;        ZK_CONN = Some(ZooKeeper::connect(ZK_SERVERS, Duration::from_secs(5), LoggingWatcher).unwrap());        let zk = ZK_CONN.as_ref().unwrap();        let path = &quot;/services/provider-service&quot;;        if zk.exists(path, false).unwrap().is_none() &#123;            zk.create(path, vec![], Acl::open_unsafe().clone(), CreateMode::Persistent).unwrap();        &#125;        let service_data = get_service_data();        let service_path = format!(&quot;&#123;&#125;/&#123;&#125;&quot;, path, generate_service_id());        zk.create(&amp;service_path, service_data, Acl::open_unsafe().clone(), CreateMode::Ephemeral).unwrap();    &#125;&#125;fn get_service_data() -&gt; Vec&lt;u8&gt; &#123;    let mut data: HashMap&lt;&amp;str, Value&gt; = HashMap::new();    data.insert(&quot;name&quot;, serde_json::Value::String(&quot;provider-service&quot;.to_string()));    data.insert(&quot;address&quot;, serde_json::Value::String(&quot;127.0.0.1&quot;.to_string()));    data.insert(&quot;port&quot;, serde_json::Value::Number(8083.into()));    serde_json::to_vec(&amp;data).unwrap()&#125;fn generate_service_id() -&gt; String &#123;    format!(&quot;&#123;&#125;&quot;, chrono::Utc::now().timestamp_nanos())&#125;\n\nRust服务消费者在SpringCloud ZooKeeperuse std::collections::HashMap;use std::time::Duration;use zookeeper::&#123;WatchedEvent, Watcher, ZooKeeper&#125;;use reqwest;use serde_json::Value;static ZK_SERVERS: &amp;str = &quot;localhost:2181&quot;;struct LoggingWatcher;impl Watcher for LoggingWatcher &#123;    fn handle(&amp;self, e: WatchedEvent) &#123;        println!(&quot;WatchedEvent: &#123;:?&#125;&quot;, e);    &#125;&#125;#[tokio::main]async fn main() &#123;    let provider_data = fetch_provider_data_from_zookeeper().await;    let response = request_provider(&amp;provider_data).await;    println!(&quot;Response from provider: &#123;&#125;&quot;, response);&#125;async fn fetch_provider_data_from_zookeeper() -&gt; HashMap&lt;String, Value&gt; &#123;    let zk = ZooKeeper::connect(ZK_SERVERS, Duration::from_secs(5), LoggingWatcher).unwrap();    let children = zk.get_children(&quot;/services/provider-service&quot;, false).unwrap();    if children.is_empty() &#123;        panic!(&quot;No provider services found!&quot;);    &#125;    // For simplicity, we just take the first child (i.e., service instance).     // In a real-world scenario, load balancing strategies would determine which service instance to use.    let data = zk.get_data(&amp;format!(&quot;/services/provider-service/&#123;&#125;&quot;, children[0]), false).unwrap();    serde_json::from_slice(&amp;data.0).unwrap()&#125;async fn request_provider(provider_data: &amp;HashMap&lt;String, Value&gt;) -&gt; String &#123;    let address = provider_data.get(&quot;address&quot;).unwrap().as_str().unwrap();    let port = provider_data.get(&quot;port&quot;).unwrap().as_i64().unwrap();    let url = format!(&quot;http://&#123;&#125;:&#123;&#125;/hello&quot;, address, port);    let response = reqwest::get(&amp;url).await.unwrap();    response.text().await.unwrap()&#125;\n","tags":["ZooKeeper","Spring"]},{"title":"SaaS服务功能权限控制是怎么做的","url":"/2024/07/23/SaaS%E6%9C%8D%E5%8A%A1%E5%8A%9F%E8%83%BD%E6%9D%83%E9%99%90%E6%8E%A7%E5%88%B6%E6%98%AF%E6%80%8E%E4%B9%88%E5%81%9A%E7%9A%84/","content":"SaaS服务全局级别的功能前端调用SaaS服务一个全局级别的接口\nsequenceDiagram\n    participant User as 用户\n    participant Frontend as 前端\n    participant Backend as 后端\n\n    User->>Frontend: 点击页面\n    Frontend->>Backend: 请求当前功能集\n    Backend->>Backend: 返回当前功能集\n    alt 用户有权限\n        Backend->>Frontend: 返回全局数据\n        Frontend->>User: 显示数据\n    else 用户无权限\n        Backend->>Frontend: 返回错误信息\n        Frontend->>User: 显示错误信息\n    end\n\nSaaS服务用户级别的功能前端调用SaaS服务一个用户权限的接口\nsequenceDiagram\n    participant User as 用户\n    participant Frontend as 前端\n    participant Backend as 后端\n\n    User->>Frontend: 点击页面\n    Frontend->>Backend: 查看用户权限\n    Backend->>Backend: 验证用户权限\n    alt 用户有权限\n        Backend->>Frontend: 返回用户项目数据\n        Frontend->>User: 显示数据\n    else 用户无权限\n        Backend->>Frontend: 返回错误信息\n        Frontend->>User: 显示错误信息\n    end\n\n\n import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs';\tmermaid.initialize({startOnLoad: true, flowchart: {curve: 'linear'}}); "},{"title":"Spring单元测试总结","url":"/2023/08/12/Spring%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%E6%80%BB%E7%BB%93/","content":"目录\n模块组织\n测试手段\n依赖组件\n\n典型Spring单元测试模块组织-- xxx-app-- xxx-util-- test-common\n\ntest-common尽量减少依赖，仅依赖必须的非spring组件。也可以统一将需要使用的resources文件放到test-common中。由test-common统一管理，避免每个模块测试都需要拷贝必须的文件。所需的maven配置如下：\n&lt;build&gt;    &lt;resources&gt;        &lt;resource&gt;            &lt;directory&gt;src/main/resources&lt;/directory&gt;            &lt;includes&gt;                &lt;include&gt;**&lt;/include&gt;                &lt;include&gt;**/**&lt;/include&gt;            &lt;/includes&gt;        &lt;/resource&gt;    &lt;/resources&gt;    &lt;plugins&gt;        &lt;plugin&gt;            &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;            &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt;            &lt;version&gt;$&#123;maven-resources-plugin.version&#125;&lt;/version&gt;            &lt;executions&gt;                &lt;execution&gt;                    &lt;id&gt;copy-resources&lt;/id&gt;                    &lt;phase&gt;process-resources&lt;/phase&gt;                    &lt;goals&gt;                        &lt;goal&gt;copy-resources&lt;/goal&gt;                    &lt;/goals&gt;                    &lt;configuration&gt;                        &lt;outputDirectory&gt;$&#123;project.build.directory&#125;/resources&lt;/outputDirectory&gt;                        &lt;resources&gt;                            &lt;resource&gt;                                &lt;directory&gt;src/main/resources&lt;/directory&gt;                            &lt;/resource&gt;                        &lt;/resources&gt;                    &lt;/configuration&gt;                &lt;/execution&gt;            &lt;/executions&gt;        &lt;/plugin&gt;    &lt;/plugins&gt;&lt;/build&gt;\n\n一些典型的配置文件，比如log4j2配置文件，同时，由于test-common不属于测试代码，可能在某些组织下会有更高的要求（如不能存在敏感信息等），如组织有这样的要求，则这类内容不适合放在test-common里统一复用:\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;Configuration status=&quot;info&quot; monitorInterval=&quot;10&quot;&gt;    &lt;Appenders&gt;        &lt;Console name=&quot;Console&quot; target=&quot;SYSTEM_OUT&quot;&gt;            &lt;PatternLayout pattern=&#x27;%d&#123;yyyy-MM-dd,HH:mm:ss,SSSXXX&#125;(%C:%L):%4p%X[%t#%T]--&gt;%m%n&#x27;/&gt;        &lt;/Console&gt;    &lt;/Appenders&gt;    &lt;Loggers&gt;        &lt;Root level=&quot;INFO&quot;&gt;            &lt;AppenderRef ref=&quot;Console&quot;/&gt;        &lt;/Root&gt;    &lt;/Loggers&gt;&lt;/Configuration&gt;\n\n测试手段利用RestAssured端到端测试http接口添加依赖\n&lt;dependency&gt;    &lt;groupId&gt;io.rest-assured&lt;/groupId&gt;    &lt;artifactId&gt;rest-assured&lt;/artifactId&gt;    &lt;version&gt;5.3.1&lt;/version&gt;    &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;\n\n为了在SpringBoot测试中使用 RestAssured, 需要配置端口 webEnvironment &#x3D; SpringBootTest.WebEnvironment.RANDOM_PORT。如：\n@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT)public class MyRestControllerTest &#123;    @LocalServerPort    int port;    @BeforeEach    public void setUp() &#123;        RestAssured.port = port;    &#125;&#125;\n\n随后可以使用RestAssured来请求接口\nRestAssured.given().contentType(ContentType.JSON).body(&quot;&#123;&#125;&quot;).post(&quot;url&quot;).then().statusCode(200);\n\n依赖组件mariadbmariadb可以使用mariadb4j\n&lt;dependency&gt;    &lt;groupId&gt;ch.vorburger.mariaDB4j&lt;/groupId&gt;    &lt;artifactId&gt;mariaDB4j&lt;/artifactId&gt;    &lt;version&gt;3.0.1&lt;/version&gt;    &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;\n\n书写Extension并使用\nimport ch.vorburger.mariadb4j.DB;import ch.vorburger.mariadb4j.DBConfigurationBuilder;import org.junit.jupiter.api.extension.AfterAllCallback;import org.junit.jupiter.api.extension.BeforeAllCallback;import org.junit.jupiter.api.extension.ExtensionContext;public class MariaDBExtension implements BeforeAllCallback, AfterAllCallback &#123;    private DB database;    @Override    public void beforeAll(ExtensionContext context) throws Exception &#123;        DBConfigurationBuilder configBuilder = DBConfigurationBuilder.newBuilder();        configBuilder.setPort(3306);        database = DB.newEmbeddedDB(configBuilder.build());    &#125;    @Override    public void afterAll(ExtensionContext context) throws Exception &#123;        if (database != null) &#123;            database.stop();        &#125;    &#125;&#125;\n\nigniteIgnite可以使用现有的junit5集成\n&lt;dependency&gt;    &lt;groupId&gt;io.github.embedded-middleware&lt;/groupId&gt;    &lt;artifactId&gt;embedded-ignite-junit5&lt;/artifactId&gt;    &lt;version&gt;0.0.3&lt;/version&gt;&lt;/dependency&gt;\n\n可以直接使用EmbeddedIgniteExtension，还可以使用EmbeddedIgnitePorts自定义Ignite的关键端口号\n","tags":["Java","Spring"]},{"title":"TypeScript Http SDK设计","url":"/2023/10/28/TypeScript%20Http%20SDK%E8%AE%BE%E8%AE%A1/","content":"TypeScript的调用方式通常是\nimport &#123; ClassName &#125; from &#x27;moduleName&#x27;;const object = new ClassName();\n\n根据TypeScript项目的需求和特性，可以为TypeScript的Http SDK项目选择以下命名方式：\n\nxxx-client-ts：如果这个项目只有Http SDK，没有其他协议的SDK，推荐使用这个命名方式。在npm可以注册为”xxx”。\nxxx-http-client-ts：当存在其他协议的SDK时，可以使用这个命名方式，以区分不同协议的SDK。\nxxx-admin-ts：当项目使用其他协议作为数据通道，使用HTTP协议作为管理通道时，可以使用这个命名方式。\n\n","tags":["SDK","TypeScript"]},{"title":"Spring记录数据库操作时间的几种方式","url":"/2023/12/15/Spring%E8%AE%B0%E5%BD%95%E6%95%B0%E6%8D%AE%E5%BA%93%E6%93%8D%E4%BD%9C%E6%97%B6%E9%97%B4%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F/","content":"Spring记录数据库操作时间的几种方式\nSpring Jpa@EnableJpaAuditing注解开启Jpa的审计功能，然后在实体类上使用@CreatedDate和@LastModifiedDate注解即可\n@Column(name = &quot;create_time&quot;)@CreatedDateprivate LocalDateTime createTime;@Column(name = &quot;update_time&quot;)@LastModifiedDateprivate LocalDateTime updateTime;\n\nSpring R2dbcSpring R2dbc可以使用@CreatedDate和@LastModifiedDate注解来实现。但是需要在Application上开启@EnableR2dbcAuditing\n@Column(&quot;created_time&quot;)@CreatedDateprivate LocalDateTime createdTime;@Column(&quot;updated_time&quot;)@LastModifiedDateprivate LocalDateTime updatedTime;\n\n应用程序修改应用程序修改就比较简单，简单设置一下即可,以PersonPo类为例\nPersonPo personPo = new PersonPo();personPo.setCreateTime(LocalDateTime.now());personPo.setUpdateTime(LocalDateTime.now());\n\nMysql场景下利用TIMESTAMP能力CREATE TABLE person (    id INT PRIMARY KEY,    // ... 其他字段 ...    create_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,    update_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP);\n","tags":["Java","Spring"]},{"title":"WebFlux最佳实践","url":"/2024/06/08/WebFlux%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/","content":"WebFlux是Spring 5引入的新的响应式编程框架，它提供了一种基于反应式流的编程模型，可以用于构建高性能、高吞吐量的Web应用程序。\n防止大量请求堆积限制同一时间的并发处理个数由于WebFlux可以处理大量的请求，如果后端处理较慢（如写db较慢等），可能会导致大量的请求堆积，可以通过限制同一时间的并发处理个数来防止请求堆积。\nimport org.springframework.http.HttpStatus;import org.springframework.stereotype.Component;import org.springframework.web.server.ServerWebExchange;import org.springframework.web.server.WebFilter;import org.springframework.web.server.WebFilterChain;import reactor.core.publisher.Mono;import java.util.concurrent.Semaphore;@Componentpublic class ConcurrencyLimitingFilter implements WebFilter &#123;    private final Semaphore semaphore;    public ConcurrencyLimitingFilter() &#123;        this.semaphore = new Semaphore(10);    &#125;    @Override    public Mono&lt;Void&gt; filter(ServerWebExchange exchange, WebFilterChain chain) &#123;        if (semaphore.tryAcquire()) &#123;            return chain.filter(exchange)                    .doFinally(sig -&gt; semaphore.release());        &#125; else &#123;            exchange.getResponse().setStatusCode(HttpStatus.TOO_MANY_REQUESTS);            return exchange.getResponse().setComplete();        &#125;    &#125;&#125;\n\n配置超时时间网络编程中，任何操作都应该有超时时间。WebFlux允许大量的请求进入，如果不设置超时时间，可能会导致大量的请求排队处理（可能客户端早已放弃），可以通过统一Filter来设置最大超时时间。\nimport lombok.extern.slf4j.Slf4j;import org.springframework.http.HttpStatus;import org.springframework.stereotype.Component;import org.springframework.web.server.ResponseStatusException;import org.springframework.web.server.ServerWebExchange;import org.springframework.web.server.WebFilter;import org.springframework.web.server.WebFilterChain;import reactor.core.publisher.Mono;import java.time.Duration;import java.util.concurrent.TimeoutException;@Slf4j@Componentpublic class WebRequestTimeoutFilter implements WebFilter &#123;    @Override    public Mono&lt;Void&gt; filter(ServerWebExchange exchange, WebFilterChain chain) &#123;        return chain.filter(exchange)                .timeout(Duration.ofSeconds(10))                .onErrorResume(TimeoutException.class, e -&gt; &#123;                    log.error(&quot;Request timeout&quot;, e);                    return Mono.error(new ResponseStatusException(HttpStatus.GATEWAY_TIMEOUT, &quot;Request timeout&quot;));                &#125;);    &#125;&#125;\n","tags":["Java","Spring","WebFlux"]},{"title":"Wireshark 安装及基本操作","url":"/2018/09/07/WireShark%20%E5%AE%89%E8%A3%85%E5%8F%8A%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/","content":"WireShark安装wireshark在windows和mac上的安装方式都比较简单,下面是Linux下的安装方式\nsudo apt-add-repository ppa:wireshark-dev/stablesudo apt-get updatesudo apt-get install wireshark#以root权限启动sudo wireshark\n\nWireShark的名字解析\n\nL2层的名字解析，对Mac地址进行解析，返回机器名\nL3层 ip解析为域名\nL4层 端口号解析为协议端口号\n\nWireshark抓到的包更改时间格式\n查看EndPoint点击Statistics-&gt;EndPoints，可以查看每一个捕获文件里的每个端点\n\n查看网络会话Statistics-&gt;Conversations. 查看地址A和地址B，以及每个设备发送或收到的数据包和字节数\n\n基于协议分层结构的统计数据Statistics-&gt;Protocol Hierarchy\n\n跟随流功能右键选中一个数据包，然后右键，follow。比如我在这里跟随一个tcp流\n\n&#x2F;&#x2F;这里也可以使用decode as解码功能，但是没有例子，暂不附图\n查看IO图Statistics-&gt;IO Graphs\n\n双向时间图Statistics-&gt;TCP Stream Graph -&gt; Round Trip Time Graph\n数据流图Statistics-&gt;Flow Graph\n专家信息Analyze-&gt;Expert Info Composite\n触发的专家信息对话消息窗口更新 由接收者发送，用来通知发送者TCP接收窗口的大小已被改变注意消息TCP重传输 数据包丢失的结果，发生在收到重复的ACK，或者数据包的重传输计时器超时的时候重复ACK 当一台主机没有收到下一个期望序列的数据包时，它会生成最近收到一次数据的重复ACK零窗口探查ACK 用来响应零窗口探查数据包窗口已满 用来通知传输主机及其接收者的TCP接收窗口已满警告消息上一段丢失 指明数据包丢失,发生在当数据流中一个期望的序列号被跳过时。收到丢失数据包的ACK 发生在当一个数据包已经确认丢失但受到了其ACK数据包时保活 当一个连接的保活数据包出现时触发零窗口 当接收方已经达到TCP接收窗口大小时，发出一个零窗口通知，要求发送方停止传输数据乱序 当数据包被乱序接收时，会利用序列号进行检测快速重传输 一次重传会在收到一个重复ACK的20ms内进行WireShark性能Statistics -&gt; Summary 查看平均速度Analyze -&gt; Expert InfosStatistics -&gt; TCP StreamGraph -&gt; TCP Sequence Graph(Stenens)TCP Previous segment not captured在TCP传输过程中,同一台主机发出的数据段应该是连续的,即后一个包的Seq号等于前一个包的Seq + Len. 如果在网络包中没有找到,就会出现这个错误\nTCP ACKed unseen segmentWireshark发现被Ack的那个包没被wireshark捕获\nTCP Out-of-Order在TCP传输过程中,同一台主机发出的数据段应该是连续的,即后一个包的Seq号等于前一个包的Seq +Len.当Wireshark发现后一个包的Seq号小于前一个包的Seq+Len 就乱序le\nTCP Dup ACK当乱序或者丢包的时候,接收方会收到Seq号比期望值大的包,每收到一个这种包就会Ack一次期望的Seq值\nTCP Fast Retransmission当发送方收到3个或以上TCP Dup ACK,就意识到之前发的包可能丢了,触发快速重传\nTCP Retransmission没有触发tcp超时重传,超时重传\nTCP zerowindow缓存区已满,不能再接收数据了\nTCP window FUllWireshark检测到,发送方发送的数据会把接收方的接收窗口耗尽\n","tags":["Wireshark"]},{"title":"Wireshark 捕获过滤器","url":"/2018/09/09/WireShark%20%E6%8D%95%E8%8E%B7%E8%BF%87%E6%BB%A4%E5%99%A8/","content":"如何使用捕获过滤器点击捕获，选项，然后在所选择的捕获过滤器上输入对应的捕获表达式\n\n\n抓包过滤器\ntype(类型) 限定符: 比如host，net，port限定符等\ndir(方向) 限定符: src dst\nProto(协议类型)限定符: ether ip arp\n\n二层过滤器举例tcp dst port 135 //tcp协议，目标端口为135的数据包ether host &lt;Ethernet host&gt; //让wireshark只抓取这个地址相关的以太网帧ether dst &lt;Ethernet host&gt;ether src &lt;Ethernet src&gt;ether broadcast //Wireshark只抓取所有以太网广播流量ether multicast //只抓取多播流量ether proto &lt;protocol&gt;vlan &lt;vlan_id&gt;\n\n三层过滤器举例ip #只抓取ipv4流量ipv6host 10.0.0.2dest host &lt;host&gt;src host &lt;host&gt;broadcast #ip广播包multicast #ip多播包ip proto &lt;protocol code&gt; #ip数据包有多种类型，比如TCP(6), UDP(17) ICMP(1)\n\n只抓取源于或者发往IPv6 2001::&#x2F;16的数据包net 2001::&#x2F;16\n只抓取ICMP流量ip proto 1\n只抓取ICMP echo request流量icmp[icmptype]&#x3D;&#x3D;icmp-echoicmp[icmptype]&#x3D;&#x3D;8\n只抓取特定长度的IP数据包ip[2:2] &#x3D;&#x3D; \n只抓取具有特定TTL的IP数据包ip[8] &#x3D;&#x3D; \n抓取数据包的源和目的IP地址相同ip[12:4] &#x3D;&#x3D;1 ip[16:4]\n四层抓包过滤器举例port &lt;port&gt;dst port &lt;port&gt;src port &lt;port&gt;tcp portrange &lt;p1&gt;-&lt;p2&gt;\n\n只抓取TCP中SYN或者FIN的数据包tcp [tcpflags] &amp; (tcp-syn | tcp-fin) !&#x3D; 0\n只抓所有RST标记位置为1的TCP数据包tcp[tcpflags] &amp; (tcp-rst) !&#x3D; 0\ntcp头部的常用标记位\nSYN: 用来表示打开连接\nFIN: 用来表示拆除连接\nACK: 用来确认收到的数据\nRST: 用来表示立刻拆除连接\nPSH: 用来表示应将数据提交给末端应用程序处理\n\n抓取所有标记位都未置1的TCP流量该报文可能用于端口探测,即如果tcp[13] &amp; 0x00 &#x3D; 0\n设置了URG位的TCP数据包URG位,表示该数据包十分紧急,不进入缓冲区,直接送给进程tcp[13] &amp; 32 &#x3D;&#x3D; 32\n设置了ACK位的TCP数据包tcp[13] &amp; 16 &#x3D;&#x3D; 16\n设置了PSH位的TCP数据包PSH代表这个消息要从缓冲区立刻发送给应用程序tcp[13] &amp; 8 &#x3D;&#x3D; 8\n设置了RST位的TCP数据包tcp[13] &amp; 4 &#x3D;&#x3D; 4\n设置了SYN位的TCP数据包tcp[13] &amp; 2 &#x3D;&#x3D; 2\n设置了FIN位的TCP数据包tcp[13] &amp; 1 &#x3D;&#x3D; 1\nTCP SYN-ACK数据包tcp[13] &#x3D;&#x3D; 18\n抓取目的端口范围的数据包tcp portrange 2000-2500\n###tcpdump捕获过滤器\n常见命令介绍\ntcpdump -w hzj.pcap -s0 -iany port 1028\n\n上面的命令代表-w hzj.pcap 存储在hzj.pcap这个文件中-s 0 代表抓取字节数不限制,在大多数linux系统下,默认捕获每个帧的前96个字节\ntcpdump捕获一定范围的端口(9200-9400)tcpdump portrange 9200-9400\ntcpdump -r 可以阅读捕获的文件(建议拷贝到wireshark中分析)","tags":["Wireshark"]},{"title":"Wireshark 显示过滤器","url":"/2018/09/09/WireShark%20%E6%98%BE%E7%A4%BA%E8%BF%87%E6%BB%A4%E5%99%A8/","content":"如何使用显示过滤器或者按住 CTRL + F，输入显示过滤器\n二层显示过滤器举例长度小于128字节的数据包frame.len&lt;&#x3D;128\n排除ARP流量!arp\n三层显示过滤器举例只显示192.168.0.1 IP相关数据包ip.addr&#x3D;&#x3D;192.168.0.1\n四层显示过滤器举例排除RDP流量!tcp.port&#x3D;&#x3D;3389\n具有SYN标志的TCP数据包tcp.flags.syn&#x3D;&#x3D;1\n具有RST标志的TCP数据包tcp.flags.rst&#x3D;&#x3D;1\nTCP确认时间较久tcp.analysis.ack_rtt &gt; 0.2 and tcp.len &#x3D;&#x3D; 0###启用TCP Relative Sequence Number的情况如何启用?Edit -&gt; Preferences -&gt; Protocols -&gt; TCP Relative Sequence Numbers\n握手被对方拒绝的包tcp.flags.reset &#x3D;&#x3D; 1 &amp;&amp; tcp.seq &#x3D;&#x3D; 1\n客户端重传tcp.flags.syn &#x3D;&#x3D; 1 &amp;&amp; tcp.analysis.retransmission\nTcp包含tcp contains {str}\n应用层显示过滤器举例所有http流量http\n文本管理流量tcp.port &#x3D;&#x3D; 23 || tcp.port &#x3D;&#x3D; 21\n文本email流量email || pop || imap\n只显示访问某指定主机名的HTTP协议数据包http.host &#x3D;&#x3D; &lt;”hostname”&gt;\n只显示包含HTTP GET方法的HTTP协议数据包http.request.method &#x3D;&#x3D; ‘GET’\n只显示HTTP 客户端发起的包含指定URI请求的HTTP协议数据包http.request.uri &#x3D;&#x3D; &lt;”Full request URI”&gt;\n只显示包含ZIP文件的数据包http matches “.zip” &amp;&amp; http.request.method &#x3D;&#x3D; ‘GET’\n","tags":["Wireshark"]},{"title":"Java DefaultUncaughtExceptionHandler 详解","url":"/2023/06/15/java%20DefaultUncaughtExceptionHandler%20%E8%AF%A6%E8%A7%A3/","content":"在Java程序运行时，一些非受检异常可能会导致程序崩溃，比如NullPointerException、ArrayIndexOutOfBoundsException等等，这些异常都是由JVM抛出的，如果不对这些异常进行处理，小则线程运行中突然退出，大则整个程序崩溃。理想的场景下，每一个非受检异常都应该被捕获并进行处理，但是在实际开发中，我们往往会忽略一些异常，这些异常可能是由于程序员的疏忽导致的，也可能是由于程序员无法预知的原因导致的，比如第三方库抛出的异常。\n为了避免这些异常导致程序崩溃，Java提供了一个全局的异常处理器，即DefaultUncaughtExceptionHandler，它可以捕获所有未被捕获的异常，从而避免程序崩溃。\nDefaultUncaught的使用示例如下：\npublic class UncaughtExceptionHandle &#123;    public static void main(String[] args) &#123;        Thread.setDefaultUncaughtExceptionHandler((t, e) -&gt; log.error(&quot;Uncaught exception: &quot;, e));    &#125;&#125;\n\n上述的代码会将未捕获的异常打印到日志中，如果你希望打印至标准输出或标准输出，可以将log替换为：\n// 标准输出System.out.println(&quot;Uncaught exception: &quot; + e);// 错误输出System.err.println(&quot;Uncaught exception: &quot; + e);\n","tags":["Java"]},{"title":"jetty servlet的代码字符集选择","url":"/2023/06/02/jetty%20servlet%E7%9A%84%E7%BC%96%E7%A0%81%E5%AD%97%E7%AC%A6%E9%9B%86%E9%80%89%E6%8B%A9/","content":"记一次中文指标乱码问题，问题也很简单，如下图所示：\n\n从metricbeat开始找原因，发现其实只要是UTF-8的编码格式就都可以解析，最终发现是webServer返回的数据非UTF-8格式，修改方案也很简单。将servlet中的content-type里面的text&#x2F;plain修改成text&#x2F;plain; charset&#x3D;utf-8就可以了，如下面代码所示:\nprotected void doGet(HttpServletRequest request, HttpServletResponse response)        throws IOException &#123;    response.setContentType(&quot;text/plain&quot;);    response.setStatus(HttpServletResponse.SC_OK);    response.getWriter().write(&quot;&lt;h1&gt;哈哈&lt;/h1&gt;&quot;);&#125;\n\n我们可以轻易使用一个demo来复现这个问题，在maven中添加如下依赖\n&lt;dependency&gt;    &lt;groupId&gt;org.eclipse.jetty&lt;/groupId&gt;    &lt;artifactId&gt;jetty-server&lt;/artifactId&gt;    &lt;version&gt;9.4.35.v20201120&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;org.eclipse.jetty&lt;/groupId&gt;    &lt;artifactId&gt;jetty-servlet&lt;/artifactId&gt;    &lt;version&gt;9.4.35.v20201120&lt;/version&gt;&lt;/dependency&gt;\n\npackage com.hezhangjian.jetty;import org.eclipse.jetty.server.Server;import org.eclipse.jetty.servlet.ServletContextHandler;import org.eclipse.jetty.servlet.ServletHolder;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.IOException;public class SimpleJettyServer &#123;    public static void main(String[] args) throws Exception &#123;        Server server = new Server(8080);        ServletContextHandler context = new ServletContextHandler(ServletContextHandler.SESSIONS);        context.setContextPath(&quot;/&quot;);        server.setHandler(context);        context.addServlet(new ServletHolder(new HelloDefaultServlet()), &quot;/hello-default&quot;);        context.addServlet(new ServletHolder(new HelloUTF8Servlet()), &quot;/hello-utf8&quot;);        server.start();        server.join();    &#125;    public static class HelloDefaultServlet extends HttpServlet &#123;        @Override        protected void doGet(HttpServletRequest request, HttpServletResponse response)                throws IOException &#123;            response.setContentType(&quot;text/plain&quot;);            response.setStatus(HttpServletResponse.SC_OK);            response.getWriter().write(&quot;&lt;h1&gt;哈哈&lt;/h1&gt;&quot;);        &#125;    &#125;    public static class HelloUTF8Servlet extends HttpServlet &#123;        @Override        protected void doGet(HttpServletRequest request, HttpServletResponse response)                throws IOException &#123;            response.setContentType(&quot;text/plain; charset=UTF-8&quot;);            response.setStatus(HttpServletResponse.SC_OK);            response.getWriter().write(&quot;&lt;h1&gt;哈哈&lt;/h1&gt;&quot;);        &#125;    &#125;&#125;\n\n通过curl命令来复现这个问题\ncurl localhost:8080/hello-default&lt;h1&gt;??&lt;/h1&gt;%curl localhost:8080/hello-utf8&lt;h1&gt;哈哈&lt;/h1&gt;%\n\n那么servlet里面的数据如何编码，我们可以dive一下，首先servlet里面有一个函数叫**response.setCharacterEncoding();**这个函数可以指定编码格式。其次，servlet还会通过上面的setContentType函数来做一定的推断，比如content-type中携带了charset，就使用content-type中的charset。还有些特定的content-type，比如text&#x2F;json，在没有设置的情况下，servlet容器会假设它使用utf-8编码。在推断不出来，也没有手动设置的情况下，jetty默认的编码是iso-8859-1，这就解释了乱码的问题。\n","tags":["Java","Jetty"]},{"title":"Prometheus tsdb索引布局及查询流程","url":"/2022/07/18/prometheus%20tsdb%E7%B4%A2%E5%BC%95%E5%B8%83%E5%B1%80%E5%8F%8A%E6%9F%A5%E8%AF%A2%E6%B5%81%E7%A8%8B/","content":"prometheus 磁盘布局采集到的数据每两个小时形成一个block。每个block由一个目录组成，并存放在data路径下。该目录包含一个包含该时间窗口的所有时间序列样本的块子目录、一个元数据文件和一个索引文件（将metric_name和label索引到目录下的时间序列）。 chunks 目录中的样本默认组合成一个或多个段文件，每个段文件最大为 512MB。 当通过 API 删除系列时，删除记录存储在单独的 tombstone 文件中（而不是立即从块段中删除数据）。\n当前正在写入的块保存在内存中，没有完全持久化。通过WAL日志来防止崩溃丢失数据。预写日志分为数节(segments)保存在wal文件夹中。这些文件包含尚未压缩的原始数据； 因此它们比常规块文件大得多。 Prometheus 将至少保留三个预写日志文件。在高流量下，会保留三个以上的 WAL 文件，以便保留至少两个小时的原始数据。\n./data├── 01BKGV7JBM69T2G1BGBGM6KB12│   └── meta.json├── 01BKGTZQ1SYQJTR4PB43C8PD98│   ├── chunks│   │   └── 000001│   ├── tombstones│   ├── index│   └── meta.json├── 01BKGTZQ1HHWHV8FBJXW1Y3W0K│   └── meta.json├── 01BKGV7JC0RY8A6MACW02A2PJD│   ├── chunks│   │   └── 000001│   ├── tombstones│   ├── index│   └── meta.json├── chunks_head│   └── 000001└── wal    ├── 000000002    └── checkpoint.00000001        └── 00000000\n\nprometheus概念\nLabel: 标签，string格式的kv组合\nseries: 时间序列，label的组合\nchunk: 时间，value的数据\n\nprometheus索引格式┌────────────────────────────┬─────────────────────┐│ magic(0xBAAAD700) &lt;4b&gt;     │ version(1) &lt;1 byte&gt; │├────────────────────────────┴─────────────────────┤│ ┌──────────────────────────────────────────────┐ ││ │                 Symbol Table                 │ ││ ├──────────────────────────────────────────────┤ ││ │                    Series                    │ ││ ├──────────────────────────────────────────────┤ ││ │                   Postings 1                 │ ││ ├──────────────────────────────────────────────┤ ││ │                      ...                     │ ││ ├──────────────────────────────────────────────┤ ││ │                   Postings N                 │ ││ ├──────────────────────────────────────────────┤ ││ │             Postings Offset Table            │ ││ ├──────────────────────────────────────────────┤ ││ │                      TOC                     │ ││ └──────────────────────────────────────────────┘ │└──────────────────────────────────────────────────┘\n\n写入索引时，可以在上面列出的主要部分之间添加任意数量的0字节作为填充。顺序扫描文件时，必须跳过部分间的任意0字节。\n下面描述的大部分部分都以 len 字段开头。 它总是指定就在尾随 CRC32 校验和之前的字节数。 校验和就计算这些字节的校验和（不包含len字段）\n符号表符号表包含已存储序列的标签对中出现的重复数据删除字符串的排序列表。 它们可以从后续部分中引用，并显着减少总索引大小。\n该部分包含一系列字符串entry，每个entry都以字符串的原始字节长度为前缀。 所有字符串均采用 utf-8 编码。 字符串由顺序索引引用。 字符串按字典顺序升序排序。\n┌────────────────────┬─────────────────────┐│ len &lt;4b&gt;           │ #symbols &lt;4b&gt;       │├────────────────────┴─────────────────────┤│ ┌──────────────────────┬───────────────┐ ││ │ len(str_1) &lt;uvarint&gt; │ str_1 &lt;bytes&gt; │ ││ ├──────────────────────┴───────────────┤ ││ │                . . .                 │ ││ ├──────────────────────┬───────────────┤ ││ │ len(str_n) &lt;uvarint&gt; │ str_n &lt;bytes&gt; │ ││ └──────────────────────┴───────────────┘ │├──────────────────────────────────────────┤│ CRC32 &lt;4b&gt;                               │└──────────────────────────────────────────┘\n序列 series保存一个具体的时间序列，其中包含系列的label集合和block中的chunks。\n每个series都是16字节对齐。series的id为偏移量除以16。series ID 的排序列表也就是series label的字典排序列表。\n┌───────────────────────────────────────┐│ ┌───────────────────────────────────┐ ││ │   series_1                        │ ││ ├───────────────────────────────────┤ ││ │                 . . .             │ ││ ├───────────────────────────────────┤ ││ │   series_n                        │ ││ └───────────────────────────────────┘ │└───────────────────────────────────────┘\n\n每一个series先保存label的数量，然后是包含label键值对的引用。 标签对按字典顺序排序。然后是series涉及的索引块的个数，然后是一系列元数据条目，其中包含块的最小 (mint) 和最大 (maxt) 时间戳以及对其在块文件中位置的引用。mint 是第一个样本的时间，maxt 是块中最后一个样本的时间。 在索引中保存时间范围数据, 允许按照时间范围删除数据时，如果时间范围匹配，不需要直接访问时间数据。\n空间大小优化: 第一个块的 mint 被存储，它的 maxt 被存储为一个增量，并且 mint 和 maxt 被编码为后续块的前一个时间的增量。 类似的，第一个chunk的引用被存储，下一个引用被存储为前一个chunk的增量。\n┌──────────────────────────────────────────────────────────────────────────┐│ len &lt;uvarint&gt;                                                            │├──────────────────────────────────────────────────────────────────────────┤│ ┌──────────────────────────────────────────────────────────────────────┐ ││ │                     labels count &lt;uvarint64&gt;                         │ ││ ├──────────────────────────────────────────────────────────────────────┤ ││ │              ┌────────────────────────────────────────────┐          │ ││ │              │ ref(l_i.name) &lt;uvarint32&gt;                  │          │ ││ │              ├────────────────────────────────────────────┤          │ ││ │              │ ref(l_i.value) &lt;uvarint32&gt;                 │          │ ││ │              └────────────────────────────────────────────┘          │ ││ │                             ...                                      │ ││ ├──────────────────────────────────────────────────────────────────────┤ ││ │                     chunks count &lt;uvarint64&gt;                         │ ││ ├──────────────────────────────────────────────────────────────────────┤ ││ │              ┌────────────────────────────────────────────┐          │ ││ │              │ c_0.mint &lt;varint64&gt;                        │          │ ││ │              ├────────────────────────────────────────────┤          │ ││ │              │ c_0.maxt - c_0.mint &lt;uvarint64&gt;            │          │ ││ │              ├────────────────────────────────────────────┤          │ ││ │              │ ref(c_0.data) &lt;uvarint64&gt;                  │          │ ││ │              └────────────────────────────────────────────┘          │ ││ │              ┌────────────────────────────────────────────┐          │ ││ │              │ c_i.mint - c_i-1.maxt &lt;uvarint64&gt;          │          │ ││ │              ├────────────────────────────────────────────┤          │ ││ │              │ c_i.maxt - c_i.mint &lt;uvarint64&gt;            │          │ ││ │              ├────────────────────────────────────────────┤          │ ││ │              │ ref(c_i.data) - ref(c_i-1.data) &lt;varint64&gt; │          │ ││ │              └────────────────────────────────────────────┘          │ ││ │                             ...                                      │ ││ └──────────────────────────────────────────────────────────────────────┘ │├──────────────────────────────────────────────────────────────────────────┤│ CRC32 &lt;4b&gt;                                                               │└──────────────────────────────────────────────────────────────────────────┘\n\nPostingPosting这一节存放着关于series引用的单调递增列表，简单来说就是存放id和时间序列的对应关系\n┌────────────────────┬────────────────────┐│ len &lt;4b&gt;           │ #entries &lt;4b&gt;      │├────────────────────┴────────────────────┤│ ┌─────────────────────────────────────┐ ││ │ ref(series_1) &lt;4b&gt;                  │ ││ ├─────────────────────────────────────┤ ││ │ ...                                 │ ││ ├─────────────────────────────────────┤ ││ │ ref(series_n) &lt;4b&gt;                  │ ││ └─────────────────────────────────────┘ │├─────────────────────────────────────────┤│ CRC32 &lt;4b&gt;                              │└─────────────────────────────────────────┘\n\nPosting sections的顺序由postings offset table决定。\nPosting Offset Tablepostings offset table包含着一系列posting offset entry，根据label的名称和值排序。每一个posting offset entry存放着label的键值对以及在posting sections中其series列表的偏移量。用来跟踪posting sections。当index文件加载时，它们将部分加载到内存中。\n┌─────────────────────┬──────────────────────┐│ len &lt;4b&gt;            │ #entries &lt;4b&gt;        │├─────────────────────┴──────────────────────┤│ ┌────────────────────────────────────────┐ ││ │  n = 2 &lt;1b&gt;                            │ ││ ├──────────────────────┬─────────────────┤ ││ │ len(name) &lt;uvarint&gt;  │ name &lt;bytes&gt;    │ ││ ├──────────────────────┼─────────────────┤ ││ │ len(value) &lt;uvarint&gt; │ value &lt;bytes&gt;   │ ││ ├──────────────────────┴─────────────────┤ ││ │  offset &lt;uvarint64&gt;                    │ ││ └────────────────────────────────────────┘ ││                    . . .                   │├────────────────────────────────────────────┤│  CRC32 &lt;4b&gt;                                │└────────────────────────────────────────────┘\n\nTOCtable of contents是整个索引的入口点，并指向文件中的各个部分。 如果引用为零，则表示相应的部分不存在，查找时应返回空结果。\n┌─────────────────────────────────────────┐│ ref(symbols) &lt;8b&gt;                       │├─────────────────────────────────────────┤│ ref(series) &lt;8b&gt;                        │├─────────────────────────────────────────┤│ ref(label indices start) &lt;8b&gt;           │├─────────────────────────────────────────┤│ ref(label offset table) &lt;8b&gt;            │├─────────────────────────────────────────┤│ ref(postings start) &lt;8b&gt;                │├─────────────────────────────────────────┤│ ref(postings offset table) &lt;8b&gt;         │├─────────────────────────────────────────┤│ CRC32 &lt;4b&gt;                              │└─────────────────────────────────────────┘\n\nchunks 磁盘格式chunks文件创建在block中的chunks/目录中。 每个段文件的最大大小为 512MB。文件中的chunk由uint64的索引组织，索引低四位为文件内偏移，高四位为段序列号。\n┌──────────────────────────────┐│  magic(0x85BD40DD) &lt;4 byte&gt;  │├──────────────────────────────┤│    version(1) &lt;1 byte&gt;       │├──────────────────────────────┤│    padding(0) &lt;3 byte&gt;       │├──────────────────────────────┤│ ┌──────────────────────────┐ ││ │         Chunk 1          │ ││ ├──────────────────────────┤ ││ │          ...             │ ││ ├──────────────────────────┤ ││ │         Chunk N          │ ││ └──────────────────────────┘ │└──────────────────────────────┘\n\nchunks中的Chunk格式┌───────────────┬───────────────────┬──────────────┬────────────────┐│ len &lt;uvarint&gt; │ encoding &lt;1 byte&gt; │ data &lt;bytes&gt; │ CRC32 &lt;4 byte&gt; │└───────────────┴───────────────────┴──────────────┴────────────────┘\n\n查询数据code查询的prometheus方法签名\nSelect(sortSeries bool, hints *SelectHints, matchers ...*labels.Matcher) SeriesSet\n\n支持从block中，remote等各种地方查询获取数据\nprometheus会在内存中维护一个数据结构\n// Map of LabelName to a list of some LabelValues&#x27;s position in the offset table.// The first and last values for each name are always present.postings map[string][]postingOffset\n\n在内存中，保留每个label name，并且每n个保存label值，降低内存的占用。但是第一个和最后一个值总是保存在内存中。\n查询数据流程\n参考资料\nhttps://prometheus.io/docs/prometheus/latest/storage/\nhttps://github.com/prometheus/prometheus/blob/release-2.37/tsdb/docs/format/README.md\nhttps://github.com/prometheus/prometheus/blob/release-2.37/tsdb/docs/format/index.md\n\n","tags":["Prometheus"]},{"title":"一些微服务开发规范","url":"/2024/12/08/%E4%B8%80%E4%BA%9B%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%BC%80%E5%8F%91%E8%A7%84%E8%8C%83/","content":"消费组名称\n共享消费者使用微服务名称，比如(DeviceManager)\n广播消费者使用微服务名称+唯一标识，比如\nkubernetes部署场景下可以将pod名称的唯一部分作为唯一标识，比如下图的nginx可以使用5d4f5c59f8-7hztx作为唯一标识$ kubectl get podNAME                          READY   STATUS    RESTARTS   AGEnginx-deployment-5d4f5c59f8-7hztx   1/1     Running   0          2d3hnginx-deployment-5d4f5c59f8-xvbnm   1/1     Running   0          2d3hredis-5f67c8d8c9-4g2h3              1/1     Running   0          10h\n\npod的IP地址\nUUID\n\n\n\n数据库表\n数据库表名使用单数。\n数据库的主键，要考虑对应实体物理上是否唯一。\n数据库可以分为多个列组合唯一、单列唯一、是否有唯一索引、是否有二级索引。\n\n","tags":["微服务"]},{"title":"一步一步教你写kubernetes sidecar","url":"/2022/03/31/%E4%B8%80%E6%AD%A5%E4%B8%80%E6%AD%A5%E6%95%99%E4%BD%A0%E5%86%99kubernetes%20sidecar/","content":"什么是sidecar？\nsidecar，直译为边车。 如上图所示，边车就是加装在摩托车旁来达到拓展功能的目的，比如行驶更加稳定，可以拉更多的人和货物，坐在边车上的人可以给驾驶员指路等。边车模式通过给应用服务加装一个“边车”来达到控制和逻辑的分离的目的。\n对于微服务来讲，我们可以用边车模式来做诸如 日志收集、服务注册、服务发现、限流、鉴权等不需要业务服务实现的控制面板能力。通常和边车模式比较的就是像spring-cloud那样的sdk模式，像上面提到的这些能力都通过sdk实现。\n\n这两种实现模式各有优劣，sidecar模式会引入额外的性能损耗以及延时，但传统的sdk模式会让代码变得臃肿并且升级复杂，控制面能力和业务面能力不能分开升级。\n本文的代码已经上传到gitee\nsidecar 实现原理介绍了sidecar的诸多功能，但是，sidecar是如何做到这些能力的呢？\n原来，在kubernetes中，一个pod是部署的最小单元，但一个pod里面，允许运行多个container(容器)，多个container(容器)之间共享存储卷和网络栈。这样子，我们就可以多container来做sidecar，或者init-container（初始化容器）来调整挂载卷的权限\n\n日志收集sidecar日志收集sidecar的原理是利用多个container间可以共用挂载卷的原理实现的，通过将应用程序的日志路径挂出，用另一个程序访问路径下的日志来实现日志收集，这里用cat来替代了日志收集，部署yaml模板如下\napiVersion: v1kind: Podmetadata:  name: webserverspec:  volumes:    - name: shared-logs      emptyDir: &#123;&#125;  containers:    - name: nginx      image: ttbb/nginx:mate      volumeMounts:        - name: shared-logs          mountPath: /opt/sh/openresty/nginx/logs    - name: sidecar-container      image: ttbb/base      command: [&quot;sh&quot;,&quot;-c&quot;,&quot;while true; do cat /opt/sh/openresty/nginx/logs/nginx.pid; sleep 30; done&quot;]      volumeMounts:        - name: shared-logs          mountPath: /opt/sh/openresty/nginx/logs\n\n使用kubectl create -f 创建pod，通过kubectl logs命令就可以看到sidecar-container打印的日志输出\nkubectl logs webserver sidecar-container\n\n转发请求sidecar这一节我们来实现，一个给应用程序转发请求的sidecar，应用程序代码如下\nuse std::io::prelude::*;use std::net::&#123;TcpListener, TcpStream&#125;;fn main() &#123;    let listener = TcpListener::bind(&quot;127.0.0.1:7878&quot;).unwrap();    for stream in listener.incoming() &#123;        let stream = stream.unwrap();        handle_connection(stream);    &#125;    println!(&quot;Hello, world!&quot;);&#125;fn handle_connection(mut stream: TcpStream) &#123;    let mut buffer = [0; 1024];    stream.read(&amp;mut buffer).unwrap();    let contents = &quot;Hello&quot;;    let response = format!(        &quot;HTTP/1.1 200 OK\\r\\nContent-Length: &#123;&#125;\\r\\n\\r\\n&#123;&#125;&quot;,        contents.len(),        contents    );    println!(&quot;receive a request!&quot;);    stream.write(response.as_bytes()).unwrap();    stream.flush().unwrap();&#125;\n\n我们再来写一个sidecar，它会每15秒向应用程序发出请求\nuse std::thread;use std::time::Duration;fn main() &#123;    loop &#123;        thread::sleep(Duration::from_secs(15));        let response = reqwest::blocking::get(&quot;http://localhost:7878&quot;).unwrap();        println!(&quot;&#123;&#125;&quot;, response.text().unwrap())    &#125;&#125;\n\n通过仓库下的intput/build.sh脚本构造镜像，运行yaml如下\napiVersion: v1kind: Podmetadata:  name: webserverspec:  containers:    - name: input-server      image: sidecar-examples:input-http-server    - name: input-sidecar      image: sidecar-examples:sidecar-input\n通过查看kubectl logs input input-http-server可以看到input-http-server收到了请求\nreceive a request!receive a request!\n拦截请求sidecar应用程序代码，它会每15s向localhost发出请求\npackage com.hezhangjian.sidecarimport akka.actor.typed.ActorSystemimport akka.actor.typed.scaladsl.Behaviorsimport akka.http.scaladsl.Httpimport akka.http.scaladsl.model._import scala.concurrent.&#123;ExecutionContextExecutor, Future&#125;import scala.util.&#123;Failure, Success&#125;object HttpClient &#123;    def main(args: Array[String]): Unit = &#123;        while (true) &#123;            Thread.sleep(15_000L)            implicit val system: ActorSystem[Nothing] = ActorSystem(Behaviors.empty, &quot;SingleRequest&quot;)            // needed for the future flatMap/onComplete in the end            implicit val executionContext: ExecutionContextExecutor = system.executionContext            val responseFuture: Future[HttpResponse] = Http().singleRequest(HttpRequest(uri = &quot;http://localhost:7979/hello&quot;))            responseFuture                    .onComplete &#123;                        case Success(res) =&gt; println(res)                        case Failure(_) =&gt; sys.error(&quot;something wrong&quot;)                    &#125;        &#125;    &#125;&#125;\n\n我们再来写一个sidecar，它会拦截http请求并打印日志\npackage com.hezhangjian.sidecarimport akka.actor.typed.ActorSystemimport akka.actor.typed.scaladsl.Behaviorsimport akka.http.scaladsl.Httpimport akka.http.scaladsl.model._import akka.http.scaladsl.server.Directives._import scala.concurrent.ExecutionContextExecutorimport scala.io.StdInobject HttpServer &#123;    def main(args: Array[String]): Unit = &#123;        implicit val system: ActorSystem[Nothing] = ActorSystem(Behaviors.empty, &quot;my-system&quot;)        // needed for the future flatMap/onComplete in the end        implicit val executionContext: ExecutionContextExecutor = system.executionContext        val route =            path(&quot;hello&quot;) &#123;                get &#123;                    println(&quot;receive a request&quot;)                    complete(HttpEntity(ContentTypes.`text/html(UTF-8)`, &quot;&lt;h1&gt;Say hello to akka-http&lt;/h1&gt;&quot;))                &#125;            &#125;        val bindingFuture = Http().newServerAt(&quot;localhost&quot;, 7979).bind(route)        while (true) &#123;            Thread.sleep(15_000L)        &#125;    &#125;&#125;\n\n通过仓库下的output/build.sh脚本构造镜像，运行yaml如下\napiVersion: v1kind: Podmetadata:  name: outputspec:  volumes:    - name: shared-logs      emptyDir: &#123;&#125;  containers:    - name: output-workload      image: sidecar-examples:output-workload      imagePullPolicy: Never    - name: sidecar-output      image: sidecar-examples:sidecar-output      imagePullPolicy: Never\n\n通过查看kubectl logs output output-workload可以看到output-sidecar收到了请求\nHttpResponse(200 OK,List(Server: akka-http/10.2.9, Date: Tue, 29 Mar 2022 00:15:47 GMT),HttpEntity.Strict(text/html; charset=UTF-8,31 bytes total),HttpProtocol(HTTP/1.1))HttpResponse(200 OK,List(Server: akka-http/10.2.9, Date: Tue, 29 Mar 2022 00:16:02 GMT),HttpEntity.Strict(text/html; charset=UTF-8,31 bytes total),HttpProtocol(HTTP/1.1))HttpResponse(200 OK,List(Server: akka-http/10.2.9, Date: Tue, 29 Mar 2022 00:16:17 GMT),HttpEntity.Strict(text/html; charset=UTF-8,31 bytes total),HttpProtocol(HTTP/1.1))HttpResponse(200 OK,List(Server: akka-http/10.2.9, Date: Tue, 29 Mar 2022 00:16:32 GMT),HttpEntity.Strict(text/html; charset=UTF-8,31 bytes total),HttpProtocol(HTTP/1.1))HttpResponse(200 OK,List(Server: akka-http/10.2.9, Date: Tue, 29 Mar 2022 00:16:47 GMT),HttpEntity.Strict(text/html; charset=UTF-8,31 bytes total),HttpProtocol(HTTP/1.1))HttpResponse(200 OK,List(Server: akka-http/10.2.9, Date: Tue, 29 Mar 2022 00:17:02 GMT),HttpEntity.Strict(text/html; charset=UTF-8,31 bytes total),HttpProtocol(HTTP/1.1))HttpResponse(200 OK,List(Server: akka-http/10.2.9, Date: Tue, 29 Mar 2022 00:17:17 GMT),HttpEntity.Strict(text/html; charset=UTF-8,31 bytes total),HttpProtocol(HTTP/1.1))HttpResponse(200 OK,List(Server: akka-http/10.2.9, Date: Tue, 29 Mar 2022 00:17:32 GMT),HttpEntity.Strict(text/html; charset=UTF-8,31 bytes total),HttpProtocol(HTTP/1.1))\n","tags":["Kubernetes"]},{"title":"业务配置中心的实现","url":"/2021/05/13/%E4%B8%9A%E5%8A%A1%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83%E7%9A%84%E5%AE%9E%E7%8E%B0/","content":"前言之前在InfoQ的《华为云物联网四年配置中心实践》文章中分享了业务配置中心。\n本文讲述业务配置中心（下文简述为配置中心）的关键技术和实现方式。华为云物联网平台按照本文的实现方式实现了一个业务配置中心，该配置中心2020年1月上线，平稳运行至今。\n概念运维配置和用户无关，通常为集群界级别的配置，程序只会进行读取，如数据库配置、邮箱服务器配置、网卡配置、子网地址配置等。\n业务配置作为SaaS 服务，每个用户在上面都有一些业务配置。如用户的证书配置、用户服务器的流控配置等，这些业务配置相对运维配置来说更加复杂，且可能会有唯一性限制，如按用户 id 唯一。这部分配置数据一般由用户操作触发，代码动态写入，并且通知到各个微服务实例。通常，我们希望这些配置能在界面展示，且支持人为修改。上述逻辑如果由各微服务自己实现，会存在大量重复代码，并且质量无法保证。我们希望由一个公共组件来统一实现这个能力。开源或体量较小的项目就不会选择依赖一个配置中心，而是直接通过连接数据库或etcd来解决问题\nenv代表一个部署环境。\ncluster代表环境下的集群。常见于单环境下蓝绿发布，蓝集群、绿集群、金丝雀集群等。\n配置配置名称，如用户证书配置、用户流控配置等。\nKey配置的唯一键，如用户id。\nValue配置唯一键对应的值。\n配置中心设计梗概业务配置特点\n虽然业务配置写入可能存在并发，但并发量不大，频率较低。\n业务配置常常以用户为id，单集群用户量有限，一般不超过5万。\n\n配置中心要解决的问题\n设计要点\n单配置要求有配置id，每个id上通过version的乐观并发控制来解决多版本冲突问题\n通知不追求可靠，应用程序和配置中心断链无法接收通知的场景下，通过定期同步数据来保证数据的可靠\n支持Schema的变更，因Schema变更不频繁，也采用version的乐观并发控制来解决多版本冲突问题\n\n通知是否包含消息内容我认为应该只通知Key，具体的数值让应用程序再去配置中心查询。仅通知Key实现简洁易懂。同时通知Key&amp;Value需要多考虑定期同步和通知两条通道并发，可能引起的竞态冲突。\n配置中心业务流程本小节描述业务配置中心的所有业务流程，并试图从交互中抽象出与具体实现无关的接口\n配置的增删改查\n配置值的增删改查\n定期同步分布式场景下，通知有可能无法送达，如程序陷入网络中断（或长gc），通知消息送达超时，待程序恢复后，数据不再准确。因此需要对数据做定期同步，提高可靠性。\n\n同步过程中，仅仅请求交互id和version，避免传输大量数据。应用程序接收到需要同步的数据后：\n\n删除操作，触发删除通知，从本地缓存中移除数据。\n添加、修改操作，向配置中心查询最新数据，触发通知并写入本地缓存。\n\n服务启动服务启动也可看做是一个同步的流程，只是需要同步大量的数据添加。为了避免向配置中心频繁大量的请求，引入批量操作来减轻压力\n\n限制该配置中心设计思路依赖客户端可把数据全量放入到内存中，如用户量太大，则不适合采用这种模式。\n注：一个节省内存的思路是，内存中只放置全量的id和version，数据只有当用到的时候再去查询。这个思路要求配置中心持久化一些老旧数据以供以下场景的查询使用\n\n业务流程中，需要使用该配置值的。\n\n回调业务程序修改的时候，需要提供旧值的。\n\n\n除此之外没有任何区别。\n业务配置抽象实现从上述描述的业务场景，我们抽象出业务配置中心的交互接口和抽象实现。接口的Swagger Yaml已上传到Github：https://gist.github.com/hezhangjian/68c9c2ecae72cc2a125184e95b0a741e\n配置相关接口\n提供env、cluster、配置名称、配置Schema、配置版本号添加配置\n提供env、cluster、配置名称删除配置\n提供env、cluster、配置名称、新Schema、新Version来修改配置\n提供env、cluster、配置名称来查询配置\n\n配置值相关接口\n提供env、cluster、配置名称、Key、Value来添加配置值\n提供env、cluster、Key、ValueVersion（可选）来删除配置值\n提供env、cluster、Key、Value、ValueVersion（可选）修改配置值\n提供env、cluster、Key查询配置值\n根据env、cluster、应用程序当前的配置数据来做定期同步\n根据Key列表批量查询配置值\n\n通知相关接口\n通知某env某cluster下，配置项中的一个Key发生变化，新增、修改或是删除。可选方式有HTTP长链接（Inspired by Apollo）、Mqtt、WebSocket等。\n\n配置中心存储层抽象实现配置中心存储层需要存储配置和配置值数据，支持UpdateByVersion，且需要捕捉数据的变化，用来通知到应用程序\n服务发现抽象实现为了使应用程序连接到配置中心，需要一个发现机制可以让应用程序感知到配置中心的地址。高可用的方式很多，如K8s发现、ZooKeeper、Etcd、ServiceComb、业务环境变量注入ELB地址（ELB后端挂载配置中心的地址）等。\n抽象总结\n根据这个抽象，我们可以进行关键技术点选型，来实现业务配置中心。\n配置中心实现华为云物联网配置中心实现\n\nenv+cluster+config组成数据表的名称\n一个key、value对应一行数据\n\n另一种实现方式只要实现上述接口和抽象能力，都可以实现业务配置中心，也可以这么实现\n\n\nenv+cluster+config+key 组合成etcd的key\n一个key、value对应一个键值对\n\n又一种实现方式当然也可以\n\n\nenv+cluster+config+key 组合成RocksDB的key\n一个key、value对应一个键值对\n\n"},{"title":"从ASCII到Unicode，以及UTF-8、UTF-16、UTF-32","url":"/2024/11/24/%E4%BB%8EASCII%E5%88%B0Unicode%EF%BC%8C%E4%BB%A5%E5%8F%8AUTF-8%E3%80%81UTF-16%E3%80%81UTF-32/","content":"Unicode起源ASCIIASCII（American Standard Code for Information Interchange）是一种字符编码标准，它使用7位二进制数来表示128个字符，包括大小写字母、数字、标点符号、控制字符等。ASCII编码是由美国国家标准协会（ANSI）制定的，于1963年发布，是最早的字符编码标准之一。\nASCII不够用了随着计算机不仅仅用于英文，而是用于全球各种语言，ASCII编码已经不能满足需求，针对不同语言的编码方案也应运而生，这其中诞生了很多编码方案，比如GB2312、BIG5、ISO-8859等，这些字符集典型的就是将ASCII的最高位利用起来，将7位扩展到8位，这样就可以表示256个字符。比如ISO-8859-1就是将ASCII的最高位利用起来，表示了拉丁字母。ISO-8859-5表示了西里尔字母。\n这些字符集各自不包含全部的字符，而且不兼容，这就导致了字符集混乱。这导致在一个文件中混用多种字符成为了不可能完成的事情。而Unicode改变了这一切，它的愿景就是Unicode官网中说到的。\nEveryone in the world should be able to use their own language on phones and computers.\n\n在早期，Unicode曾想过固定使用16位来表示字符，这就是UCS-2编码，也是UTF-16的前身，后面发现固定16位字符还是不够用，这才发展成了我们现在熟知的Unicode。\nUnicode介绍Unicode是一个文本编码标准。Unicode通过一个唯一的数字来定义每个字符，不管平台、程序或语言。这个数字叫做码点（code point）。Unicode码点是从0x000000到0x10FFFF（十六进制），书写上通常使用U+打头，跟上至少4位十六进制数（不足则补0），如U+0041（字母A）、U+1F600（emoji 😀），理论上，Unicode可以定义1114112个字符。\nUnicode的码点跟字符是怎么对应的呢？Unicode将这些码点分成了若干个区段，每个区段称为一个平面（plane），每个平面包含65536（对应低位的0x0000~0xffff）个码点。Unicode总共有17个平面，编号从0到16。Unicode的码点分布如下：\n\n\n\n平面编号\n码点区间\n英文缩写\n英文名\n中文名\n\n\n\n0 号平面\nU+000000 - U+00FFFF\nBMP\nBasic Multilingual Plane\n基本多文种平面\n\n\n1 号平面\nU+010000 - U+01FFFF\nSMP\nSupplementary Multilingual Plane\n多文种补充平面\n\n\n2 号平面\nU+020000 - U+02FFFF\nSIP\nSupplementary Ideographic Plane\n表意文字补充平面\n\n\n3 号平面\nU+030000 - U+03FFFF\nTIP\nTertiary Ideographic Plane\n表意文字第三平面\n\n\n4 号平面 ~ 13 号平面\nU+040000 - U+0DFFFF\n&#x2F;\n已分配，但尚未使用\n&#x2F;\n\n\n14 号平面\nU+0E0000 - U+0EFFFF\nSSP\nSupplementary Special-purpose Plane\n特别用途补充平面\n\n\n15 号平面\nU+0F0000 - U+0FFFFF\nPUA-A\nPrivate Use Area-A\n保留作为私人使用区 (A区)\n\n\n16 号平面\nU+100000 - U+10FFFF\nPUA-B\nPrivate Use Area-B\n保留作为私人使用区 (B区)\n\n\n中文、英文均在0号平面，详细的分配可以参考Unicode的RoadMap。\n那么Unicode先定义了码点和字符之间的对应关系，但是如何存储在磁盘上，如何在网络中传输，这就引入了编码方式，编码方式决定了Unicode的码点如何转换为字节流。这就是Unicode定义的三种编码方式：UTF-32、UTF-16、UTF-8。\nUTF-32（32-bit Unicode Transformation Format）在介绍完Unicode之后，UTF-32是最简单、最容易想到的一种编码方式，直接将Unicode的码点以32位整数的方式存储起来。其中Rust的字符类型char，就使用32位值来表示Unicode字符。\n但是这种方式也有很显然的缺点，就是浪费空间，实际Unicode的范围，只需要21位就可以表示了，变长编码就应运而生。\nUTF-16（16-bit Unicode Transformation Format）这里我想给大家讲一个背景知识，编码方案的扩展，通常会尝试去兼容旧的编码方案，这使得新的编辑器可以打开旧的文件，如果没有用到新的字符，那么新的文件也可以被旧的编辑器打开。这使得演进更加平滑，更易落地。\n那就不得不先说一下UCS-2编码方案，如前所述，UCS-2想通过固定16位来表示字符，虽然它最终失败了，但是也影响了很多的系统，比如Windows、Jdk。\nUTF-16编码就以兼容UCS-2编码、变长为两个目标，UTF-16的编码规则\n\n① 对于码点小于等于U+FFFF的字符，直接使用16位表示，兼容UCS-2\n② 对于码点小于等于U+10FFFF的字符，使用两个16位表示\n\n\n这个补丁机制也常被人称作是surrogate。\n\n对于变长编码来说，对于文件中的任意一个字符，怎么能判断出来这是场景①的字符，还是场景②的第一个字符？抑或是场景②的第二个字符？\nUnicode给出的答案是，通过在BMP中舍弃U+D800到U+DFFF的码点，这个区间被称为代理对（surrogate pair），这个区间的码点不会被分配给字符，这样就可以通过这个区间来判断是场景①还是场景②。如果读取的时候，发现前两个字节是D8到DB，那么就是场景②的第一个字符；如果是DC到DF，那么就是场景②的第二个字符；否则就是场景①的字符。\n\n高代理（High-half surrogates）：范围是0xD800~0xDBFF，二进制范围为1101 1000 0000 ~ 1101 1111 1111，这也代表着高代理的前六位一定是110110。\n低代理（Low-half surrogates）：范围是0xDC00~0xDFFF，二进制范围为1101 1100 0000 ~ 1101 1111 1111，这也代表着低代理的前六位一定是110111。\n\n那么聪明的读者应该分析出来了，使用两个16位表示，由于存在代理对的固定部分，剩余的有效位还剩下20位。这20位恰好可以覆盖从U+010000到U+10FFFF的码点范围。由于U+0000-U+FFFF已经在场景①中覆盖，通过将码点减去0x10000，范围就变成了0x000000~0x0FFFFF，恰好是20位整数。\nUTF-8（8-bit Unicode Transformation Format）UTF-8的编码规则\n\n① 对于码点小于等于U+007F的字符，直接使用8位表示，兼容ASCII。\n② 对于码点小于等于U+07FF的字符，使用两个8位表示，其中有效位为11位。\n③ 对于码点小于等于U+FFFF的字符，使用三个8位表示，其中有效位为16位。\n④ 对于码点小于等于U+10FFFF的字符，使用四个8位表示，其中有效位为21位。\n⑤ 使用n个字节（n&gt;1）来表示一个字符时，第一个字节的前n位都是1，第n+1位是0，后面的字节的前两位都是10\n\n那么对于一个字节，就可以通过首位是不是1，来判断是1个字节还是n个字节，再通过第二个字节判断是否是首位，最后通过首位来判断字节的个数。\n由于UTF-8的有效位最大可达21位，这也就使得UTF-8不用像UTF-16那样减去0x10000。\n通过兼容ASCII，最短只用1个字节，这使得UTF-8成为了堪称最流行的编码方式，如果不需要兼容UCS-2，那么几乎可以说UTF-8是最好的选择，堪称当前事实上的标准。值得一提的是，UTF-8的主要设计者，也是Unix的创始人之一，Go语言的设计者之一，Ken Thompson。\n扩展知识JDK17中英文字符集内存占用量降低了一半读者可能会觉得JDK17中中文字符内存占用降低一半是从UTF-16切换到UTF-8导致的，但实则不然，对于JDK来说，切换一种编码方式可谓是伤筋动骨，JDK17通过了JEP254提案，通过添加一个标志位，如果字符串的字符都是ISO-8859-1&#x2F;Latin-1字符，那么就使用一个字节进行存储。\n","tags":["Unicode"]},{"title":"中间件是开箱即用的吗？为什么要开发中间件adapter？","url":"/2021/08/09/%E4%B8%AD%E9%97%B4%E4%BB%B6%E6%98%AF%E5%BC%80%E7%AE%B1%E5%8D%B3%E7%94%A8%E7%9A%84%E5%90%97%EF%BC%9F%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%BC%80%E5%8F%91%E4%B8%AD%E9%97%B4%E4%BB%B6adapter%EF%BC%9F/","content":"中间件在很多系统中都存在在一个系统里面，或多或少地都会有中间件的存在，总会有数据库吧，其他的如消息队列，缓存，大数据组件。即使是基于公有云构筑的系统，公有云厂商只提供广泛使用的中间件，假如你的系统里面有很多组件没那么泛用，那么就只能自己维护，如ZooKeeper、Etcd、Pulsar、Prometheus、Lvs等\n什么是中间件adapter中间件adapter指的是和中间件运行在一起（同一个物理机或同一个容器），使得中间件和商用系统中已有的组件进行对接，最终使得该中间件达到在该系统商用的标准。像Prometheus的众多exporter，就是将中间件和已有的监控系统（Prometheus）进行对接的adpater。\n为什么不修改中间件源码直接集成原因可以有很多，这里我列出几点\n源码修改容易，维护困难很多时候不是社区通用需求，无法合并到社区主干。后续每次中间件版本升级，源码的修改就要重新进行一次。社区大版本代码重构，有的甚至不知道如何修改下去。并且对研发人员的技能要求高。\n源码与团队技术栈不同，修改困难这是最常见的，像java团队维护erlang写的rabbitmq\n和其他系统对接，有语言要求XX监控系统，只能使用X语言接入，但中间件使用Y语言写的，怎么办？adapter的能力就体现出来了。\n为什么在商用系统中中间件做不到开箱即用在商用系统中，对一个新引入的中间件，往往有如下能力上的诉求，原生的中间件很难满足\n\n适配原有的监控系统\n适配原有的告警系统\n适配原有的证书系统\n适配原有的备份系统（如果该中间件有状态）\n适配原有的容灾系统（如果该中间件有状态）\n自动化能力（适配部署、账号创建、权限策略创建）\n对外暴露时封装一层接口\n应用程序和中间件的服务发现\n\n有时候，业务也会根据业务的需求对中间件做一些能力增强，这部分需求比较定制，这里无法展开讨论了。\n我们来逐一讨论上面列出的能力诉求，凡是adapter能实现的功能，对中间件做修改也能实现，只不过因为上一节列出的原因，选择不在中间件处侵入式修改。\n适配原有的监控系统监控系统获取数据，往往是推拉两种模式，如果该中间件原生不支持和该监控系统对接。我们就可以让adapter先从中间件处取得监控数据，再和监控系统对接\n适配原有的告警系统如果中间件发生了不可恢复的错误，如写事务文件失败，操作ZooKeeper元数据失败，可以通过adapter来识别中间件是否发生了上述不可恢复的错误，并和告警系统对接，发出告警。\n适配原有的证书系统这一点也很关键，开源的中间件，根据我的了解，几乎没有项目做了动态证书轮换的方案，证书基本都不支持变更。而出色的商用系统是一定要支持证书轮换的。不过很遗憾的是，这些涉及到TLS握手的关键流程，adapter无法干涉这个流程，只能对中间件进行侵入式修改。\n适配原有的备份系统通过adapter对中间件进行定期备份、按照配置中心的策略备份、备份文件自动上传到文件服务器等。\n适配原有的容灾系统这个视中间件而定，有些中间件如Pulsar原生支持跨地域容灾的话，我们可能做一做配置就好了。另外一些，像mysql和mongo这种，可能我们还需要通过adapter来进行数据同步。不过这个时候adapter负责的职责就大了，还包括了容灾能力。\n自动化能力自动化部署比如ZooKeeper、Kafka、filebeat在安装的时候，要求填写配置文件，我们就可以让adapter来自动化生成配置或更新配置\n账号和策略的创建更新像kubernetes、mysql、mongo，我们可以在安装的时候通过adapter来自动化创建或更新\n对外暴露时封装一层接口封装接口常用于中间件的提供者，出于种种原因，如中间件原本接口能力太大、中间件原本接口未做权限控制、中间件原本接口未适配期望的权限框架等。我们可以用adapter封装实现一层新的接口对外暴露。\n应用程序和中间件的服务发现应用程序发现中间件应用程序与中间件的连接，说的简单一点就是如何获取Ip，如果是基于kubernetes的部署，那么不推荐配置Ip，最好是配置域名，因为Ip会跟着容器的生命周期变化。首先，你的应用程序并不会因为中间件的一个容器重启了来重建客户端，往往是通过一个简单重连的方式连接到新的中间件容器继续工作。其次，我们的运维人员也不会每时每刻盯着容器Ip是否变化来进行配置吧。以下图为例，域名的配置要优于Ip的配置。\n\n截止到目前，我们只需要一个静态配置，使得应用程序可以连接到中间件。最好这个配置是可以修改的，这样我们还可以继承蓝绿、灰度发布的能力。\n中间件到业务程序的发现这个模式常用于负载均衡中间件如Lvs、Nginx自动维护后端列表，我们可以通过adapter来从注册中心获取后端服务的实例信息，并实时更新。\n总结在商用系统中，中间件并没有想象中的那么开箱即用，本文讲述了一些中间件集成到商用系统中需要具备的能力。在对中间件侵入式修改没有技术能力或不想对中间件进行侵入式修改的场景。选用团队常用的、占用资源少的语言来开发中间件adapter应该是更好的选择。\n","tags":["middleware"]},{"title":"优雅启停VS重试，谁能更好地保证RPC无损","url":"/2021/03/22/%E4%BC%98%E9%9B%85%E5%90%AF%E5%81%9CVS%E9%87%8D%E8%AF%95%EF%BC%8C%E8%B0%81%E8%83%BD%E6%9B%B4%E5%A5%BD%E5%9C%B0%E4%BF%9D%E8%AF%81RPC%E6%97%A0%E6%8D%9F/","content":"背景我们的业务有些时候总是在升级期间rpc业务有一些呼损，想总结一下让rpc调用零呼损的两种方式：重试和优雅启停。我先介绍这两种方式，再描述一下这两种方式的优缺点\n\nA是一个微服务\nB也是一个微服务\n蓝色的是常见的注册中心，有zookeeper、eureka等实现。\n重试重试，在发生可重试错误的时候，重试一次。什么是可重试错误呢？就是重试一次，可能会成功。比如400 BadRequest，那出现这种错误，基本上重试也没有用，就不要浪费我们宝贵的服务器资源了。常见的如servicecomb框架就有重试几次、重试间隔这样的参数。值得一提的是，如果你指望通过重试让升级零呼损，那么你的重试次数，要比你的并行升级实例数大才行。\n这也很容易理解，比如A服务调用B服务，B服务有5个实例,B1~B5。这个时候，同时升级B1和B2，A第一次调用了B1，接下来重试，如果运气不好，恰好重试到了B2节点，那么业务还是会失败的。如果防异常故障，就得重试三次才行。\n如果是防止单数据中心宕机，重试次数大于同时宕机节点数，这个规则可能就没那么靠谱了。现在，企业部署十几个乃至二十几个微服务实例，已经不是什么新闻了，假设分3数据中心部署，总不能重试接近10次吧，这种时候，最好重试策略和数据中心相关，重试的时候，选择另一个az的实例。目前servicecomb还不支持这种功能。\n优雅启停优雅停止优雅停止，就是说当微服务快要宕机的时候，先从注册中心进行去注册，然后把发送给微服务的消息，处理完毕后，再彻底关闭。这个方式，可以有效地防止升级期间，发送到老节点的呼损。\n优雅启动优雅启动，当微服务实例，能够处理rpc请求的时候，再将实例自己注册到注册中心。避免请求发进来，实例却无法处理。\n这里有一个要求，就是调用方发现被调用方（即A发现B）的注册中心，要和B注册、去注册的注册中心是一个注册中心。有案例是，发现采用k8s发现，注册、去注册却使用微服务引擎，导致呼损。\n优劣对比可预知节点升级的场景重试相对于优雅启停，在预知节点升级的场景没那么优雅，重试次数可能还要和并行升级的节点挂钩，非常的不优雅，且难以维护\n不可预知节点升级的场景优雅启停无法对不可预知节点升级的场景生效。只有重试能在这个场景发挥作用\n其他场景重试可以很好地处理网络闪断、长链接中断等场景\n总结想要实现rpc调用零呼损，重试和优雅启停都不可或缺，都需要实现。\n","tags":["RPC"]},{"title":"修改运行中kubernetes集群中etcd的参数","url":"/2023/01/04/%E4%BF%AE%E6%94%B9%E8%BF%90%E8%A1%8C%E4%B8%ADkubernetes%E9%9B%86%E7%BE%A4%E4%B8%ADetcd%E7%9A%84%E5%8F%82%E6%95%B0/","content":"在一些场景下，您的kubernetes集群已经搭建完成了，但是还需要修改一些核心组件的参数，如etcd、kube-apiserver、kube-scheduler、kube-controller-manager等。\n通过kubectl get pod -owide -n kube-system 可以查看到这些核心容器。\nNAME                               READY   STATUS    RESTARTS       AGEcoredns-78fcd69978-rdmjm           1/1     Running   11 (23s ago)   281detcd-$NODE1                        1/1     Running   13 (23s ago)   281detcd-$NODE2                        1/1     Running   13 (23s ago)   281detcd-$NODE3                        1/1     Running   13 (23s ago)   281d.....\n\n以etcd为例，etcd的参数就在pod中的commands参数里。可以通过kubectl describe pod etcd-$NODENAME -n kube-system来查看(省略部分参数)\nName: etcd-$NODENAMENamespace: kube-systemContainers:etcd:Command:--client-cert-auth=true--trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt\n\n然而，如果您尝试编辑pod中的参数，会发现它们是不可修改的。\n不过，如果您需要修改参数，还有另一个办法，通过修改/etc/kubernetes/manifests/下的yaml文件来修改运行中kubernetes集群中”系统”Pod的参数。原理是，当您把yaml文件修改后，kubelet会自动监听yaml文件的变更，并重新拉起本机器上的pod。\n举个例子，如果您希望关闭etcd集群对客户端的认证，那么您可以修改/etc/kubernetes/mainfiest/etcd.yaml,将client-cert-auth设置为false，把trusted-ca-file去掉。注意：三台master机器节点都需要执行此操作\n","tags":["Kubernetes"]},{"title":"分页实践：前后端多种分页方式实现对比","url":"/2023/12/16/%E5%88%86%E9%A1%B5%E5%AE%9E%E8%B7%B5%EF%BC%9A%E5%89%8D%E5%90%8E%E7%AB%AF%E5%A4%9A%E7%A7%8D%E5%88%86%E9%A1%B5%E6%96%B9%E5%BC%8F%E5%AE%9E%E7%8E%B0%E5%AF%B9%E6%AF%94/","content":"在软件开发中，分页没有统一的规范，实现方式也各不相同，有的会返回总页数，有的会返回总条数，有的可以任意翻页。本文对比一下几种常见的分页方式。\n总体来说，分页的实现方案分为四种：\n\n后端全部返回，由前端分页\nlimit offset方案\ncursor方案\ncursor方案与offset结合\n\n后端全部返回，由前端分页sequenceDiagram\n    participant 前端\n    participant 后端\n    前端 ->> 后端: 请求资源集数据\n    后端 -->> 前端: 返回全部数据\n\n\n\n\n前端功能\n支持情况\n\n\n\n显示总页\n🙂\n\n\n任意页码跳转\n🙂\n\n\n跳转附近数页\n🙂\n\n\n大量数据集\n😭完全不可用\n\n\n实现难度\n简单\n\n\nlimit offset方案sequenceDiagram\n    participant 前端\n    participant 后端\n    前端 ->> 后端: 请求满足条件的资源总数\n    后端 -->> 前端: 返回满足条件的资源总数\n    前端 ->> 后端: 请求资源集数据、PageNo\n    后端 -->> 前端: 部分数据\n\n\n\n\n前端功能\n支持情况\n\n\n\n显示总页\n🙂\n\n\n任意页码跳转\n🙂\n\n\n跳转附近数页\n🙂\n\n\n大量数据集\n😭海量数据集下性能差\n\n\n实现难度\n相对简单\n\n\ncursor方案sequenceDiagram\n    participant 前端\n    participant 后端\n    前端 ->> 后端: 请求满足条件的资源总数\n    后端 -->> 前端: 返回满足条件的资源总数\n    前端 ->> 后端: 请求资源集数据、cursor、limit\n    后端 -->> 前端: 部分数据、prevCursor、nextCursor\n\n\n\n\n前端功能\n支持情况\n\n\n\n显示总页\n🙂\n\n\n任意页码跳转\n😭\n\n\n跳转附近数页\n🙂\n\n\n大量数据集\n🙂\n\n\n实现难度\n相对复杂\n\n\n如果每一次翻页都返回总页数的话，对性能来讲也是不小的开销。\n相对动态的数据来说，如果不一直翻到没有数据为止，也不好确定是否到了最后一页。为了解决这个问题，以及跳转附近数页的问题，可以演进为这样的方案。\n假定前端最多显示最近6页，每页50条数据，那么前端可以直接尝试预读300条数据，根据返回的数据来做局部的分页。一言以蔽之：读取更多的数据来进行局部分页。\n\n这里可以再简化一下前端的实现，添加offset参数，这样子前端只需要判断当前页前后数据条数是否足够，附近页的跳转可以通过携带offset字段请求得到。\ncursor方案与offset结合\n import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs';\tmermaid.initialize({startOnLoad: true, flowchart: {curve: 'linear'}}); ","tags":["Pagination"]},{"title":"创建自解压的可执行文件","url":"/2023/10/23/%E5%88%9B%E5%BB%BA%E8%87%AA%E8%A7%A3%E5%8E%8B%E7%9A%84%E5%8F%AF%E6%89%A7%E8%A1%8C%E6%96%87%E4%BB%B6/","content":"为什么需要自解压的可执行文件大部分软件的安装包是一个压缩包，用户需要自己解压，然后再执行安装脚本。常见的两种格式是tar.gz和zip。常见的解压执行脚本如下\ntar.gz#!/bin/bashtar -zxvf xxx.tar.gzcd xxx./install.sh\n\nzip#!/bin/bashunzip xxx.zipcd xxx./install.sh\n\n在有些场景下，为了方便分发、安装，我们需要将多个文件和目录打包并与一个启动脚本结合。这样子就可以实现一键安装，而不需要用户自己解压文件，然后再执行启动脚本。\n核心原理是，通过固定分隔符分隔脚本和压缩包部分，脚本通过分隔符将压缩包部分提取出来，然后解压，执行安装脚本，脚本不会超过固定分隔符。解压可以通过临时文件(zip)或流式解压(tar.gz)的方式实现。\n创建包含zip压缩包的自解压可执行文件构造一个zip压缩包echo &quot;hello zip&quot; &gt; temp.txtzip -r temp.zip temp.txtrm -f temp.txt\n\n构造可执行文件 self_extracting.sh以使用__ARCHIVE_BELOW__做分隔符为例，self_extracting.sh里面内容:\n推荐把临时文件放在内存文件路径下，这样子可以避免磁盘IO\n#!/bin/bashCURRENT_DIR=&quot;$(dirname &quot;$0&quot;)&quot;ARCHIVE_START_LINE=$(awk &#x27;/^__ARCHIVE_BELOW__/ &#123;print NR + 1; exit 0; &#125;&#x27; $0)tail -n+$ARCHIVE_START_LINE $0 &gt; /tmp/temp.zipunzip /tmp/temp.zip&quot; -d &quot;$CURRENT_DIR&quot;rm &quot;$CURRENT_DIR/temp.zip&quot;# replace the following line with your own codecat temp.txtexit 0__ARCHIVE_BELOW__\n\n将zip文件追加到self_extracting.sh文件的尾部\ncat temp.zip &gt;&gt; self_extracting.shchmod +x self_extracting.sh\n\n创建包含tar.gz压缩包的自解压可执行文件构造一个tar.gz压缩包echo &quot;hello tar.gz&quot; &gt; temp.txttar -czf temp.tar.gz temp.txtrm -f temp.txt\n\n构造可执行文件 self_extracting.sh以使用__ARCHIVE_BELOW__做分隔符为例，self_extracting.sh里面内容:\n#!/bin/bashCURRENT_DIR=&quot;$(dirname &quot;$0&quot;)&quot;ARCHIVE_START_LINE=$(awk &#x27;/^__ARCHIVE_BELOW__/ &#123;print NR + 1; exit 0; &#125;&#x27; $0)tail -n+$ARCHIVE_START_LINE $0 | tar xz -C &quot;$CURRENT_DIR&quot;# replace the following line with your own codecat temp.txtexit 0__ARCHIVE_BELOW__\n"},{"title":"利用Lombok的@RequiredArgsConstructor简化Spring构造函数","url":"/2024/03/11/%E5%88%A9%E7%94%A8Lombok%E7%9A%84@RequiredArgsConstructor%E7%AE%80%E5%8C%96Spring%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0/","content":"从Spring的新版本开始，推荐使用构造函数的注入方式，通过构造函数注入有很多优点，诸如不变性等等。同时在构造函数上，也不需要添加@Autowire注解就可以完成注入\n// Beforepublic class ABC &#123;    private final A a;    private final B b;    private final C c;    public ABC(@Autowire A a, @Autowire B b, @Autowire C c) &#123;        this.a = a;        this.b = b;        this.c = c;    &#125;&#125;// Afterpublic class ABC &#123;    private final A a;    private final B b;    private final C c;    public ABC(A a, B b, C c) &#123;        this.a = a;        this.b = b;        this.c = c;    &#125;&#125;\n\n但是，这种注入方式会导致变动代码的时候，需要同时修改field以及构造函数，在项目早期发展时期，这种变动显得有一些枯燥，再加上已经不需要@Autowire注解。这时，我们可以用Lombok的@RequiredArgsConstructor来简化这个流程。\nLombok的@RequiredArgsConstructor会包含这些参数：\n\n所有未初始化的 final 字段\n被标记为 @NonNull 但在声明时未初始化的字段。\n\n对于那些被标记为 @NonNull的字段，还会生成一个显式的空检查（不过在Spring框架里这个没什么作用）。通过应用@RequiredArgsConstructor，代码可以简化为如下模样，同时添加新的字段也不需要修改多行。\n@RequiredArgsConstructorpublic class ABC &#123;    private final A a;    private final B b;    private final C c;&#125;\n","tags":["Java","Spring","Lombok"]},{"title":"后端开发实体命名","url":"/2023/12/25/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91%E5%AE%9E%E4%BD%93%E5%91%BD%E5%90%8D/","content":"对于一个资源实体来说，在解决方案里，常见的操作场景有：\n\n由外部&#x2F;客户发起的增删改查、列表查询，访问协议一般为HTTP协议。\n由系统内部组件发起的增删改查、列表查询，协议可能为HTTP协议，也可能是RPC协议如gRPC等。\n由资源实体的owner服务跟数据库进行实体读写。\n由资源实体的owner服务将变更广播到消息中间件里。\n\n可以将实体命名如下：\n实体类详细说明：\n\nCreateXxxReq 创建资源请求，包含除资源id之外的所有字段，有些变种里面可能会包含id字段。\nUpdateXxxReq 更新资源请求，包含除资源id之外支持更新的所有字段。\nXxxResp 资源响应，可用于Crate、Update接口的返回，包含所有字段。\nListXxxsResp 资源列表响应，包含资源列表。\nList 资源列表响应，包含资源列表，每个资源包含部分字段，一般是id、name、createdTime、updatedTime等。\n\n出于复杂性的考虑，可以将XxxNotify类跟InnerXxx进行简化合并，转化为:\n\nswagger&#x2F;openapi里，operationId可使用如下\n\n\n\n操作\noperationId\n\n\n\n创建资源\nCreateXxx\n\n\n删除资源\nDeleteXxx\n\n\n更新资源\nUpdateXxx\n\n\n查询单个资源\nShowXxx\n\n\n查询资源列表\nListXxx\n\n\n内部创建资源\nCreateInnerXxx\n\n\n内部删除资源\nDeleteInnerXxx\n\n\n内部更新资源\nUpdateInnerXxx\n\n\n内部查询单个资源\nShowInnerXxx\n\n\n内部查询资源列表\nListInnerXxx\n\n\n"},{"title":"多语言SDK设计","url":"/2023/11/12/%E5%A4%9A%E8%AF%AD%E8%A8%80SDK%E8%AE%BE%E8%AE%A1/","content":"多语言SDK设计的常见问题日志打印的设计策略在SDK的关键节点，比如初始化完成、连接建立或者连接断开，都可以打印日志。如果是PerRequest的日志，一般默认不会打印INFO级别的日志。\nSDK应该避免仅仅打印错误日志然后忽略异常；相反，它应该提供机制让调用者能够捕获并处理异常信息。这种做法有助于保持错误处理的透明性，并允许调用者根据需要采取适当的响应措施。正如David J. Wheeler所说”Put the control in the hands of those who know how to handle the information, not those who know how to manage the computers, because encapsulated details will eventually leak out.”把控制权放到那些知道如何处理信息的人手中，而不是放在那些知道如何管理计算机的人手中，因为封装的细节最终都会暴露。\n是否需要使用显式的start&#x2F;connect方法？像go这样的语言，一般来说不太在意特定的时间内，某个协程是否处于阻塞等待连接的状态。而在java这样的语言，特别是在采用响应式编程模型的场景下，通常需要通过异步操作来管理连接的建立。这可以通过显式的start&#x2F;connect方法来或者是异步的工厂方法来实现。\n","tags":["SDK","Code"]},{"title":"多语言编程 TLS配置参数设计","url":"/2023/11/06/%E5%A4%9A%E8%AF%AD%E8%A8%80%E7%BC%96%E7%A8%8B%20TLS%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0%E8%AE%BE%E8%AE%A1/","content":"背景TLS(Transport Layer Security)是一种安全协议，用于在两个通信应用程序之间提供保密性和数据完整性。TLS是SSL(Secure Sockets Layer)的继任者。\n不同的编程语言处理TLS配置的方式各有千秋, 本文针对TLS配置参数的设计进行探讨。\n代码配置中，建议使用反映状态的参数名。\n通用参数\ntlsEnable: 是否启用TLS\n\nGo推荐使用方式一\n方式一：\n\ntlsConfig *tls.Config: Go标准库的内置TLS结构体\n\n方式二：\n由于Go不支持加密的私钥文件，推荐使用文件内容，而不是文件路径，避免敏感信息泄露。\n\ntlsCertContent []byte: 证书文件内容\ntlsPrivateKeyContent []byte: 私钥文件内容\ntlsMinVersion uint16: TLS最低版本\ntlsMaxVersion uint16: TLS最高版本\ntlsCipherSuites []uint16: TLS加密套件列表\n\nJavaJava的TLS参数基本上都是基于keystore和truststore来配置的。一般常见设计如下参数：\n\nkeyStorePath: keystore文件路径\nkeyStorePassword: keystore密码\ntrustStorePath: truststore文件路径\ntrustStorePassword: truststore密码\ntlsVerificationDisabled: 是否禁用TLS校验\ntlsHostnameVerificationDisabled: 是否禁用TLS主机名校验，仅部分框架支持。\ntlsVersions: TLS版本列表\ntlsCipherSuites: TLS加密套件列表\n\nJavaScriptJavaScript可以使用标准库里的tls.SecureContextOptions\nKotlinkotlin的Tls与Java相同：\n\nkeyStorePath: keystore文件路径\nkeyStorePassword: keystore密码\ntrustStorePath: truststore文件路径\ntrustStorePassword: truststore密码\ntlsVerificationDisabled: 是否禁用TLS校验\ntlsHostnameVerificationDisabled: 是否禁用TLS主机名校验，仅部分框架支持。\ntlsVersions: TLS版本列表\ntlsCipherSuites: TLS加密套件列表\n\nPython推荐使用方式一\n方式一\n\nssl.SSLContext: Python标准库的内置TLS结构体\n\n方式二\nPython可以使用文件路径以及加密的私钥文件。\n\ntlsCertPath: 证书文件路径\ntlsPrivateKeyPath: 私钥文件路径\ntlsPrivateKeyPassword: 私钥密码\ntlsMinVersion: TLS最低版本\ntlsMaxVersion: TLS最高版本\ntlsCipherSuites: TLS加密套件列表\n\nRust由于常见的Rust TLS实现不支持加密的私钥文件，推荐使用文件内容，而不是文件路径，避免敏感信息泄露。 一般常见如下设计参数:\n\ntls_cert_content Vec: 证书内容\ntsl_private_key_content Vec: 私钥内容\ntls_versions: TLS版本列表\ntls_cipher_suites: TLS加密套件列表\ntls_verification_disabled: 是否禁用TLS校验\n\n","tags":["Code","多语言编程"]},{"title":"多语言编程 各大Http库配置指南","url":"/2023/11/18/%E5%A4%9A%E8%AF%AD%E8%A8%80%E7%BC%96%E7%A8%8B%20%E5%90%84%E5%A4%A7Http%E5%BA%93%E9%85%8D%E7%BD%AE%E6%8C%87%E5%8D%97/","content":"GoGo标准库timeoutclient := http.Client&#123;    Timeout: timeout,&#125;\n\nconnection timeoutclient := http.Client&#123;    Transport: &amp;http.Transport&#123;        Dial: (&amp;net.Dialer&#123;            Timeout: timeout,        &#125;).Dial,    &#125;,&#125;\n\nJava标准库(jdk17+)timeoutHttpRequest request = HttpRequest.newBuilder()    .uri(URI.create(&quot;http://example.com&quot;))    .timeout(Duration.ofSeconds(10))    .build();\n\nconnectionTimeoutHttpClient.Builder builder = HttpClient.newBuilder().connectTimeout(Duration.ofSeconds(10)).version(HttpClient.Version.HTTP_1_1);\n\nReactor NettytimeoutHttpClient client = HttpClient.create().responseTimeout(Duration.ofSeconds(10));\n\nconnectionTimeoutHttpClient client = HttpClient.create().option(ChannelOption.CONNECT_TIMEOUT_MILLIS, 5000);\n","tags":["Code"]},{"title":"多语言编程 返回多个不同类型的方法样例","url":"/2023/09/18/%E5%A4%9A%E8%AF%AD%E8%A8%80%E7%BC%96%E7%A8%8B%20%E8%BF%94%E5%9B%9E%E5%A4%9A%E4%B8%AA%E4%B8%8D%E5%90%8C%E7%B1%BB%E5%9E%8B%E7%9A%84%E6%96%B9%E6%B3%95%E6%A0%B7%E4%BE%8B/","content":"背景你可能会在一些场景下碰到需要返回多个不同类型的方法。比如协议解析读取报文时，更具体地像kubernetes在开始解析Yaml的时候，怎么知道这个类型是属于Deployment还是Service？\nCC语言通常通过使用Struct（结构体）和Union（联合体）的方式来实现这个功能，如下文例子\n#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;typedef enum &#123;    MONKEY,    COW,    UNKNOWN&#125; AnimalType;typedef struct &#123;    char* description;&#125; Monkey;typedef struct &#123;    char* description;&#125; Cow;typedef struct &#123;    AnimalType type;    union &#123;        Monkey monkey;        Cow cow;    &#125;;&#125; Animal;Animal createAnimal(const char* animalType) &#123;    Animal animal;    if (strcmp(animalType, &quot;Monkey&quot;) == 0) &#123;        animal.type = MONKEY;        animal.monkey.description = &quot;I am a monkey!&quot;;    &#125; else if (strcmp(animalType, &quot;Cow&quot;) == 0) &#123;        animal.type = COW;        animal.cow.description = &quot;I am a cow!&quot;;    &#125; else &#123;        animal.type = UNKNOWN;    &#125;    return animal;&#125;int main() &#123;    Animal animal1 = createAnimal(&quot;Monkey&quot;);    if (animal1.type == MONKEY) &#123;        printf(&quot;%s\\n&quot;, animal1.monkey.description);    &#125;    Animal animal2 = createAnimal(&quot;Cow&quot;);    if (animal2.type == COW) &#123;        printf(&quot;%s\\n&quot;, animal2.cow.description);    &#125;    Animal animal3 = createAnimal(&quot;Dog&quot;);    if (animal3.type == UNKNOWN) &#123;        printf(&quot;Unknown animal type\\n&quot;);    &#125;    return 0;&#125;\n\nC++在C++中，我们可以使用基类指针来指向派生类的对象。可以使用动态类型识别（RTTI）来在运行时确定对象的类型\n#include &lt;iostream&gt;#include &lt;stdexcept&gt;class Animal &#123;public:    virtual std::string toString() const = 0;&#125;;class Monkey : public Animal &#123;public:    std::string toString() const override &#123;        return &quot;I am a monkey!&quot;;    &#125;&#125;;class Cow : public Animal &#123;public:    std::string toString() const override &#123;        return &quot;I am a cow!&quot;;    &#125;&#125;;Animal* createAnimal(const std::string&amp; animalType) &#123;    if (animalType == &quot;Monkey&quot;) &#123;        return new Monkey();    &#125;    if (animalType == &quot;Cow&quot;) &#123;        return new Cow();    &#125;    throw std::runtime_error(&quot;Unknown animal type: &quot; + animalType);&#125;int main() &#123;    try &#123;        Animal* animal1 = createAnimal(&quot;Monkey&quot;);        if (Monkey* monkey = dynamic_cast&lt;Monkey*&gt;(animal1)) &#123;            std::cout &lt;&lt; monkey-&gt;toString() &lt;&lt; std::endl;        &#125;        delete animal1;        Animal* animal2 = createAnimal(&quot;Cow&quot;);        if (Cow* cow = dynamic_cast&lt;Cow*&gt;(animal2)) &#123;            std::cout &lt;&lt; cow-&gt;toString() &lt;&lt; std::endl;        &#125;        delete animal2;    &#125;    catch (const std::runtime_error&amp; e) &#123;        std::cerr &lt;&lt; e.what() &lt;&lt; std::endl;    &#125;    return 0;&#125;\n\nGoGo的常见处理方式，是返回一个接口或者**interface{}**类型。调用者使用Go语言类型断言来检查具体的类型\npackage mainimport (\t&quot;fmt&quot;)type Animal interface &#123;\tString() string&#125;type Monkey struct&#123;&#125;func (m Monkey) String() string &#123;\treturn &quot;I am a monkey!&quot;&#125;type Cow struct&#123;&#125;func (c Cow) String() string &#123;\treturn &quot;I am a cow!&quot;&#125;func createAnimal(typeName string) (Animal, error) &#123;\tswitch typeName &#123;\tcase &quot;Monkey&quot;:\t\treturn Monkey&#123;&#125;, nil\tcase &quot;Cow&quot;:\t\treturn Cow&#123;&#125;, nil\tdefault:\t\treturn nil, fmt.Errorf(&quot;Unknown animal type: %s&quot;, typeName)\t&#125;&#125;func main() &#123;\tanimal1, err := createAnimal(&quot;Monkey&quot;)\tif err != nil &#123;\t\tfmt.Println(err)\t\treturn\t&#125;\tif monkey, ok := animal1.(Monkey); ok &#123;\t\tfmt.Println(monkey)\t&#125;\tanimal2, err := createAnimal(&quot;Cow&quot;)\tif err != nil &#123;\t\tfmt.Println(err)\t\treturn\t&#125;\tif cow, ok := animal2.(Cow); ok &#123;\t\tfmt.Println(cow)\t&#125;&#125;\n\nJavaJava语言的常见处理方式，是返回Object类型或者一个基础类型。然后由调用方在进行instance of判断。或者Java17之后，可以使用模式匹配的方式来简化转型\npublic class MultiTypeReturnExample &#123;    static class Monkey &#123;        @Override        public String toString() &#123;            return &quot;I am a monkey!&quot;;        &#125;    &#125;    static class Cow &#123;        @Override        public String toString() &#123;            return &quot;I am a cow!&quot;;        &#125;    &#125;    public static Object createAnimal(String type) throws IllegalArgumentException &#123;        switch (type) &#123;            case &quot;Monkey&quot;:                return new Monkey();            case &quot;Cow&quot;:                return new Cow();            default:                throw new IllegalArgumentException(&quot;Unknown animal type: &quot; + type);        &#125;    &#125;    public static void main(String[] args) throws Exception &#123;        Object animal1 = createAnimal(&quot;Monkey&quot;);        // java8 写法，后面如果明确用做精确的类型，需要强制转换        if (animal1 instanceof Monkey) &#123;            System.out.println(animal1);        &#125;        Object animal2 = createAnimal(&quot;Cow&quot;);        if (animal2 instanceof Cow) &#123;            System.out.println(animal2);        &#125;        // java17 写法，不需要强制转换        if (createAnimal(&quot;Monkey&quot;) instanceof Monkey animal3) &#123;            System.out.println(animal3);        &#125;        if (createAnimal(&quot;Cow&quot;) instanceof Cow animal4) &#123;            System.out.println(animal4);        &#125;    &#125;&#125;\n\nJavascript动态类型语言，使用instanceof运算符判断\nclass Animal &#123;    toString() &#123;        return &#x27;I am an animal&#x27;;    &#125;&#125;class Monkey extends Animal &#123;    toString() &#123;        return &#x27;I am a monkey&#x27;;    &#125;&#125;class Cow extends Animal &#123;    toString() &#123;        return &#x27;I am a cow&#x27;;    &#125;&#125;function createAnimal(animalType) &#123;    switch (animalType) &#123;        case &#x27;Monkey&#x27;:            return new Monkey();        case &#x27;Cow&#x27;:            return new Cow();        default:            throw new Error(`Unknown animal type: $&#123;animalType&#125;`);    &#125;&#125;try &#123;    const animal1 = createAnimal(&#x27;Monkey&#x27;);    if (animal1 instanceof Monkey) &#123;        console.log(animal1.toString());    &#125;    const animal2 = createAnimal(&#x27;Cow&#x27;);    if (animal2 instanceof Cow) &#123;        console.log(animal2.toString());    &#125;    const animal3 = createAnimal(&#x27;Dog&#x27;);&#125; catch (error) &#123;    console.error(error.message);&#125;\n\nKotlinKotlin可以使用Sealed Class(密封类)和Any类型两种方式。使用Any的场景，与Java返回Object类似。Sealed Class更加安全、更方便一些。\n使用Any类型open class Animalclass Monkey: Animal() &#123;    override fun toString(): String &#123;        return &quot;I am a monkey!&quot;    &#125;&#125;class Cow: Animal() &#123;    override fun toString(): String &#123;        return &quot;I am a cow!&quot;    &#125;&#125;fun createAnimal(type: String): Any &#123;    return when (type) &#123;        &quot;Monkey&quot; -&gt; Monkey()        &quot;Cow&quot; -&gt; Cow()        else -&gt; throw IllegalArgumentException(&quot;Unknown animal type: $type&quot;)    &#125;&#125;fun main() &#123;    val animal1 = createAnimal(&quot;Monkey&quot;)    when (animal1) &#123;        is Monkey -&gt; println(animal1)        is Cow -&gt; println(animal1)    &#125;    val animal2 = createAnimal(&quot;Cow&quot;)    when (animal2) &#123;        is Monkey -&gt; println(animal2)        is Cow -&gt; println(animal2)    &#125;&#125;\n\n使用SealedClasssealed class Animal &#123;    data class Monkey(val info: String = &quot;I am a monkey!&quot;) : Animal()    data class Cow(val info: String = &quot;I am a cow!&quot;) : Animal()&#125;fun createAnimal(type: String): Animal &#123;    return when (type) &#123;        &quot;Monkey&quot; -&gt; Animal.Monkey()        &quot;Cow&quot; -&gt; Animal.Cow()        else -&gt; throw IllegalArgumentException(&quot;Unknown animal type: $type&quot;)    &#125;&#125;fun main() &#123;    val animal1 = createAnimal(&quot;Monkey&quot;)    when (animal1) &#123;        is Animal.Monkey -&gt; println(animal1.info)        is Animal.Cow -&gt; println(animal1.info)    &#125;    val animal2 = createAnimal(&quot;Cow&quot;)    when (animal2) &#123;        is Animal.Monkey -&gt; println(animal2.info)        is Animal.Cow -&gt; println(animal2.info)    &#125;&#125;\n\nPythonPython是动态类型的语言，可以简单基于一些条件返回不同类型的对象，然后在接收到返回值之后使用type()函数或isinstance()函数来确定其类型\nclass Animal:    def __str__(self):        return &quot;I am an animal&quot;class Monkey(Animal):    def __str__(self):        return &quot;I am a monkey&quot;class Cow(Animal):    def __str__(self):        return &quot;I am a cow&quot;def create_animal(animal_type):    if animal_type == &quot;Monkey&quot;:        return Monkey()    elif animal_type == &quot;Cow&quot;:        return Cow()    else:        raise ValueError(f&quot;Unknown animal type: &#123;animal_type&#125;&quot;)def main():    animal1 = create_animal(&quot;Monkey&quot;)    if isinstance(animal1, Monkey):        print(animal1)    animal2 = create_animal(&quot;Cow&quot;)    if isinstance(animal2, Cow):        print(animal2)if __name__ == &quot;__main__&quot;:    main()\n\nRubyRuby也较为简单，在方法内部直接返回不同类型的对象。然后，可以使用is_a方法或class方法来确定返回对象的实际类型。\nclass Animal  def to_s    &quot;I am an animal&quot;  endendclass Monkey &lt; Animal  def to_s    &quot;I am a monkey&quot;  endendclass Cow &lt; Animal  def to_s    &quot;I am a cow&quot;  endenddef create_animal(animal_type)  case animal_type  when &quot;Monkey&quot;    Monkey.new  when &quot;Cow&quot;    Cow.new  else    raise &quot;Unknown animal type: #&#123;animal_type&#125;&quot;  endendbegin  animal1 = create_animal(&quot;Monkey&quot;)  if animal1.is_a? Monkey    puts animal1  end  animal2 = create_animal(&quot;Cow&quot;)  if animal2.is_a? Cow    puts animal2  endend\n\nRust在Rust中，可以使用enum（枚举）来创建一个持有多种不同类型的数据结构。然后使用match语句来做模式匹配。\nuse std::fmt;enum Animal &#123;    Monkey,    Cow,&#125;impl fmt::Display for Animal &#123;    fn fmt(&amp;self, f: &amp;mut fmt::Formatter&lt;&#x27;_&gt;) -&gt; fmt::Result &#123;        match self &#123;            Animal::Monkey =&gt; write!(f, &quot;I am a monkey!&quot;),            Animal::Cow =&gt; write!(f, &quot;I am a cow!&quot;),        &#125;    &#125;&#125;fn create_animal(animal_type: &amp;str) -&gt; Result&lt;Animal, String&gt; &#123;    match animal_type &#123;        &quot;Monkey&quot; =&gt; Ok(Animal::Monkey),        &quot;Cow&quot; =&gt; Ok(Animal::Cow),        _ =&gt; Err(format!(&quot;Unknown animal type: &#123;&#125;&quot;, animal_type)),    &#125;&#125;fn main() &#123;    match create_animal(&quot;Monkey&quot;) &#123;        Ok(animal) =&gt; match animal &#123;            Animal::Monkey =&gt; println!(&quot;&#123;&#125;&quot;, animal),            _ =&gt; (),        &#125;,        Err(e) =&gt; println!(&quot;&#123;&#125;&quot;, e),    &#125;    match create_animal(&quot;Cow&quot;) &#123;        Ok(animal) =&gt; match animal &#123;            Animal::Cow =&gt; println!(&quot;&#123;&#125;&quot;, animal),            _ =&gt; (),        &#125;,        Err(e) =&gt; println!(&quot;&#123;&#125;&quot;, e),    &#125;    match create_animal(&quot;Dog&quot;) &#123;        Ok(_) =&gt; (),        Err(e) =&gt; println!(&quot;&#123;&#125;&quot;, e),    &#125;&#125;\n\nScalascala中，可以使用sealed trait和case class来创建一个能够返回多种不同类型的方法。Sealed trait可以定义一个有限的子类集合，可以确保类型安全\nsealed trait Animal &#123;  def info: String&#125;case class Monkey() extends Animal &#123;  val info: String = &quot;I am a monkey!&quot;&#125;case class Cow() extends Animal &#123;  val info: String = &quot;I am a cow!&quot;&#125;object MultiTypeReturnExample &#123;  def createAnimal(animalType: String): Animal = &#123;    animalType match &#123;      case &quot;Monkey&quot; =&gt; Monkey()      case &quot;Cow&quot; =&gt; Cow()      case _ =&gt; throw new IllegalArgumentException(s&quot;Unknown animal type: $animalType&quot;)    &#125;  &#125;  def main(args: Array[String]): Unit = &#123;    try &#123;      val animal1 = createAnimal(&quot;Monkey&quot;)      animal1 match &#123;        case Monkey() =&gt; println(animal1.info)        case _ =&gt;      &#125;      val animal2 = createAnimal(&quot;Cow&quot;)      animal2 match &#123;        case Cow() =&gt; println(animal2.info)        case _ =&gt;      &#125;    &#125; catch &#123;      case e: IllegalArgumentException =&gt; println(e.getMessage)    &#125;  &#125;&#125;\n\nTypeScript总得来说，和javascript区别不大\nabstract class Animal &#123;  abstract toString(): string;&#125;class Monkey extends Animal &#123;  toString(): string &#123;    return &#x27;I am a monkey&#x27;;  &#125;&#125;class Cow extends Animal &#123;  toString(): string &#123;    return &#x27;I am a cow&#x27;;  &#125;&#125;function createAnimal(animalType: string): Animal &#123;  switch (animalType) &#123;    case &#x27;Monkey&#x27;:      return new Monkey();    case &#x27;Cow&#x27;:      return new Cow();    default:      throw new Error(`Unknown animal type: $&#123;animalType&#125;`);  &#125;&#125;try &#123;  const animal1 = createAnimal(&#x27;Monkey&#x27;);  if (animal1 instanceof Monkey) &#123;    console.log(animal1.toString());  &#125;  const animal2 = createAnimal(&#x27;Cow&#x27;);  if (animal2 instanceof Cow) &#123;    console.log(animal2.toString());  &#125;  const animal3 = createAnimal(&#x27;Dog&#x27;);&#125; catch (error) &#123;  console.error(error.message);&#125;\n","tags":["Code","多语言编程"]},{"title":"大型系统中的证书管理","url":"/2021/05/30/%E5%A4%A7%E5%9E%8B%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E8%AF%81%E4%B9%A6%E7%AE%A1%E7%90%86/","content":"大型系统中的证书管理随着安全的要求，现在我们在越来越多的通信中使用TLS加密。下图是一个微服务架构下数据流向的例子\n\n\n蓝色部分，即和三方交互时需要TLS加密认证\n红色部分，各个微服务、消息中间件等通信需要TLS加密认证\n绿色部分，各个微服务和存储层通信也需要TLS加密认证\n\n安全上对我们的要求逐步变化为，仅蓝色使用TLS&#x3D;》蓝色和红色使用TLS&#x3D;》全部使用TLS加密\n证书管理的必要性从安全的角度上来说，我们最好能支持证书的更换和热加载。如果您的业务当前使用加密的场景不多，可能暂时看不到证书管理的意义。但是当你在各个方面使用TLS更加频繁之后，会发现证书管理可带来如下好处：\n\n可以通过抽象出场景，通过场景和证书的关联联系，在各个地方通信使用的证书，可以统一更换。\n统一提供证书过期告警等功能\n统一提供证书的变更通知，通知到各个实例\n\n以我在工作中接触到的两个基础PAAS平台，都有证书管理的功能，可见证书管理的必要性。\nPS: 开源组件大多都拥有证书配置能力，没有可对接证书管理的能力，但这个能力很难贡献给社区，需要自己开发。\n证书管理概念在TLS会话中，从依赖的证书文件角度来看，可以分为加密流程和验证流程。\n加密证书TLS加密流程的证书，包含证书链文件和密钥\n验证证书TLS验证流程的证书，仅包含证书链文件\n拆分为加密流程和验证流程的合理性这使得加密流程证书和验证流程证书可以互相独立的替换，更方便在大型场景下复用证书。\n让我们来假设如下的场景：\n\n客户A、客户B、客户C、客户D的验证流程证书自然不相同，但服务跟客户交互的时候，使用的加密流程证书确实同一份。如果将两个阶段的证书合一，那么在更换证书的时候，就需要更新4份数据，当你有1000名用户的时候，这个数字将会是1000，这对于存储和应用程序来说都是不小的冲击。\nSceneScene是在一个会话中，代表会话和请求证书、验证证书的绑定关系。Scene和请求证书、验证证书都是1：1的关系。这使得我们不仅仅可以修改证书文件，也可以对TLS会话中使用的证书进行修改。在证书无法复用，且证书绑定了多个场景的时候，针对单个场景修改其绑定的证书。\n以上图作为例子，假设客户D有特殊的要求，要求加密流程使用特定的证书或密钥，我们就可以将客户D的场景绑定到客户D独有的加密证书\n多集群管理如果证书管理需要管理多个集群，那么证书和Scene前面可以加上层级来隔离，如环境、集群等。\n对小型系统的建议如果规模不大，且TLS场景有限，需要考虑一下有无拆分加密证书和验证证书的必要，可以合一，应用程序直接以合一的证书id来关联，而非场景id。虽不方便复用，但大大降低了复杂性。\n证书管理的功能\n证书管理场景设定一个TLS会话\n使用TLS会话这要求应用程序持久化场景信息\n\n组织架构相关大型系统下，证书管理是一个必须的组件，且一定是由团队最底层的组织架构承接。如若不然，那么由底层组织架构维护的组件，因为依赖关系，无法基于证书管理来统一实现证书的更换和过期告警。除非不基于证书管理自己构筑一套能力。\nTLDR随着组件和使用加密场景的不断扩大，证书管理是一个必须的组件，通过抽象出场景的概念来复用证书，通过变更通知在微服务模式下快速更换所有微服务实例上的证书，并提供统一的证书过期告警功能来提醒管理员更换证书。\n","tags":["cert"]},{"title":"如果不是公有云的供应商，能提供什么样的Pulsar服务体验","url":"/2021/04/20/%E5%A6%82%E6%9E%9C%E4%B8%8D%E6%98%AF%E5%85%AC%E6%9C%89%E4%BA%91%E7%9A%84%E4%BE%9B%E5%BA%94%E5%95%86%EF%BC%8C%E8%83%BD%E6%8F%90%E4%BE%9B%E4%BB%80%E4%B9%88%E6%A0%B7%E7%9A%84Pulsar%E6%9C%8D%E5%8A%A1%E4%BD%93%E9%AA%8C/","content":"需要了解的概念\nVPC：用户的私有网段\npeering：多个VPC之间打通的方式，可跨用户\n\n前言今天微信推送Pulsar社区有个Hackathon比赛, 开始想的idea就是，实现pulsar在华为云上提供服务。因为是社区的比赛，是以一个三方系统的方式在华为云上提供服务，而非是以华为云的名义提供服务。分析了下可行性和能达到的效果，对比了StreamNative的官网上提供的pulsar服务在阿里云托管的能力，能提供的能力差不多，最多只不过是实现了在华为云托管的能力，没有从0到1的突破。\n现在，在公有云上买redis和kafka这类组件已经变得非常普遍，由公有云供应商提供的中间件往往能给你带来良好的体验，相比三方厂家在云上进行托管，我个人认为云厂商的优势主要在以下三点\n网络打通容易下文说一下不是公有云的供应商能以什么样的方式暴露自己的服务。云厂商可以把中间件的ip地址申请在你的vpc内，对任何应用程序来说，连接都是最方便的。无论是容器化部署、虚拟机部署、和其他vpc peering打通的场景，都可以通信。\n低廉的成本不考虑人力成本，云厂商自运营的价格要低于三方厂家。\n监控系统对接方便地和云厂商的告警、统计系统对接，接收告警通知和报表等。\n其中网络打通和成本尤为重要，三方厂家好好做监控统计系统，也能给用户较为良好的体验。\n三方厂家能提供什么样的Pulsar接入统一接入三方厂家自己作为公有云上一个用户，无论这个Region上有多少个租户，都用这一个用户提供服务，这也就意味着无法与每个用户进行私网通信。如果在华为云，利用华为云推出的VPCEP服务（此处应有链接），倒是可以给每个用户提供私网通信，不过这个是做了DNAT地址转换的，跟做了DNAT转换的中间件连接，是非常麻烦的。（懂的自然懂。如果有人想详细了解，可以留言，我可以写一个文章介绍里面的坑）\n如果使用公网，又想避免扩容的时候动态申请EIP，动态申请EIP并不复杂，问题是EIP是有配额限制的，这才是关键。那么就需要一个统一的接入点，就需要部署pulsar proxy。到这一步，是每个用户申请一个EIP的，如果还想继续节省EIP，那么可以统一域名接入，后端通过SNI的方式转发，个别流量大的客户，单独把域名指向单独的集群。\n\nPeering打通Peering打通可以给用户不错的私网体验，需要用户预留一个网段，网段不需要太大，能容纳pulsar所在的vm就行。采用peering打通一般绝不会选择容器化部署，想要两个容器化的集群互通，对网设的要求很高，暂且忽略Service的存在，这要求用户的vpc网段和pod网段和三方厂商的vpc网段和pod网段都不重叠！而且peering打通，给用户私有，再搭建一个k8s集群，对成本影响比较大。主要有如下两个问题\n自动化和客户peering打通，需要较大的权限，如何自动化，最大程度的减少需要的权限。\n客户网段和其他网段又做了peering\n这个问题其实还好，就是路由规则配置麻烦\n总结Peering打通对用户来说已经比较方便了，相信做到自动化也没有太大的技术难度，只是时间和人力投入的问题。统一接入因为网络打通的原因，不好使用kop、mop这些高级特性，此外还有不小的公网带宽成本，羊毛出在羊身上，比较大量的用户也会倾向于Peering打通的模式吧。\n","tags":["Pulsar"]},{"title":"容器内指定特定域名解析结果的几种方式","url":"/2023/07/10/%E5%AE%B9%E5%99%A8%E5%86%85%E6%8C%87%E5%AE%9A%E7%89%B9%E5%AE%9A%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E7%BB%93%E6%9E%9C%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F/","content":"在本篇文章中，我们将探讨如何在容器内指定特定域名解析结果的几种方式。为了方便演示，首先我们创建一个演示用的Deployment配置文件。\napiVersion: apps/v1kind: Deploymentmetadata:  name: busybox-deployment  labels:    app: busyboxspec:  replicas: 1  selector:    matchLabels:      app: busybox  template:    metadata:      labels:        app: busybox    spec:      containers:      - name: busybox        image: busybox        args:        - /bin/sh        - -c        - &quot;while true; do echo Hello, Kubernetes!; sleep 10;done&quot;\n\n这个deployment会创建1个busybox的pod，容器每隔10s会打印“Hello, Kubernetes!”到控制台\nTL;DR\n\n\n方案\n修改级别\n是否推荐\n备注\n\n\n\n修改&#x2F;etc&#x2F;hosts\npod\n否\n\n\n\n添加HostAliases记录\npod&#x2F;deploy&#x2F;statefulset\n是\n\n\n\n修改Coredns配置\n整个kubernetes集群\n是\n\n\n\n自定义DNS策略\npod&#x2F;deploy&#x2F;statefulset\n视情况而定\n如需对接三方的DNS服务器，推荐采用\n\n\n使用三方DNS插件\n整个kubernetes集群\n否\n不推荐，Coredns为业内主流\n\n\n修改&#x2F;etc&#x2F;hosts修改&#x2F;etc&#x2F;hosts是最传统的方式，直接在容器内修改相应的文件来实现域名解析，在Pod级别生效。由于其可维护性较差（每次pod发生重启都需要手动修改），不推荐在生产环境使用。\n例如，我们可以在&#x2F;etc&#x2F;hosts里面添加这样一条记录\n250.250.250.250 four-250\n\n/ # ping four-250PING four-250 (250.250.250.250): 56 data bytes\n\n添加HostAliases记录HostAliases是kubernetes中Pod配置的一个字段，它提供了Pod内容器的/etc/hosts文件的附加记录。这在某些情况下非常有用，特别是当你想要覆盖某个主机名的解析结果，或者提供网络中没有的主机名解析时。\n这个可以在Pod、Replica、Deployment、StatefulSet的级别修改，维护性稍强。举个🌰，我们将上面的yaml修改为\napiVersion: apps/v1kind: Deploymentmetadata:  name: busybox-deployment  labels:    app: busyboxspec:  replicas: 3  selector:    matchLabels:      app: busybox  template:    metadata:      labels:        app: busybox    spec:      hostAliases:      - ip: &quot;250.250.250.250&quot;        hostnames:        - &quot;four-250&quot;      containers:      - name: busybox        image: busybox        args:        - /bin/sh        - -c        - &quot;while true; do echo Hello, Kubernetes!; sleep 10;done&quot;\n\n这个时候我们查看容器的&#x2F;etc&#x2F;hosts，发现它被kubernetes自动插入了一条记录**Entries add by HostAliases。**这就是hostAliases的实现原理\n在kubelet_pods代码中进行了这样的写入动作\nfunc hostsEntriesFromHostAliases(hostAliases []v1.HostAlias) []byte &#123;\tif len(hostAliases) == 0 &#123;\t\treturn []byte&#123;&#125;\t&#125;\tvar buffer bytes.Buffer\tbuffer.WriteString(&quot;\\n&quot;)\tbuffer.WriteString(&quot;# Entries added by HostAliases.\\n&quot;)\t// for each IP, write all aliases onto single line in hosts file\tfor _, hostAlias := range hostAliases &#123;\t\tbuffer.WriteString(fmt.Sprintf(&quot;%s\\t%s\\n&quot;, hostAlias.IP, strings.Join(hostAlias.Hostnames, &quot;\\t&quot;)))\t&#125;\treturn buffer.Bytes()&#125;\n\nCoredns配置我们可以通过修改ConfigMap来实现让容器解析特定域名的目的。\n更改Coredns配置我们可以通过以下命令修改Coredns的配置：\nkubectl edit cm coredns -n kube-system\n\n原有的configmapCorefile: |    .:53 &#123;        log        errors        health &#123;           lameduck 5s        &#125;        ready        kubernetes cluster.local in-addr.arpa ip6.arpa &#123;           pods insecure           fallthrough in-addr.arpa ip6.arpa           ttl 30        &#125;        prometheus :9153        hosts &#123;           192.168.65.2 host.minikube.internal           fallthrough        &#125;        forward . /etc/resolv.conf &#123;           max_concurrent 1000        &#125;        cache 30        loop        reload        loadbalance    &#125;\n\n在hosts里面加上特定的记录\n250.250.250.250 four-250\n\n如果您没有配置reload插件，则需要重启Coredns才能生效，默认的reload时间是30s，在plugin&#x2F;reload&#x2F;setup.go的defaultInterval中定义\n自定义DNS策略通过修改DNS策略。使得对于单个Pod&#x2F;Deploy&#x2F;StatefulSet将特定的域名解析发给特定的服务器来达到效果，如下，可以对pod添加dns的服务器以及search域\nspec:   dnsConfig:     nameservers:       - 1.2.3.4     searches:       - search.prefix   containers:   - name: busybox     image: busybox     args:     - /bin/sh     - -c     - &quot;while true; do echo Hello, Kubernetes!; sleep 10;done&quot;\n\n使用第三方DNS插件不推荐，使用其他的DNS插件，来做一些炫酷的自定义操作。而且目前Coredns也是业内的主流，没有很好的替代\n","tags":["Kubernetes"]},{"title":"开发一个filebeat output websocket插件","url":"/2021/07/04/%E5%BC%80%E5%8F%91%E4%B8%80%E4%B8%AAfilebeat%20output%20websocket%E6%8F%92%E4%BB%B6/","content":"开发一个filebeat的websocket插件， 代码仓地址: https://github.com/hezhangjian/beats_output_websocket\n引入对beat的依赖go get github.com/elastic/beats/v7\n\n定义在filebeat中的配置文件filebeat通常以配置文件的方式加载插件。让我们定义一下必须的配置，就像elasticsearch中的连接地址等等一样。\noutput.websocket:  # worker  # 用于工作的websocket客户端数量  workers: 1  # 日志批量的最大大小  batch_size: 1  # 重试的最大次数，0代表不重试  retry_limit: 1  # conn  # ws/wss  schema: &quot;ws&quot;  # websocket连接地址  addr: &quot;localhost:8080&quot;  # websocket路径  path: &quot;/echo&quot;  # websocket心跳间隔，用于保活  ping_interval: 30\n\ngo文件中的配置type clientConfig struct &#123;\t// Number of worker goroutines publishing log events\tWorkers int `config:&quot;workers&quot; validate:&quot;min=1&quot;`\t// Max number of events in a batch to send to a single client\tBatchSize int `config:&quot;batch_size&quot; validate:&quot;min=1&quot;`\t// Max number of retries for single batch of events\tRetryLimit int `config:&quot;retry_limit&quot;`\t// Schema WebSocket Schema\tSchema string `config:&quot;schema&quot;`\t// Addr WebSocket Addr\tAddr string `config:&quot;addr&quot;`\t// Path WebSocket Path\tPath string `config:&quot;path&quot;`\t// PingInterval WebSocket PingInterval\tPingInterval int `config:&quot;ping_interval&quot;`&#125;\n\n\n\n初始化加载插件加载插件在某个init函数中注册插件\nfunc init() &#123;\toutputs.RegisterType(&quot;websocket&quot;, newWsOutput)&#125;\n\n在newWsOutput中卸载配置，并提供配置给WebSocket客户端\nfunc newWsOutput(_ outputs.IndexManager, _ beat.Info, stats outputs.Observer, cfg *common.Config) (outputs.Group, error) &#123;\tconfig := clientConfig&#123;&#125;\t// 卸载配置，将配置用于初始化WebSocket客户端\tif err := cfg.Unpack(&amp;config); err != nil &#123;\t\treturn outputs.Fail(err)\t&#125;\tclients := make([]outputs.NetworkClient, config.Workers)\tfor i := 0; i &lt; config.Workers; i++ &#123;\t\tclients[i] = &amp;wsClient&#123;\t\t\tstats:  stats,\t\t\tSchema: config.Schema,\t\t\tHost:   config.Addr,\t\t\tPath:   config.Path,\t\t\tPingInterval: config.PingInterval,\t\t&#125;\t&#125;\treturn outputs.SuccessNet(true, config.BatchSize, config.RetryLimit, clients)&#125;\n\n初始化WebSocket客户端WebSocket客户端不仅仅是一个WebSocket客户端，而且还需要实现filebeat中的NetworkClient接口，接下来，让我们来关注接口中的每一个方法的作用及实现\nString()接口String作为客户端的名字，用来标识日志以及指标。是最简单的一个接口\nfunc (w *wsClient) String() string &#123;\treturn &quot;websocket&quot;&#125;\n\nConnect()接口Connect用来初始化客户端\nfunc (w *wsClient) Connect() error &#123;\tu := url.URL&#123;Scheme: w.Schema, Host: w.Host, Path: w.Path&#125;\tdial, _, err := websocket.DefaultDialer.Dial(u.String(), nil)\tif err == nil &#123;\t\tw.conn = dial\t\tticker := time.NewTicker(time.Duration(w.PingInterval) * time.Second)\t\tgo func() &#123;\t\t\tfor range ticker.C &#123;\t\t\t\tw.conn.WriteMessage(websocket.PingMessage, nil)\t\t\t&#125;\t\t&#125;()\t&#125; else &#123;\t\ttime.Sleep(10 * time.Second)\t&#125;\treturn err&#125;\n\n注意，这里初始化失败，需要Sleep一段时间，否则，filebeat会一直重试。这绝非是你想要的。或许对于场景来说，退避重试可能会更好\nClose()接口关闭客户端，也是很简单的接口\nfunc (w *wsClient) Close() error &#123;\treturn w.conn.Close()&#125;\n\nPublish()接口func (w *wsClient) Publish(_ context.Context, batch publisher.Batch) error &#123;\tevents := batch.Events()\t// 记录这批日志\tw.stats.NewBatch(len(events))\tfailEvents, err := w.PublishEvents(events)\tif err != nil &#123;\t\t// 如果发送正常，则ACK\t\tbatch.ACK()\t&#125; else &#123;\t\t// 发送失败，则重试。受RetryLimit的限制\t\tbatch.RetryEvents(failEvents)\t&#125;\treturn err&#125;func (w *wsClient) PublishEvents(events []publisher.Event) ([]publisher.Event, error) &#123;\tfor i, event := range events &#123;\t\terr := w.publishEvent(&amp;event)\t\tif err != nil &#123;\t\t\t// 如果单条消息发送失败，则将剩余的消息直接重试\t\t\treturn events[i:], err\t\t&#125;\t&#125;\treturn nil, nil&#125;func (w *wsClient) publishEvent(event *publisher.Event) error &#123;\tbytes, err := encode(&amp;event.Content)\tif err != nil &#123;\t\t// 如果编码失败，就不重试了，重试也不会成功\t\t// encode error, don&#x27;t retry.\t\t// consider being success\t\treturn nil\t&#125;\terr = w.conn.WriteMessage(websocket.TextMessage, bytes)\tif err != nil &#123;\t\t// 写入WebSocket Server失败\t\treturn err\t&#125;\treturn nil&#125;\n\n编码编码的逻辑因人而异，事实上，这可能是大家最大的差异所在。这里只是做一个简单地例子\ntype LogOutput struct &#123;\tTimestamp time.Time `json:&quot;timestamp&quot;`\tMessage   string    `json:&quot;message&quot;`&#125;func encode(event *beat.Event) ([]byte, error) &#123;\tlogOutput := &amp;LogOutput&#123;&#125;\tvalue, err := event.Fields.GetValue(&quot;message&quot;)\tif err != nil &#123;\t\treturn nil, err\t&#125;\tlogOutput.Timestamp = event.Timestamp\tlogOutput.Message = value.(string)\treturn json.Marshal(logOutput)&#125;\n\n最后是我们的wsclienttype wsClient struct &#123;\t// construct field\tSchema       string\tHost         string\tPath         string\tPingInterval int\tstats outputs.Observer\tconn  *websocket.Conn&#125;\n\n添加额外的功能：大包丢弃你可能会想保护你的WebSocket服务器，避免接收到超级大的日志。我们可以在配置项中添加一个配置\nmaxLen用来限制日志长度，超过maxLen的日志直接丢弃。为什么不使用filebeat中的max_bytes？\n因为filebeat中max_bytes的默认行为是截断，截断的日志在某些场景下不如丢弃。（比如，日志是json格式，截断后格式无法解析）\n配置中添加maxLenmax_len: 1024\n\n省略掉那些重复的添加结构体，读取max_len在encode的时候忽略掉\ns := value.(string)if len(s) &gt;= w.MaxLen &#123;\treturn nil, err&#125;\n","tags":["Go","Filebeat","WebSocket"]},{"title":"异步网络请求编码","url":"/2023/12/10/%E5%BC%82%E6%AD%A5%E7%BD%91%E7%BB%9C%E8%AF%B7%E6%B1%82%E7%BC%96%E7%A0%81/","content":"本文介绍常见的异步网络请求编码手法。尽管像golang这些的语言，支持协程，可以使得Programmer以同步的方式编写代码，大大降低编码者的心智负担。但网络编程中，批量又非常常见，这就导致即使在Golang中，也不得不进行协程的切换来满足批量的诉求，在Golang中往往对外以callback的方式暴露接口。\n无论是callback、还是返回future、还是返回Mono&#x2F;Flux，亦或是从channel中读取，这是不同的异步编程范式，编码的时候，可以从项目整体、团队编码风格、个人喜好来依次考虑。本文将以callback为主，但移植到其他异步编码范式，并不困难。\n使用callback模式后，对外的方法签名类似:\ngo\nfunc (c *Client) Get(ctx context.Context, req *Request, callback func(resp *Response, err error)) error\n\njava\npublic interface Client &#123;    void get(Request req, Callback callback);&#125;\n\n网络编程中的批量对于网络请求来说，批量可以提高性能。 批量处理是指将多个请求或任务组合在一起，作为单一的工作单元进行处理。批量尽量对用户透明，用户只需要简单地对批量进行配置，而不需要关心批量的实现细节。\n常见的批量相关配置\n\nbatch interval: 批量的时间间隔，比如每隔1s，批量一次\nbatch size: 批量的最大大小，比如每次最多批量100个请求\n\n批量可以通过定时任务实现，也可以做一些优化，比如队列中无请求时，暂停定时任务，有请求时，启动定时任务。\n编码细节整体流程大概如下图所示：\n\n一定要先把请求放到队列&#x2F;map中避免网络请求响应过快，导致callback还没注册上，就已经收到响应了。\n队列中的消息一定要有超时机制避免由于丢包等原因，导致请求一直没有响应，而导致队列中的请求越来越多，最终内存溢出。\nwait队列生命周期与底层网络client生命周期一致wait队列中请求一定是依附于client的，一旦client重建，队列也需要重建，并触发callback、future的失败回调。\n","tags":["Code"]},{"title":"微服务广播模式实践","url":"/2023/06/01/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%B9%BF%E6%92%AD%E6%A8%A1%E5%BC%8F%E5%AE%9E%E8%B7%B5/","content":"微服务广播模式，指的是在微服务多实例部署的场景下，将消息广播到多个微服务实例的一种模式。\n\n广播模式，一般用来维护微服务的内存数据，根据数据类型的不同，有助于解决两类问题。通常广播模式会使用支持发布订阅的消息中间件实现（如Redis、Kafka、Pulsar等），本文也基于消息中间件进行讨论。\n利用广播模式维护一致的缓存这应该是广播模式利用最多的一种场景，假想一个拥有海量用户的电商网站、或是一个亿级设备连接的IoT平台。势必会存在一些缓存数据，像是用户的购物车信息，或是设备的密钥缓存。如果没有广播模式，可能会存在这样的问题\n\n当用户更新了它的购物车之后，微服务实例1的数据发生了更新，数据库的数据也成功更新。但是微服务实例2中的缓存数据未能更新，那么如果用户的请求均衡到了实例2，就会发生意想不到的后果。\n这种情况下我们可以让微服务1在广播通道中发送一个缓存的invalidate消息，将微服务实例2中该用户的缓存清零，使得微服务实例2在下一次处理该用户的请求时，从数据库中读取最新的消息。\n使用该模式需要注意的点：\n\n每个微服务实例应该使用不同的消费组，可以通过微服务的IP、主机名、UUID等拼装成订阅组名称，这才称得上广播之名\n微服务消费消息的时候，应从Latest开始消费，避免从Earliest开始消费无用的缓存清理消息\n由于每一次微服务重启都会产生一个新的消费组，需要注意消费组的老化，可以通过消息中间件自带的不活跃消费组老化能力兜底，建议通过gracefulExit、监听kill信号等机制来主动删除消费组信息\n\n为什么说消费组老化比较重要呢，因为很多监控系统都会根据消费组的积压来做告警，很容易产生误告警。\n利用广播模式维护内存中的数据这种模式相对比较少见，常见于key的基数不是很大，能够将数据完整地存储在内存中，比如电商平台的企业卖家个数、物联网平台的用户个数等，并且对数据的一致性要求不是很高（因为广播模式情况下，对于两个微服务实例来说没有一致性保障）。像Apache Pulsar设计的TableView，在我看来，就是做这个事的一个最佳实践。Pulsar内部大量使用了topic存储数据，就是采用这个方式。\n使用该模式需要注意的点：\n\n同上，需要使用不同的消费组名称\n微服务消费消息的时候，应该从Earliest开始消费，保证所有微服务内存中的消息视图一致\n同上，需要注意消费组的老化\n\n为什么需要消费组老化作为保底手段因为在极端场景下，无论是graceful的代码，还是监听kill信号的代码，都不能保证代码百分百地被执行。需要兜底。\nKafka消费组老化Kafka通过offsets.retention.minutes参数控制消费组中offsets保留时间，在此时间内如果没有提交offset，offsets将会被删除。Kafka判定消息组中没有在线的消费者（如empty状态），且没有offsets时，将会删除此消费组。\nPulsar消费组老化pulsar的消费组老化策略更加灵活，可以配置到namespace级别。\nbin/pulsar-admin namespaces | grep expiration    get-subscription-expiration-time      Get subscription expiration time for       Usage: get-subscription-expiration-time [options] tenant/namespace    set-subscription-expiration-time      Set subscription expiration time for       Usage: set-subscription-expiration-time [options] tenant/namespace            Subscription expiration time in minutes    remove-subscription-expiration-time      Remove subscription expiration       Usage: remove-subscription-expiration-time [options] tenant/namespace\n\n这里注意要合理地配置消费组的老化时间，在pulsar的当前版本（2.11版本）下，catch up读，也就是说消费组平时积压量不大。如果将消费组的老化时间配置大于等于消息的老化时间，会出现消费组老化不了的现象。\n当然，由于消费组和消息老化都是定时任务，预估时间时，要考虑一定的buffer。\n这里让我们稍稍dive一下原理，消费组的老化是通过判断Cursor游标的LastActive time来判断能否老化的。如果该消费组的游标位置到达了消息老化区域，被老化掉了，消费组的游标位置就会强制更新到一个可用的位置，这个时候会更新游标的LastActive time到当前时间，周而复始，导致消费组无法老化。举个🌰\n假设消费组的老化时间为4h，消息的老化时间为3h，就可能会发生这样的事情\n\n总结广播模式在微服务架构中起到了重要的角色，尤其是在需要在微服务实例之间同步数据的场景中，它具有显著的优势。它能够帮助维护内存数据的缓存一致性。希望本篇文章能提供您全面的广播模式的知识。\n"},{"title":"打造可商用的Java程序之可维护性","url":"/2023/06/15/%E6%89%93%E9%80%A0%E5%8F%AF%E5%95%86%E7%94%A8%E7%9A%84Java%E7%A8%8B%E5%BA%8F%E4%B9%8B%E5%8F%AF%E7%BB%B4%E6%8A%A4%E6%80%A7/","content":"在主函数中捕获未处理的异常在主函数中捕获未处理的异常，防止程序崩溃，同时记录日志，方便排查问题。\npublic class UncaughtExceptionHandle &#123;    public static void main(String[] args) &#123;        Thread.setDefaultUncaughtExceptionHandler((t, e) -&gt; log.error(&quot;Uncaught exception: &quot;, e));    &#125;&#125;\n"},{"title":"提升网络协议服务器的定位能力","url":"/2023/05/30/%E6%8F%90%E5%8D%87%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E5%AE%9A%E4%BD%8D%E8%83%BD%E5%8A%9B/","content":"近期，我再次涉足于协议服务器相关的工作领域，致力于定位并解决各种问题。简单总结一些心得给大家。如果想要定位出协议服务器的问题，那么这些能力可能至关重要。\n注：我这里比较偏向协议本身的问题，不涉及一些通用的网络问题（如网络吞吐量上不去、响应时间长等等）\n对CPU和内存的通用分析能力首先，网络协议服务器本质上也是一个应用程序。因此，需要具备一些关于CPU和内存的通用分析能力。PU&#x2F;内存火焰图，内存dump分析，锁分析，以及远程调试（研发态手段）这些手段都要具备\n日志和网络连接的关联为了有效地定位网络问题，日志需要精确到毫秒级别。没有毫秒级别的精度，定位网络问题就会变得极其困难。所以golang的logrus默认只有秒级别，我觉得不太好，用rfc3339就很好。\n在打印日志时，我们不能太过随意。例如，“connection lost”这样的日志，在调试阶段可能看似无大碍，但当真正的业务量和连接数大幅增加时，这种模糊的日志信息就会让人束手无策。\n理想的日志至少应包含网络地址信息，这样我们可以根据网络地址和时间点来查阅日志。如果有抓包的话，那就更好了，可以从中获取大量信息。\n当然，我们并不需要在所有的日志中都包含网络地址信息。例如，一旦完成了用户身份的鉴定，我们就可以打印用户的身份信息，这样更方便与后续的业务流程进行整合。如果需要查询网络地址信息，可以回溯到建立连接时的日志。举个🌰\n2023-05-30 23:59:01.000 [INFO] 127.0.0.1:62345 connected2023-05-30 23:59:02.000 [INFO] 127.0.0.1:62345 authed, username is Wolverine2023-05-30 23:59:03.000 [INFO] Wolverine killed magneto\n\n假设一条数据链上有大量的消息呢？在现代的网络环境中，一条TCP链接可以轻易达到5M bit&#x2F;s以上的数据流。即使我们提供了时间点信息，仍然很难找到具有问题的报文（在同一秒内可能有上千条报文）。在这种情况下，就需要引入会话的ID信息。许多TCP协议会携带这种信息，换句话说，支持IO复用的协议都会有这种信息（比如MQTT的messageId，Kafka的correlationId等）。此类信息应该被正确地打印在日志中。\n针对特征值的跟踪能力你可能已经在调试日志中包含了非常详尽的信息，然而在实际环境中，这可能并没有太大用处。\n原因是一旦全面开启debug日志，性能消耗会大幅增加。除非你的系统性能冗余极大，否则根本无法正常运行。\n为此，我们可以提升debug的能力，针对特定的特征值开启debug，例如网络地址、mqtt的clientId、消息中间件的topic等。应用程序仅针对这些特征值打印详细的日志，这样的开销就相对较小，而且这种方法已经在生产环境中被我多次验证。\n将网络报文与业务trace关联起来在网络协议服务器中，我们需要将网络报文与业务trace关联起来。这种关联能力的实现可以大大提高我们定位业务端到端问题的效率和准确性。 理想情况下，我们应该能够根据网络报文来查找相关的业务trace，反之亦然，根据业务trace来查找对应的网络报文。但这些手段都需要业务端的配合，比如在报文中携带traceId，或者在业务trace中携带网络地址信息。\n以mqtt协议为例，可以在payload中带上\n&#123;    &quot;traceId&quot;: &quot;xxxx&quot;,    &quot;data&quot;: &quot;xxxx&quot;&#125;\n\n在这个例子中，traceId就是我们为业务trace设定的唯一标识符，而data则是实际的业务数据。通过在网络报文中携带这些信息，我们就可以轻松地将网络报文与其对应的业务trace关联起来。\n然而，这种方法在研发和测试环境中实现相对容易，但在生产环境中可能会遇到更多的困难。首先，对于在网络报文中携带traceId这一做法，业界并未形成统一的规范和实践。这导致在生产环境，极难做到。\n更具挑战性的是，如果你面对的是一个端到端的复杂系统，将traceId从系统的入口传递到出口可能会遇到许多难以预见的问题。例如系统不支持这类数据的专递，这就封死了这条路。\n查看原始报文的能力查看原始报文的能力极其重要，特别是在协议栈的实现尚不成熟的情况下。如果无法查看原始报文，定位问题就会变得非常困难。我曾说过：“如果拿到了原始报文，还是无法复现问题，那我们的研发能力在哪里？”虽然这句话可能有些极端，但它准确地强调了抓包的重要性。\n我们可以从抓包看出网络的连通性、网络的延迟、网络的吞吐量、报文的格式、报文的正确性等等。如果途径了多个网元，那么是谁的错？（一般来说，看抓包，谁先发RST，就从谁身上找原因）\n虽然抓包的命令比较简单tcpdump port 8080 -i eth0 -s0 -w my.pcap就抓了，但实际想做成，最大的阻力是这两个，TLS和复杂的现网环境\n在旧版本的TLS密钥交换算法下，只要有私钥和密码，就可以顺利解包，但现在的tls，都支持前向加密，什么叫前向加密呢？简单地来说，就是给你私钥和密码，你也解不出来。有tls debuginfo和ebpf能解决这两个问题，tls debug-info的原理是将密钥交换时的密钥输出持久化到某个地方，然后拿这个去解，实际很少见有人用这个方案。ebpf一需要linux内核高版本，同时还需要开启功能，安装kernel-debug-info，门槛也比较高。\n现网环境，像抓包嗅探的这种工具，有时候可能是禁止上传的，或者即使能上传成功，也需要很长的时间。\n也许我们可以通过“应用层抓包”来解决上述的问题，在网络层，我们支持受限的抓包能力，比如可以抓针对某个特征值（比如网络地址、messageId）的包，因为我们在应用层，可使用的过滤条件更多，更精细，输出到某个路径，这个报文的组装，完全在应用网络层，虽然看不到物理层的一些信息，但对于应用程序来说，除非我是做nat设备的，一般用不到这些信息。继续用这个报文来分析问题。实现应用层抓包，也要注意对内存的占用等等，不能因为这个功能，把整个进程搞崩溃。\n应用层抓包的一些思考抓包地点的选择在应用层抓包，第一步就是确定抓包的地点。由于我们是在应用层进行操作，因此抓包地点一般位于应用程序与网络协议栈的交接处。例如，你可以在数据包刚被应用接收，还未被处理之前进行抓包，或者在数据包即将被应用发送出去，还未进入网络协议栈之前进行抓包。\n过滤条件的设定设定过滤条件是抓包的关键，因为在实际环境中，数据流量可能非常大，如果没有过滤条件，抓包的数据量可能会非常庞大，对应用和系统的性能产生影响。在应用层，我们可以设置更多更精细的过滤条件，如网络地址、端口、协议类型、特定的字段等。这些过滤条件可以帮助我们更精确地定位问题，减少无效的数据。\n数据存储问题将抓到的数据存储起来也是很重要的一步。可以选择将数据存储到内存或者硬盘。需要注意的是，如果选择存储到内存，要考虑到内存的大小，避免因为抓包数据过大导致内存溢出。如果选择存储到硬盘，要考虑到硬盘的读写速度和容量，避免因为抓包数据过大导致硬盘满载。\n总结本文首先阐述了网络协议服务器的一些问题定位能力，包括CPU内存分析能力、日志和网络连接的关联能力、针对特征值的跟踪能力，以及查看原始报文的能力，也讨论了将网络报文与业务trace有效关联的重要性和实现挑战。强调了抓包的重要性和对于解密TLS报文的挑战。为了解决网络层抓包遇到的困难，我们可以考虑应用层抓包方案。最后，我们讨论了应用层抓包的一些关键问题，包括抓包地点的选择、过滤条件的设定和数据存储问题。\n"},{"title":"揭秘MySQL TLS：通过抓包了解真实的加密通信","url":"/2023/02/09/%E6%8F%AD%E7%A7%98MySQL%20TLS%EF%BC%9A%E9%80%9A%E8%BF%87%E6%8A%93%E5%8C%85%E4%BA%86%E8%A7%A3%E7%9C%9F%E5%AE%9E%E7%9A%84%E5%8A%A0%E5%AF%86%E9%80%9A%E4%BF%A1/","content":"你的mysql客户端和服务端之间开启tls了吗？你的回答可能是No，我没有申请证书，也没有开启mysql客户端，服务端的tls配置。\n可是当你抓取了3306 mysql的端口之后，你会发现，抓出来的包里居然有Client Hello、Server Hello这样的典型TLS报文。\n\n其实，Mysql的通信是否加密，是由客户端和服务端共同协商是否开启的，客户端与服务端都处于默认配置下的话，有些类似于StartTls。\n服务端侧在连接建立时，Mysql服务端会返回一个Server Greeting，其中包含了一些关于服务端的信息，比如协议版本、Mysql版本等等。在其中有一个flag的集合字段，名为Capabilities Flag，顾名思义，这就是用来做兼容性，或者说特性开关的flag，大小为2个字节，其中的第12位，代表着CLIENT_SSL，如果设置为1，那代表着如果客户端具备能力，服务端可以在后面的会话中切换到TLS。可以看到里面还有一些其他的flag，事务、长密码等等相关的兼容性开关。\n\n我们可以测试一下设置为0的行为，只需要在my.cnf中添加\necho &quot;ssl=0&quot; &gt;&gt; /etc/my.cnf\n\n重启mysql。再度进行抓包，就发现没有tls的报文了，都是在使用明文进行通信了。\n\n客户端侧这个协商过程也可以在客户端进行控制，客户端对应的参数是sslMode，可以设置为DISABLED、PREFERRED、REQUIRED、VERIFY_CA、VERIFY_IDENTITY，分别代表不使用ssl、优先使用ssl、必须使用ssl、验证CA、验证身份。默认的行为是PREFERRED，example:\n比如配置sslMode为DISABLED，那么客户端就不会使用ssl进行通信，而是使用明文。\nr2dbc:mysql://localhost:3306/test?sslMode=DISABLED\n\n\n总结\n\n\n客户端\n服务端\n结果\n\n\n\nDISABLED\nssl&#x3D;0\nPLAIN\n\n\nDISABLED\nssl&#x3D;1\nPLAIN\n\n\nPREFERRED\nssl&#x3D;0\nPLAIN\n\n\nPREFERRED\nssl&#x3D;1\nTLS\n\n\nREQUIRED\nssl&#x3D;0\nFail\n\n\nREQUIRED\nssl&#x3D;1\nTLS\n\n\nVERIFY_CA\nssl&#x3D;0\nFail\n\n\nVERIFY_CA\nssl&#x3D;1 + CA配置\nTLS，客户端验证证书\n\n\nVERIFY_IDENTITY\nssl&#x3D;0\nFail\n\n\nVERIFY_IDENTITY\nssl&#x3D;1 + CA配置\nTLS，客户端验证证书和域名\n\n\n注：\n\nVERIFY_CA：确保服务器证书由受信任的CA签发，但不验证证书的主机名或IP地址。\nVERIFY_IDENTITY：不仅验证证书的CA签发，还额外验证证书的主机名或IP地址与服务器的实际地址是否一致。\n\n","tags":["MySQL"]},{"title":"敏感信息打印大全","url":"/2023/07/14/%E6%95%8F%E6%84%9F%E4%BF%A1%E6%81%AF%E6%89%93%E5%8D%B0%E5%A4%A7%E5%85%A8/","content":"JavaApache http clientWire logApache http client会打印请求和响应的wire log，包含请求和响应的header和body，打印在debug级别。\nApache http client的日志都通过org.apache.http.wire这个logger打印，可以通过配置这个logger来控制wire log的打印。\n注：Apache http client默认通过apache common logging来打印日志，可以通过配置\n&lt;dependency&gt;    &lt;groupId&gt;org.slf4j&lt;/groupId&gt;    &lt;artifactId&gt;jcl-over-slf4j&lt;/artifactId&gt;    &lt;version&gt;1.7.32&lt;/version&gt;&lt;/dependency&gt;\n来使用slf4j来打印日志。\n"},{"title":"文件编解码代码设计","url":"/2023/11/20/%E6%96%87%E4%BB%B6%E7%BC%96%E8%A7%A3%E7%A0%81%E4%BB%A3%E7%A0%81%E8%AE%BE%E8%AE%A1/","content":"概述我们以xyz文件格式为例，来说明文件编解码的代码设计。xyz文件格式内容如下：\n\nheader部分：文件头，包含文件版本号、文件类型、文件大小等信息\nbody部分：文件主体\n\n通用设计大概如下\nclassDiagram\n    class XyzHeader {\n        + byte[] content\n    }\n    class XyzBody {\n        + byte[] content\n    }\n    class Xyz{\n        + XyzHeader header\n        + XyzBody body\n    }\n    class XyzReader {\n        + Xyz read(fileName: string)\n        + void process(String fileName, XyzProcessor processor)\n        - XyzHeader readHeader()\n        - XyzBody readBody()\n    }\n    class XyzProcessor {\n        \n        + void processHeader(XyzHeader header)\n        + void processBody(XyzBody body)\n    }\n    class XyzReadCollectProcessor {\n        Xyz getXyz()\n    }\n    Xyz --> XyzHeader: contains\n    Xyz --> XyzBody: contains\n    XyzReader --> Xyz: reads\n    XyzReader --> XyzProcessor: processes\n    XyzReadCollectProcessor --|> XyzProcessor: implements\n\nJava使用java.io.RandomAccessFile和java.nio.channels.FileChannel来实现文件读取，使用io.netty.buffer.ByteBuf来读写文件。\n核心代码举例:\nXyzReader:\npublic class XyzHeader &#123;    private byte[] content;&#125;public class XyzBody &#123;    private byte[] content;&#125;public class Xyz &#123;    private XyzHeader header;    private XyzBody body;&#125;public interface XyzProcessor &#123;    void processHeader(XyzHeader header);    void processBody(XyzBody body);&#125;public class XyzReadCollectProcessor implements XyzProcessor &#123;    private final Xyz xyz = new Xyz();    public Xyz getXyz() &#123;        return xyz;    &#125;&#125;public class XyzReader &#123;    public Xyz read(String fileName) throws Exception &#123;    &#125;    private XyzHeader readHeader(FileChannel fileChannel) throws Exception &#123;    &#125;    private XyzBody readBody(FileChannel fileChannel) throws Exception &#123;    &#125;&#125;\n\n\n import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs';\tmermaid.initialize({startOnLoad: true, flowchart: {curve: 'linear'}}); ","tags":["Codec"]},{"title":"比调用Shell更高效的判断进程是否存在的方式","url":"/2021/08/12/%E6%AF%94%E8%B0%83%E7%94%A8Shell%E6%9B%B4%E9%AB%98%E6%95%88%E7%9A%84%E5%88%A4%E6%96%AD%E8%BF%9B%E7%A8%8B%E6%98%AF%E5%90%A6%E5%AD%98%E5%9C%A8%E7%9A%84%E6%96%B9%E5%BC%8F/","content":"有很多场景需要我们的代码检测一个进程是否存在，常用的一种方式是通过调用脚本通过ps -ef的方式查看，然而其实这种做法并不怎么高效，会fork一个进程出来，还会影响go协程的调度\n一种更好的方式是可以通过解析/proc文件夹来得到想要的信息，其实可以通过strace命令查看，ps -ef也是读取了这个路径下的信息\n\n下面分别是java和go的轮子示例\n使用正则表达式[0-9]+的原因是/proc路径下还有一些其他文件，其中pid都是数字。\njavaprivate static final Pattern numberPattern = Pattern.compile(&quot;[0-9]+&quot;);    public static boolean processExists(String processName) throws Exception &#123;        final File procFile = new File(&quot;/proc&quot;);        if (!procFile.isDirectory()) &#123;            throw new Exception(&quot;why proc dir is not directory&quot;);        &#125;        final File[] listFiles = procFile.listFiles();        if (listFiles == null) &#123;            return false;        &#125;        final List&lt;File&gt; procDir = Arrays.stream(listFiles).filter(f -&gt; numberPattern.matcher(f.getName()).matches()).collect(Collectors.toList());        // find the proc cmdline        for (File file : procDir) &#123;            try &#123;                final byte[] byteArray = FileUtils.readFileToByteArray(new File(file.getCanonicalPath() + File.separator + &quot;cmdline&quot;));                final byte[] bytes = new byte[byteArray.length];                for (int i = 0; i &lt; byteArray.length; i++) &#123;                    if (byteArray[i] != 0x00) &#123;                        bytes[i] = byteArray[i];                    &#125; else &#123;                        bytes[i] = (byte) 0x20;                    &#125;                &#125;                final String cmdLine = new String(bytes, StandardCharsets.UTF_8);                if (cmdLine.contains(processName)) &#123;                    return true;                &#125;            &#125; catch (IOException e) &#123;                // the proc may end during the loop, ignore it                log.error(&quot;read file exception &quot;, e);            &#125;        &#125;        return false;    &#125;\n\ngofunc ProcessExists(processName string) (bool, error) &#123;\tresult := false\tfileInfos, err := ioutil.ReadDir(&quot;/proc&quot;)\tif err != nil &#123;\t\treturn false, err\t&#125;\tfor _, info := range fileInfos &#123;\t\tname := info.Name()\t\tmatched, err := regexp.MatchString(&quot;[0-9]+&quot;, name)\t\tif err != nil &#123;\t\t\treturn false, err\t\t&#125;\t\tif !matched &#123;\t\t\tcontinue\t\t&#125;\t\tcmdLine, err := parseCmdLine(&quot;/proc/&quot; + info.Name() + &quot;/cmdline&quot;)\t\tif err != nil &#123;\t\t\tglog.Error(&quot;read cmd line failed &quot;, err)\t\t\t// the proc may end during the loop, ignore it\t\t\tcontinue\t\t&#125;\t\tif strings.Contains(cmdLine, processName) &#123;\t\t\tresult = true\t\t&#125;\t&#125;\treturn result, err&#125;func parseCmdLine(path string) (string, error) &#123;\tcmdData, err := ioutil.ReadFile(path)\tif err != nil &#123;\t\treturn &quot;&quot;, err\t&#125;\tif len(cmdData) &lt; 1 &#123;\t\treturn &quot;&quot;, nil\t&#125;\tsplit := strings.Split(string(bytes.TrimRight(cmdData, string(&quot;\\x00&quot;))), string(byte(0)))\treturn strings.Join(split, &quot; &quot;), nil&#125;\n","tags":["Linux"]},{"title":"现代编程语言中的异常处理","url":"/2024/12/26/%E7%8E%B0%E4%BB%A3%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/","content":"在软件开发中，健壮的异常处理是编写高质量代码的关键。本文将探讨现代编程语言中的通用异常处理方法，帮助你优雅地处理异常并写出健壮的代码。我们将不拘泥于某种语言，而是讨论一些普遍适用的策略。\n异常链概述现代编程语言通常将异常视为一条单向链表，链表中的节点包含根本原因和相关的上下文信息。例如：\ngraph TD\n    C --> D[MicroServiceError, call user service failed]\n    B --> C[DatabaseError, select * from user failed]\n    A --> B[HttpError, http://localhost:6379 failed]\n    A[SocketError, localhost, 6379 connect failed]\n\n异常就这么向外传播也不错，但是抽象是会泄露的，正常的时候顺风顺水，异常就需要判断一下，比如一个很常见的需求，文件已存在异常，就当做成功处理，用Java来写就是这样\nif (exception instanceof FileAlreadyExistsException) &#123;    log.info(&quot;file already exists&quot;);    return SUCCESS;&#125;throw exception;// or wrap it\n\n综上来看，我们对现代编程语言的需求就是，能组织异常链，判断异常是否是某类异常，把异常用字符串的形式打印出来。\n当我们在构筑一个library的时候，应该尽可能保持完整的异常链，除非你认为这个异常在library内可以处理，比如上面的情况。并且应该在项目的README，或者项目的某个文件中，详细地列出本library可能抛出的异常，以及异常的含义。\n我们在opengemini-client-go中就有这样的例子，我们在errors.go中定义了所有可能的异常，以及异常的含义。\n有些时候，我们构筑的不是library，出于隐藏内部实现或者是向终端用户隐藏逻辑上的低级错误，我们会对异常进行处理，比如常见的\nif (exception instanceof DuplicateKeyException) &#123;    log.info(&quot;duplicate key&quot;);    return new ServiceException(&quot;already exists&quot;);&#125;// many if elsethrow new ServiceException(&quot;unknown error&quot;); // or just internal error\n\n题外话，由于Java只能判断本级的异常类型，你会经常看到getCause的代码，比如Apache Pulsar项目中的\nif (exception.getCause() != null                    &amp;&amp; exception.getCause() instanceof PulsarClientException.InvalidServiceURL) &#123;    throw new MalformedURLException(exception.getMessage());&#125;\n包括层次一多，甚至可以看到递归代码\nprivate static Throwable mapToBkException(Throwable ex) &#123;        if (ex instanceof CompletionException || ex instanceof ExecutionException) &#123;            return mapToBkException(ex.getCause());        &#125;        if (ex instanceof MetadataStoreException.NotFoundException) &#123;            BKException bke = BKException.create(BKException.Code.NoSuchLedgerExistsOnMetadataServerException);            bke.initCause(ex);            return bke;        &#125; else if (ex instanceof MetadataStoreException.AlreadyExistsException) &#123;            BKException bke = BKException.create(BKException.Code.LedgerExistException);            bke.initCause(ex);            return bke;        &#125; else if (ex instanceof MetadataStoreException.BadVersionException) &#123;            BKException bke = BKException.create(BKException.Code.MetadataVersionException);            bke.initCause(ex);            return bke;        &#125; else if (ex instanceof MetadataStoreException.AlreadyClosedException) &#123;            BKException bke = BKException.create(BKException.Code.LedgerClosedException);            bke.initCause(ex);            return bke;        &#125;        return ex;    &#125;\n\nGo在这里易用性做的不错，支持了errors.Is和errors.As，可以判断异常链中是否包含某个异常，也可以直接获取异常链中的异常。不过如果异常链里面有两个一模一样类型的异常，你想精准取到其中一个就比较困难，不过这在实际场景中非常少见。\n这里，我们说异常链发生了变更，那么什么时候打印日志也比较明确了，当异常链发生变更的时候打印，保证完整的堆栈信息用于问题分析。这也可以保证在一条链的过程中，有且仅有一次打印日志。\n在异常链发生终止，比如转化为http content，或者是print到console的时候，要不要打印日志呢？这个问题有些见人见智，这取决于你的用户在report问题的时候，会不会携带http content或者是console output，如果不会，那么你就需要打印日志，如果会，那么你就不需要打印日志。\nJava里面，比起将底层的error抛出，我们更倾向于定义一个符合本library抽象层级的异常，并在方法的签名中只返回这个异常，一方面使得下层library的异常如果发生变化，本library依然是编译兼容的，另一方面也更符合抽象层级。\n但是在Go里面，事情就更复杂一些，我愿意称之为类型的细化具备传染性，一旦你将某个方法的签名不返回interface，而是返回一个具体的类型，比如\nfunc (c *Client) CallService() (Result, *ServiceError) &#123;    if failed &#123;        return nil, &amp;ServiceError&#123;Code: 500, Message: &quot;service error&quot;&#125;    &#125;    return result, nil&#125;\n\n然后有一个方法调用了它\nfunc main() &#123;    err := MakeFriend()    if err != nil &#123;        panic(err)    &#125;&#125;func (c *Client) MakeFriend() (Result, error) &#123;    err := io.Read(&quot;friend_list.txt&quot;)    if err != nil &#123;        return nil, err    &#125;    return CallService()    \n\n这下就麻烦了，当*ServiceError转化为error, nil的ServiceError指针转化为error的时候就不是nil了，这很致命，是的，这非常致命。即使CallService()成功了，main函数还是会panic。\n把这个叫做传染性还是比较准确的，异步的代码、鸿蒙的ets都具备一样的性质，他们会不断向上传播，我对这个词还是比较满意。\n综上，Go里面，我们可以构筑具体的异常，但是在不能确保上层一直都是用这个细化类型的情况下，接口还是返回error interface。\n漫谈了许多，我简单做一个总结\n\n现代编程语言的异常是一条链\n现代编程语言应该具备构筑异常链，判断异常是否是某类异常，异常打印的能力\n设计符合抽象层级的异常\n构筑一个library的时候，尽可能保持完整的异常链，在项目的README，或者项目的某个文件中，详细地列出本library可能抛出的异常，以及异常的含义\n在异常链发生变更的时候进行日志打印\n\n import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs';\tmermaid.initialize({startOnLoad: true, flowchart: {curve: 'linear'}}); ","tags":["Code"]},{"title":"线程锁导致的kafka客户端超时问题","url":"/2023/07/08/%E7%BA%BF%E7%A8%8B%E9%94%81%E5%AF%BC%E8%87%B4%E7%9A%84kafka%E5%AE%A2%E6%88%B7%E7%AB%AF%E8%B6%85%E6%97%B6%E9%97%AE%E9%A2%98/","content":"问题背景有一个环境的kafka client发送数据有部分超时，拓扑图也非常简单\n\n定位历程我们先对客户端的环境及JVM情况进行了排查，从JVM所在的虚拟机到kafka server的网络正常，垃圾回收（GC）时间也在预期范围内，没有出现异常。\n紧接着，我们把目光转向了kafka 服务器，进行了一些基础的检查，同时也查看了kafka处理请求的超时日志，其中我们关心的metadata和produce请求都没有超时。\n问题就此陷入了僵局，虽然也搜到了一些kafka server会对连上来的client反解导致超时的问题（ https://github.com/apache/kafka/pull/10059），但通过一些简单的分析，我们确定这并非是问题所在。\n同时，我们在环境上也发现一些异常情况，当时觉得不是核心问题&#x2F;解释不通，没有深入去看\n\n问题JVM线程数较高，已经超过10000，这个线程数量虽然确实较高，但并不会对1个4U的容器产生什么实质性的影响。\n负责指标上报的线程CPU较高，大约占用了1&#x2F;4 ~ 1&#x2F;2 的CPU核，这个对于4U的容器来看问题也不大\n\n当排查陷入僵局，我们开始考虑其他可能的调查手段。我们尝试抓包来找线索，这里的抓包是SASL鉴权+SSL加密的，非常难读，只能靠长度和响应时间勉强来推断报文的内容。\n在这个过程中，我们发现了一个非常重要的线索，客户端竟然发起了超时断链，并且超时的那条消息，实际服务端是有响应回复的。\n随后我们将kafka client的trace级别日志打开，这里不禁感叹kafka client日志打的相对较少，发现的确有log.debug(“Disconnecting from node {} due to request timeout.”, nodeId);的日志打印。\n与网络相关的流程：\ntry &#123;    // 这里发出了请求    client.send(request, time.milliseconds());    while (client.active()) &#123;        List&lt;ClientResponse&gt; responses = client.poll(Long.MAX_VALUE, time.milliseconds());        for (ClientResponse response : responses) &#123;            if (response.requestHeader().correlationId() == request.correlationId()) &#123;                if (response.wasDisconnected()) &#123;                    throw new IOException(&quot;Connection to &quot; + response.destination() + &quot; was disconnected before the response was read&quot;);                &#125;                if (response.versionMismatch() != null) &#123;                    throw response.versionMismatch();                &#125;                return response;            &#125;        &#125;    &#125;    throw new IOException(&quot;Client was shutdown before response was read&quot;);&#125; catch (DisconnectException e) &#123;    if (client.active())        throw e;    else        throw new IOException(&quot;Client was shutdown before response was read&quot;);&#125;\n\n这个poll方法，不是简单的poll方法，而在poll方法中会进行超时判断，查看poll方法中调用的handleTimedOutRequests方法\n@Overridepublic List&lt;ClientResponse&gt; poll(long timeout, long now) &#123;    ensureActive();    if (!abortedSends.isEmpty()) &#123;        // If there are aborted sends because of unsupported version exceptions or disconnects,        // handle them immediately without waiting for Selector#poll.        List&lt;ClientResponse&gt; responses = new ArrayList&lt;&gt;();        handleAbortedSends(responses);        completeResponses(responses);        return responses;    &#125;    long metadataTimeout = metadataUpdater.maybeUpdate(now);    try &#123;        this.selector.poll(Utils.min(timeout, metadataTimeout, defaultRequestTimeoutMs));    &#125; catch (IOException e) &#123;        log.error(&quot;Unexpected error during I/O&quot;, e);    &#125;    // process completed actions    long updatedNow = this.time.milliseconds();    List&lt;ClientResponse&gt; responses = new ArrayList&lt;&gt;();    handleCompletedSends(responses, updatedNow);    handleCompletedReceives(responses, updatedNow);    handleDisconnections(responses, updatedNow);    handleConnections();    handleInitiateApiVersionRequests(updatedNow);    // 关键的超时判断    handleTimedOutRequests(responses, updatedNow);    completeResponses(responses);    return responses;&#125;\n\n由此我们推断，问题可能在于客户端hang住了一段时间，从而导致超时断链。我们通过工具Arthas深入跟踪了Kafka的相关代码，甚至发现一些简单的操作（如A.field）也需要数秒的时间。这进一步确认了我们的猜想：问题可能出在JVM。JVM可能在某个时刻出现问题，导致系统hang住，但这并非由GC引起。\n\n为了解决这个问题，我们又检查了监控线程CPU较高的问题。我们发现线程的执行热点是从”sun.management.ThreadImpl”中的”getThreadInfo”方法。\n&quot;metrics-1@746&quot; prio=5 tid=0xf nid=NA runnable  java.lang.Thread.State: RUNNABLE    at sun.management.ThreadImpl.getThreadInfo(Native Method)\t  at sun.management.ThreadImpl.getThreadInfo(ThreadImpl.java:185)\t  at sun.management.ThreadImpl.getThreadInfo(ThreadImpl.java:149)\n\n进一步发现，在某些版本的JDK8中，读取线程信息是需要加锁的。\n至此，问题的根源已经清晰明了：过高的线程数以及线程监控时JVM全局锁的存在导致了这个问题。您可以使用如下的demo来复现这个问题\nimport java.lang.management.ManagementFactory;import java.lang.management.ThreadInfo;import java.lang.management.ThreadMXBean;import java.util.concurrent.Executors;import java.util.concurrent.ScheduledExecutorService;import java.util.concurrent.TimeUnit;public class ThreadLockSimple &#123;    public static void main(String[] args) &#123;        for (int i = 0; i &lt; 15_000; i++) &#123;            new Thread(new Runnable() &#123;                @Override                public void run() &#123;                    try &#123;                        Thread.sleep(200_000);                    &#125; catch (InterruptedException e) &#123;                        throw new RuntimeException(e);                    &#125;                &#125;            &#125;).start();        &#125;        ScheduledExecutorService executorService = Executors.newSingleThreadScheduledExecutor();        executorService.scheduleAtFixedRate(new Runnable() &#123;            @Override            public void run() &#123;                System.out.println(&quot;take &quot; + &quot; &quot; + System.currentTimeMillis());            &#125;        &#125;, 1, 1, TimeUnit.SECONDS);        ThreadMXBean threadMXBean = ManagementFactory.getThreadMXBean();        ScheduledExecutorService metricsService = Executors.newSingleThreadScheduledExecutor();        metricsService.scheduleAtFixedRate(new Runnable() &#123;            @Override            public void run() &#123;                long start = System.currentTimeMillis();                ThreadInfo[] threadInfoList = threadMXBean.getThreadInfo(threadMXBean.getAllThreadIds());                System.out.println(&quot;threads count &quot; + threadInfoList.length + &quot; cost :&quot; + (System.currentTimeMillis() - start));            &#125;        &#125;, 1, 1, TimeUnit.SECONDS);    &#125;&#125;\n\n为了解决这个问题，我们有以下几个可能的方案：\n\n将不合理的线程数往下降，可能存在线程泄露的场景\n升级jdk到jdk11或者jdk17（推荐）\n将Thread相关的监控临时关闭\n\n这个问题的解决方案应根据实际情况进行选择，希望对你有所帮助。\n","tags":["Kafka"]},{"title":"网络通信超时之后该不该重启客户端","url":"/2023/07/08/%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1%E8%B6%85%E6%97%B6%E4%B9%8B%E5%90%8E%E8%AF%A5%E4%B8%8D%E8%AF%A5%E9%87%8D%E5%90%AF%E5%AE%A2%E6%88%B7%E7%AB%AF/","content":"我写这篇文章来论证“超时之后要不要重启客户端”、“如何重启客户端”。简而言之，重启客户端还是为了让系统能够达到自愈，是比较高的可靠性要求。如果你的软件没有这么高的可靠性要求，像是人机交互程序等对可靠性要求较低的场景，可以选择不考虑这个功能。毕竟实现这个功能的时间至少够300倍你重新点击按钮&#x2F;重启的时间了。\n如果是一些串口协议，通过传输的间隙来判断报文的间隔，比如modbus协议，3.5个时间内不发送，就计算做一个协议报文的开始，那么故障时的报文毫无疑问会处理失败（因为存在CRC校验，奇偶校验等）。等待故障结束，又3.5个时间后，就会恢复正常。\n如果能确保网络通信报文不会遭到篡改、也没有宇宙射线&#x2F;太阳黑子修改你的比特位的场景下，笔者认为没有特别大的必要对客户端进行重启操作，因为不见得重启后就比之前更好，这种超时通常是由服务端处理时间长导致的。没做到建链限制的情况下，贸然重启，还可能会引起建链的波峰。\n但是，在实际复杂的网络环境下，如网络报文遭到篡改、部分字节丢失等的情况下，一切就大不一样了，不重启客户端就无法自愈。这其中的关键在于，切分报文是否正确。\n比如基于TCP的网络协议，这也是本文重点讨论的场景，假设应用协议采用最常见的LengthBasedFrame分包方式，这种协议，通常根据前0~4个字节来判断协议的总长度，比如前面的字节是00000014，那这个报文长度就是1*16 + 4 = 20长度。这种时候，一旦发生了报文篡改&#x2F;丢包，会导致通信端计算报文长度出错，一直在傻等，无法自愈。\n比如上面的例子一旦发生篡改，将4篡改5，那么就会导致客户端&#x2F;服务器一直在等待不存在的第21个字节，这种情况下，如果不做超时重建，那么这条链路就会一直处于等待状态，无法自愈。\n综上所述，实际复杂的网络环境下出现通信超时，这条链路可能会无法自愈。这种情况下，笔者推荐对针对tcp链路做超时重建，业内的一些例子像是：bookkeeper client没有做，kafka client做了。至于重建的触发条件，比如一次超时就重建、多次超时之后才重建、仅当心跳报文超时才重建，这些就交给读者自己把握了。如果区别不大，笔者倾向于一次超时就重建，逻辑简单清晰。\n"},{"title":"记一次kubernetes获取internal Ip错误流程","url":"/2022/11/15/%E8%AE%B0%E4%B8%80%E6%AC%A1kubernetes%E8%8E%B7%E5%8F%96internal%20Ip%E9%94%99%E8%AF%AF%E6%B5%81%E7%A8%8B/","content":"偶尔也回首一下处理的棘手问题吧。问题的现象是，通过kubernetes get node输出的ip不是期望的ip地址。大概如下所示\nip addreth0 ip1eth0:xxx ip2\n\n最终输出的不是预期的ip1地址，而是ip2地址。\n按藤摸瓜，kubernetes把节点信息保存在/registry/minions/$node-name中的InternalIp 字段。\nInternalIp是如何确定的呢，这段代码位于pkg/kubelet/nodestatus/setters.go中\n// 1) Use nodeIP if set (and not &quot;0.0.0.0&quot;/&quot;::&quot;)// 2) If the user has specified an IP to HostnameOverride, use it// 3) Lookup the IP from node name by DNS// 4) Try to get the IP from the network interface used as default gateway//// For steps 3 and 4, IPv4 addresses are preferred to IPv6 addresses// unless nodeIP is &quot;::&quot;, in which case it is reversed.\n\n我们的场景下没有手动设置nodeIp，如需设置通过kubelet命令行即可设置 –node-ip&#x3D;localhost，最终通过如下的go函数获取ip地址\naddrs, _ = net.LookupIP(node.Name)\n\n对这行go函数进行strace追溯，最终调用了c函数，getaddrinfo函数。getaddrinfo底层是发起了netlink请求，开启netlink的抓包\nmodprobe nlmonip link add nlmon0 type nlmonip link set dev nlmon0 uptcpdump -i nlmon0 -w netlinik.pcap# 使用nlmon 驱动模块，这个nlmon 驱动模块会注册一个 netlink tap 口，用户态向内核发送 netlink 消息、内核向用户态发送 netlink 消息，报文都会经过这个 tap 口。\n\n通过抓包我看到通过netlink报文请求返回的ip地址顺序都是合乎预期的，只能是getaddrinfo函数修改了返回的顺序\nGoogle了一下发现是getaddrinfo支持了rfc3484导致了ip的重新排序，代码地址glibc/sysdeps/posix/getaddrinfo.c\nRFC3484 总共有十个规则，比较关键的有\nRule9Rule 9:  Use longest matching prefix.When DA and DB belong to the same address family (both are IPv6 orboth are IPv4): If CommonPrefixLen(DA, Source(DA)) &gt;CommonPrefixLen(DB, Source(DB)), then prefer DA.  Similarly, ifCommonPrefixLen(DA, Source(DA)) &lt; CommonPrefixLen(DB, Source(DB)),then prefer DB.\n\n举个例子，假如机器的ip地址是 172.18.45.2/24，它会更青睐于172.18.45.6而不是172.31.80.8。这个RFC存在较大的争议，它与dns轮询策略不兼容，如：dns服务器轮询返回多个ip地址，客户端总是选择第一个ip连接。与这个策略存在很大的冲突。并且社区内也有投票试图停止对RFC3484 rule9的适配, 但是最终被拒绝了。\n根据分析，认为是ip2的地址小于ip1的地址，最终glibc排序的时候把ip2放在了前面。最终我们给kubelet配置了eth0地址的–node-ip，解决了这个问题。\n","tags":["Kubernetes"]},{"title":"记一次诡异的Java时间戳变化问题","url":"/2024/05/08/%E8%AE%B0%E4%B8%80%E6%AC%A1%E8%AF%A1%E5%BC%82%E7%9A%84Java%E6%97%B6%E9%97%B4%E6%88%B3%E5%8F%98%E5%8C%96%E9%97%AE%E9%A2%98/","content":"问题现象在一个使用Spring R2dbc与Mysql8.x的项目中，当创建 一个REST资源，进行创建，返回的毫秒精度时间戳，和下一瞬间查询的时间戳不一致。sql及代码大概如下\nCREATE TABLE person (    id INT PRIMARY KEY,    name VARCHAR(255),    created_time DATETIME(3),    updated_time DATETIME(3));\n\n实体类定义\n@Entityclass PersonEntity &#123;    @Id    private Long id;    private String name;    @CreatedDate    private LocalDateTime createdTime;    @LastModifiedDate    private LocalDateTime updatedTime;&#125;\n\n这里使用了@CreatedDate、@LastModifiedDate注解，并在Application类上配置了@EnableR2dbcAuditing注解用于在Repo操作实体的时候，自动更新时间戳。\npublic interface PersonRepo extends ReactiveCrudRepository&lt;PersonEntity, Long&gt; &#123;&#125;\n\n创建代码类比如下，大概就是使用r2dbc操作数据，并将r2dbc返回的实体用于转换毫秒时间戳\nreturn createPersonReq               .flatMap(req -&gt; &#123;                   PersonPo personPo = new PersonPo();                   personPo.setAge(18);                   personPo.setName(req.getName());                   return personRepo.save(personPo);               &#125;)               .map(person -&gt; &#123;                   PersonResp personResp = new PersonResp();                   personResp.setName(person.getName());                   personResp.setCreatedTime(TimeUtil.format(person.getCreatedTime()));                   return new ResponseEntity&lt;&gt;(personResp, null, HttpStatus.CREATED);               &#125;);\n\n然而创建的时候返回的时间戳和查询的时间戳不一致，现象举例：创建的时候返回：2024-05-08T08:11:47.333Z，查询的时候却返回：2024-05-08T08:11:47.334Z，\n走读代码，发现代码基本上万无一失，那么问题出在哪里呢？\n通过仔细观察时间戳的区别，发现时间戳的变化都在最后一位，且相差为一，醒悟到这估计是由于内存中纳秒时间戳精度在转化为数据库毫秒时间戳的时候，部分库的行为是截断，部分库的行为是四舍五入，导致了这个问题。\n最终通过写demo，docker抓包复现了这个问题，如下图所示，mysql server会将接收的时间戳进行四舍五入，而java常见的format工具类都是截断，导致了这一不一致。同时，这也体现了，r2dbc返回的entity可能并不是实际存入数据的内容，而是”原始”的entity。\n\nr2dbc与mysql的时间精度失调问题在这个问题里面，存在三个时间精度：\n\n内存中的时间精度\nr2dbc发给mysql的时间精度，有趣的是，r2dbc发给mysql的时间精度，并不是sql中列定义的精度，而是mysql server所能支持的最高精度即微秒精度。\nmysql实际存储的时间精度\n\nr2dbc返回的entity可能并不是实际存入数据的内容，而是经过r2dbc处理之后，发送到数据库之前的entity。问题的关键就在r2dbc并不根据列定义的精度处理数据，而是根据mysql server支持的最高精度处理数据。\n解决问题的方式有几种：\n\n将mysql列定义到微秒级别精度，优选方案\n在进入r2dbc之前，将时间戳截断到mysql列定义的精度\n在r2dbc返回的entity中，将时间戳截断到mysql支持的精度。这其实对开发者的心智负担较重，返回的entity并不是实际存储的，使用前要做进位，限制也比较大。\n\n在进入r2dbc之前，将时间戳截断到数据库表定义的精度，也有两种方式\n\n不使用@CreatedDate、@LastModifiedDate注解，而是在应用程序中手动设置时间戳\n继续使用@CreatedDate、@LastModifiedDate注解，通过拦截器统一进位\n\n通过拦截器的代码如下，定义基类，不然每个实体类都要书写拦截器。一般来说，一个项目里，时间戳的精度都应该统一，所以可以定义一个统一的拦截器。\nimport lombok.ToString;import org.springframework.data.annotation.CreatedDate;import org.springframework.data.annotation.LastModifiedDate;import java.time.LocalDateTime;@ToStringpublic abstract class AuditableEntity &#123;    @CreatedDate    protected LocalDateTime createdTime;    @LastModifiedDate    protected LocalDateTime updatedTime;    public LocalDateTime getCreatedTime() &#123;        return createdTime;    &#125;    public void setCreatedTime(LocalDateTime createdTime) &#123;        this.createdTime = createdTime;    &#125;    public LocalDateTime getUpdatedTime() &#123;        return updatedTime;    &#125;    public void setUpdatedTime(LocalDateTime updatedTime) &#123;        this.updatedTime = updatedTime;    &#125;&#125;\n\nimport org.reactivestreams.Publisher;import org.springframework.data.r2dbc.mapping.OutboundRow;import org.springframework.data.r2dbc.mapping.event.BeforeSaveCallback;import org.springframework.data.relational.core.mapping.event.BeforeConvertCallback;import org.springframework.data.relational.core.sql.SqlIdentifier;import org.springframework.stereotype.Component;import reactor.core.publisher.Mono;import java.time.LocalDateTime;import java.time.temporal.ChronoUnit;@Componentpublic class AuditableEntityCallback implements BeforeSaveCallback&lt;AuditableEntity&gt;, BeforeConvertCallback&lt;AuditableEntity&gt; &#123;    @Override    public Publisher&lt;AuditableEntity&gt; onBeforeSave(AuditableEntity entity, OutboundRow row, SqlIdentifier table) &#123;        System.out.println(&quot;before save &quot; + entity.getCreatedTime());        entity.setCreatedTime(roundToMilliseconds(entity.getCreatedTime()));        entity.setUpdatedTime(roundToMilliseconds(entity.getUpdatedTime()));        System.out.println(&quot;before save &quot; + entity.getCreatedTime());        return Mono.just(entity);    &#125;    @Override    public AuditableEntity onBeforeConvert(AuditableEntity entity) &#123;        System.out.println(&quot;before convert &quot; + entity.getCreatedTime());        entity.setCreatedTime(roundToMilliseconds(entity.getCreatedTime()));        entity.setUpdatedTime(roundToMilliseconds(entity.getUpdatedTime()));        System.out.println(&quot;before convert &quot; + entity.getCreatedTime());        return entity;    &#125;    private static LocalDateTime roundToMilliseconds(LocalDateTime dateTime) &#123;        LocalDateTime localDateTime = dateTime.truncatedTo(ChronoUnit.MILLIS);        int dateTimeNano = dateTime.getNano() % 1000_000;        if (dateTimeNano &gt;= 500_000) &#123;            localDateTime = localDateTime.plusNanos(1_000_000);        &#125;        return localDateTime;    &#125;&#125;\n\njpa有没有问题呢？出于好奇，我也做了jpa的尝试，jpa也是一样的行为\n\n","tags":["Java","mysql","r2dbc"]},{"title":"软件应该以标准的格式来交付","url":"/2025/09/22/%E8%BD%AF%E4%BB%B6%E5%BA%94%E8%AF%A5%E4%BB%A5%E6%A0%87%E5%87%86%E7%9A%84%E6%A0%BC%E5%BC%8F%E6%9D%A5%E4%BA%A4%E4%BB%98/","content":"令人深思的经历曾经历过这样的事情，平台侧要求应用提供满足平台特有格式的交付件，经过多次协商，最终还是应用侧与平台侧一起开会，由平台侧帮助应用侧输出。\n另一件事，Kubernetes Yaml以其独特、强大的合并属性能力闻名于江湖。应用侧对Kubernetes Yaml不熟悉，新手想要把环境上的Yaml导出直接作为标准交付件，虽然也行，但是包含了很多噪音，环境上的id、环境上的annotation、时间戳等等。\n私有化格式的交付困境越来越多的软件将自己定位为”平台”，无论是微信、飞书这样的国民应用，还是各类企业级软件。但平台交付的过程中，一个普遍存在的问题是：许多平台要求合作伙伴或第三方开发者使用其私有化的交付格式。这种私有化格式往往存在诸多问题：\n\n学习成本高，难以掌握。\n文档不完善，依赖平台方支持。\n迁移困难，形成供应商锁定。\n最终往往仍需平台方投入人力协助。\n\n软件交付应该标准化软件交付应该使用标准的格式，这有助于降低合作伙伴的接入成本，提高自身的可扩展性，尤其在AI辅助研发的现状下，采用标准的格式更有利于AI理解和生成代码。\n\n\n\n交付件\n标准格式\n使用场景\n\n\n\nJava库\nJar包\n作为依赖库被其他Java项目引用和集成，需要发布到Maven仓库。\n\n\n应用镜像\n标准镜像包\n以容器方式交付，确保运行的一致性。（但如x86、armv8、armv7）的差异依然存在。\n\n\n应用部署（I层资源已具备）\nhelm、docker compose\n商用场景多用Helm包，单机伪集群&#x2F;组合方式多用docker compose。\n\n\n应用部署及I层资源创建\nTerraform\n需要交付底层基础设施或云服务的场景，如整个应用运行环境。\n\n\n如果实在要使用私有的格式，可以对标准格式做一些裁剪&#x2F;扩展（Kubernetes的annotation），将标准格式转化到私有格式。\n"},{"title":"通用4层获取源IP的负载均衡网关建设","url":"/2020/12/25/%E9%80%9A%E7%94%A84%E5%B1%82%E8%8E%B7%E5%8F%96%E6%BA%90IP%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%BD%91%E5%85%B3%E5%BB%BA%E8%AE%BE/","content":"网关建设今天给大家介绍三种常见的四层负载均衡、网络转发方案，可用于四层的网关建设。\n利用ipvs实现(需要后端服务能连通外部网络)\n该方案需要后端服务器与前端client网络打通，GatewayIp可以采用主备的方式保证高可用\n配置都在GatewayIp上，需要配置的如下:\nipvsadm -A -u $GatewayIp:$port -s rr -p 600# -u表示为udp协议，-t表示为tcp协议# rr 为均衡算法，roundroubin的意思，lc则代表最短连接数ipvsadm -a -u $GatewayIp:$port -r $ServerIp:$port -m\n\nIpvs+Iptables实现如果您不希望后端Server与客户端面对面打通，那么您可能会喜欢这种方式，将GatewayIP设置为ServerIp的默认网关，再由Snat转换将报文转换出去，这样子Server就不需要与客户端面对面打通了，图示如下:\n\n配置默认路由也很简单\nip route add 客户端IP网段 via GateWayIp dev eth0\n配置iptables\niptables -t nat -A POSTROUTING -m iprange -p udp --dst-range $client_ip_range -o eth1  -j SNAT  --to-source $GateWayIp\n\nIpvs+Iptables+Iptunnel实现默认路由有一个限制，就是说Server与Gateway都在一个子网内，有过商用经验的大家都知道DMZ之类的说法，就是说应用服务器和网关服务器在诸如安全组，子网等等上需要隔离。假设你需要将应用服务器和网关放在不同的子网，上面的方案就搞不定啊，这个时候需要使用ip隧道的方式来跨子网，图示如下，仅仅后边红色路线的ip发生了变化，原来的报文被ip隧道Wrap:\n\n配置ip 隧道倒也不难\nip tunnel add $tun_name mode ipip remote $remote_ip local $local_ip ttl 255\n总结以上三种方案均没有单点问题，且都兼容tcp，udp协议。GateWay处的单点问题，通过zk选主、etcd选主，keepalive等 + 浮动IP迁移的方式均能解决。大家可以根据自己的网规网设自由选择\n","tags":["LB"]},{"title":"错误码国际化总结","url":"/2024/03/21/%E9%94%99%E8%AF%AF%E7%A0%81%E5%9B%BD%E9%99%85%E5%8C%96%E6%80%BB%E7%BB%93/","content":"错误信息无模板变量假设我们的错误信息返回如下\nHTTP/1.1 200 OK&#123;&quot;error_code&quot;: &quot;IEEE.754&quot;, &quot;error_msg&quot;: &quot;IEE 754 error&quot;&#125;\n\n无模板变量的错误信息国际化，可以直接在前端对整体字符串根据错误码进行静态国际化。\n// catch the error code firstconst error_code = body.error_codeconst error_msg_map = &#123;    &quot;IEEE.754&quot;: &#123;        &quot;en&quot;: &quot;IEE 754 error&quot;,        &quot;zh&quot;: &quot;IEE 754 错误&quot;    &#125;&#125;const error_msg = error_msg_map[error_code][lang]\n\n错误信息包含模板变量假设我们的错误信息返回如下\nHTTP/1.1 200 OK&#123;&quot;error_code&quot;: &quot;IEEE.754&quot;, &quot;error_msg&quot;: &quot;IEE 754 NbN error, do you mean Nan?&quot;&#125;\n\n包含模板变量的错误信息国际化，可以在前端通过正则表达式提取，并代入到中文字符串模板中实现。如示例代码\n// catch the error code firstconst error_code = body.codeconst error_msg_capture_map = &#123;    &quot;IEEE.754&quot;: &quot;/IEE 754 (\\w+) error, do you mean (\\w+)?/&quot;&#125;;const error_msg_template_map = &#123;    &quot;IEEE.754&quot;: &#123;        &quot;en&quot;: &quot;IEE 754 &#123;&#123;var1&#125;&#125; error, do you mean &#123;&#123;var2&#125;&#125;?&quot;,        &quot;zh&quot;: &quot;IEE 754 &#123;&#123;var1&#125;&#125; 错误，你是指 &#123;&#123;var2&#125;&#125; 吗？&quot;    &#125;&#125;;const matches = error_msg_capture_map[error_code].exec(body.error_msg);const variables = matches.slice(1);let error_msg = error_msg_template_map[error_code][lang];variables.forEach((value, index) =&gt; &#123;    error_msg = error_msg.replace(`&#123;&#123;var$&#123;index + 1&#125;&#125;&#125;`, value);&#125;);\n","tags":["Code"]},{"title":"高可用无单点架构之kubernetes集群","url":"/2021/08/28/%E9%AB%98%E5%8F%AF%E7%94%A8%E6%97%A0%E5%8D%95%E7%82%B9%E6%9E%B6%E6%9E%84%E4%B9%8Bkubernetes%E9%9B%86%E7%BE%A4/","content":"k8s高可用无单点故障涉及那些场景k8s 节点添加、pod添加等增删查改无单点故障需要元数据的存储和处理能力高可用\nk8s对外的apiServer（如worker）无单点故障worker node和其他组件访问apiServer路径高可用\nk8s无单点故障技术关键点元数据存储通过etcd存储元数据，etcd三节点集群保证高可用\n元数据处理通过多个kube-controller和kube-scheduler节点来保证高可用\nworker节点请求数据通过多ip或负载均衡来保证节点请求通信通过多Ip或负载均衡来保证高可用，这里也有几种方式\nIaaS厂商可提供负载均衡的场景下如下图所示，可将worker node的访问地址指向负载均衡的地址\n\n私有化部署KeepAlived私有化部署场景常用keepAlived提供浮动IP来给worker node或其他组件访问，如下图所示\n\n私有化部署加上负载均衡组件如果你觉得同一时刻只有单个apiServer工作会成瓶颈，也可以使用KeepAlived加Nginx或HaProxy来对ApiServer做负载均衡\n\n为了简化图像，只画出了master1上的Nginx向后转发的场景。\n至于Nginx和KeepAlived如何部署，推荐采用容器化的部署模式，方便进行监控和运维；但是镜像不从镜像仓库拉取，而是保存在master节点上，这样虽然升级复杂一点，但是这样子kubernetes的高可用就不依赖镜像仓库了，不会和镜像仓库形成循环依赖，更不会影响镜像仓库的高可用方案，大大简化了后续的技术方案。（因为镜像仓库可能会占据较大的存储空间，可能会和master节点分离部署，这时会作为worker节点连接master节点）。\n","tags":["Kubernetes"]},{"title":"高可用无单点架构之镜像仓库","url":"/2021/08/28/%E9%AB%98%E5%8F%AF%E7%94%A8%E6%97%A0%E5%8D%95%E7%82%B9%E6%9E%B6%E6%9E%84%E4%B9%8B%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93/","content":"本篇文章探讨镜像仓库registry的高可用\n镜像仓库高可用无单点故障涉及那些场景镜像仓库对外提供访问无单点故障镜像仓库对外提供的访问点保持高可用\n镜像仓库的数据存储高可用存储在镜像仓库中的数据都得是高可用的\n镜像仓库无单点故障技术关键点镜像仓库对外提供访问无单点故障和上一篇文章一样，如果IaaS能提供ELB，我们最好是使用ELB，或者使用浮动IP的方式替换\n镜像仓库的数据存储高可用\n配置镜像仓库使用IaaS的S3存储\n配置镜像仓库使用本地存储，通过共享文件路径存储来实现高可用，如Glusterfs等\n配置镜像仓库使用S3存储，自建兼容S3 API的存储Server\n\n通常会使用共享存储来做到镜像仓库存储的高可用\n方案概述那么其实镜像仓库的高可用方案就是对上面方案的组合，下面我们举几个例子\n镜像仓库依赖组件部署方式MinIo、KeepAlived、registry都推荐使用容器部署，方便运维管理，但是镜像推荐内置到虚拟机中，不依赖镜像仓库或其他组件，避免循环依赖\n使用IaaS的S3存储 + 负载均衡组件这是最简单的方案，得益于云厂商提供的S3存储和负载均衡组件，我们可以进行很简单的配置，并部署一台以上的registry,如下图所示\n\n自建兼容S3存储 + KeepAlived浮动Ip我们可以自己搭建MinIo集群来作为兼容S3存储，由于MINIO最低部署4个节点，我们需要根据故障域机器来选择部署MINIO的数目，比如，故障域是三台物理机，我们部署4节点就不妥。原因是，4节点，总会有一台物理机上会部署2个minio节点，如果这台物理机挂掉，就会导致单点故障。所以，如果故障域为三台物理机，我们最好部署6节点，可容忍一台物理机宕机。其他的节点，读者也可以自行测算。\n下图是假设三台物理机，minio6副本场景下的部署示意图\n\n注，为了图的美观，并未画出所有的连线\nMINIO关键配置\n节点数目6个\nEC2\n\n","tags":["Kubernetes"]}]